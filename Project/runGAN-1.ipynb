{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:40px;\"><center>Exercise V:<br> GANs\n",
    "</center></h1>\n",
    "\n",
    "## Short summary\n",
    "In this exercise, we will design a generative network to generate the last rgb image given the first image. These folder has **three files**: \n",
    "- **configGAN.py:** this involves definitions of all parameters and data paths\n",
    "- **utilsGAN.py:** includes utility functions required to grab and visualize data \n",
    "- **runGAN.ipynb:** contains the script to design, train and test the network \n",
    "\n",
    "Make sure that before running this script, you created an environment and **installed all required libraries** such \n",
    "as keras.\n",
    "\n",
    "## The data\n",
    "There exists also a subfolder called **data** which contains the traning, validation, and testing data each has both RGB input images together with the corresponding ground truth images.\n",
    "\n",
    "\n",
    "## The exercises\n",
    "As for the previous lab all exercises are found below.\n",
    "\n",
    "\n",
    "## The different 'Cells'\n",
    "This notebook contains several cells with python code, together with the markdown cells (like this one) with only text. Each of the cells with python code has a \"header\" markdown cell with information about the code. The table below provides a short overview of the code cells. \n",
    "\n",
    "| #  |  CellName | CellType | Comment |\n",
    "| :--- | :-------- | :-------- | :------- |\n",
    "| 1 | Init | Needed | Sets up the environment|\n",
    "| 2 | Ex | Exercise 1| A class definition of a network model  |\n",
    "| 3 | Loading | Needed | Loading parameters and initializing the model |\n",
    "| 4 | Stats | Needed | Show data distribution | \n",
    "| 5 | Data | Needed | Generating the data batches |\n",
    "| 6 | Debug | Needed | Debugging the data |\n",
    "| 7 | Device | Needed | Selecting CPU/GPU |\n",
    "| 8 | Init | Needed | Sets up the timer and other neccessary components |\n",
    "| 9 | Training | Exercise 1-2 | Training the model   |\n",
    "| 10 | Testing | Exercise 1-2| Testing the  method   |  \n",
    "\n",
    "\n",
    "In order for you to start with the exercise you need to run all cells. It is important that you do this in the correct order, starting from the top and continuing with the next cells. Later when you have started to work with the notebook it may be easier to use the command \"Run All\" found in the \"Cell\" dropdown menu.\n",
    "\n",
    "## Writing the report\n",
    "\n",
    "There is no need to provide any report. However, implemented network architecuture and observed experimental results must be presented as a short presentation in the last lecture, May 28."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) We first start with importing all required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating network model using gpu 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from configGAN import *\n",
    "cfg = flying_objects_config()\n",
    "if cfg.GPU >=0:\n",
    "    print(\"creating network model using gpu \" + str(cfg.GPU))\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(cfg.GPU)\n",
    "elif cfg.GPU >=-1:\n",
    "    print(\"creating network model using cpu \")  \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "from tensorflow import keras\n",
    "from utilsGAN import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# import seaborn as sns\n",
    "from datetime import datetime\n",
    "import imageio\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "import pprint\n",
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv3D, Conv2D, Conv1D, Convolution2D, Deconvolution2D, Cropping2D, UpSampling2D\n",
    "from keras.layers import Input, Conv2DTranspose, ConvLSTM2D, TimeDistributed\n",
    "from keras.layers.convolutional import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers import Concatenate, concatenate, Reshape\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from keras.layers import Input, merge\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout, LeakyReLU, Conv2DTranspose\n",
    "import keras.backend as kb\n",
    "\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator.\n",
    "reg_value_g = 0.001 # L2 regularization.\n",
    "momentum_value_g = 0.8 # Batch normalization momentum. \n",
    "relu_alpha_g = 0.2 # # LeakyReLU alpha value.\n",
    "\n",
    "# Discriminator.\n",
    "reg_value_d = 0.001 # L2 regularization.\n",
    "momentum_value_d = 0.8 # Batch normalization momentum.\n",
    "relu_alpha_d = 0.2 # LeakyReLU alpha value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Here, we have the network model class definition. In this class, the most important functions are **build_generator()** and **build_discriminator()**. As defined in the exercises section, your task is to update the both network architectures defined in these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANModel():\n",
    "    def __init__(self, batch_size=32, inputShape=(64, 64, 3), dropout_prob=0.25): \n",
    "        self.batch_size = batch_size\n",
    "        self.inputShape = inputShape\n",
    "        self.dropout_prob = dropout_prob\n",
    "\n",
    "        # Calculate the shape of patches\n",
    "        patch = int(self.inputShape[0] / 2**4)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "  \n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss=['mse', 'mae'], optimizer=Adam(learning_rate=0.0002, beta_1=0.5),metrics=['accuracy'])\n",
    " \n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # Input images and their conditioning images\n",
    "        first_frame = Input(shape=self.inputShape)\n",
    "        last_frame = Input(shape=self.inputShape)\n",
    "\n",
    "        # By conditioning on the first frame generate a fake version of the last frame\n",
    "        fake_last_frame = self.generator(first_frame)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        # Discriminators determines validity of fake and condition first image pairs\n",
    "        valid = self.discriminator([fake_last_frame, first_frame])\n",
    "\n",
    "        self.combined = Model(inputs=[last_frame, first_frame], outputs=[valid, fake_last_frame])\n",
    "        self.combined.compile(loss=['mse', 'mae'], # mean squared and mean absolute errors\n",
    "                              loss_weights=[1, 100],\n",
    "                              optimizer=Adam(learning_rate=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "\n",
    "    def build_generator(self):\n",
    "        inputs = Input(shape=self.inputShape)\n",
    "        # 128 x 128\n",
    "        conv1 = Conv2D(filters=64,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(inputs)\n",
    "        conv1 = BatchNormalization(momentum=momentum_value_g)(conv1)\n",
    "        conv1 = Activation(LeakyReLU(relu_alpha_g))(conv1)\n",
    "        conv1 = Conv2D(filters=64,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv1)\n",
    "        conv1 = BatchNormalization(momentum=momentum_value_g)(conv1)\n",
    "        conv1 = Activation(LeakyReLU(relu_alpha_g))(conv1)\n",
    "        conv1 = Conv2D(filters=64,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv1)\n",
    "        conv1 = BatchNormalization(momentum=momentum_value_g)(conv1)\n",
    "        conv1 = Activation(LeakyReLU(relu_alpha_g))(conv1)\n",
    "        conv1 = Conv2D(filters=64,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv1)\n",
    "        conv1 = BatchNormalization(momentum=momentum_value_g)(conv1)\n",
    "        conv1 = Activation(LeakyReLU(relu_alpha_g))(conv1)\n",
    "        conv1 = Conv2D(filters=64,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv1)\n",
    "        conv1 = BatchNormalization(momentum=momentum_value_g)(conv1)\n",
    "        conv1 = Activation(LeakyReLU(relu_alpha_g))(conv1)\n",
    "        conv1 = Conv2D(filters=64,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv1)\n",
    "        conv1 = BatchNormalization(momentum=momentum_value_g)(conv1)\n",
    "        conv1 = Activation(LeakyReLU(relu_alpha_g))(conv1)\n",
    "        pool1 = Conv2D(filters=64,kernel_size=3, strides=2,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv1)\n",
    "        pool1 = BatchNormalization(momentum=momentum_value_g)(pool1)\n",
    "        pool1 = Activation(LeakyReLU(relu_alpha_g))(pool1)\n",
    "        \n",
    "        # 64 x 64\n",
    "        conv2 = Conv2D(filters=128,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(pool1)\n",
    "        conv2 = BatchNormalization(momentum=momentum_value_g)(conv2)\n",
    "        conv2 = Activation(LeakyReLU(relu_alpha_g))(conv2)\n",
    "        conv2 = Conv2D(filters=128,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv2)\n",
    "        conv2 = BatchNormalization(momentum=momentum_value_g)(conv2)\n",
    "        conv2 = Activation(LeakyReLU(relu_alpha_g))(conv2)\n",
    "        conv2 = Conv2D(filters=128,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv2)\n",
    "        conv2 = BatchNormalization(momentum=momentum_value_g)(conv2)\n",
    "        conv2 = Activation(LeakyReLU(relu_alpha_g))(conv2)\n",
    "        conv2 = Conv2D(filters=128,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv2)\n",
    "        conv2 = BatchNormalization(momentum=momentum_value_g)(conv2)\n",
    "        conv2 = Activation(LeakyReLU(relu_alpha_g))(conv2)\n",
    "        conv2 = Conv2D(filters=128,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv2)\n",
    "        conv2 = BatchNormalization(momentum=momentum_value_g)(conv2)\n",
    "        conv2 = Activation(LeakyReLU(relu_alpha_g))(conv2)\n",
    "        conv2 = Conv2D(filters=128,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv2)\n",
    "        conv2 = BatchNormalization(momentum=momentum_value_g)(conv2)\n",
    "        conv2 = Activation(LeakyReLU(relu_alpha_g))(conv2)\n",
    "        pool2 = Conv2D(filters=128,kernel_size=3, strides=2,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv2)\n",
    "        pool2 = BatchNormalization(momentum=momentum_value_g)(pool2)\n",
    "        pool2 = Activation(LeakyReLU(relu_alpha_g))(pool2)\n",
    "        \n",
    "        # 32 x 32\n",
    "        conv3 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(pool2)\n",
    "        conv3 = BatchNormalization(momentum=momentum_value_g)(conv3)\n",
    "        conv3 = Activation(LeakyReLU(relu_alpha_g))(conv3)\n",
    "        conv3 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv3)\n",
    "        conv3 = BatchNormalization(momentum=momentum_value_g)(conv3)\n",
    "        conv3 = Activation(LeakyReLU(relu_alpha_g))(conv3)\n",
    "        conv3 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv3)\n",
    "        conv3 = BatchNormalization(momentum=momentum_value_g)(conv3)\n",
    "        conv3 = Activation(LeakyReLU(relu_alpha_g))(conv3)\n",
    "        conv3 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv3)\n",
    "        conv3 = BatchNormalization(momentum=momentum_value_g)(conv3)\n",
    "        conv3 = Activation(LeakyReLU(relu_alpha_g))(conv3)\n",
    "        conv3 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv3)\n",
    "        conv3 = BatchNormalization(momentum=momentum_value_g)(conv3)\n",
    "        conv3 = Activation(LeakyReLU(relu_alpha_g))(conv3)\n",
    "        conv3 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv3)\n",
    "        conv3 = BatchNormalization(momentum=momentum_value_g)(conv3)\n",
    "        conv3 = Activation(LeakyReLU(relu_alpha_g))(conv3)\n",
    "        pool3 = Conv2D(filters=256,kernel_size=3, strides=2,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv3)\n",
    "        pool3 = BatchNormalization(momentum=momentum_value_g)(pool3)\n",
    "        pool3 = Activation(LeakyReLU(relu_alpha_g))(pool3)\n",
    "        \n",
    "        # 16 x 16\n",
    "        conv4 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(pool3)\n",
    "        conv4 = BatchNormalization(momentum=momentum_value_g)(conv4)\n",
    "        conv4 = Activation(LeakyReLU(relu_alpha_g))(conv4)\n",
    "        conv4 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv4)\n",
    "        conv4 = BatchNormalization(momentum=momentum_value_g)(conv4)\n",
    "        conv4 = Activation(LeakyReLU(relu_alpha_g))(conv4)\n",
    "        conv4 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv4)\n",
    "        conv4 = BatchNormalization(momentum=momentum_value_g)(conv4)\n",
    "        conv4 = Activation(LeakyReLU(relu_alpha_g))(conv4)\n",
    "        conv4 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv4)\n",
    "        conv4 = BatchNormalization(momentum=momentum_value_g)(conv4)\n",
    "        conv4 = Activation(LeakyReLU(relu_alpha_g))(conv4)\n",
    "        conv4 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv4)\n",
    "        conv4 = BatchNormalization(momentum=momentum_value_g)(conv4)\n",
    "        conv4 = Activation(LeakyReLU(relu_alpha_g))(conv4)\n",
    "        conv4 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv4)\n",
    "        conv4 = BatchNormalization(momentum=momentum_value_g)(conv4)\n",
    "        conv4 = Activation(LeakyReLU(relu_alpha_g))(conv4)\n",
    "        pool4 = Conv2D(filters=256,kernel_size=3, strides=2,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv4)\n",
    "        pool4 = BatchNormalization(momentum=momentum_value_g)(pool4)\n",
    "        pool4 = Activation(LeakyReLU(relu_alpha_g))(pool4)\n",
    "        \n",
    "        # 8 x 8 \n",
    "        conv5 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(pool4)\n",
    "        conv5 = BatchNormalization(momentum=momentum_value_g)(conv5)\n",
    "        conv5 = Activation(LeakyReLU(relu_alpha_g))(conv5)\n",
    "        conv5 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv5)\n",
    "        conv5 = BatchNormalization(momentum=momentum_value_g)(conv5)\n",
    "        conv5 = Activation(LeakyReLU(relu_alpha_g))(conv5)\n",
    "        conv5 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv5)\n",
    "        conv5 = BatchNormalization(momentum=momentum_value_g)(conv5)\n",
    "        conv5 = Activation(LeakyReLU(relu_alpha_g))(conv5)\n",
    "        conv5 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv5)\n",
    "        conv5 = BatchNormalization(momentum=momentum_value_g)(conv5)\n",
    "        conv5 = Activation(LeakyReLU(relu_alpha_g))(conv5)\n",
    "        conv5 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv5)\n",
    "        conv5 = BatchNormalization(momentum=momentum_value_g)(conv5)\n",
    "        conv5 = Activation(LeakyReLU(relu_alpha_g))(conv5)\n",
    "        conv5 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv5)\n",
    "        conv5 = BatchNormalization(momentum=momentum_value_g)(conv5)\n",
    "        conv5 = Activation(LeakyReLU(relu_alpha_g))(conv5)\n",
    "        pool5 = Conv2D(filters=256,kernel_size=3, strides=2,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv5)\n",
    "        pool5 = BatchNormalization(momentum=momentum_value_g)(pool5)\n",
    "        pool5 = Activation(LeakyReLU(relu_alpha_g))(pool5)\n",
    "        \n",
    "        # 4 x 4\n",
    "        conv6 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(pool5)\n",
    "        conv6 = BatchNormalization(momentum=momentum_value_g)(conv6)\n",
    "        conv6 = Activation(LeakyReLU(relu_alpha_g))(conv6)\n",
    "        conv6 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv6)\n",
    "        conv6 = BatchNormalization(momentum=momentum_value_g)(conv6)\n",
    "        conv6 = Activation(LeakyReLU(relu_alpha_g))(conv6)\n",
    "        conv6 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv6)\n",
    "        conv6 = BatchNormalization(momentum=momentum_value_g)(conv6)\n",
    "        conv6 = Activation(LeakyReLU(relu_alpha_g))(conv6)\n",
    "        conv6 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv6)\n",
    "        conv6 = BatchNormalization(momentum=momentum_value_g)(conv6)\n",
    "        conv6 = Activation(LeakyReLU(relu_alpha_g))(conv6)\n",
    "        conv6 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv6)\n",
    "        conv6 = BatchNormalization(momentum=momentum_value_g)(conv6)\n",
    "        conv6 = Activation(LeakyReLU(relu_alpha_g))(conv6)\n",
    "        conv6 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv6)\n",
    "        conv6 = BatchNormalization(momentum=momentum_value_g)(conv6)\n",
    "        conv6 = Activation(LeakyReLU(relu_alpha_g))(conv6)\n",
    "        pool6 = Conv2D(filters=256,kernel_size=3, strides=2,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv6)\n",
    "        pool6 = BatchNormalization(momentum=momentum_value_g)(pool6)\n",
    "        pool6 = Activation(LeakyReLU(relu_alpha_g))(pool6)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 2 x 2\n",
    "        conv17 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(pool6)\n",
    "        conv17 = BatchNormalization(momentum=momentum_value_g)(conv17)\n",
    "        conv17 = Activation(LeakyReLU(relu_alpha_g))(conv17)\n",
    "        conv17 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv17)\n",
    "        conv17 = BatchNormalization(momentum=momentum_value_g)(conv17)\n",
    "        conv17 = Activation(LeakyReLU(relu_alpha_g))(conv17)\n",
    "        conv17 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv17)\n",
    "        conv17 = BatchNormalization(momentum=momentum_value_g)(conv17)\n",
    "        conv17 = Activation(LeakyReLU(relu_alpha_g))(conv17)\n",
    "        conv17 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv17)\n",
    "        conv17 = BatchNormalization(momentum=momentum_value_g)(conv17)\n",
    "        conv17 = Activation(LeakyReLU(relu_alpha_g))(conv17)\n",
    "        conv17 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv17)\n",
    "        conv17 = BatchNormalization(momentum=momentum_value_g)(conv17)\n",
    "        conv17 = Activation(LeakyReLU(relu_alpha_g))(conv17)\n",
    "        conv17 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv17)\n",
    "        conv17 = BatchNormalization(momentum=momentum_value_g)(conv17)\n",
    "        conv17 = Activation(LeakyReLU(relu_alpha_g))(conv17)\n",
    "        pool17 = Conv2D(filters=256,kernel_size=3, strides=2,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv17)\n",
    "        pool17 = BatchNormalization(momentum=momentum_value_g)(pool17)\n",
    "        pool17 = Activation(LeakyReLU(relu_alpha_g))(pool17)\n",
    "        \n",
    "        # 1 x 1\n",
    "        conv18 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(pool17)\n",
    "        conv18 = BatchNormalization(momentum=momentum_value_g)(conv18)\n",
    "        conv18 = Activation(LeakyReLU(relu_alpha_g))(conv18)\n",
    "        conv18 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv18)\n",
    "        conv18 = BatchNormalization(momentum=momentum_value_g)(conv18)\n",
    "        conv18 = Activation(LeakyReLU(relu_alpha_g))(conv18)\n",
    "        conv18 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv18)\n",
    "        conv18 = BatchNormalization(momentum=momentum_value_g)(conv18)\n",
    "        conv18 = Activation(LeakyReLU(relu_alpha_g))(conv18)\n",
    "        conv18 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv18)\n",
    "        conv18 = BatchNormalization(momentum=momentum_value_g)(conv18)\n",
    "        conv18 = Activation(LeakyReLU(relu_alpha_g))(conv18)\n",
    "        conv18 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv18)\n",
    "        conv18 = BatchNormalization(momentum=momentum_value_g)(conv18)\n",
    "        conv18 = Activation(LeakyReLU(relu_alpha_g))(conv18)\n",
    "        conv18 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv18)\n",
    "        conv18 = BatchNormalization(momentum=momentum_value_g)(conv18)\n",
    "        conv18 = Activation(LeakyReLU(relu_alpha_g))(conv18)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 2 x 2\n",
    "        up19 = Conv2DTranspose(filters=256,kernel_size=3,strides=2,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv18)\n",
    "        up19 = Concatenate(axis=3)([conv17, up19])\n",
    "        conv19 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(up19)\n",
    "        conv19 = BatchNormalization(momentum=momentum_value_g)(conv19)\n",
    "        conv19 = Activation(LeakyReLU(relu_alpha_g))(conv19)\n",
    "        conv19 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv19)\n",
    "        conv19 = BatchNormalization(momentum=momentum_value_g)(conv19)\n",
    "        conv19 = Activation(LeakyReLU(relu_alpha_g))(conv19)\n",
    "        conv19 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv19)\n",
    "        conv19 = BatchNormalization(momentum=momentum_value_g)(conv19)\n",
    "        conv19 = Activation(LeakyReLU(relu_alpha_g))(conv19)\n",
    "        conv19 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv19)\n",
    "        conv19 = BatchNormalization(momentum=momentum_value_g)(conv19)\n",
    "        conv19 = Activation(LeakyReLU(relu_alpha_g))(conv19)\n",
    "        conv19 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv19)\n",
    "        conv19 = BatchNormalization(momentum=momentum_value_g)(conv19)\n",
    "        conv19 = Activation(LeakyReLU(relu_alpha_g))(conv19)\n",
    "        conv19 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv19)\n",
    "        conv19 = BatchNormalization(momentum=momentum_value_g)(conv19)\n",
    "        conv19 = Activation(LeakyReLU(relu_alpha_g))(conv19)\n",
    "        \n",
    "        \n",
    "        # 4 x 4\n",
    "        up20 = Conv2DTranspose(filters=256,kernel_size=3,strides=2,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv19)\n",
    "        up20 = Concatenate(axis=3)([conv6, up20])\n",
    "        conv20 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(up20)\n",
    "        conv20 = BatchNormalization(momentum=momentum_value_g)(conv20)\n",
    "        conv20 = Activation(LeakyReLU(relu_alpha_g))(conv20)\n",
    "        conv20 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv20)\n",
    "        conv20 = BatchNormalization(momentum=momentum_value_g)(conv20)\n",
    "        conv20 = Activation(LeakyReLU(relu_alpha_g))(conv20)\n",
    "        conv20 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv20)\n",
    "        conv20 = BatchNormalization(momentum=momentum_value_g)(conv20)\n",
    "        conv20 = Activation(LeakyReLU(relu_alpha_g))(conv20)\n",
    "        conv20 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv20)\n",
    "        conv20 = BatchNormalization(momentum=momentum_value_g)(conv20)\n",
    "        conv20 = Activation(LeakyReLU(relu_alpha_g))(conv20)\n",
    "        conv20 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv20)\n",
    "        conv20 = BatchNormalization(momentum=momentum_value_g)(conv20)\n",
    "        conv20 = Activation(LeakyReLU(relu_alpha_g))(conv20)\n",
    "        conv20 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv20)\n",
    "        conv20 = BatchNormalization(momentum=momentum_value_g)(conv20)\n",
    "        conv20 = Activation(LeakyReLU(relu_alpha_g))(conv20)\n",
    "        \n",
    "        \n",
    "        # 8 x 8\n",
    "        up7 = Conv2DTranspose(filters=256,kernel_size=3,strides=2,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv20)\n",
    "        up7 = Concatenate(axis=3)([conv5, up7])\n",
    "        conv7 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(up7)\n",
    "        conv7 = BatchNormalization(momentum=momentum_value_g)(conv7)\n",
    "        conv7 = Activation(LeakyReLU(relu_alpha_g))(conv7)\n",
    "        conv7 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv7)\n",
    "        conv7 = BatchNormalization(momentum=momentum_value_g)(conv7)\n",
    "        conv7 = Activation(LeakyReLU(relu_alpha_g))(conv7)\n",
    "        conv7 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv7)\n",
    "        conv7 = BatchNormalization(momentum=momentum_value_g)(conv7)\n",
    "        conv7 = Activation(LeakyReLU(relu_alpha_g))(conv7)\n",
    "        conv7 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv7)\n",
    "        conv7 = BatchNormalization(momentum=momentum_value_g)(conv7)\n",
    "        conv7 = Activation(LeakyReLU(relu_alpha_g))(conv7)\n",
    "        conv7 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv7)\n",
    "        conv7 = BatchNormalization(momentum=momentum_value_g)(conv7)\n",
    "        conv7 = Activation(LeakyReLU(relu_alpha_g))(conv7)\n",
    "        conv7 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv7)\n",
    "        conv7 = BatchNormalization(momentum=momentum_value_g)(conv7)\n",
    "        conv7 = Activation(LeakyReLU(relu_alpha_g))(conv7)\n",
    "        # Until here.\n",
    "        \n",
    "\n",
    "        # 16 x 16\n",
    "        up8 = Conv2DTranspose(filters=256,kernel_size=3,strides=2,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv7)\n",
    "        up8 = Concatenate(axis=3)([conv4, up8])\n",
    "        conv8 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(up8)\n",
    "        conv8 = BatchNormalization(momentum=momentum_value_g)(conv8)\n",
    "        conv8 = Activation(LeakyReLU(relu_alpha_g))(conv8)\n",
    "        conv8 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv8)\n",
    "        conv8 = BatchNormalization(momentum=momentum_value_g)(conv8)\n",
    "        conv8 = Activation(LeakyReLU(relu_alpha_g))(conv8)\n",
    "        conv8 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv8)\n",
    "        conv8 = BatchNormalization(momentum=momentum_value_g)(conv8)\n",
    "        conv8 = Activation(LeakyReLU(relu_alpha_g))(conv8)\n",
    "        conv8 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv8)\n",
    "        conv8 = BatchNormalization(momentum=momentum_value_g)(conv8)\n",
    "        conv8 = Activation(LeakyReLU(relu_alpha_g))(conv8)\n",
    "        conv8 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv8)\n",
    "        conv8 = BatchNormalization(momentum=momentum_value_g)(conv8)\n",
    "        conv8 = Activation(LeakyReLU(relu_alpha_g))(conv8)\n",
    "        conv8 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv8)\n",
    "        conv8 = BatchNormalization(momentum=momentum_value_g)(conv8)\n",
    "        conv8 = Activation(LeakyReLU(relu_alpha_g))(conv8)\n",
    "        \n",
    "\n",
    "        # 32 x 32\n",
    "        up9 = Conv2DTranspose(filters=256,kernel_size=3,strides=2,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv8)\n",
    "        up9 = Concatenate(axis=3)([conv3, up9])\n",
    "        conv9 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(up9)\n",
    "        conv9 = BatchNormalization(momentum=momentum_value_g)(conv9)\n",
    "        conv9 = Activation(LeakyReLU(relu_alpha_g))(conv9)\n",
    "        conv9 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv9)\n",
    "        conv9 = BatchNormalization(momentum=momentum_value_g)(conv9)\n",
    "        conv9 = Activation(LeakyReLU(relu_alpha_g))(conv9)\n",
    "        conv9 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv9)\n",
    "        conv9 = BatchNormalization(momentum=momentum_value_g)(conv9)\n",
    "        conv9 = Activation(LeakyReLU(relu_alpha_g))(conv9)\n",
    "        conv9 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv9)\n",
    "        conv9 = BatchNormalization(momentum=momentum_value_g)(conv9)\n",
    "        conv9 = Activation(LeakyReLU(relu_alpha_g))(conv9)\n",
    "        conv9 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv9)\n",
    "        conv9 = BatchNormalization(momentum=momentum_value_g)(conv9)\n",
    "        conv9 = Activation(LeakyReLU(relu_alpha_g))(conv9)\n",
    "        conv9 = Conv2D(filters=256,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv9)\n",
    "        conv9 = BatchNormalization(momentum=momentum_value_g)(conv9)\n",
    "        conv9 = Activation(LeakyReLU(relu_alpha_g))(conv9)\n",
    "        \n",
    "\n",
    "        # 64 x 64\n",
    "        up10 = Conv2DTranspose(filters=128,kernel_size=3,strides=2,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv9)\n",
    "        up10 = Concatenate(axis=3)([conv2, up10])\n",
    "        conv10 = Conv2D(filters=128,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(up10)\n",
    "        conv10 = BatchNormalization(momentum=momentum_value_g)(conv10)\n",
    "        conv10 = Activation(LeakyReLU(relu_alpha_g))(conv10)\n",
    "        conv10 = Conv2D(filters=128,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv10)\n",
    "        conv10 = BatchNormalization(momentum=momentum_value_g)(conv10)\n",
    "        conv10 = Activation(LeakyReLU(relu_alpha_g))(conv10)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 128 x 128\n",
    "        up11 = Conv2DTranspose(filters=64,kernel_size=3,strides=2,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv10)\n",
    "        up11 = Concatenate(axis=3)([conv1, up11])\n",
    "        conv11 = Conv2D(filters=64,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(up11)\n",
    "        conv11 = BatchNormalization(momentum=momentum_value_g)(conv11)\n",
    "        conv11 = Activation(LeakyReLU(relu_alpha_g))(conv11)\n",
    "        conv11 = Conv2D(filters=64,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv11)\n",
    "        conv11 = BatchNormalization(momentum=momentum_value_g)(conv11)\n",
    "        conv11 = Activation(LeakyReLU(relu_alpha_g))(conv11)\n",
    "        conv11 = Conv2D(filters=64,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv11)\n",
    "        conv11 = BatchNormalization(momentum=momentum_value_g)(conv11)\n",
    "        conv11 = Activation(LeakyReLU(relu_alpha_g))(conv11)\n",
    "        conv11 = Conv2D(filters=64,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv11)\n",
    "        conv11 = BatchNormalization(momentum=momentum_value_g)(conv11)\n",
    "        conv11 = Activation(LeakyReLU(relu_alpha_g))(conv11)\n",
    "        conv11 = Conv2D(filters=64,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv11)\n",
    "        conv11 = BatchNormalization(momentum=momentum_value_g)(conv11)\n",
    "        conv11 = Activation(LeakyReLU(relu_alpha_g))(conv11)\n",
    "        conv11 = Conv2D(filters=64,kernel_size=3,padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_g))(conv11)\n",
    "        conv11 = BatchNormalization(momentum=momentum_value_g)(conv11)\n",
    "        conv11 = Activation(LeakyReLU(relu_alpha_g))(conv11)\n",
    "        \n",
    "        \n",
    "        nbr_img_channels = self.inputShape[2]\n",
    "\n",
    "        outputs = Conv2D(nbr_img_channels, (1, 1), activation='sigmoid')(conv11)\n",
    "\n",
    "        model = Model(inputs=inputs, outputs=outputs, name='Generator')\n",
    "        model.summary()\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def build_discriminator(self):\n",
    "  \n",
    "        last_img = Input(shape=self.inputShape)\n",
    "        first_img = Input(shape=self.inputShape)\n",
    "\n",
    "        # Concatenate image and conditioning image by channels to produce input\n",
    "        combined_imgs = Concatenate(axis=-1)([last_img, first_img])\n",
    "        \n",
    "        # 128 x 128 - > 64 x 64\n",
    "        d1 = Conv2D(32, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_d))(combined_imgs) \n",
    "        d1 = BatchNormalization(momentum=momentum_value_d)(d1)\n",
    "        d1 = Activation(LeakyReLU(relu_alpha_d))(d1)\n",
    "        d1 = Conv2D(128, kernel_size=3, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_d))(d1)\n",
    "        d1 = BatchNormalization(momentum=momentum_value_d)(d1)\n",
    "        d1 = Activation(LeakyReLU(relu_alpha_d))(d1)\n",
    "        \n",
    "        # 64 x 64 - > 32 x 32\n",
    "        d2 = Conv2D(32, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_d))(d1)\n",
    "        d2 = BatchNormalization(momentum=momentum_value_d)(d2)\n",
    "        d2 = Activation(LeakyReLU(relu_alpha_d))(d2)\n",
    "        d2 = Conv2D(128, kernel_size=4, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_d))(d2)\n",
    "        d2 = BatchNormalization(momentum=momentum_value_d)(d2)\n",
    "        d2 = Activation(LeakyReLU(relu_alpha_d))(d2)\n",
    "        \n",
    "        # 32 x 32 - > 16 x 16\n",
    "        d3 = Conv2D(64, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_d))(d2)\n",
    "        d3 = BatchNormalization(momentum=momentum_value_d)(d3)\n",
    "        d3 = Activation(LeakyReLU(relu_alpha_d))(d3)\n",
    "        d3 = Conv2D(256, kernel_size=4, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_d))(d3)\n",
    "        d3 = BatchNormalization(momentum=momentum_value_d)(d3)\n",
    "        d3 = Activation(LeakyReLU(relu_alpha_d))(d3)\n",
    "        \n",
    "        # 16 x 16 - > 8 x 8\n",
    "        d4 = Conv2D(64, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_d))(d3)\n",
    "        d4 = BatchNormalization(momentum=momentum_value_d)(d4)\n",
    "        d4 = Activation(LeakyReLU(relu_alpha_d))(d4)\n",
    "        d4 = Conv2D(512, kernel_size=4, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_d))(d4)\n",
    "        d4 = BatchNormalization(momentum=momentum_value_d)(d4)\n",
    "        d4 = Activation(LeakyReLU(relu_alpha_d))(d4)\n",
    "        \n",
    "        # 8 x 8 - > 4 x 4\n",
    "        d5 = Conv2D(64, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_d))(d4)\n",
    "        d5 = BatchNormalization(momentum=momentum_value_d)(d5)\n",
    "        d5 = Activation(LeakyReLU(relu_alpha_d))(d5)\n",
    "        d5 = Conv2D(128, kernel_size=4, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_d))(d5)\n",
    "        d5 = BatchNormalization(momentum=momentum_value_d)(d5)\n",
    "        d5 = Activation(LeakyReLU(relu_alpha_d))(d5)\n",
    "        \n",
    "        # 4 x 4 - > 2 x 2\n",
    "        d6 = Conv2D(32, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_d))(d5)\n",
    "        d6 = BatchNormalization(momentum=momentum_value_d)(d6)\n",
    "        d6 = Activation(LeakyReLU(relu_alpha_d))(d6)\n",
    "        d6 = Conv2D(64, kernel_size=2, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(reg_value_d))(d6)\n",
    "        d6 = BatchNormalization(momentum=momentum_value_d)(d6)\n",
    "        d6 = Activation(LeakyReLU(relu_alpha_d))(d6)\n",
    "         \n",
    "        # 2 x 2 - > 1 x 1\n",
    "        validity = Conv2D(1, (3, 3), strides=2, padding='same')(d6)\n",
    "\n",
    "        model = Model([last_img, first_img], validity, name='Discriminator')\n",
    "        model.summary()\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) We import the network **hyperparameters** and build a simple network by calling the class introduced in the previous step. Please note that to change the hyperparameters, you just need to change the values in the file called **configPredictor.py.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Discriminator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128, 128, 6)  0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 32)   3104        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 32)   128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 128)  36992       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 128)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 32)   65568       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 128)  65664       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 64)   131136      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 256)  262400      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 256)  1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 256)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 8, 64)     262208      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 8, 64)     256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 8, 8, 64)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 8, 512)    524800      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8, 8, 512)    2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 8, 8, 512)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 4, 64)     524352      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 4, 64)     256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 4, 4, 64)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 4, 4, 128)    131200      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4, 4, 128)    512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 4, 4, 128)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 2, 2, 32)     65568       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 2, 2, 32)     128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 2, 2, 32)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 2, 2, 64)     8256        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 2, 2, 64)     256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 2, 2, 64)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 1, 1, 1)      577         activation_11[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,087,841\n",
      "Trainable params: 2,084,833\n",
      "Non-trainable params: 3,008\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"Generator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 128, 128, 64) 1792        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 128, 128, 64) 256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 128, 128, 64) 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 64) 36928       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128, 128, 64) 256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 128, 128, 64) 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 64) 36928       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 128, 128, 64) 256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 128, 128, 64) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 64) 36928       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128, 128, 64) 256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 128, 128, 64) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 64) 36928       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128, 128, 64) 256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 128, 128, 64) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 64) 36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 128, 128, 64) 256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 128, 128, 64) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 64)   36928       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 64, 64, 64)   256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 64, 64, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 128)  73856       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 64, 64, 128)  512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 64, 64, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 64, 128)  147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 64, 64, 128)  512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 64, 64, 128)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 64, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 64, 64, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 64, 64, 128)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 64, 128)  147584      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 64, 64, 128)  512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 64, 64, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 64, 64, 128)  147584      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 64, 64, 128)  512         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 64, 64, 128)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 64, 64, 128)  147584      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 64, 64, 128)  512         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 64, 64, 128)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 128)  147584      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 32, 128)  512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 32, 32, 128)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 256)  295168      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 256)  1024        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 32, 32, 256)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 256)  1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 32, 32, 256)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 32, 32, 256)  590080      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 32, 32, 256)  1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 32, 32, 256)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 32, 32, 256)  590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 32, 32, 256)  1024        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 32, 32, 256)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 32, 32, 256)  1024        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 32, 32, 256)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 256)  590080      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 32, 32, 256)  1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 32, 32, 256)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 256)  590080      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 16, 256)  1024        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 256)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 16, 256)  1024        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 256)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 256)  590080      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 256)  1024        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 256)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 256)  590080      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 256)  1024        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 256)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 256)  1024        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 256)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 256)  590080      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 256)  1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 256)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 256)  590080      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 256)  1024        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 256)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 8, 8, 256)    590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 8, 8, 256)    1024        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 8, 8, 256)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 8, 8, 256)    590080      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 8, 8, 256)    1024        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 8, 8, 256)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 8, 8, 256)    590080      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 8, 8, 256)    1024        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 8, 8, 256)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 8, 8, 256)    590080      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 8, 8, 256)    1024        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 8, 8, 256)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 8, 8, 256)    590080      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 8, 8, 256)    1024        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 8, 8, 256)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 8, 8, 256)    590080      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 8, 256)    1024        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 8, 8, 256)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 8, 8, 256)    590080      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 8, 256)    1024        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 8, 8, 256)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 4, 4, 256)    590080      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 4, 4, 256)    1024        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 4, 4, 256)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 4, 4, 256)    590080      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 4, 4, 256)    1024        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 4, 4, 256)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 4, 4, 256)    590080      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 4, 4, 256)    1024        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 4, 4, 256)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 4, 4, 256)    590080      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 4, 4, 256)    1024        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 4, 4, 256)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 4, 4, 256)    590080      activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 4, 4, 256)    1024        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 4, 4, 256)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 4, 4, 256)    590080      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 4, 4, 256)    1024        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 4, 4, 256)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 4, 4, 256)    590080      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 4, 4, 256)    1024        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 4, 4, 256)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 2, 2, 256)    590080      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 2, 2, 256)    1024        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 2, 2, 256)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 2, 2, 256)    590080      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 2, 2, 256)    1024        conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 2, 2, 256)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 2, 2, 256)    590080      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 2, 2, 256)    1024        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 2, 2, 256)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 2, 2, 256)    590080      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 2, 2, 256)    1024        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 2, 2, 256)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 2, 2, 256)    590080      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 2, 2, 256)    1024        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 2, 2, 256)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 2, 2, 256)    590080      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 2, 2, 256)    1024        conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 2, 2, 256)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 2, 2, 256)    590080      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 2, 2, 256)    1024        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 2, 2, 256)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 1, 1, 256)    590080      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 1, 1, 256)    1024        conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 1, 1, 256)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 1, 1, 256)    590080      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 1, 1, 256)    1024        conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 1, 1, 256)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 1, 1, 256)    590080      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 1, 1, 256)    1024        conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 1, 1, 256)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 1, 1, 256)    590080      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 1, 1, 256)    1024        conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 1, 1, 256)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 1, 1, 256)    590080      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 1, 1, 256)    1024        conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 1, 1, 256)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 1, 1, 256)    590080      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 1, 1, 256)    1024        conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 1, 1, 256)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 1, 1, 256)    590080      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 1, 1, 256)    1024        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 1, 1, 256)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 2, 2, 256)    590080      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2, 2, 512)    0           activation_59[0][0]              \n",
      "                                                                 conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 2, 2, 256)    1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 2, 2, 256)    1024        conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 2, 2, 256)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 2, 2, 256)    590080      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 2, 2, 256)    1024        conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 2, 2, 256)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 2, 2, 256)    590080      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 2, 2, 256)    1024        conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 2, 2, 256)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 2, 2, 256)    590080      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 2, 2, 256)    1024        conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 2, 2, 256)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 2, 2, 256)    590080      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 2, 2, 256)    1024        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 2, 2, 256)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 2, 2, 256)    590080      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 2, 2, 256)    1024        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 2, 2, 256)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 4, 4, 256)    590080      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4, 4, 512)    0           activation_52[0][0]              \n",
      "                                                                 conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 4, 4, 256)    1179904     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 4, 4, 256)    1024        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 4, 4, 256)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 4, 4, 256)    590080      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 4, 4, 256)    1024        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 4, 4, 256)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 4, 4, 256)    590080      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 4, 4, 256)    1024        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 4, 4, 256)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 4, 4, 256)    590080      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 4, 4, 256)    1024        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 4, 4, 256)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 4, 4, 256)    590080      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 4, 4, 256)    1024        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 4, 4, 256)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 4, 4, 256)    590080      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 4, 4, 256)    1024        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 4, 4, 256)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 8, 8, 256)    590080      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8, 8, 512)    0           activation_45[0][0]              \n",
      "                                                                 conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 256)    1179904     concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 256)    1024        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 256)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 256)    590080      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 256)    1024        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 256)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 256)    590080      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 256)    1024        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 256)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 256)    590080      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 256)    1024        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 256)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 256)    590080      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 256)    1024        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 256)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 256)    590080      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 256)    1024        conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 256)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 16, 16, 256)  590080      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 16, 16, 512)  0           activation_38[0][0]              \n",
      "                                                                 conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 16, 16, 256)  1179904     concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 16, 16, 256)  1024        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 16, 16, 256)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 16, 16, 256)  590080      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 16, 16, 256)  1024        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 16, 16, 256)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 16, 16, 256)  590080      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 16, 16, 256)  1024        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 16, 16, 256)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 16, 16, 256)  590080      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 16, 16, 256)  1024        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 16, 16, 256)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 16, 16, 256)  590080      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 16, 16, 256)  1024        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 16, 16, 256)  0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 16, 16, 256)  590080      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 16, 16, 256)  1024        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 16, 16, 256)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 32, 32, 256)  590080      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 512)  0           activation_31[0][0]              \n",
      "                                                                 conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 32, 32, 256)  1179904     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 32, 32, 256)  1024        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 32, 32, 256)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 32, 32, 256)  590080      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 32, 32, 256)  1024        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 32, 32, 256)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 32, 32, 256)  590080      activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 32, 32, 256)  1024        conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 32, 32, 256)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 32, 32, 256)  590080      activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 32, 32, 256)  1024        conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 32, 32, 256)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 32, 32, 256)  590080      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 32, 32, 256)  1024        conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 32, 32, 256)  0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 32, 32, 256)  590080      activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 32, 32, 256)  1024        conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 32, 32, 256)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 64, 64, 128)  295040      activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 64, 64, 256)  0           activation_24[0][0]              \n",
      "                                                                 conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 64, 64, 128)  295040      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 64, 64, 128)  512         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 64, 64, 128)  0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 64, 64, 128)  147584      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 64, 64, 128)  512         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 64, 64, 128)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 128, 128, 64) 73792       activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 128, 128, 128 0           activation_17[0][0]              \n",
      "                                                                 conv2d_transpose_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 128, 128, 64) 73792       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 128, 128, 64) 256         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 128, 128, 64) 0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 128, 128, 64) 36928       activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 128, 128, 64) 256         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 128, 128, 64) 0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 128, 128, 64) 36928       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 128, 128, 64) 256         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 128, 128, 64) 0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 128, 128, 64) 36928       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 128, 128, 64) 256         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 128, 128, 64) 0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 128, 128, 64) 36928       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 128, 128, 64) 256         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 128, 128, 64) 0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 128, 128, 64) 36928       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 128, 128, 64) 256         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 128, 128, 64) 0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 128, 128, 3)  195         activation_104[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 49,833,731\n",
      "Trainable params: 49,793,411\n",
      "Non-trainable params: 40,320\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_shape = (cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH, cfg.IMAGE_CHANNEL)\n",
    "modelObj = GANModel(batch_size=cfg.BATCH_SIZE, inputShape=image_shape,\n",
    "                                 dropout_prob=cfg.DROPOUT_PROB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) We call the utility function **show_statistics** to display the data distribution. This is just for debugging purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "##################### Training Data Statistics #####################\n",
      "######################################################################\n",
      "total image number \t 10817\n",
      "total class number \t 3\n",
      "class circular \t 3626 images\n",
      "class square \t 3488 images\n",
      "class triangle \t 3703 images\n",
      "######################################################################\n",
      "\n",
      "######################################################################\n",
      "##################### Validation Data Statistics #####################\n",
      "######################################################################\n",
      "total image number \t 2241\n",
      "total class number \t 3\n",
      "class triangle \t 745 images\n",
      "class circular \t 713 images\n",
      "class square \t 783 images\n",
      "######################################################################\n",
      "\n",
      "######################################################################\n",
      "##################### Testing Data Statistics #####################\n",
      "######################################################################\n",
      "total image number \t 2220\n",
      "total class number \t 3\n",
      "class triangle \t 733 images\n",
      "class circular \t 722 images\n",
      "class square \t 765 images\n",
      "######################################################################\n"
     ]
    }
   ],
   "source": [
    "#### show how the data looks like\n",
    "show_statistics(cfg.training_data_dir, fineGrained=False, title=\" Training Data Statistics \")\n",
    "show_statistics(cfg.validation_data_dir, fineGrained=False, title=\" Validation Data Statistics \")\n",
    "show_statistics(cfg.testing_data_dir, fineGrained=False, title=\" Testing Data Statistics \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) We now create batch generators to get small batches from the entire dataset. There is no need to change these functions as they already return **normalized inputs as batches**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch generators are created!\n"
     ]
    }
   ],
   "source": [
    "nbr_train_data = get_dataset_size(cfg.training_data_dir)\n",
    "nbr_valid_data = get_dataset_size(cfg.validation_data_dir)\n",
    "nbr_test_data = get_dataset_size(cfg.testing_data_dir)\n",
    "train_batch_generator = generate_lastframepredictor_batches(cfg.training_data_dir, image_shape, cfg.BATCH_SIZE)\n",
    "valid_batch_generator = generate_lastframepredictor_batches(cfg.validation_data_dir, image_shape, cfg.BATCH_SIZE)\n",
    "test_batch_generator = generate_lastframepredictor_batches(cfg.testing_data_dir, image_shape, cfg.BATCH_SIZE)\n",
    "print(\"Data batch generators are created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) We can visualize how the data looks like for debugging purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x (10, 128, 128, 3) float32 0.0 1.0\n",
      "train_y (10, 128, 128, 3) float32 0.0 1.0\n",
      "{'BATCH_SIZE': 10,\n",
      " 'DATA_AUGMENTATION': True,\n",
      " 'DEBUG_MODE': True,\n",
      " 'DROPOUT_PROB': 0,\n",
      " 'GPU': 0,\n",
      " 'IMAGE_CHANNEL': 3,\n",
      " 'IMAGE_HEIGHT': 128,\n",
      " 'IMAGE_WIDTH': 128,\n",
      " 'LEARNING_RATE': 0.9,\n",
      " 'LR_DECAY_FACTOR': 0.8,\n",
      " 'NUM_EPOCHS': 10,\n",
      " 'PRINT_EVERY': 20,\n",
      " 'SAVE_EVERY': 1,\n",
      " 'SEQUENCE_LENGTH': 10,\n",
      " 'testing_data_dir': '../data/FlyingObjectDataset_10K/testing',\n",
      " 'training_data_dir': '../data/FlyingObjectDataset_10K/training',\n",
      " 'validation_data_dir': '../data/FlyingObjectDataset_10K/validation'}\n"
     ]
    }
   ],
   "source": [
    "if cfg.DEBUG_MODE:\n",
    "    t_x, t_y = next(train_batch_generator)\n",
    "    print('train_x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\n",
    "    print('train_y', t_y.shape, t_y.dtype, t_y.min(), t_y.max()) \n",
    "    #plot_sample_lastframepredictor_data_with_groundtruth(t_x, t_y, t_y)\n",
    "    pprint.pprint (cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Start timer and init matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "# Adversarial loss ground truths\n",
    "valid = np.ones((cfg.BATCH_SIZE,) + modelObj.disc_patch)\n",
    "fake = np.zeros((cfg.BATCH_SIZE,) + modelObj.disc_patch)\n",
    "# log file\n",
    "output_log_dir = \"./logs/{}\".format(datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "if not os.path.exists(output_log_dir):\n",
    "    os.makedirs(output_log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) We can now feed the training and validation data to the network. This will train the network for **some epochs**. Note that the epoch number is also predefined in the file called **configGAN.py.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ TRAINING OF EPOCH 0 ############\n",
      "(10, 128, 128, 3)\n",
      "0.3161238\n",
      "[Epoch 0/10] [Batch 0/1081] [D loss: 4.692429] [D acc: 0.25 (0.00 real, 0.50 fake)] [G loss: 94.597290] time: 0:00:16.487552\n",
      "(10, 128, 128, 3)\n",
      "0.24228708\n",
      "[Epoch 0/10] [Batch 1/1081] [D loss: 3.553585] [D acc: 0.40 (0.50 real, 0.30 fake)] [G loss: 91.104630] time: 0:00:16.875373\n",
      "(10, 128, 128, 3)\n",
      "0.22586243\n",
      "[Epoch 0/10] [Batch 2/1081] [D loss: 3.715031] [D acc: 0.50 (0.40 real, 0.60 fake)] [G loss: 88.831390] time: 0:00:17.267733\n",
      "(10, 128, 128, 3)\n",
      "0.26212573\n",
      "[Epoch 0/10] [Batch 3/1081] [D loss: 3.355564] [D acc: 0.75 (0.80 real, 0.70 fake)] [G loss: 86.321472] time: 0:00:17.671898\n",
      "(10, 128, 128, 3)\n",
      "0.33264658\n",
      "[Epoch 0/10] [Batch 4/1081] [D loss: 3.500930] [D acc: 0.60 (0.60 real, 0.60 fake)] [G loss: 84.772057] time: 0:00:18.076079\n",
      "(10, 128, 128, 3)\n",
      "0.4303964\n",
      "[Epoch 0/10] [Batch 5/1081] [D loss: 3.358809] [D acc: 0.75 (0.80 real, 0.70 fake)] [G loss: 82.744743] time: 0:00:18.467399\n",
      "(10, 128, 128, 3)\n",
      "0.50219053\n",
      "[Epoch 0/10] [Batch 6/1081] [D loss: 3.624133] [D acc: 0.35 (0.40 real, 0.30 fake)] [G loss: 81.726395] time: 0:00:18.879874\n",
      "(10, 128, 128, 3)\n",
      "0.5278773\n",
      "[Epoch 0/10] [Batch 7/1081] [D loss: 3.413713] [D acc: 0.50 (0.50 real, 0.50 fake)] [G loss: 81.129807] time: 0:00:19.278684\n",
      "(10, 128, 128, 3)\n",
      "0.51023173\n",
      "[Epoch 0/10] [Batch 8/1081] [D loss: 3.723895] [D acc: 0.15 (0.20 real, 0.10 fake)] [G loss: 79.740097] time: 0:00:19.656556\n",
      "(10, 128, 128, 3)\n",
      "0.5260045\n",
      "[Epoch 0/10] [Batch 9/1081] [D loss: 3.440815] [D acc: 0.35 (0.20 real, 0.50 fake)] [G loss: 77.107941] time: 0:00:20.042200\n",
      "(10, 128, 128, 3)\n",
      "0.5137429\n",
      "[Epoch 0/10] [Batch 10/1081] [D loss: 3.473144] [D acc: 0.60 (0.50 real, 0.70 fake)] [G loss: 77.395897] time: 0:00:20.418117\n",
      "(10, 128, 128, 3)\n",
      "0.61470723\n",
      "[Epoch 0/10] [Batch 11/1081] [D loss: 3.301998] [D acc: 0.65 (0.70 real, 0.60 fake)] [G loss: 77.205963] time: 0:00:20.858791\n",
      "(10, 128, 128, 3)\n",
      "0.5903343\n",
      "[Epoch 0/10] [Batch 12/1081] [D loss: 3.186661] [D acc: 0.70 (0.70 real, 0.70 fake)] [G loss: 75.927917] time: 0:00:21.261315\n",
      "(10, 128, 128, 3)\n",
      "0.6662905\n",
      "[Epoch 0/10] [Batch 13/1081] [D loss: 3.090196] [D acc: 0.90 (0.90 real, 0.90 fake)] [G loss: 75.073471] time: 0:00:21.653688\n",
      "(10, 128, 128, 3)\n",
      "0.6836066\n",
      "[Epoch 0/10] [Batch 14/1081] [D loss: 3.279934] [D acc: 0.70 (0.80 real, 0.60 fake)] [G loss: 77.003494] time: 0:00:22.050687\n",
      "(10, 128, 128, 3)\n",
      "0.6449783\n",
      "[Epoch 0/10] [Batch 15/1081] [D loss: 3.555842] [D acc: 0.30 (0.50 real, 0.10 fake)] [G loss: 74.744675] time: 0:00:22.509992\n",
      "(10, 128, 128, 3)\n",
      "0.635962\n",
      "[Epoch 0/10] [Batch 16/1081] [D loss: 3.436796] [D acc: 0.40 (0.30 real, 0.50 fake)] [G loss: 74.505646] time: 0:00:22.921426\n",
      "(10, 128, 128, 3)\n",
      "0.661097\n",
      "[Epoch 0/10] [Batch 17/1081] [D loss: 3.629388] [D acc: 0.35 (0.50 real, 0.20 fake)] [G loss: 73.431015] time: 0:00:23.342691\n",
      "(10, 128, 128, 3)\n",
      "0.6705454\n",
      "[Epoch 0/10] [Batch 18/1081] [D loss: 3.379865] [D acc: 0.65 (0.70 real, 0.60 fake)] [G loss: 72.674736] time: 0:00:23.721481\n",
      "(10, 128, 128, 3)\n",
      "0.59621185\n",
      "[Epoch 0/10] [Batch 19/1081] [D loss: 3.631381] [D acc: 0.30 (0.10 real, 0.50 fake)] [G loss: 73.273636] time: 0:00:24.143037\n",
      "(10, 128, 128, 3)\n",
      "0.7181802\n",
      "[Epoch 0/10] [Batch 20/1081] [D loss: 3.257037] [D acc: 0.75 (0.90 real, 0.60 fake)] [G loss: 72.638000] time: 0:00:24.541181\n",
      "(10, 128, 128, 3)\n",
      "0.67483526\n",
      "[Epoch 0/10] [Batch 21/1081] [D loss: 3.346499] [D acc: 0.60 (0.20 real, 1.00 fake)] [G loss: 71.889511] time: 0:00:24.934117\n",
      "(10, 128, 128, 3)\n",
      "0.6738474\n",
      "[Epoch 0/10] [Batch 22/1081] [D loss: 3.248838] [D acc: 0.65 (0.70 real, 0.60 fake)] [G loss: 70.529236] time: 0:00:25.352791\n",
      "(10, 128, 128, 3)\n",
      "0.68487066\n",
      "[Epoch 0/10] [Batch 23/1081] [D loss: 3.184041] [D acc: 0.85 (0.80 real, 0.90 fake)] [G loss: 70.955986] time: 0:00:25.766236\n",
      "(10, 128, 128, 3)\n",
      "0.66474456\n",
      "[Epoch 0/10] [Batch 24/1081] [D loss: 3.173046] [D acc: 0.75 (0.80 real, 0.70 fake)] [G loss: 69.758972] time: 0:00:26.143866\n",
      "(10, 128, 128, 3)\n",
      "0.6400524\n",
      "[Epoch 0/10] [Batch 25/1081] [D loss: 3.304426] [D acc: 0.80 (0.80 real, 0.80 fake)] [G loss: 71.406464] time: 0:00:26.521977\n",
      "(10, 128, 128, 3)\n",
      "0.7157312\n",
      "[Epoch 0/10] [Batch 26/1081] [D loss: 3.230847] [D acc: 0.75 (0.70 real, 0.80 fake)] [G loss: 69.781189] time: 0:00:26.896712\n",
      "(10, 128, 128, 3)\n",
      "0.61981255\n",
      "[Epoch 0/10] [Batch 27/1081] [D loss: 3.154595] [D acc: 0.80 (0.70 real, 0.90 fake)] [G loss: 68.911171] time: 0:00:27.295734\n",
      "(10, 128, 128, 3)\n",
      "0.66775423\n",
      "[Epoch 0/10] [Batch 28/1081] [D loss: 3.073714] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 69.427322] time: 0:00:27.684209\n",
      "(10, 128, 128, 3)\n",
      "0.72609395\n",
      "[Epoch 0/10] [Batch 29/1081] [D loss: 3.093174] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 70.157394] time: 0:00:28.065152\n",
      "(10, 128, 128, 3)\n",
      "0.6850147\n",
      "[Epoch 0/10] [Batch 30/1081] [D loss: 3.075407] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 69.214371] time: 0:00:28.498526\n",
      "(10, 128, 128, 3)\n",
      "0.7384928\n",
      "[Epoch 0/10] [Batch 31/1081] [D loss: 3.188462] [D acc: 0.70 (0.70 real, 0.70 fake)] [G loss: 70.097954] time: 0:00:28.900767\n",
      "(10, 128, 128, 3)\n",
      "0.73120517\n",
      "[Epoch 0/10] [Batch 32/1081] [D loss: 3.092563] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 68.965317] time: 0:00:29.321850\n",
      "(10, 128, 128, 3)\n",
      "0.74990517\n",
      "[Epoch 0/10] [Batch 33/1081] [D loss: 3.272925] [D acc: 0.50 (0.70 real, 0.30 fake)] [G loss: 69.395927] time: 0:00:29.701701\n",
      "(10, 128, 128, 3)\n",
      "0.68947124\n",
      "[Epoch 0/10] [Batch 34/1081] [D loss: 3.111499] [D acc: 0.85 (0.80 real, 0.90 fake)] [G loss: 67.974838] time: 0:00:30.110109\n",
      "(10, 128, 128, 3)\n",
      "0.7306004\n",
      "[Epoch 0/10] [Batch 35/1081] [D loss: 3.086301] [D acc: 0.90 (0.90 real, 0.90 fake)] [G loss: 69.971100] time: 0:00:30.538747\n",
      "(10, 128, 128, 3)\n",
      "0.65889055\n",
      "[Epoch 0/10] [Batch 36/1081] [D loss: 3.111172] [D acc: 0.90 (0.90 real, 0.90 fake)] [G loss: 68.781509] time: 0:00:30.974572\n",
      "(10, 128, 128, 3)\n",
      "0.70418096\n",
      "[Epoch 0/10] [Batch 37/1081] [D loss: 3.071164] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 67.063347] time: 0:00:31.350649\n",
      "(10, 128, 128, 3)\n",
      "0.62728447\n",
      "[Epoch 0/10] [Batch 38/1081] [D loss: 3.093231] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 67.523659] time: 0:00:31.770515\n",
      "(10, 128, 128, 3)\n",
      "0.7296076\n",
      "[Epoch 0/10] [Batch 39/1081] [D loss: 3.065014] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 69.197632] time: 0:00:32.186244\n",
      "(10, 128, 128, 3)\n",
      "0.64419353\n",
      "[Epoch 0/10] [Batch 40/1081] [D loss: 3.156023] [D acc: 0.75 (0.80 real, 0.70 fake)] [G loss: 69.093750] time: 0:00:32.608380\n",
      "(10, 128, 128, 3)\n",
      "0.6974595\n",
      "[Epoch 0/10] [Batch 41/1081] [D loss: 3.067390] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 67.752167] time: 0:00:32.983792\n",
      "(10, 128, 128, 3)\n",
      "0.6809493\n",
      "[Epoch 0/10] [Batch 42/1081] [D loss: 3.108222] [D acc: 0.90 (0.90 real, 0.90 fake)] [G loss: 66.800735] time: 0:00:33.406175\n",
      "(10, 128, 128, 3)\n",
      "0.7244342\n",
      "[Epoch 0/10] [Batch 43/1081] [D loss: 3.142044] [D acc: 0.90 (1.00 real, 0.80 fake)] [G loss: 66.499565] time: 0:00:33.792529\n",
      "(10, 128, 128, 3)\n",
      "0.7186288\n",
      "[Epoch 0/10] [Batch 44/1081] [D loss: 3.066788] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 67.232254] time: 0:00:34.208315\n",
      "(10, 128, 128, 3)\n",
      "0.7085204\n",
      "[Epoch 0/10] [Batch 45/1081] [D loss: 3.059810] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 66.379288] time: 0:00:34.601214\n",
      "(10, 128, 128, 3)\n",
      "0.6871154\n",
      "[Epoch 0/10] [Batch 46/1081] [D loss: 3.075375] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 67.294304] time: 0:00:35.005255\n",
      "(10, 128, 128, 3)\n",
      "0.73919487\n",
      "[Epoch 0/10] [Batch 47/1081] [D loss: 3.033129] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 66.506966] time: 0:00:35.429421\n",
      "(10, 128, 128, 3)\n",
      "0.7252946\n",
      "[Epoch 0/10] [Batch 48/1081] [D loss: 3.040565] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 66.862007] time: 0:00:35.808420\n",
      "(10, 128, 128, 3)\n",
      "0.71308875\n",
      "[Epoch 0/10] [Batch 49/1081] [D loss: 3.046967] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 68.180710] time: 0:00:36.184526\n",
      "(10, 128, 128, 3)\n",
      "0.6780364\n",
      "[Epoch 0/10] [Batch 50/1081] [D loss: 3.140877] [D acc: 0.75 (0.60 real, 0.90 fake)] [G loss: 67.017914] time: 0:00:36.588624\n",
      "(10, 128, 128, 3)\n",
      "0.7208185\n",
      "[Epoch 0/10] [Batch 51/1081] [D loss: 3.037174] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 66.966454] time: 0:00:37.004486\n",
      "(10, 128, 128, 3)\n",
      "0.7027991\n",
      "[Epoch 0/10] [Batch 52/1081] [D loss: 3.039279] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 66.383430] time: 0:00:37.407193\n",
      "(10, 128, 128, 3)\n",
      "0.7294979\n",
      "[Epoch 0/10] [Batch 53/1081] [D loss: 3.024268] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 66.241592] time: 0:00:37.791204\n",
      "(10, 128, 128, 3)\n",
      "0.7492977\n",
      "[Epoch 0/10] [Batch 54/1081] [D loss: 3.060126] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 67.309921] time: 0:00:38.185544\n",
      "(10, 128, 128, 3)\n",
      "0.67872506\n",
      "[Epoch 0/10] [Batch 55/1081] [D loss: 3.059620] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 67.494156] time: 0:00:38.601966\n",
      "(10, 128, 128, 3)\n",
      "0.7487218\n",
      "[Epoch 0/10] [Batch 56/1081] [D loss: 3.073544] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 68.324463] time: 0:00:38.993054\n",
      "(10, 128, 128, 3)\n",
      "0.67976785\n",
      "[Epoch 0/10] [Batch 57/1081] [D loss: 3.068481] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 66.513687] time: 0:00:39.410801\n",
      "(10, 128, 128, 3)\n",
      "0.67357963\n",
      "[Epoch 0/10] [Batch 58/1081] [D loss: 3.038122] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 66.123009] time: 0:00:39.799314\n",
      "(10, 128, 128, 3)\n",
      "0.7322871\n",
      "[Epoch 0/10] [Batch 59/1081] [D loss: 3.031154] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 66.445251] time: 0:00:40.187212\n",
      "(10, 128, 128, 3)\n",
      "0.706341\n",
      "[Epoch 0/10] [Batch 60/1081] [D loss: 3.055235] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 66.554359] time: 0:00:40.582990\n",
      "(10, 128, 128, 3)\n",
      "0.6558485\n",
      "[Epoch 0/10] [Batch 61/1081] [D loss: 3.045293] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 65.516975] time: 0:00:40.981095\n",
      "(10, 128, 128, 3)\n",
      "0.6918703\n",
      "[Epoch 0/10] [Batch 62/1081] [D loss: 3.031351] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 64.615402] time: 0:00:41.367768\n",
      "(10, 128, 128, 3)\n",
      "0.742146\n",
      "[Epoch 0/10] [Batch 63/1081] [D loss: 3.030067] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 64.245941] time: 0:00:41.772235\n",
      "(10, 128, 128, 3)\n",
      "0.74686176\n",
      "[Epoch 0/10] [Batch 64/1081] [D loss: 3.088960] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 65.403793] time: 0:00:42.167058\n",
      "(10, 128, 128, 3)\n",
      "0.6953759\n",
      "[Epoch 0/10] [Batch 65/1081] [D loss: 3.047048] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 64.750511] time: 0:00:42.579383\n",
      "(10, 128, 128, 3)\n",
      "0.73110217\n",
      "[Epoch 0/10] [Batch 66/1081] [D loss: 3.021957] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 64.889145] time: 0:00:42.976598\n",
      "(10, 128, 128, 3)\n",
      "0.7392154\n",
      "[Epoch 0/10] [Batch 67/1081] [D loss: 3.023419] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 65.536545] time: 0:00:43.398911\n",
      "(10, 128, 128, 3)\n",
      "0.7658543\n",
      "[Epoch 0/10] [Batch 68/1081] [D loss: 3.017232] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 64.182533] time: 0:00:43.802374\n",
      "(10, 128, 128, 3)\n",
      "0.80130213\n",
      "[Epoch 0/10] [Batch 69/1081] [D loss: 3.014091] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 65.384033] time: 0:00:44.214115\n",
      "(10, 128, 128, 3)\n",
      "0.73465776\n",
      "[Epoch 0/10] [Batch 70/1081] [D loss: 3.033240] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 64.652069] time: 0:00:44.607740\n",
      "(10, 128, 128, 3)\n",
      "0.7547107\n",
      "[Epoch 0/10] [Batch 71/1081] [D loss: 3.053777] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 64.104706] time: 0:00:45.000716\n",
      "(10, 128, 128, 3)\n",
      "0.6961\n",
      "[Epoch 0/10] [Batch 72/1081] [D loss: 3.025758] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 64.040901] time: 0:00:45.412916\n",
      "(10, 128, 128, 3)\n",
      "0.70831126\n",
      "[Epoch 0/10] [Batch 73/1081] [D loss: 3.008172] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 64.341095] time: 0:00:45.798225\n",
      "(10, 128, 128, 3)\n",
      "0.7231832\n",
      "[Epoch 0/10] [Batch 74/1081] [D loss: 3.023563] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 64.059494] time: 0:00:46.244188\n",
      "(10, 128, 128, 3)\n",
      "0.7247448\n",
      "[Epoch 0/10] [Batch 75/1081] [D loss: 3.017781] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 63.825264] time: 0:00:46.675157\n",
      "(10, 128, 128, 3)\n",
      "0.7422192\n",
      "[Epoch 0/10] [Batch 76/1081] [D loss: 3.017172] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 63.983105] time: 0:00:47.061770\n",
      "(10, 128, 128, 3)\n",
      "0.6663769\n",
      "[Epoch 0/10] [Batch 77/1081] [D loss: 3.020546] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 63.538689] time: 0:00:47.491710\n",
      "(10, 128, 128, 3)\n",
      "0.743304\n",
      "[Epoch 0/10] [Batch 78/1081] [D loss: 3.038197] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 64.209274] time: 0:00:47.905806\n",
      "(10, 128, 128, 3)\n",
      "0.74200773\n",
      "[Epoch 0/10] [Batch 79/1081] [D loss: 3.008582] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 62.716347] time: 0:00:48.319354\n",
      "(10, 128, 128, 3)\n",
      "0.75673145\n",
      "[Epoch 0/10] [Batch 80/1081] [D loss: 2.999596] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 64.315552] time: 0:00:48.708997\n",
      "(10, 128, 128, 3)\n",
      "0.7369712\n",
      "[Epoch 0/10] [Batch 81/1081] [D loss: 2.989324] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 64.506874] time: 0:00:49.149875\n",
      "(10, 128, 128, 3)\n",
      "0.7082896\n",
      "[Epoch 0/10] [Batch 82/1081] [D loss: 3.045761] [D acc: 0.90 (0.90 real, 0.90 fake)] [G loss: 62.740082] time: 0:00:49.546901\n",
      "(10, 128, 128, 3)\n",
      "0.7942612\n",
      "[Epoch 0/10] [Batch 83/1081] [D loss: 2.991758] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 63.467854] time: 0:00:49.945341\n",
      "(10, 128, 128, 3)\n",
      "0.68352336\n",
      "[Epoch 0/10] [Batch 84/1081] [D loss: 3.024566] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 63.646484] time: 0:00:50.352286\n",
      "(10, 128, 128, 3)\n",
      "0.71664405\n",
      "[Epoch 0/10] [Batch 85/1081] [D loss: 3.040058] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 63.859150] time: 0:00:50.736997\n",
      "(10, 128, 128, 3)\n",
      "0.67999953\n",
      "[Epoch 0/10] [Batch 86/1081] [D loss: 3.656252] [D acc: 0.05 (0.10 real, 0.00 fake)] [G loss: 62.591179] time: 0:00:51.156617\n",
      "(10, 128, 128, 3)\n",
      "0.71150017\n",
      "[Epoch 0/10] [Batch 87/1081] [D loss: 3.091465] [D acc: 0.80 (0.90 real, 0.70 fake)] [G loss: 63.704811] time: 0:00:51.585048\n",
      "(10, 128, 128, 3)\n",
      "0.6734386\n",
      "[Epoch 0/10] [Batch 88/1081] [D loss: 3.129086] [D acc: 0.80 (0.60 real, 1.00 fake)] [G loss: 62.956390] time: 0:00:51.970425\n",
      "(10, 128, 128, 3)\n",
      "0.6966729\n",
      "[Epoch 0/10] [Batch 89/1081] [D loss: 3.057807] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 61.776123] time: 0:00:52.367936\n",
      "(10, 128, 128, 3)\n",
      "0.7514427\n",
      "[Epoch 0/10] [Batch 90/1081] [D loss: 3.010359] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 63.312019] time: 0:00:52.794065\n",
      "(10, 128, 128, 3)\n",
      "0.71716213\n",
      "[Epoch 0/10] [Batch 91/1081] [D loss: 2.997027] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 62.299797] time: 0:00:53.224869\n",
      "(10, 128, 128, 3)\n",
      "0.78821087\n",
      "[Epoch 0/10] [Batch 92/1081] [D loss: 3.023954] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 62.748077] time: 0:00:53.639060\n",
      "(10, 128, 128, 3)\n",
      "0.7523716\n",
      "[Epoch 0/10] [Batch 93/1081] [D loss: 3.033753] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 62.713844] time: 0:00:54.043282\n",
      "(10, 128, 128, 3)\n",
      "0.7828017\n",
      "[Epoch 0/10] [Batch 94/1081] [D loss: 3.008144] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 62.106762] time: 0:00:54.452151\n",
      "(10, 128, 128, 3)\n",
      "0.7757449\n",
      "[Epoch 0/10] [Batch 95/1081] [D loss: 2.987279] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 62.532845] time: 0:00:54.886004\n",
      "(10, 128, 128, 3)\n",
      "0.728851\n",
      "[Epoch 0/10] [Batch 96/1081] [D loss: 3.045045] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 61.628765] time: 0:00:55.282539\n",
      "(10, 128, 128, 3)\n",
      "0.73674256\n",
      "[Epoch 0/10] [Batch 97/1081] [D loss: 2.988836] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 61.533802] time: 0:00:55.676367\n",
      "(10, 128, 128, 3)\n",
      "0.76998305\n",
      "[Epoch 0/10] [Batch 98/1081] [D loss: 3.005634] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 61.796227] time: 0:00:56.102224\n",
      "(10, 128, 128, 3)\n",
      "0.7083671\n",
      "[Epoch 0/10] [Batch 99/1081] [D loss: 2.999992] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 61.714424] time: 0:00:56.518806\n",
      "(10, 128, 128, 3)\n",
      "0.73342395\n",
      "[Epoch 0/10] [Batch 100/1081] [D loss: 3.005522] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 61.839684] time: 0:00:56.915173\n",
      "(10, 128, 128, 3)\n",
      "0.7233763\n",
      "[Epoch 0/10] [Batch 101/1081] [D loss: 2.988578] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 62.011158] time: 0:00:57.331063\n",
      "(10, 128, 128, 3)\n",
      "0.7212288\n",
      "[Epoch 0/10] [Batch 102/1081] [D loss: 2.996415] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 59.836071] time: 0:00:57.711813\n",
      "(10, 128, 128, 3)\n",
      "0.77092797\n",
      "[Epoch 0/10] [Batch 103/1081] [D loss: 2.992164] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 60.344311] time: 0:00:58.104992\n",
      "(10, 128, 128, 3)\n",
      "0.79294205\n",
      "[Epoch 0/10] [Batch 104/1081] [D loss: 2.975592] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 61.549904] time: 0:00:58.503385\n",
      "(10, 128, 128, 3)\n",
      "0.7575888\n",
      "[Epoch 0/10] [Batch 105/1081] [D loss: 2.999667] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 60.966846] time: 0:00:58.897834\n",
      "(10, 128, 128, 3)\n",
      "0.76070124\n",
      "[Epoch 0/10] [Batch 106/1081] [D loss: 2.996889] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 61.251808] time: 0:00:59.284060\n",
      "(10, 128, 128, 3)\n",
      "0.7942314\n",
      "[Epoch 0/10] [Batch 107/1081] [D loss: 2.972169] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 61.756836] time: 0:00:59.701298\n",
      "(10, 128, 128, 3)\n",
      "0.7946754\n",
      "[Epoch 0/10] [Batch 108/1081] [D loss: 2.968410] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 60.275200] time: 0:01:00.111109\n",
      "(10, 128, 128, 3)\n",
      "0.76522464\n",
      "[Epoch 0/10] [Batch 109/1081] [D loss: 2.968331] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 60.933632] time: 0:01:00.511480\n",
      "(10, 128, 128, 3)\n",
      "0.703986\n",
      "[Epoch 0/10] [Batch 110/1081] [D loss: 2.982465] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 59.775154] time: 0:01:00.926933\n",
      "(10, 128, 128, 3)\n",
      "0.7340868\n",
      "[Epoch 0/10] [Batch 111/1081] [D loss: 2.992449] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 61.408897] time: 0:01:01.371055\n",
      "(10, 128, 128, 3)\n",
      "0.77252746\n",
      "[Epoch 0/10] [Batch 112/1081] [D loss: 2.991145] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 60.707935] time: 0:01:01.769523\n",
      "(10, 128, 128, 3)\n",
      "0.72499377\n",
      "[Epoch 0/10] [Batch 113/1081] [D loss: 3.013935] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 59.777428] time: 0:01:02.216766\n",
      "(10, 128, 128, 3)\n",
      "0.74189305\n",
      "[Epoch 0/10] [Batch 114/1081] [D loss: 2.995793] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 60.541180] time: 0:01:02.624699\n",
      "(10, 128, 128, 3)\n",
      "0.7302076\n",
      "[Epoch 0/10] [Batch 115/1081] [D loss: 2.967026] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 60.448448] time: 0:01:03.013686\n",
      "(10, 128, 128, 3)\n",
      "0.761\n",
      "[Epoch 0/10] [Batch 116/1081] [D loss: 2.965445] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 60.340965] time: 0:01:03.435122\n",
      "(10, 128, 128, 3)\n",
      "0.7336506\n",
      "[Epoch 0/10] [Batch 117/1081] [D loss: 2.966616] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 59.076057] time: 0:01:03.864243\n",
      "(10, 128, 128, 3)\n",
      "0.7039358\n",
      "[Epoch 0/10] [Batch 118/1081] [D loss: 2.967960] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 59.584351] time: 0:01:04.250198\n",
      "(10, 128, 128, 3)\n",
      "0.7401387\n",
      "[Epoch 0/10] [Batch 119/1081] [D loss: 2.971270] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 61.329437] time: 0:01:04.634845\n",
      "(10, 128, 128, 3)\n",
      "0.76768947\n",
      "[Epoch 0/10] [Batch 120/1081] [D loss: 2.972621] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 61.286877] time: 0:01:05.053029\n",
      "(10, 128, 128, 3)\n",
      "0.7914448\n",
      "[Epoch 0/10] [Batch 121/1081] [D loss: 2.957002] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 60.615242] time: 0:01:05.441582\n",
      "(10, 128, 128, 3)\n",
      "0.75070995\n",
      "[Epoch 0/10] [Batch 122/1081] [D loss: 2.955297] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 59.221886] time: 0:01:05.836551\n",
      "(10, 128, 128, 3)\n",
      "0.7783575\n",
      "[Epoch 0/10] [Batch 123/1081] [D loss: 2.972493] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 60.030323] time: 0:01:06.253881\n",
      "(10, 128, 128, 3)\n",
      "0.7740016\n",
      "[Epoch 0/10] [Batch 124/1081] [D loss: 2.964956] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 59.745983] time: 0:01:06.680608\n",
      "(10, 128, 128, 3)\n",
      "0.79290134\n",
      "[Epoch 0/10] [Batch 125/1081] [D loss: 2.962464] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 59.207085] time: 0:01:07.094736\n",
      "(10, 128, 128, 3)\n",
      "0.6798405\n",
      "[Epoch 0/10] [Batch 126/1081] [D loss: 2.973342] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 59.635841] time: 0:01:07.498061\n",
      "(10, 128, 128, 3)\n",
      "0.7655478\n",
      "[Epoch 0/10] [Batch 127/1081] [D loss: 2.953959] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 59.375465] time: 0:01:07.957201\n",
      "(10, 128, 128, 3)\n",
      "0.7337397\n",
      "[Epoch 0/10] [Batch 128/1081] [D loss: 2.969881] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 59.338814] time: 0:01:08.374439\n",
      "(10, 128, 128, 3)\n",
      "0.733929\n",
      "[Epoch 0/10] [Batch 129/1081] [D loss: 2.964085] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 59.999767] time: 0:01:08.771428\n",
      "(10, 128, 128, 3)\n",
      "0.781586\n",
      "[Epoch 0/10] [Batch 130/1081] [D loss: 2.961724] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 59.500450] time: 0:01:09.175160\n",
      "(10, 128, 128, 3)\n",
      "0.7818379\n",
      "[Epoch 0/10] [Batch 131/1081] [D loss: 2.951306] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 60.587677] time: 0:01:09.616644\n",
      "(10, 128, 128, 3)\n",
      "0.7462056\n",
      "[Epoch 0/10] [Batch 132/1081] [D loss: 2.955213] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 60.243553] time: 0:01:10.010436\n",
      "(10, 128, 128, 3)\n",
      "0.8306103\n",
      "[Epoch 0/10] [Batch 133/1081] [D loss: 2.957160] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 59.052418] time: 0:01:10.414288\n",
      "(10, 128, 128, 3)\n",
      "0.75724906\n",
      "[Epoch 0/10] [Batch 134/1081] [D loss: 2.949162] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 59.252541] time: 0:01:10.819274\n",
      "(10, 128, 128, 3)\n",
      "0.7781889\n",
      "[Epoch 0/10] [Batch 135/1081] [D loss: 2.950496] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 59.718433] time: 0:01:11.244699\n",
      "(10, 128, 128, 3)\n",
      "0.75353783\n",
      "[Epoch 0/10] [Batch 136/1081] [D loss: 2.953401] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 59.841045] time: 0:01:11.651172\n",
      "(10, 128, 128, 3)\n",
      "0.8241432\n",
      "[Epoch 0/10] [Batch 137/1081] [D loss: 2.945082] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 58.791420] time: 0:01:12.040691\n",
      "(10, 128, 128, 3)\n",
      "0.7648473\n",
      "[Epoch 0/10] [Batch 138/1081] [D loss: 2.948340] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 58.720695] time: 0:01:12.447510\n",
      "(10, 128, 128, 3)\n",
      "0.75633186\n",
      "[Epoch 0/10] [Batch 139/1081] [D loss: 2.991935] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 59.436695] time: 0:01:12.861115\n",
      "(10, 128, 128, 3)\n",
      "0.7462556\n",
      "[Epoch 0/10] [Batch 140/1081] [D loss: 2.975151] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 59.329578] time: 0:01:13.253716\n",
      "(10, 128, 128, 3)\n",
      "0.778495\n",
      "[Epoch 0/10] [Batch 141/1081] [D loss: 2.954709] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 58.855064] time: 0:01:13.664095\n",
      "(10, 128, 128, 3)\n",
      "0.7664098\n",
      "[Epoch 0/10] [Batch 142/1081] [D loss: 2.946044] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 57.836037] time: 0:01:14.081570\n",
      "(10, 128, 128, 3)\n",
      "0.7812813\n",
      "[Epoch 0/10] [Batch 143/1081] [D loss: 2.949682] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 57.936363] time: 0:01:14.479333\n",
      "(10, 128, 128, 3)\n",
      "0.828604\n",
      "[Epoch 0/10] [Batch 144/1081] [D loss: 2.943659] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 59.769371] time: 0:01:14.869262\n",
      "(10, 128, 128, 3)\n",
      "0.7436232\n",
      "[Epoch 0/10] [Batch 145/1081] [D loss: 2.938172] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 59.672615] time: 0:01:15.256861\n",
      "(10, 128, 128, 3)\n",
      "0.7538623\n",
      "[Epoch 0/10] [Batch 146/1081] [D loss: 2.934948] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 58.997017] time: 0:01:15.695211\n",
      "(10, 128, 128, 3)\n",
      "0.75728655\n",
      "[Epoch 0/10] [Batch 147/1081] [D loss: 2.937577] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 58.567249] time: 0:01:16.113478\n",
      "(10, 128, 128, 3)\n",
      "0.8087058\n",
      "[Epoch 0/10] [Batch 148/1081] [D loss: 2.943452] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 59.059582] time: 0:01:16.531717\n",
      "(10, 128, 128, 3)\n",
      "0.74322766\n",
      "[Epoch 0/10] [Batch 149/1081] [D loss: 2.936016] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 57.589928] time: 0:01:16.949948\n",
      "(10, 128, 128, 3)\n",
      "0.7668403\n",
      "[Epoch 0/10] [Batch 150/1081] [D loss: 2.938684] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 58.183826] time: 0:01:17.361110\n",
      "(10, 128, 128, 3)\n",
      "0.79368854\n",
      "[Epoch 0/10] [Batch 151/1081] [D loss: 2.933608] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 57.520729] time: 0:01:17.774116\n",
      "(10, 128, 128, 3)\n",
      "0.7753372\n",
      "[Epoch 0/10] [Batch 152/1081] [D loss: 2.935477] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 57.516315] time: 0:01:18.177184\n",
      "(10, 128, 128, 3)\n",
      "0.8136328\n",
      "[Epoch 0/10] [Batch 153/1081] [D loss: 2.938153] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 58.703796] time: 0:01:18.569147\n",
      "(10, 128, 128, 3)\n",
      "0.7898554\n",
      "[Epoch 0/10] [Batch 154/1081] [D loss: 2.931367] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 58.037506] time: 0:01:18.974706\n",
      "(10, 128, 128, 3)\n",
      "0.7181704\n",
      "[Epoch 0/10] [Batch 155/1081] [D loss: 2.930266] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 57.698181] time: 0:01:19.385522\n",
      "(10, 128, 128, 3)\n",
      "0.76500124\n",
      "[Epoch 0/10] [Batch 156/1081] [D loss: 2.928286] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 56.312244] time: 0:01:19.820822\n",
      "(10, 128, 128, 3)\n",
      "0.74802893\n",
      "[Epoch 0/10] [Batch 157/1081] [D loss: 2.931324] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 58.063282] time: 0:01:20.229774\n",
      "(10, 128, 128, 3)\n",
      "0.8588852\n",
      "[Epoch 0/10] [Batch 158/1081] [D loss: 2.925100] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 58.715485] time: 0:01:20.631842\n",
      "(10, 128, 128, 3)\n",
      "0.77885914\n",
      "[Epoch 0/10] [Batch 159/1081] [D loss: 2.927695] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 58.049561] time: 0:01:21.033513\n",
      "(10, 128, 128, 3)\n",
      "0.7121675\n",
      "[Epoch 0/10] [Batch 160/1081] [D loss: 2.923829] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 57.523693] time: 0:01:21.446030\n",
      "(10, 128, 128, 3)\n",
      "0.76697046\n",
      "[Epoch 0/10] [Batch 161/1081] [D loss: 2.923127] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 57.491234] time: 0:01:21.857015\n",
      "(10, 128, 128, 3)\n",
      "0.7672565\n",
      "[Epoch 0/10] [Batch 162/1081] [D loss: 2.921715] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 57.517601] time: 0:01:22.295964\n",
      "(10, 128, 128, 3)\n",
      "0.7201309\n",
      "[Epoch 0/10] [Batch 163/1081] [D loss: 2.922244] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 56.750866] time: 0:01:22.700337\n",
      "(10, 128, 128, 3)\n",
      "0.7449742\n",
      "[Epoch 0/10] [Batch 164/1081] [D loss: 2.920376] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 57.778130] time: 0:01:23.106046\n",
      "(10, 128, 128, 3)\n",
      "0.7774052\n",
      "[Epoch 0/10] [Batch 165/1081] [D loss: 2.916430] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 57.327911] time: 0:01:23.491956\n",
      "(10, 128, 128, 3)\n",
      "0.8548639\n",
      "[Epoch 0/10] [Batch 166/1081] [D loss: 2.925082] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 56.741322] time: 0:01:23.891125\n",
      "(10, 128, 128, 3)\n",
      "0.70922476\n",
      "[Epoch 0/10] [Batch 167/1081] [D loss: 2.916104] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 57.553516] time: 0:01:24.278502\n",
      "(10, 128, 128, 3)\n",
      "0.73357606\n",
      "[Epoch 0/10] [Batch 168/1081] [D loss: 2.919753] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 56.796520] time: 0:01:24.715275\n",
      "(10, 128, 128, 3)\n",
      "0.6696222\n",
      "[Epoch 0/10] [Batch 169/1081] [D loss: 2.918168] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 57.555969] time: 0:01:25.102604\n",
      "(10, 128, 128, 3)\n",
      "0.75492\n",
      "[Epoch 0/10] [Batch 170/1081] [D loss: 2.919681] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 56.785755] time: 0:01:25.502771\n",
      "(10, 128, 128, 3)\n",
      "0.77308315\n",
      "[Epoch 0/10] [Batch 171/1081] [D loss: 2.918259] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 56.571739] time: 0:01:25.923660\n",
      "(10, 128, 128, 3)\n",
      "0.7903752\n",
      "[Epoch 0/10] [Batch 172/1081] [D loss: 2.917078] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 57.481407] time: 0:01:26.333545\n",
      "(10, 128, 128, 3)\n",
      "0.72841114\n",
      "[Epoch 0/10] [Batch 173/1081] [D loss: 2.910018] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 55.629101] time: 0:01:26.719049\n",
      "(10, 128, 128, 3)\n",
      "0.8321101\n",
      "[Epoch 0/10] [Batch 174/1081] [D loss: 2.918331] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 57.351067] time: 0:01:27.131112\n",
      "(10, 128, 128, 3)\n",
      "0.7943317\n",
      "[Epoch 0/10] [Batch 175/1081] [D loss: 2.919061] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 56.523376] time: 0:01:27.538423\n",
      "(10, 128, 128, 3)\n",
      "0.80323124\n",
      "[Epoch 0/10] [Batch 176/1081] [D loss: 2.913092] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 56.073578] time: 0:01:27.971371\n",
      "(10, 128, 128, 3)\n",
      "0.81879187\n",
      "[Epoch 0/10] [Batch 177/1081] [D loss: 2.916225] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 56.956371] time: 0:01:28.379610\n",
      "(10, 128, 128, 3)\n",
      "0.8088157\n",
      "[Epoch 0/10] [Batch 178/1081] [D loss: 2.910271] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 57.113823] time: 0:01:28.800240\n",
      "(10, 128, 128, 3)\n",
      "0.8206389\n",
      "[Epoch 0/10] [Batch 179/1081] [D loss: 2.907933] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 56.591553] time: 0:01:29.211579\n",
      "(10, 128, 128, 3)\n",
      "0.7895693\n",
      "[Epoch 0/10] [Batch 180/1081] [D loss: 2.906054] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 57.831520] time: 0:01:29.632756\n",
      "(10, 128, 128, 3)\n",
      "0.7384741\n",
      "[Epoch 0/10] [Batch 181/1081] [D loss: 2.905649] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 56.599770] time: 0:01:30.059847\n",
      "(10, 128, 128, 3)\n",
      "0.80321056\n",
      "[Epoch 0/10] [Batch 182/1081] [D loss: 2.902744] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 56.147694] time: 0:01:30.482578\n",
      "(10, 128, 128, 3)\n",
      "0.8564474\n",
      "[Epoch 0/10] [Batch 183/1081] [D loss: 2.902296] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 55.913868] time: 0:01:30.887298\n",
      "(10, 128, 128, 3)\n",
      "0.8606329\n",
      "[Epoch 0/10] [Batch 184/1081] [D loss: 3.730061] [D acc: 0.45 (0.90 real, 0.00 fake)] [G loss: 55.479847] time: 0:01:31.317086\n",
      "(10, 128, 128, 3)\n",
      "0.6828582\n",
      "[Epoch 0/10] [Batch 185/1081] [D loss: 3.147954] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 56.369823] time: 0:01:31.741847\n",
      "(10, 128, 128, 3)\n",
      "0.8307657\n",
      "[Epoch 0/10] [Batch 186/1081] [D loss: 3.245320] [D acc: 0.15 (0.10 real, 0.20 fake)] [G loss: 56.687122] time: 0:01:32.137921\n",
      "(10, 128, 128, 3)\n",
      "0.8398342\n",
      "[Epoch 0/10] [Batch 187/1081] [D loss: 3.277515] [D acc: 0.20 (0.20 real, 0.20 fake)] [G loss: 56.493763] time: 0:01:32.515840\n",
      "(10, 128, 128, 3)\n",
      "0.8286524\n",
      "[Epoch 0/10] [Batch 188/1081] [D loss: 3.226440] [D acc: 0.15 (0.10 real, 0.20 fake)] [G loss: 56.528473] time: 0:01:32.957586\n",
      "(10, 128, 128, 3)\n",
      "0.7808714\n",
      "[Epoch 0/10] [Batch 189/1081] [D loss: 3.214720] [D acc: 0.25 (0.20 real, 0.30 fake)] [G loss: 55.617836] time: 0:01:33.367786\n",
      "(10, 128, 128, 3)\n",
      "0.7698567\n",
      "[Epoch 0/10] [Batch 190/1081] [D loss: 3.182259] [D acc: 0.30 (0.20 real, 0.40 fake)] [G loss: 55.242287] time: 0:01:33.815234\n",
      "(10, 128, 128, 3)\n",
      "0.79223365\n",
      "[Epoch 0/10] [Batch 191/1081] [D loss: 3.175856] [D acc: 0.35 (0.50 real, 0.20 fake)] [G loss: 56.833057] time: 0:01:34.233780\n",
      "(10, 128, 128, 3)\n",
      "0.80886906\n",
      "[Epoch 0/10] [Batch 192/1081] [D loss: 3.172464] [D acc: 0.55 (0.30 real, 0.80 fake)] [G loss: 54.568939] time: 0:01:34.621655\n",
      "(10, 128, 128, 3)\n",
      "0.7615817\n",
      "[Epoch 0/10] [Batch 193/1081] [D loss: 3.158683] [D acc: 0.30 (0.30 real, 0.30 fake)] [G loss: 55.789051] time: 0:01:35.041403\n",
      "(10, 128, 128, 3)\n",
      "0.76685476\n",
      "[Epoch 0/10] [Batch 194/1081] [D loss: 3.174782] [D acc: 0.35 (0.70 real, 0.00 fake)] [G loss: 54.557850] time: 0:01:35.448386\n",
      "(10, 128, 128, 3)\n",
      "0.7791352\n",
      "[Epoch 0/10] [Batch 195/1081] [D loss: 3.150364] [D acc: 0.55 (0.40 real, 0.70 fake)] [G loss: 55.521217] time: 0:01:35.914857\n",
      "(10, 128, 128, 3)\n",
      "0.7597496\n",
      "[Epoch 0/10] [Batch 196/1081] [D loss: 3.186999] [D acc: 0.25 (0.10 real, 0.40 fake)] [G loss: 56.551521] time: 0:01:36.354294\n",
      "(10, 128, 128, 3)\n",
      "0.8177636\n",
      "[Epoch 0/10] [Batch 197/1081] [D loss: 3.131028] [D acc: 0.60 (0.70 real, 0.50 fake)] [G loss: 56.206818] time: 0:01:36.781663\n",
      "(10, 128, 128, 3)\n",
      "0.83218104\n",
      "[Epoch 0/10] [Batch 198/1081] [D loss: 3.186456] [D acc: 0.35 (0.00 real, 0.70 fake)] [G loss: 54.385548] time: 0:01:37.179098\n",
      "(10, 128, 128, 3)\n",
      "0.8347861\n",
      "[Epoch 0/10] [Batch 199/1081] [D loss: 3.141613] [D acc: 0.45 (0.50 real, 0.40 fake)] [G loss: 55.520103] time: 0:01:37.581216\n",
      "(10, 128, 128, 3)\n",
      "0.76252824\n",
      "[Epoch 0/10] [Batch 200/1081] [D loss: 3.104554] [D acc: 0.60 (0.30 real, 0.90 fake)] [G loss: 54.343170] time: 0:01:37.983510\n",
      "(10, 128, 128, 3)\n",
      "0.8134405\n",
      "[Epoch 0/10] [Batch 201/1081] [D loss: 3.122509] [D acc: 0.45 (0.60 real, 0.30 fake)] [G loss: 55.296093] time: 0:01:38.376239\n",
      "(10, 128, 128, 3)\n",
      "0.7490899\n",
      "[Epoch 0/10] [Batch 202/1081] [D loss: 3.084284] [D acc: 0.70 (0.50 real, 0.90 fake)] [G loss: 56.030296] time: 0:01:38.797394\n",
      "(10, 128, 128, 3)\n",
      "0.7925233\n",
      "[Epoch 0/10] [Batch 203/1081] [D loss: 3.089414] [D acc: 0.70 (0.60 real, 0.80 fake)] [G loss: 55.866993] time: 0:01:39.236179\n",
      "(10, 128, 128, 3)\n",
      "0.821503\n",
      "[Epoch 0/10] [Batch 204/1081] [D loss: 3.093470] [D acc: 0.75 (0.70 real, 0.80 fake)] [G loss: 54.430580] time: 0:01:39.634100\n",
      "(10, 128, 128, 3)\n",
      "0.76285267\n",
      "[Epoch 0/10] [Batch 205/1081] [D loss: 2.964971] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 55.193352] time: 0:01:40.015128\n",
      "(10, 128, 128, 3)\n",
      "0.8662626\n",
      "[Epoch 0/10] [Batch 206/1081] [D loss: 3.029197] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 54.073448] time: 0:01:40.410571\n",
      "(10, 128, 128, 3)\n",
      "0.8447697\n",
      "[Epoch 0/10] [Batch 207/1081] [D loss: 2.912965] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 54.859886] time: 0:01:40.808562\n",
      "(10, 128, 128, 3)\n",
      "0.7809555\n",
      "[Epoch 0/10] [Batch 208/1081] [D loss: 2.942084] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 55.511665] time: 0:01:41.240228\n",
      "(10, 128, 128, 3)\n",
      "0.7234282\n",
      "[Epoch 0/10] [Batch 209/1081] [D loss: 2.972082] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 53.592102] time: 0:01:41.649186\n",
      "(10, 128, 128, 3)\n",
      "0.82123023\n",
      "[Epoch 0/10] [Batch 210/1081] [D loss: 2.907768] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 55.122364] time: 0:01:42.062462\n",
      "(10, 128, 128, 3)\n",
      "0.7922184\n",
      "[Epoch 0/10] [Batch 211/1081] [D loss: 2.899865] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 54.643147] time: 0:01:42.476167\n",
      "(10, 128, 128, 3)\n",
      "0.84935504\n",
      "[Epoch 0/10] [Batch 212/1081] [D loss: 2.898349] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 54.857006] time: 0:01:42.881583\n",
      "(10, 128, 128, 3)\n",
      "0.79161096\n",
      "[Epoch 0/10] [Batch 213/1081] [D loss: 2.913679] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 54.367260] time: 0:01:43.289461\n",
      "(10, 128, 128, 3)\n",
      "0.8258051\n",
      "[Epoch 0/10] [Batch 214/1081] [D loss: 2.887357] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 54.413979] time: 0:01:43.695704\n",
      "(10, 128, 128, 3)\n",
      "0.76120263\n",
      "[Epoch 0/10] [Batch 215/1081] [D loss: 2.881908] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 53.830772] time: 0:01:44.105584\n",
      "(10, 128, 128, 3)\n",
      "0.8075845\n",
      "[Epoch 0/10] [Batch 216/1081] [D loss: 2.889138] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 53.747387] time: 0:01:44.486454\n",
      "(10, 128, 128, 3)\n",
      "0.8121257\n",
      "[Epoch 0/10] [Batch 217/1081] [D loss: 2.879110] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 54.612053] time: 0:01:44.895977\n",
      "(10, 128, 128, 3)\n",
      "0.79242367\n",
      "[Epoch 0/10] [Batch 218/1081] [D loss: 2.894865] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 55.009472] time: 0:01:45.325228\n",
      "(10, 128, 128, 3)\n",
      "0.80897075\n",
      "[Epoch 0/10] [Batch 219/1081] [D loss: 2.872197] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 54.563812] time: 0:01:45.713855\n",
      "(10, 128, 128, 3)\n",
      "0.77772135\n",
      "[Epoch 0/10] [Batch 220/1081] [D loss: 2.875682] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 53.764381] time: 0:01:46.126757\n",
      "(10, 128, 128, 3)\n",
      "0.79817456\n",
      "[Epoch 0/10] [Batch 221/1081] [D loss: 2.885287] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 53.781929] time: 0:01:46.556350\n",
      "(10, 128, 128, 3)\n",
      "0.7116847\n",
      "[Epoch 0/10] [Batch 222/1081] [D loss: 2.878634] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 53.986462] time: 0:01:46.984424\n",
      "(10, 128, 128, 3)\n",
      "0.84617376\n",
      "[Epoch 0/10] [Batch 223/1081] [D loss: 2.875673] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 53.315563] time: 0:01:47.417938\n",
      "(10, 128, 128, 3)\n",
      "0.82682943\n",
      "[Epoch 0/10] [Batch 224/1081] [D loss: 2.869065] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 53.713646] time: 0:01:47.834002\n",
      "(10, 128, 128, 3)\n",
      "0.7767815\n",
      "[Epoch 0/10] [Batch 225/1081] [D loss: 2.873179] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 52.928917] time: 0:01:48.219315\n",
      "(10, 128, 128, 3)\n",
      "0.8369548\n",
      "[Epoch 0/10] [Batch 226/1081] [D loss: 2.863914] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 53.729797] time: 0:01:48.642320\n",
      "(10, 128, 128, 3)\n",
      "0.8497034\n",
      "[Epoch 0/10] [Batch 227/1081] [D loss: 2.867019] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 54.057575] time: 0:01:49.046904\n",
      "(10, 128, 128, 3)\n",
      "0.79561824\n",
      "[Epoch 0/10] [Batch 228/1081] [D loss: 2.866914] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 54.445812] time: 0:01:49.469803\n",
      "(10, 128, 128, 3)\n",
      "0.78609776\n",
      "[Epoch 0/10] [Batch 229/1081] [D loss: 2.865784] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 52.807362] time: 0:01:49.890319\n",
      "(10, 128, 128, 3)\n",
      "0.79234195\n",
      "[Epoch 0/10] [Batch 230/1081] [D loss: 2.864006] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 53.047081] time: 0:01:50.328742\n",
      "(10, 128, 128, 3)\n",
      "0.7971446\n",
      "[Epoch 0/10] [Batch 231/1081] [D loss: 2.872912] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 53.091667] time: 0:01:50.738704\n",
      "(10, 128, 128, 3)\n",
      "0.8308546\n",
      "[Epoch 0/10] [Batch 232/1081] [D loss: 2.869628] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 53.431225] time: 0:01:51.164377\n",
      "(10, 128, 128, 3)\n",
      "0.82944137\n",
      "[Epoch 0/10] [Batch 233/1081] [D loss: 2.933562] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 53.465843] time: 0:01:51.595983\n",
      "(10, 128, 128, 3)\n",
      "0.7912162\n",
      "[Epoch 0/10] [Batch 234/1081] [D loss: 2.864990] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 53.254723] time: 0:01:52.001877\n",
      "(10, 128, 128, 3)\n",
      "0.736147\n",
      "[Epoch 0/10] [Batch 235/1081] [D loss: 2.862122] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 53.165333] time: 0:01:52.400570\n",
      "(10, 128, 128, 3)\n",
      "0.77583426\n",
      "[Epoch 0/10] [Batch 236/1081] [D loss: 2.855525] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 52.811516] time: 0:01:52.793439\n",
      "(10, 128, 128, 3)\n",
      "0.7501056\n",
      "[Epoch 0/10] [Batch 237/1081] [D loss: 2.870316] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 52.661144] time: 0:01:53.180301\n",
      "(10, 128, 128, 3)\n",
      "0.8213644\n",
      "[Epoch 0/10] [Batch 238/1081] [D loss: 2.862183] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 53.137749] time: 0:01:53.594142\n",
      "(10, 128, 128, 3)\n",
      "0.8053953\n",
      "[Epoch 0/10] [Batch 239/1081] [D loss: 3.376726] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 53.531567] time: 0:01:54.036562\n",
      "(10, 128, 128, 3)\n",
      "0.793349\n",
      "[Epoch 0/10] [Batch 240/1081] [D loss: 3.514474] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 53.298454] time: 0:01:54.433011\n",
      "(10, 128, 128, 3)\n",
      "0.7893965\n",
      "[Epoch 0/10] [Batch 241/1081] [D loss: 3.281399] [D acc: 0.10 (0.00 real, 0.20 fake)] [G loss: 52.824768] time: 0:01:54.829977\n",
      "(10, 128, 128, 3)\n",
      "0.83996207\n",
      "[Epoch 0/10] [Batch 242/1081] [D loss: 3.141603] [D acc: 0.45 (0.70 real, 0.20 fake)] [G loss: 52.752144] time: 0:01:55.217284\n",
      "(10, 128, 128, 3)\n",
      "0.79658467\n",
      "[Epoch 0/10] [Batch 243/1081] [D loss: 3.131678] [D acc: 0.30 (0.20 real, 0.40 fake)] [G loss: 52.600639] time: 0:01:55.635841\n",
      "(10, 128, 128, 3)\n",
      "0.85710984\n",
      "[Epoch 0/10] [Batch 244/1081] [D loss: 3.128625] [D acc: 0.15 (0.20 real, 0.10 fake)] [G loss: 53.130943] time: 0:01:56.027750\n",
      "(10, 128, 128, 3)\n",
      "0.83697695\n",
      "[Epoch 0/10] [Batch 245/1081] [D loss: 3.106162] [D acc: 0.35 (0.10 real, 0.60 fake)] [G loss: 52.719536] time: 0:01:56.433947\n",
      "(10, 128, 128, 3)\n",
      "0.7961052\n",
      "[Epoch 0/10] [Batch 246/1081] [D loss: 3.086750] [D acc: 0.45 (0.30 real, 0.60 fake)] [G loss: 52.042370] time: 0:01:56.827278\n",
      "(10, 128, 128, 3)\n",
      "0.8192468\n",
      "[Epoch 0/10] [Batch 247/1081] [D loss: 3.046676] [D acc: 0.75 (0.90 real, 0.60 fake)] [G loss: 53.297607] time: 0:01:57.273818\n",
      "(10, 128, 128, 3)\n",
      "0.75604445\n",
      "[Epoch 0/10] [Batch 248/1081] [D loss: 3.036518] [D acc: 0.80 (0.60 real, 1.00 fake)] [G loss: 53.107563] time: 0:01:57.681767\n",
      "(10, 128, 128, 3)\n",
      "0.8584339\n",
      "[Epoch 0/10] [Batch 249/1081] [D loss: 2.972153] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 52.384735] time: 0:01:58.108245\n",
      "(10, 128, 128, 3)\n",
      "0.8066177\n",
      "[Epoch 0/10] [Batch 250/1081] [D loss: 2.960755] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 51.770226] time: 0:01:58.540727\n",
      "(10, 128, 128, 3)\n",
      "0.8408432\n",
      "[Epoch 0/10] [Batch 251/1081] [D loss: 3.073005] [D acc: 0.55 (0.30 real, 0.80 fake)] [G loss: 51.124794] time: 0:01:58.967565\n",
      "(10, 128, 128, 3)\n",
      "0.7896754\n",
      "[Epoch 0/10] [Batch 252/1081] [D loss: 2.897462] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 52.629082] time: 0:01:59.383281\n",
      "(10, 128, 128, 3)\n",
      "0.83317024\n",
      "[Epoch 0/10] [Batch 253/1081] [D loss: 2.999427] [D acc: 0.80 (0.60 real, 1.00 fake)] [G loss: 51.586067] time: 0:01:59.821103\n",
      "(10, 128, 128, 3)\n",
      "0.84440035\n",
      "[Epoch 0/10] [Batch 254/1081] [D loss: 2.932833] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 51.703270] time: 0:02:00.220915\n",
      "(10, 128, 128, 3)\n",
      "0.8348227\n",
      "[Epoch 0/10] [Batch 255/1081] [D loss: 2.884595] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 52.286751] time: 0:02:00.669946\n",
      "(10, 128, 128, 3)\n",
      "0.8355787\n",
      "[Epoch 0/10] [Batch 256/1081] [D loss: 2.837835] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 52.352226] time: 0:02:01.075253\n",
      "(10, 128, 128, 3)\n",
      "0.8223935\n",
      "[Epoch 0/10] [Batch 257/1081] [D loss: 2.854792] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 51.094234] time: 0:02:01.502139\n",
      "(10, 128, 128, 3)\n",
      "0.82839614\n",
      "[Epoch 0/10] [Batch 258/1081] [D loss: 2.836269] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 52.034729] time: 0:02:01.928017\n",
      "(10, 128, 128, 3)\n",
      "0.84288955\n",
      "[Epoch 0/10] [Batch 259/1081] [D loss: 2.834162] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 51.780773] time: 0:02:02.339849\n",
      "(10, 128, 128, 3)\n",
      "0.8298049\n",
      "[Epoch 0/10] [Batch 260/1081] [D loss: 2.828895] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 51.260765] time: 0:02:02.771255\n",
      "(10, 128, 128, 3)\n",
      "0.84217525\n",
      "[Epoch 0/10] [Batch 261/1081] [D loss: 3.642989] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 50.795628] time: 0:02:03.169824\n",
      "(10, 128, 128, 3)\n",
      "0.78271365\n",
      "[Epoch 0/10] [Batch 262/1081] [D loss: 2.996193] [D acc: 0.60 (1.00 real, 0.20 fake)] [G loss: 52.433022] time: 0:02:03.565614\n",
      "(10, 128, 128, 3)\n",
      "0.7884016\n",
      "[Epoch 0/10] [Batch 263/1081] [D loss: 2.925164] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 51.028481] time: 0:02:03.984499\n",
      "(10, 128, 128, 3)\n",
      "0.8415391\n",
      "[Epoch 0/10] [Batch 264/1081] [D loss: 2.920864] [D acc: 0.80 (0.60 real, 1.00 fake)] [G loss: 52.440784] time: 0:02:04.415026\n",
      "(10, 128, 128, 3)\n",
      "0.8097153\n",
      "[Epoch 0/10] [Batch 265/1081] [D loss: 2.912928] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 51.455986] time: 0:02:04.831086\n",
      "(10, 128, 128, 3)\n",
      "0.8060708\n",
      "[Epoch 0/10] [Batch 266/1081] [D loss: 2.921153] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 51.216972] time: 0:02:05.236081\n",
      "(10, 128, 128, 3)\n",
      "0.78113896\n",
      "[Epoch 0/10] [Batch 267/1081] [D loss: 2.851255] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 51.554737] time: 0:02:05.639082\n",
      "(10, 128, 128, 3)\n",
      "0.7894204\n",
      "[Epoch 0/10] [Batch 268/1081] [D loss: 2.822879] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 50.860168] time: 0:02:06.099539\n",
      "(10, 128, 128, 3)\n",
      "0.82090837\n",
      "[Epoch 0/10] [Batch 269/1081] [D loss: 2.827165] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 51.039661] time: 0:02:06.488728\n",
      "(10, 128, 128, 3)\n",
      "0.7885321\n",
      "[Epoch 0/10] [Batch 270/1081] [D loss: 2.836334] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 50.248940] time: 0:02:06.911821\n",
      "(10, 128, 128, 3)\n",
      "0.81881547\n",
      "[Epoch 0/10] [Batch 271/1081] [D loss: 2.904733] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 49.601212] time: 0:02:07.329575\n",
      "(10, 128, 128, 3)\n",
      "0.86812073\n",
      "[Epoch 0/10] [Batch 272/1081] [D loss: 2.849389] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 51.038628] time: 0:02:07.729771\n",
      "(10, 128, 128, 3)\n",
      "0.82489747\n",
      "[Epoch 0/10] [Batch 273/1081] [D loss: 2.816627] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 51.434650] time: 0:02:08.156177\n",
      "(10, 128, 128, 3)\n",
      "0.80335355\n",
      "[Epoch 0/10] [Batch 274/1081] [D loss: 2.819898] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 50.814133] time: 0:02:08.600536\n",
      "(10, 128, 128, 3)\n",
      "0.864276\n",
      "[Epoch 0/10] [Batch 275/1081] [D loss: 2.811323] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 52.004036] time: 0:02:09.017356\n",
      "(10, 128, 128, 3)\n",
      "0.90319806\n",
      "[Epoch 0/10] [Batch 276/1081] [D loss: 2.812433] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 51.786003] time: 0:02:09.401897\n",
      "(10, 128, 128, 3)\n",
      "0.82738\n",
      "[Epoch 0/10] [Batch 277/1081] [D loss: 2.809020] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 51.091339] time: 0:02:09.825933\n",
      "(10, 128, 128, 3)\n",
      "0.8031277\n",
      "[Epoch 0/10] [Batch 278/1081] [D loss: 2.807016] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 49.800156] time: 0:02:10.254812\n",
      "(10, 128, 128, 3)\n",
      "0.86501336\n",
      "[Epoch 0/10] [Batch 279/1081] [D loss: 2.808590] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 50.512192] time: 0:02:10.706443\n",
      "(10, 128, 128, 3)\n",
      "0.80683994\n",
      "[Epoch 0/10] [Batch 280/1081] [D loss: 2.810735] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 50.424500] time: 0:02:11.106002\n",
      "(10, 128, 128, 3)\n",
      "0.85387677\n",
      "[Epoch 0/10] [Batch 281/1081] [D loss: 2.808257] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 50.633011] time: 0:02:11.501308\n",
      "(10, 128, 128, 3)\n",
      "0.8367338\n",
      "[Epoch 0/10] [Batch 282/1081] [D loss: 2.807871] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 50.824692] time: 0:02:11.927702\n",
      "(10, 128, 128, 3)\n",
      "0.8078277\n",
      "[Epoch 0/10] [Batch 283/1081] [D loss: 2.800630] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 50.457081] time: 0:02:12.342456\n",
      "(10, 128, 128, 3)\n",
      "0.8528771\n",
      "[Epoch 0/10] [Batch 284/1081] [D loss: 2.802430] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 49.657902] time: 0:02:12.747969\n",
      "(10, 128, 128, 3)\n",
      "0.8372417\n",
      "[Epoch 0/10] [Batch 285/1081] [D loss: 2.803226] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 50.902306] time: 0:02:13.150297\n",
      "(10, 128, 128, 3)\n",
      "0.82141113\n",
      "[Epoch 0/10] [Batch 286/1081] [D loss: 2.810872] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 50.445938] time: 0:02:13.548781\n",
      "(10, 128, 128, 3)\n",
      "0.8536456\n",
      "[Epoch 0/10] [Batch 287/1081] [D loss: 2.794461] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 50.522556] time: 0:02:13.972421\n",
      "(10, 128, 128, 3)\n",
      "0.82416874\n",
      "[Epoch 0/10] [Batch 288/1081] [D loss: 2.804333] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 50.137753] time: 0:02:14.363554\n",
      "(10, 128, 128, 3)\n",
      "0.83486766\n",
      "[Epoch 0/10] [Batch 289/1081] [D loss: 2.799240] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 50.528156] time: 0:02:14.796131\n",
      "(10, 128, 128, 3)\n",
      "0.8000159\n",
      "[Epoch 0/10] [Batch 290/1081] [D loss: 2.790759] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 50.084541] time: 0:02:15.221627\n",
      "(10, 128, 128, 3)\n",
      "0.843394\n",
      "[Epoch 0/10] [Batch 291/1081] [D loss: 2.792437] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 50.241493] time: 0:02:15.613873\n",
      "(10, 128, 128, 3)\n",
      "0.7733295\n",
      "[Epoch 0/10] [Batch 292/1081] [D loss: 2.790711] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 49.835770] time: 0:02:16.043730\n",
      "(10, 128, 128, 3)\n",
      "0.8450481\n",
      "[Epoch 0/10] [Batch 293/1081] [D loss: 2.814301] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 49.426399] time: 0:02:16.455925\n",
      "(10, 128, 128, 3)\n",
      "0.8441536\n",
      "[Epoch 0/10] [Batch 294/1081] [D loss: 2.790365] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 50.642246] time: 0:02:16.873581\n",
      "(10, 128, 128, 3)\n",
      "0.7977524\n",
      "[Epoch 0/10] [Batch 295/1081] [D loss: 2.798614] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 49.156261] time: 0:02:17.303487\n",
      "(10, 128, 128, 3)\n",
      "0.83651876\n",
      "[Epoch 0/10] [Batch 296/1081] [D loss: 2.793290] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 50.193562] time: 0:02:17.701197\n",
      "(10, 128, 128, 3)\n",
      "0.8499615\n",
      "[Epoch 0/10] [Batch 297/1081] [D loss: 2.785893] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 49.064964] time: 0:02:18.092550\n",
      "(10, 128, 128, 3)\n",
      "0.833455\n",
      "[Epoch 0/10] [Batch 298/1081] [D loss: 2.793199] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 49.705559] time: 0:02:18.516300\n",
      "(10, 128, 128, 3)\n",
      "0.8663009\n",
      "[Epoch 0/10] [Batch 299/1081] [D loss: 2.781888] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 50.498734] time: 0:02:18.911092\n",
      "(10, 128, 128, 3)\n",
      "0.82767874\n",
      "[Epoch 0/10] [Batch 300/1081] [D loss: 2.788172] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 48.803970] time: 0:02:19.284325\n",
      "(10, 128, 128, 3)\n",
      "0.8443056\n",
      "[Epoch 0/10] [Batch 301/1081] [D loss: 3.148272] [D acc: 0.45 (0.90 real, 0.00 fake)] [G loss: 48.461807] time: 0:02:19.691649\n",
      "(10, 128, 128, 3)\n",
      "0.82574177\n",
      "[Epoch 0/10] [Batch 302/1081] [D loss: 2.791528] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 49.891426] time: 0:02:20.111382\n",
      "(10, 128, 128, 3)\n",
      "0.81959325\n",
      "[Epoch 0/10] [Batch 303/1081] [D loss: 2.872541] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 49.680603] time: 0:02:20.517346\n",
      "(10, 128, 128, 3)\n",
      "0.88208133\n",
      "[Epoch 0/10] [Batch 304/1081] [D loss: 2.785916] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 49.970245] time: 0:02:20.920906\n",
      "(10, 128, 128, 3)\n",
      "0.80316764\n",
      "[Epoch 0/10] [Batch 305/1081] [D loss: 2.807912] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 48.860001] time: 0:02:21.310282\n",
      "(10, 128, 128, 3)\n",
      "0.8447831\n",
      "[Epoch 0/10] [Batch 306/1081] [D loss: 2.781806] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 49.670334] time: 0:02:21.719199\n",
      "(10, 128, 128, 3)\n",
      "0.83742046\n",
      "[Epoch 0/10] [Batch 307/1081] [D loss: 2.805048] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 49.446796] time: 0:02:22.111446\n",
      "(10, 128, 128, 3)\n",
      "0.86540514\n",
      "[Epoch 0/10] [Batch 308/1081] [D loss: 2.773598] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 49.139954] time: 0:02:22.513633\n",
      "(10, 128, 128, 3)\n",
      "0.8421356\n",
      "[Epoch 0/10] [Batch 309/1081] [D loss: 2.803994] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 48.754982] time: 0:02:22.925481\n",
      "(10, 128, 128, 3)\n",
      "0.8361613\n",
      "[Epoch 0/10] [Batch 310/1081] [D loss: 2.782667] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 49.610027] time: 0:02:23.349792\n",
      "(10, 128, 128, 3)\n",
      "0.82319736\n",
      "[Epoch 0/10] [Batch 311/1081] [D loss: 2.772209] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 49.688770] time: 0:02:23.752370\n",
      "(10, 128, 128, 3)\n",
      "0.85529286\n",
      "[Epoch 0/10] [Batch 312/1081] [D loss: 2.780847] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 49.433666] time: 0:02:24.155699\n",
      "(10, 128, 128, 3)\n",
      "0.8721614\n",
      "[Epoch 0/10] [Batch 313/1081] [D loss: 2.763568] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 49.004501] time: 0:02:24.600295\n",
      "(10, 128, 128, 3)\n",
      "0.8586132\n",
      "[Epoch 0/10] [Batch 314/1081] [D loss: 2.765495] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 50.023289] time: 0:02:25.024814\n",
      "(10, 128, 128, 3)\n",
      "0.82713383\n",
      "[Epoch 0/10] [Batch 315/1081] [D loss: 2.771909] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 49.441666] time: 0:02:25.435134\n",
      "(10, 128, 128, 3)\n",
      "0.8097941\n",
      "[Epoch 0/10] [Batch 316/1081] [D loss: 2.779482] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 48.318855] time: 0:02:25.847886\n",
      "(10, 128, 128, 3)\n",
      "0.8244481\n",
      "[Epoch 0/10] [Batch 317/1081] [D loss: 2.764734] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 48.438221] time: 0:02:26.264601\n",
      "(10, 128, 128, 3)\n",
      "0.80044913\n",
      "[Epoch 0/10] [Batch 318/1081] [D loss: 2.766346] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 48.867275] time: 0:02:26.704990\n",
      "(10, 128, 128, 3)\n",
      "0.8363293\n",
      "[Epoch 0/10] [Batch 319/1081] [D loss: 2.774634] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.957085] time: 0:02:27.110776\n",
      "(10, 128, 128, 3)\n",
      "0.8197946\n",
      "[Epoch 0/10] [Batch 320/1081] [D loss: 2.770348] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 49.303268] time: 0:02:27.519170\n",
      "(10, 128, 128, 3)\n",
      "0.82777053\n",
      "[Epoch 0/10] [Batch 321/1081] [D loss: 2.764323] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 48.295509] time: 0:02:27.945336\n",
      "(10, 128, 128, 3)\n",
      "0.86166936\n",
      "[Epoch 0/10] [Batch 322/1081] [D loss: 2.762169] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 48.978733] time: 0:02:28.367047\n",
      "(10, 128, 128, 3)\n",
      "0.7766299\n",
      "[Epoch 0/10] [Batch 323/1081] [D loss: 2.754998] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 48.312187] time: 0:02:28.781911\n",
      "(10, 128, 128, 3)\n",
      "0.8415312\n",
      "[Epoch 0/10] [Batch 324/1081] [D loss: 2.756152] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 49.233635] time: 0:02:29.198222\n",
      "(10, 128, 128, 3)\n",
      "0.8206083\n",
      "[Epoch 0/10] [Batch 325/1081] [D loss: 2.765540] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.876976] time: 0:02:29.617898\n",
      "(10, 128, 128, 3)\n",
      "0.84163165\n",
      "[Epoch 0/10] [Batch 326/1081] [D loss: 2.755089] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.604984] time: 0:02:30.042515\n",
      "(10, 128, 128, 3)\n",
      "0.8105786\n",
      "[Epoch 0/10] [Batch 327/1081] [D loss: 2.752823] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 48.688591] time: 0:02:30.438144\n",
      "(10, 128, 128, 3)\n",
      "0.88810176\n",
      "[Epoch 0/10] [Batch 328/1081] [D loss: 2.749821] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 49.104668] time: 0:02:30.855472\n",
      "(10, 128, 128, 3)\n",
      "0.82865196\n",
      "[Epoch 0/10] [Batch 329/1081] [D loss: 2.746027] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 48.330643] time: 0:02:31.286909\n",
      "(10, 128, 128, 3)\n",
      "0.84290075\n",
      "[Epoch 0/10] [Batch 330/1081] [D loss: 2.743890] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 48.496460] time: 0:02:31.695203\n",
      "(10, 128, 128, 3)\n",
      "0.852252\n",
      "[Epoch 0/10] [Batch 331/1081] [D loss: 2.744892] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.892921] time: 0:02:32.113588\n",
      "(10, 128, 128, 3)\n",
      "0.828358\n",
      "[Epoch 0/10] [Batch 332/1081] [D loss: 2.743809] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 48.257336] time: 0:02:32.545288\n",
      "(10, 128, 128, 3)\n",
      "0.8675031\n",
      "[Epoch 0/10] [Batch 333/1081] [D loss: 2.744149] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 48.500408] time: 0:02:32.952573\n",
      "(10, 128, 128, 3)\n",
      "0.87319833\n",
      "[Epoch 0/10] [Batch 334/1081] [D loss: 2.742616] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 48.056648] time: 0:02:33.386864\n",
      "(10, 128, 128, 3)\n",
      "0.8673134\n",
      "[Epoch 0/10] [Batch 335/1081] [D loss: 2.739856] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.994701] time: 0:02:33.790195\n",
      "(10, 128, 128, 3)\n",
      "0.9130287\n",
      "[Epoch 0/10] [Batch 336/1081] [D loss: 2.739476] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 48.421337] time: 0:02:34.191075\n",
      "(10, 128, 128, 3)\n",
      "0.8240015\n",
      "[Epoch 0/10] [Batch 337/1081] [D loss: 2.736095] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 48.081558] time: 0:02:34.606777\n",
      "(10, 128, 128, 3)\n",
      "0.80305547\n",
      "[Epoch 0/10] [Batch 338/1081] [D loss: 2.738344] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 48.795155] time: 0:02:35.043172\n",
      "(10, 128, 128, 3)\n",
      "0.8287506\n",
      "[Epoch 0/10] [Batch 339/1081] [D loss: 2.733828] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.927631] time: 0:02:35.460968\n",
      "(10, 128, 128, 3)\n",
      "0.8351492\n",
      "[Epoch 0/10] [Batch 340/1081] [D loss: 2.733600] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 48.406441] time: 0:02:35.855453\n",
      "(10, 128, 128, 3)\n",
      "0.87889236\n",
      "[Epoch 0/10] [Batch 341/1081] [D loss: 2.730845] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.817001] time: 0:02:36.267584\n",
      "(10, 128, 128, 3)\n",
      "0.8205178\n",
      "[Epoch 0/10] [Batch 342/1081] [D loss: 2.731214] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.700706] time: 0:02:36.711741\n",
      "(10, 128, 128, 3)\n",
      "0.8775892\n",
      "[Epoch 0/10] [Batch 343/1081] [D loss: 2.731649] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 48.408009] time: 0:02:37.146940\n",
      "(10, 128, 128, 3)\n",
      "0.85400534\n",
      "[Epoch 0/10] [Batch 344/1081] [D loss: 2.731600] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.147602] time: 0:02:37.639092\n",
      "(10, 128, 128, 3)\n",
      "0.8189133\n",
      "[Epoch 0/10] [Batch 345/1081] [D loss: 2.728100] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.603558] time: 0:02:38.095037\n",
      "(10, 128, 128, 3)\n",
      "0.8346785\n",
      "[Epoch 0/10] [Batch 346/1081] [D loss: 2.725560] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 48.232769] time: 0:02:38.568984\n",
      "(10, 128, 128, 3)\n",
      "0.8481601\n",
      "[Epoch 0/10] [Batch 347/1081] [D loss: 2.724256] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.549110] time: 0:02:39.037973\n",
      "(10, 128, 128, 3)\n",
      "0.828311\n",
      "[Epoch 0/10] [Batch 348/1081] [D loss: 2.725388] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.184540] time: 0:02:39.524243\n",
      "(10, 128, 128, 3)\n",
      "0.84539\n",
      "[Epoch 0/10] [Batch 349/1081] [D loss: 2.723085] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.374352] time: 0:02:40.006307\n",
      "(10, 128, 128, 3)\n",
      "0.8494041\n",
      "[Epoch 0/10] [Batch 350/1081] [D loss: 2.719823] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.147438] time: 0:02:40.483060\n",
      "(10, 128, 128, 3)\n",
      "0.88055015\n",
      "[Epoch 0/10] [Batch 351/1081] [D loss: 2.719131] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.717571] time: 0:02:40.980346\n",
      "(10, 128, 128, 3)\n",
      "0.84590214\n",
      "[Epoch 0/10] [Batch 352/1081] [D loss: 2.725644] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.892521] time: 0:02:41.450340\n",
      "(10, 128, 128, 3)\n",
      "0.81798667\n",
      "[Epoch 0/10] [Batch 353/1081] [D loss: 2.721105] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 48.892113] time: 0:02:41.944296\n",
      "(10, 128, 128, 3)\n",
      "0.84566146\n",
      "[Epoch 0/10] [Batch 354/1081] [D loss: 2.715637] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.040131] time: 0:02:42.405150\n",
      "(10, 128, 128, 3)\n",
      "0.8427007\n",
      "[Epoch 0/10] [Batch 355/1081] [D loss: 2.716421] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.949570] time: 0:02:42.873798\n",
      "(10, 128, 128, 3)\n",
      "0.8036079\n",
      "[Epoch 0/10] [Batch 356/1081] [D loss: 2.718761] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.339012] time: 0:02:43.374357\n",
      "(10, 128, 128, 3)\n",
      "0.9204066\n",
      "[Epoch 0/10] [Batch 357/1081] [D loss: 2.709556] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 46.359180] time: 0:02:43.858740\n",
      "(10, 128, 128, 3)\n",
      "0.8386483\n",
      "[Epoch 0/10] [Batch 358/1081] [D loss: 2.711087] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 46.966843] time: 0:02:44.334276\n",
      "(10, 128, 128, 3)\n",
      "0.8303108\n",
      "[Epoch 0/10] [Batch 359/1081] [D loss: 2.709355] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 46.716034] time: 0:02:44.840820\n",
      "(10, 128, 128, 3)\n",
      "0.84723353\n",
      "[Epoch 0/10] [Batch 360/1081] [D loss: 2.706797] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 46.579773] time: 0:02:45.336804\n",
      "(10, 128, 128, 3)\n",
      "0.8350193\n",
      "[Epoch 0/10] [Batch 361/1081] [D loss: 2.708761] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.321571] time: 0:02:45.867988\n",
      "(10, 128, 128, 3)\n",
      "0.838891\n",
      "[Epoch 0/10] [Batch 362/1081] [D loss: 2.705177] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 46.777973] time: 0:02:46.364215\n",
      "(10, 128, 128, 3)\n",
      "0.8458864\n",
      "[Epoch 0/10] [Batch 363/1081] [D loss: 2.704831] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.737240] time: 0:02:46.881197\n",
      "(10, 128, 128, 3)\n",
      "0.8527821\n",
      "[Epoch 0/10] [Batch 364/1081] [D loss: 2.706494] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.228809] time: 0:02:47.381665\n",
      "(10, 128, 128, 3)\n",
      "0.7500805\n",
      "[Epoch 0/10] [Batch 365/1081] [D loss: 2.708896] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 46.459911] time: 0:02:47.855866\n",
      "(10, 128, 128, 3)\n",
      "0.8557255\n",
      "[Epoch 0/10] [Batch 366/1081] [D loss: 2.701529] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 46.115761] time: 0:02:48.348906\n",
      "(10, 128, 128, 3)\n",
      "0.87711364\n",
      "[Epoch 0/10] [Batch 367/1081] [D loss: 2.697878] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 46.960396] time: 0:02:48.850389\n",
      "(10, 128, 128, 3)\n",
      "0.8572111\n",
      "[Epoch 0/10] [Batch 368/1081] [D loss: 2.702058] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.289581] time: 0:02:49.365080\n",
      "(10, 128, 128, 3)\n",
      "0.87737733\n",
      "[Epoch 0/10] [Batch 369/1081] [D loss: 2.695423] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 46.962547] time: 0:02:49.851370\n",
      "(10, 128, 128, 3)\n",
      "0.88988894\n",
      "[Epoch 0/10] [Batch 370/1081] [D loss: 2.694561] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.060341] time: 0:02:50.328578\n",
      "(10, 128, 128, 3)\n",
      "0.8540435\n",
      "[Epoch 0/10] [Batch 371/1081] [D loss: 2.693265] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 46.224590] time: 0:02:50.821238\n",
      "(10, 128, 128, 3)\n",
      "0.8884771\n",
      "[Epoch 0/10] [Batch 372/1081] [D loss: 2.692563] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.777580] time: 0:02:51.293346\n",
      "(10, 128, 128, 3)\n",
      "0.87290627\n",
      "[Epoch 0/10] [Batch 373/1081] [D loss: 2.693853] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.170723] time: 0:02:51.772215\n",
      "(10, 128, 128, 3)\n",
      "0.8870104\n",
      "[Epoch 0/10] [Batch 374/1081] [D loss: 2.695491] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.818478] time: 0:02:52.241869\n",
      "(10, 128, 128, 3)\n",
      "0.82295924\n",
      "[Epoch 0/10] [Batch 375/1081] [D loss: 2.687706] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 46.716354] time: 0:02:52.734236\n",
      "(10, 128, 128, 3)\n",
      "0.8919733\n",
      "[Epoch 0/10] [Batch 376/1081] [D loss: 2.686980] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 46.972420] time: 0:02:53.212233\n",
      "(10, 128, 128, 3)\n",
      "0.90148705\n",
      "[Epoch 0/10] [Batch 377/1081] [D loss: 2.684236] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 46.020111] time: 0:02:53.682339\n",
      "(10, 128, 128, 3)\n",
      "0.8603359\n",
      "[Epoch 0/10] [Batch 378/1081] [D loss: 2.684943] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.917717] time: 0:02:54.150532\n",
      "(10, 128, 128, 3)\n",
      "0.85959405\n",
      "[Epoch 0/10] [Batch 379/1081] [D loss: 2.682598] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 46.135975] time: 0:02:54.671694\n",
      "(10, 128, 128, 3)\n",
      "0.87450534\n",
      "[Epoch 0/10] [Batch 380/1081] [D loss: 2.682287] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.061848] time: 0:02:55.178883\n",
      "(10, 128, 128, 3)\n",
      "0.78094524\n",
      "[Epoch 0/10] [Batch 381/1081] [D loss: 2.680029] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.829918] time: 0:02:55.684024\n",
      "(10, 128, 128, 3)\n",
      "0.8422017\n",
      "[Epoch 0/10] [Batch 382/1081] [D loss: 2.678749] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 46.525711] time: 0:02:56.170416\n",
      "(10, 128, 128, 3)\n",
      "0.8031154\n",
      "[Epoch 0/10] [Batch 383/1081] [D loss: 2.679055] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.358559] time: 0:02:56.635535\n",
      "(10, 128, 128, 3)\n",
      "0.8549215\n",
      "[Epoch 0/10] [Batch 384/1081] [D loss: 2.676612] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.301025] time: 0:02:57.158337\n",
      "(10, 128, 128, 3)\n",
      "0.8456759\n",
      "[Epoch 0/10] [Batch 385/1081] [D loss: 2.674774] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 46.324287] time: 0:02:57.654000\n",
      "(10, 128, 128, 3)\n",
      "0.8513704\n",
      "[Epoch 0/10] [Batch 386/1081] [D loss: 2.676822] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.851532] time: 0:02:58.133328\n",
      "(10, 128, 128, 3)\n",
      "0.86534005\n",
      "[Epoch 0/10] [Batch 387/1081] [D loss: 2.673098] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 47.012108] time: 0:02:58.623383\n",
      "(10, 128, 128, 3)\n",
      "0.8596789\n",
      "[Epoch 0/10] [Batch 388/1081] [D loss: 2.672383] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 46.581299] time: 0:02:59.108584\n",
      "(10, 128, 128, 3)\n",
      "0.8429453\n",
      "[Epoch 0/10] [Batch 389/1081] [D loss: 2.669321] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.301125] time: 0:02:59.606386\n",
      "(10, 128, 128, 3)\n",
      "0.89474064\n",
      "[Epoch 0/10] [Batch 390/1081] [D loss: 2.668648] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.529381] time: 0:03:00.094816\n",
      "(10, 128, 128, 3)\n",
      "0.85505885\n",
      "[Epoch 0/10] [Batch 391/1081] [D loss: 2.667144] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 46.286095] time: 0:03:00.576569\n",
      "(10, 128, 128, 3)\n",
      "0.8699214\n",
      "[Epoch 0/10] [Batch 392/1081] [D loss: 2.665562] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.939747] time: 0:03:01.042709\n",
      "(10, 128, 128, 3)\n",
      "0.8739445\n",
      "[Epoch 0/10] [Batch 393/1081] [D loss: 2.668263] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.380890] time: 0:03:01.520688\n",
      "(10, 128, 128, 3)\n",
      "0.8386974\n",
      "[Epoch 0/10] [Batch 394/1081] [D loss: 2.664830] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.587368] time: 0:03:02.003983\n",
      "(10, 128, 128, 3)\n",
      "0.85185814\n",
      "[Epoch 0/10] [Batch 395/1081] [D loss: 2.662662] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 46.078560] time: 0:03:02.530445\n",
      "(10, 128, 128, 3)\n",
      "0.8778148\n",
      "[Epoch 0/10] [Batch 396/1081] [D loss: 2.663327] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.012596] time: 0:03:03.007729\n",
      "(10, 128, 128, 3)\n",
      "0.89816093\n",
      "[Epoch 0/10] [Batch 397/1081] [D loss: 2.661202] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 46.557060] time: 0:03:03.498191\n",
      "(10, 128, 128, 3)\n",
      "0.86164504\n",
      "[Epoch 0/10] [Batch 398/1081] [D loss: 2.660993] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.813393] time: 0:03:03.978758\n",
      "(10, 128, 128, 3)\n",
      "0.83162016\n",
      "[Epoch 0/10] [Batch 399/1081] [D loss: 2.656611] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.166901] time: 0:03:04.478424\n",
      "(10, 128, 128, 3)\n",
      "0.8737383\n",
      "[Epoch 0/10] [Batch 400/1081] [D loss: 2.655567] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.391525] time: 0:03:04.959737\n",
      "(10, 128, 128, 3)\n",
      "0.8599486\n",
      "[Epoch 0/10] [Batch 401/1081] [D loss: 2.653398] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.230530] time: 0:03:05.441304\n",
      "(10, 128, 128, 3)\n",
      "0.7977777\n",
      "[Epoch 0/10] [Batch 402/1081] [D loss: 2.655725] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.513000] time: 0:03:05.950526\n",
      "(10, 128, 128, 3)\n",
      "0.8055332\n",
      "[Epoch 0/10] [Batch 403/1081] [D loss: 2.651189] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.404362] time: 0:03:06.434281\n",
      "(10, 128, 128, 3)\n",
      "0.8763462\n",
      "[Epoch 0/10] [Batch 404/1081] [D loss: 2.651555] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.599815] time: 0:03:06.908257\n",
      "(10, 128, 128, 3)\n",
      "0.82577705\n",
      "[Epoch 0/10] [Batch 405/1081] [D loss: 2.648419] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 46.605545] time: 0:03:07.386564\n",
      "(10, 128, 128, 3)\n",
      "0.8294482\n",
      "[Epoch 0/10] [Batch 406/1081] [D loss: 2.646967] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.573536] time: 0:03:07.872663\n",
      "(10, 128, 128, 3)\n",
      "0.83672696\n",
      "[Epoch 0/10] [Batch 407/1081] [D loss: 2.654616] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.907955] time: 0:03:08.368936\n",
      "(10, 128, 128, 3)\n",
      "0.8646975\n",
      "[Epoch 0/10] [Batch 408/1081] [D loss: 2.647276] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.467422] time: 0:03:08.873549\n",
      "(10, 128, 128, 3)\n",
      "0.85892457\n",
      "[Epoch 0/10] [Batch 409/1081] [D loss: 2.643626] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 46.336693] time: 0:03:09.393964\n",
      "(10, 128, 128, 3)\n",
      "0.82811326\n",
      "[Epoch 0/10] [Batch 410/1081] [D loss: 2.644252] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.855873] time: 0:03:09.865800\n",
      "(10, 128, 128, 3)\n",
      "0.86894387\n",
      "[Epoch 0/10] [Batch 411/1081] [D loss: 2.639962] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 46.389339] time: 0:03:10.369619\n",
      "(10, 128, 128, 3)\n",
      "0.88689035\n",
      "[Epoch 0/10] [Batch 412/1081] [D loss: 2.640011] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.934395] time: 0:03:10.842430\n",
      "(10, 128, 128, 3)\n",
      "0.85554266\n",
      "[Epoch 0/10] [Batch 413/1081] [D loss: 2.637616] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.373466] time: 0:03:11.338465\n",
      "(10, 128, 128, 3)\n",
      "0.84539604\n",
      "[Epoch 0/10] [Batch 414/1081] [D loss: 2.640119] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.382561] time: 0:03:11.853555\n",
      "(10, 128, 128, 3)\n",
      "0.8826217\n",
      "[Epoch 0/10] [Batch 415/1081] [D loss: 2.639013] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.384460] time: 0:03:12.365129\n",
      "(10, 128, 128, 3)\n",
      "0.86451125\n",
      "[Epoch 0/10] [Batch 416/1081] [D loss: 2.634632] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.627666] time: 0:03:12.858227\n",
      "(10, 128, 128, 3)\n",
      "0.7969911\n",
      "[Epoch 0/10] [Batch 417/1081] [D loss: 2.632810] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.409439] time: 0:03:13.338608\n",
      "(10, 128, 128, 3)\n",
      "0.873916\n",
      "[Epoch 0/10] [Batch 418/1081] [D loss: 2.633645] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.216732] time: 0:03:13.810097\n",
      "(10, 128, 128, 3)\n",
      "0.8135678\n",
      "[Epoch 0/10] [Batch 419/1081] [D loss: 2.629616] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.196659] time: 0:03:14.312219\n",
      "(10, 128, 128, 3)\n",
      "0.9006582\n",
      "[Epoch 0/10] [Batch 420/1081] [D loss: 2.628401] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.127735] time: 0:03:14.793690\n",
      "(10, 128, 128, 3)\n",
      "0.86271405\n",
      "[Epoch 0/10] [Batch 421/1081] [D loss: 2.627267] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.193748] time: 0:03:15.276011\n",
      "(10, 128, 128, 3)\n",
      "0.86475784\n",
      "[Epoch 0/10] [Batch 422/1081] [D loss: 2.637168] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.963413] time: 0:03:15.749368\n",
      "(10, 128, 128, 3)\n",
      "0.86941314\n",
      "[Epoch 0/10] [Batch 423/1081] [D loss: 2.624093] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.421696] time: 0:03:16.231995\n",
      "(10, 128, 128, 3)\n",
      "0.8582237\n",
      "[Epoch 0/10] [Batch 424/1081] [D loss: 2.628440] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.859211] time: 0:03:16.719486\n",
      "(10, 128, 128, 3)\n",
      "0.8488805\n",
      "[Epoch 0/10] [Batch 425/1081] [D loss: 2.622433] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.173508] time: 0:03:17.204621\n",
      "(10, 128, 128, 3)\n",
      "0.8918626\n",
      "[Epoch 0/10] [Batch 426/1081] [D loss: 2.621368] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.176323] time: 0:03:17.680402\n",
      "(10, 128, 128, 3)\n",
      "0.90724057\n",
      "[Epoch 0/10] [Batch 427/1081] [D loss: 2.619588] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 45.222733] time: 0:03:18.173393\n",
      "(10, 128, 128, 3)\n",
      "0.8436863\n",
      "[Epoch 0/10] [Batch 428/1081] [D loss: 2.618019] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.483955] time: 0:03:18.644343\n",
      "(10, 128, 128, 3)\n",
      "0.88753533\n",
      "[Epoch 0/10] [Batch 429/1081] [D loss: 2.615823] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.383640] time: 0:03:19.127956\n",
      "(10, 128, 128, 3)\n",
      "0.8995278\n",
      "[Epoch 0/10] [Batch 430/1081] [D loss: 2.614333] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.342369] time: 0:03:19.624330\n",
      "(10, 128, 128, 3)\n",
      "0.90967685\n",
      "[Epoch 0/10] [Batch 431/1081] [D loss: 2.614453] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.199402] time: 0:03:20.154119\n",
      "(10, 128, 128, 3)\n",
      "0.8473547\n",
      "[Epoch 0/10] [Batch 432/1081] [D loss: 2.617475] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.264198] time: 0:03:20.656860\n",
      "(10, 128, 128, 3)\n",
      "0.85222095\n",
      "[Epoch 0/10] [Batch 433/1081] [D loss: 2.612290] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.443356] time: 0:03:21.144540\n",
      "(10, 128, 128, 3)\n",
      "0.9078533\n",
      "[Epoch 0/10] [Batch 434/1081] [D loss: 2.609913] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.521667] time: 0:03:21.616060\n",
      "(10, 128, 128, 3)\n",
      "0.7892141\n",
      "[Epoch 0/10] [Batch 435/1081] [D loss: 2.611609] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.786987] time: 0:03:22.129175\n",
      "(10, 128, 128, 3)\n",
      "0.8551422\n",
      "[Epoch 0/10] [Batch 436/1081] [D loss: 2.628097] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.272453] time: 0:03:22.634180\n",
      "(10, 128, 128, 3)\n",
      "0.88966656\n",
      "[Epoch 0/10] [Batch 437/1081] [D loss: 2.612228] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.495514] time: 0:03:23.128389\n",
      "(10, 128, 128, 3)\n",
      "0.8655121\n",
      "[Epoch 0/10] [Batch 438/1081] [D loss: 2.603957] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.892303] time: 0:03:23.606085\n",
      "(10, 128, 128, 3)\n",
      "0.895123\n",
      "[Epoch 0/10] [Batch 439/1081] [D loss: 2.603176] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.975853] time: 0:03:24.119594\n",
      "(10, 128, 128, 3)\n",
      "0.90762424\n",
      "[Epoch 0/10] [Batch 440/1081] [D loss: 2.600534] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.148064] time: 0:03:24.602907\n",
      "(10, 128, 128, 3)\n",
      "0.874427\n",
      "[Epoch 0/10] [Batch 441/1081] [D loss: 2.600141] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.766972] time: 0:03:25.087278\n",
      "(10, 128, 128, 3)\n",
      "0.91262704\n",
      "[Epoch 0/10] [Batch 442/1081] [D loss: 2.601776] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.226593] time: 0:03:25.549206\n",
      "(10, 128, 128, 3)\n",
      "0.92653745\n",
      "[Epoch 0/10] [Batch 443/1081] [D loss: 2.598474] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.211372] time: 0:03:26.055520\n",
      "(10, 128, 128, 3)\n",
      "0.82557696\n",
      "[Epoch 0/10] [Batch 444/1081] [D loss: 2.595278] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.748562] time: 0:03:26.551553\n",
      "(10, 128, 128, 3)\n",
      "0.90504736\n",
      "[Epoch 0/10] [Batch 445/1081] [D loss: 2.594889] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.300690] time: 0:03:27.051134\n",
      "(10, 128, 128, 3)\n",
      "0.855948\n",
      "[Epoch 0/10] [Batch 446/1081] [D loss: 2.597206] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.783302] time: 0:03:27.536055\n",
      "(10, 128, 128, 3)\n",
      "0.8143978\n",
      "[Epoch 0/10] [Batch 447/1081] [D loss: 2.591608] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.837036] time: 0:03:28.030451\n",
      "(10, 128, 128, 3)\n",
      "0.8674281\n",
      "[Epoch 0/10] [Batch 448/1081] [D loss: 2.589706] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.305214] time: 0:03:28.532720\n",
      "(10, 128, 128, 3)\n",
      "0.8298382\n",
      "[Epoch 0/10] [Batch 449/1081] [D loss: 2.589266] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.983406] time: 0:03:29.066106\n",
      "(10, 128, 128, 3)\n",
      "0.8744059\n",
      "[Epoch 0/10] [Batch 450/1081] [D loss: 2.587510] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.775257] time: 0:03:29.541219\n",
      "(10, 128, 128, 3)\n",
      "0.9172408\n",
      "[Epoch 0/10] [Batch 451/1081] [D loss: 2.587746] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.418076] time: 0:03:30.040223\n",
      "(10, 128, 128, 3)\n",
      "0.90181947\n",
      "[Epoch 0/10] [Batch 452/1081] [D loss: 2.589242] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.645199] time: 0:03:30.513787\n",
      "(10, 128, 128, 3)\n",
      "0.86904836\n",
      "[Epoch 0/10] [Batch 453/1081] [D loss: 2.583578] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.001640] time: 0:03:31.001228\n",
      "(10, 128, 128, 3)\n",
      "0.8532352\n",
      "[Epoch 0/10] [Batch 454/1081] [D loss: 2.582950] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.663246] time: 0:03:31.520723\n",
      "(10, 128, 128, 3)\n",
      "0.8314614\n",
      "[Epoch 0/10] [Batch 455/1081] [D loss: 2.582519] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.966499] time: 0:03:32.013274\n",
      "(10, 128, 128, 3)\n",
      "0.8295202\n",
      "[Epoch 0/10] [Batch 456/1081] [D loss: 2.579868] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 44.299900] time: 0:03:32.497642\n",
      "(10, 128, 128, 3)\n",
      "0.8271993\n",
      "[Epoch 0/10] [Batch 457/1081] [D loss: 2.579955] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.727776] time: 0:03:32.965274\n",
      "(10, 128, 128, 3)\n",
      "0.8790331\n",
      "[Epoch 0/10] [Batch 458/1081] [D loss: 2.578790] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.095417] time: 0:03:33.466525\n",
      "(10, 128, 128, 3)\n",
      "0.93608457\n",
      "[Epoch 0/10] [Batch 459/1081] [D loss: 2.573888] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.646011] time: 0:03:33.984961\n",
      "(10, 128, 128, 3)\n",
      "0.82958156\n",
      "[Epoch 0/10] [Batch 460/1081] [D loss: 2.578850] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.875172] time: 0:03:34.503224\n",
      "(10, 128, 128, 3)\n",
      "0.9048989\n",
      "[Epoch 0/10] [Batch 461/1081] [D loss: 2.573671] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.244755] time: 0:03:35.022345\n",
      "(10, 128, 128, 3)\n",
      "0.8878229\n",
      "[Epoch 0/10] [Batch 462/1081] [D loss: 2.571888] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.695419] time: 0:03:35.523777\n",
      "(10, 128, 128, 3)\n",
      "0.8517735\n",
      "[Epoch 0/10] [Batch 463/1081] [D loss: 2.569677] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.635117] time: 0:03:35.996746\n",
      "(10, 128, 128, 3)\n",
      "0.7988727\n",
      "[Epoch 0/10] [Batch 464/1081] [D loss: 2.568833] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.905781] time: 0:03:36.492896\n",
      "(10, 128, 128, 3)\n",
      "0.8429136\n",
      "[Epoch 0/10] [Batch 465/1081] [D loss: 2.566574] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.020569] time: 0:03:37.002374\n",
      "(10, 128, 128, 3)\n",
      "0.80364037\n",
      "[Epoch 0/10] [Batch 466/1081] [D loss: 2.564368] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.108639] time: 0:03:37.509758\n",
      "(10, 128, 128, 3)\n",
      "0.8337903\n",
      "[Epoch 0/10] [Batch 467/1081] [D loss: 2.572891] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.271164] time: 0:03:38.015340\n",
      "(10, 128, 128, 3)\n",
      "0.8487323\n",
      "[Epoch 0/10] [Batch 468/1081] [D loss: 2.569013] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.746155] time: 0:03:38.505809\n",
      "(10, 128, 128, 3)\n",
      "0.8833243\n",
      "[Epoch 0/10] [Batch 469/1081] [D loss: 2.561419] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.680401] time: 0:03:38.987387\n",
      "(10, 128, 128, 3)\n",
      "0.8257347\n",
      "[Epoch 0/10] [Batch 470/1081] [D loss: 2.559223] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.940350] time: 0:03:39.478000\n",
      "(10, 128, 128, 3)\n",
      "0.8402397\n",
      "[Epoch 0/10] [Batch 471/1081] [D loss: 2.557746] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.354347] time: 0:03:39.991078\n",
      "(10, 128, 128, 3)\n",
      "0.8836581\n",
      "[Epoch 0/10] [Batch 472/1081] [D loss: 2.556703] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.595402] time: 0:03:40.515735\n",
      "(10, 128, 128, 3)\n",
      "0.87022185\n",
      "[Epoch 0/10] [Batch 473/1081] [D loss: 2.555104] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.777161] time: 0:03:41.022448\n",
      "(10, 128, 128, 3)\n",
      "0.8135939\n",
      "[Epoch 0/10] [Batch 474/1081] [D loss: 2.552580] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.893013] time: 0:03:41.511344\n",
      "(10, 128, 128, 3)\n",
      "0.86861354\n",
      "[Epoch 0/10] [Batch 475/1081] [D loss: 2.551008] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.489571] time: 0:03:42.026373\n",
      "(10, 128, 128, 3)\n",
      "0.90979296\n",
      "[Epoch 0/10] [Batch 476/1081] [D loss: 2.550132] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.700932] time: 0:03:42.520091\n",
      "(10, 128, 128, 3)\n",
      "0.8880829\n",
      "[Epoch 0/10] [Batch 477/1081] [D loss: 2.549284] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.637997] time: 0:03:42.996662\n",
      "(10, 128, 128, 3)\n",
      "0.87891704\n",
      "[Epoch 0/10] [Batch 478/1081] [D loss: 2.547768] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.964691] time: 0:03:43.505870\n",
      "(10, 128, 128, 3)\n",
      "0.84832716\n",
      "[Epoch 0/10] [Batch 479/1081] [D loss: 2.558215] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.443085] time: 0:03:44.007773\n",
      "(10, 128, 128, 3)\n",
      "0.9349329\n",
      "[Epoch 0/10] [Batch 480/1081] [D loss: 2.545123] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.509300] time: 0:03:44.498294\n",
      "(10, 128, 128, 3)\n",
      "0.82228047\n",
      "[Epoch 0/10] [Batch 481/1081] [D loss: 2.545215] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.559120] time: 0:03:44.981110\n",
      "(10, 128, 128, 3)\n",
      "0.8840305\n",
      "[Epoch 0/10] [Batch 482/1081] [D loss: 2.542244] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.754745] time: 0:03:45.456341\n",
      "(10, 128, 128, 3)\n",
      "0.8887119\n",
      "[Epoch 0/10] [Batch 483/1081] [D loss: 2.540855] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.322464] time: 0:03:45.942348\n",
      "(10, 128, 128, 3)\n",
      "0.8059748\n",
      "[Epoch 0/10] [Batch 484/1081] [D loss: 2.539477] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.636208] time: 0:03:46.447975\n",
      "(10, 128, 128, 3)\n",
      "0.86708754\n",
      "[Epoch 0/10] [Batch 485/1081] [D loss: 2.537363] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.458607] time: 0:03:46.920733\n",
      "(10, 128, 128, 3)\n",
      "0.88614804\n",
      "[Epoch 0/10] [Batch 486/1081] [D loss: 2.536250] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.528351] time: 0:03:47.398365\n",
      "(10, 128, 128, 3)\n",
      "0.8392973\n",
      "[Epoch 0/10] [Batch 487/1081] [D loss: 2.540742] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.661324] time: 0:03:47.898884\n",
      "(10, 128, 128, 3)\n",
      "0.87668914\n",
      "[Epoch 0/10] [Batch 488/1081] [D loss: 2.533618] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.610939] time: 0:03:48.389966\n",
      "(10, 128, 128, 3)\n",
      "0.88908035\n",
      "[Epoch 0/10] [Batch 489/1081] [D loss: 2.532769] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.427208] time: 0:03:48.869115\n",
      "(10, 128, 128, 3)\n",
      "0.8521628\n",
      "[Epoch 0/10] [Batch 490/1081] [D loss: 2.529899] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.063736] time: 0:03:49.350434\n",
      "(10, 128, 128, 3)\n",
      "0.90070415\n",
      "[Epoch 0/10] [Batch 491/1081] [D loss: 2.530478] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.100861] time: 0:03:49.855494\n",
      "(10, 128, 128, 3)\n",
      "0.8916366\n",
      "[Epoch 0/10] [Batch 492/1081] [D loss: 2.530813] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.849022] time: 0:03:50.330577\n",
      "(10, 128, 128, 3)\n",
      "0.8860342\n",
      "[Epoch 0/10] [Batch 493/1081] [D loss: 2.527558] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.454208] time: 0:03:50.804694\n",
      "(10, 128, 128, 3)\n",
      "0.8731873\n",
      "[Epoch 0/10] [Batch 494/1081] [D loss: 2.524848] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.080120] time: 0:03:51.284616\n",
      "(10, 128, 128, 3)\n",
      "0.8395276\n",
      "[Epoch 0/10] [Batch 495/1081] [D loss: 2.527286] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 43.005859] time: 0:03:51.764525\n",
      "(10, 128, 128, 3)\n",
      "0.87862617\n",
      "[Epoch 0/10] [Batch 496/1081] [D loss: 2.523260] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.608883] time: 0:03:52.262100\n",
      "(10, 128, 128, 3)\n",
      "0.88761425\n",
      "[Epoch 0/10] [Batch 497/1081] [D loss: 2.522191] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.597717] time: 0:03:52.763818\n",
      "(10, 128, 128, 3)\n",
      "0.85856724\n",
      "[Epoch 0/10] [Batch 498/1081] [D loss: 2.520558] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.979210] time: 0:03:53.289833\n",
      "(10, 128, 128, 3)\n",
      "0.8467703\n",
      "[Epoch 0/10] [Batch 499/1081] [D loss: 2.518230] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.105064] time: 0:03:53.803797\n",
      "(10, 128, 128, 3)\n",
      "0.85893863\n",
      "[Epoch 0/10] [Batch 500/1081] [D loss: 2.516980] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.745327] time: 0:03:54.315227\n",
      "(10, 128, 128, 3)\n",
      "0.8752772\n",
      "[Epoch 0/10] [Batch 501/1081] [D loss: 2.516220] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.417412] time: 0:03:54.830031\n",
      "(10, 128, 128, 3)\n",
      "0.8833949\n",
      "[Epoch 0/10] [Batch 502/1081] [D loss: 2.516713] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.644676] time: 0:03:55.311292\n",
      "(10, 128, 128, 3)\n",
      "0.8836711\n",
      "[Epoch 0/10] [Batch 503/1081] [D loss: 2.516269] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.491417] time: 0:03:55.787224\n",
      "(10, 128, 128, 3)\n",
      "0.91245437\n",
      "[Epoch 0/10] [Batch 504/1081] [D loss: 2.511617] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.827961] time: 0:03:56.271045\n",
      "(10, 128, 128, 3)\n",
      "0.86654574\n",
      "[Epoch 0/10] [Batch 505/1081] [D loss: 2.511658] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.642082] time: 0:03:56.759233\n",
      "(10, 128, 128, 3)\n",
      "0.8603242\n",
      "[Epoch 0/10] [Batch 506/1081] [D loss: 2.509112] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.071201] time: 0:03:57.236097\n",
      "(10, 128, 128, 3)\n",
      "0.89435744\n",
      "[Epoch 0/10] [Batch 507/1081] [D loss: 2.505747] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.711487] time: 0:03:57.731928\n",
      "(10, 128, 128, 3)\n",
      "0.85951334\n",
      "[Epoch 0/10] [Batch 508/1081] [D loss: 2.505718] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.825974] time: 0:03:58.227845\n",
      "(10, 128, 128, 3)\n",
      "0.89572185\n",
      "[Epoch 0/10] [Batch 509/1081] [D loss: 2.502290] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.522354] time: 0:03:58.732361\n",
      "(10, 128, 128, 3)\n",
      "0.8711893\n",
      "[Epoch 0/10] [Batch 510/1081] [D loss: 2.500636] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.870003] time: 0:03:59.236313\n",
      "(10, 128, 128, 3)\n",
      "0.88454574\n",
      "[Epoch 0/10] [Batch 511/1081] [D loss: 2.500040] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.141502] time: 0:03:59.726431\n",
      "(10, 128, 128, 3)\n",
      "0.8391979\n",
      "[Epoch 0/10] [Batch 512/1081] [D loss: 2.499018] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.202751] time: 0:04:00.214567\n",
      "(10, 128, 128, 3)\n",
      "0.85312396\n",
      "[Epoch 0/10] [Batch 513/1081] [D loss: 2.496821] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.149117] time: 0:04:00.728042\n",
      "(10, 128, 128, 3)\n",
      "0.8819222\n",
      "[Epoch 0/10] [Batch 514/1081] [D loss: 2.496459] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.646828] time: 0:04:01.240314\n",
      "(10, 128, 128, 3)\n",
      "0.8747863\n",
      "[Epoch 0/10] [Batch 515/1081] [D loss: 2.494236] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.133774] time: 0:04:01.736472\n",
      "(10, 128, 128, 3)\n",
      "0.84253186\n",
      "[Epoch 0/10] [Batch 516/1081] [D loss: 2.492903] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.449535] time: 0:04:02.225637\n",
      "(10, 128, 128, 3)\n",
      "0.82565635\n",
      "[Epoch 0/10] [Batch 517/1081] [D loss: 2.491104] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.145084] time: 0:04:02.737649\n",
      "(10, 128, 128, 3)\n",
      "0.876126\n",
      "[Epoch 0/10] [Batch 518/1081] [D loss: 2.489421] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.040604] time: 0:04:03.214383\n",
      "(10, 128, 128, 3)\n",
      "0.9021204\n",
      "[Epoch 0/10] [Batch 519/1081] [D loss: 2.487905] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.664543] time: 0:04:03.749834\n",
      "(10, 128, 128, 3)\n",
      "0.907404\n",
      "[Epoch 0/10] [Batch 520/1081] [D loss: 2.489522] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.335667] time: 0:04:04.221983\n",
      "(10, 128, 128, 3)\n",
      "0.85453576\n",
      "[Epoch 0/10] [Batch 521/1081] [D loss: 2.486852] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.232899] time: 0:04:04.714427\n",
      "(10, 128, 128, 3)\n",
      "0.8415806\n",
      "[Epoch 0/10] [Batch 522/1081] [D loss: 2.484602] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.231094] time: 0:04:05.216560\n",
      "(10, 128, 128, 3)\n",
      "0.894965\n",
      "[Epoch 0/10] [Batch 523/1081] [D loss: 2.487636] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.830265] time: 0:04:05.700759\n",
      "(10, 128, 128, 3)\n",
      "0.84910315\n",
      "[Epoch 0/10] [Batch 524/1081] [D loss: 2.481032] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.626030] time: 0:04:06.197339\n",
      "(10, 128, 128, 3)\n",
      "0.80082273\n",
      "[Epoch 0/10] [Batch 525/1081] [D loss: 2.657623] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 42.947342] time: 0:04:06.671286\n",
      "(10, 128, 128, 3)\n",
      "0.86871433\n",
      "[Epoch 0/10] [Batch 526/1081] [D loss: 2.694940] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 41.546146] time: 0:04:07.157292\n",
      "(10, 128, 128, 3)\n",
      "0.8603862\n",
      "[Epoch 0/10] [Batch 527/1081] [D loss: 2.781379] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 42.520164] time: 0:04:07.673489\n",
      "(10, 128, 128, 3)\n",
      "0.8747435\n",
      "[Epoch 0/10] [Batch 528/1081] [D loss: 2.529277] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.195087] time: 0:04:08.183061\n",
      "(10, 128, 128, 3)\n",
      "0.90316993\n",
      "[Epoch 0/10] [Batch 529/1081] [D loss: 2.486956] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.893730] time: 0:04:08.669414\n",
      "(10, 128, 128, 3)\n",
      "0.83659196\n",
      "[Epoch 0/10] [Batch 530/1081] [D loss: 2.480911] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.782684] time: 0:04:09.130454\n",
      "(10, 128, 128, 3)\n",
      "0.86160535\n",
      "[Epoch 0/10] [Batch 531/1081] [D loss: 2.475672] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.243374] time: 0:04:09.636730\n",
      "(10, 128, 128, 3)\n",
      "0.80003023\n",
      "[Epoch 0/10] [Batch 532/1081] [D loss: 2.476238] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.421841] time: 0:04:10.127524\n",
      "(10, 128, 128, 3)\n",
      "0.8780475\n",
      "[Epoch 0/10] [Batch 533/1081] [D loss: 2.509584] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.147720] time: 0:04:10.656117\n",
      "(10, 128, 128, 3)\n",
      "0.91828877\n",
      "[Epoch 0/10] [Batch 534/1081] [D loss: 2.468460] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.515896] time: 0:04:11.145529\n",
      "(10, 128, 128, 3)\n",
      "0.8510725\n",
      "[Epoch 0/10] [Batch 535/1081] [D loss: 2.473096] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.239357] time: 0:04:11.653100\n",
      "(10, 128, 128, 3)\n",
      "0.8802373\n",
      "[Epoch 0/10] [Batch 536/1081] [D loss: 2.469413] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 42.329590] time: 0:04:12.133124\n",
      "(10, 128, 128, 3)\n",
      "0.92408353\n",
      "[Epoch 0/10] [Batch 537/1081] [D loss: 2.462936] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.173668] time: 0:04:12.648495\n",
      "(10, 128, 128, 3)\n",
      "0.8377635\n",
      "[Epoch 0/10] [Batch 538/1081] [D loss: 2.461655] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.039204] time: 0:04:13.141463\n",
      "(10, 128, 128, 3)\n",
      "0.85535955\n",
      "[Epoch 0/10] [Batch 539/1081] [D loss: 2.463002] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.445160] time: 0:04:13.675636\n",
      "(10, 128, 128, 3)\n",
      "0.87131006\n",
      "[Epoch 0/10] [Batch 540/1081] [D loss: 2.458537] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.880650] time: 0:04:14.209247\n",
      "(10, 128, 128, 3)\n",
      "0.85440284\n",
      "[Epoch 0/10] [Batch 541/1081] [D loss: 2.457591] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.123814] time: 0:04:14.719563\n",
      "(10, 128, 128, 3)\n",
      "0.8717199\n",
      "[Epoch 0/10] [Batch 542/1081] [D loss: 2.454753] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.930157] time: 0:04:15.191392\n",
      "(10, 128, 128, 3)\n",
      "0.84639406\n",
      "[Epoch 0/10] [Batch 543/1081] [D loss: 2.454718] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.935043] time: 0:04:15.670284\n",
      "(10, 128, 128, 3)\n",
      "0.89175445\n",
      "[Epoch 0/10] [Batch 544/1081] [D loss: 2.451822] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.821854] time: 0:04:16.190515\n",
      "(10, 128, 128, 3)\n",
      "0.87800604\n",
      "[Epoch 0/10] [Batch 545/1081] [D loss: 2.452722] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.068764] time: 0:04:16.689613\n",
      "(10, 128, 128, 3)\n",
      "0.85508394\n",
      "[Epoch 0/10] [Batch 546/1081] [D loss: 2.449647] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.369381] time: 0:04:17.197684\n",
      "(10, 128, 128, 3)\n",
      "0.90689874\n",
      "[Epoch 0/10] [Batch 547/1081] [D loss: 2.450511] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.077579] time: 0:04:17.703237\n",
      "(10, 128, 128, 3)\n",
      "0.8667311\n",
      "[Epoch 0/10] [Batch 548/1081] [D loss: 2.446383] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.768360] time: 0:04:18.225606\n",
      "(10, 128, 128, 3)\n",
      "0.88256043\n",
      "[Epoch 0/10] [Batch 549/1081] [D loss: 2.446583] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.549568] time: 0:04:18.726485\n",
      "(10, 128, 128, 3)\n",
      "0.8639675\n",
      "[Epoch 0/10] [Batch 550/1081] [D loss: 2.445764] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.945282] time: 0:04:19.216751\n",
      "(10, 128, 128, 3)\n",
      "0.8554404\n",
      "[Epoch 0/10] [Batch 551/1081] [D loss: 2.442750] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.800407] time: 0:04:19.728092\n",
      "(10, 128, 128, 3)\n",
      "0.86511153\n",
      "[Epoch 0/10] [Batch 552/1081] [D loss: 2.448251] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.850189] time: 0:04:20.201826\n",
      "(10, 128, 128, 3)\n",
      "0.89441794\n",
      "[Epoch 0/10] [Batch 553/1081] [D loss: 2.439057] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.871883] time: 0:04:20.706235\n",
      "(10, 128, 128, 3)\n",
      "0.8885014\n",
      "[Epoch 0/10] [Batch 554/1081] [D loss: 2.437115] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.825451] time: 0:04:21.199582\n",
      "(10, 128, 128, 3)\n",
      "0.83366865\n",
      "[Epoch 0/10] [Batch 555/1081] [D loss: 2.457380] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.286224] time: 0:04:21.684702\n",
      "(10, 128, 128, 3)\n",
      "0.9071254\n",
      "[Epoch 0/10] [Batch 556/1081] [D loss: 2.457904] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.702934] time: 0:04:22.178565\n",
      "(10, 128, 128, 3)\n",
      "0.8108926\n",
      "[Epoch 0/10] [Batch 557/1081] [D loss: 2.441097] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.580448] time: 0:04:22.670440\n",
      "(10, 128, 128, 3)\n",
      "0.8402657\n",
      "[Epoch 0/10] [Batch 558/1081] [D loss: 2.434930] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.844330] time: 0:04:23.154937\n",
      "(10, 128, 128, 3)\n",
      "0.8308323\n",
      "[Epoch 0/10] [Batch 559/1081] [D loss: 2.430516] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.725685] time: 0:04:23.653247\n",
      "(10, 128, 128, 3)\n",
      "0.83956975\n",
      "[Epoch 0/10] [Batch 560/1081] [D loss: 2.435340] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.419624] time: 0:04:24.176545\n",
      "(10, 128, 128, 3)\n",
      "0.8580176\n",
      "[Epoch 0/10] [Batch 561/1081] [D loss: 2.430005] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.238045] time: 0:04:24.657580\n",
      "(10, 128, 128, 3)\n",
      "0.9201439\n",
      "[Epoch 0/10] [Batch 562/1081] [D loss: 2.425765] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.570953] time: 0:04:25.140744\n",
      "(10, 128, 128, 3)\n",
      "0.9024146\n",
      "[Epoch 0/10] [Batch 563/1081] [D loss: 2.423770] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.964058] time: 0:04:25.621431\n",
      "(10, 128, 128, 3)\n",
      "0.875942\n",
      "[Epoch 0/10] [Batch 564/1081] [D loss: 2.425738] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.880360] time: 0:04:26.126168\n",
      "(10, 128, 128, 3)\n",
      "0.87650657\n",
      "[Epoch 0/10] [Batch 565/1081] [D loss: 2.424351] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.124222] time: 0:04:26.626127\n",
      "(10, 128, 128, 3)\n",
      "0.90648395\n",
      "[Epoch 0/10] [Batch 566/1081] [D loss: 2.423911] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.462193] time: 0:04:27.128965\n",
      "(10, 128, 128, 3)\n",
      "0.84812975\n",
      "[Epoch 0/10] [Batch 567/1081] [D loss: 2.428109] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.612499] time: 0:04:27.606218\n",
      "(10, 128, 128, 3)\n",
      "0.89862174\n",
      "[Epoch 0/10] [Batch 568/1081] [D loss: 2.417396] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.195580] time: 0:04:28.089698\n",
      "(10, 128, 128, 3)\n",
      "0.93120384\n",
      "[Epoch 0/10] [Batch 569/1081] [D loss: 2.416849] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.532825] time: 0:04:28.573744\n",
      "(10, 128, 128, 3)\n",
      "0.9019943\n",
      "[Epoch 0/10] [Batch 570/1081] [D loss: 2.414317] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.342354] time: 0:04:29.081788\n",
      "(10, 128, 128, 3)\n",
      "0.905911\n",
      "[Epoch 0/10] [Batch 571/1081] [D loss: 2.412028] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.324848] time: 0:04:29.569959\n",
      "(10, 128, 128, 3)\n",
      "0.79960555\n",
      "[Epoch 0/10] [Batch 572/1081] [D loss: 2.411406] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.860512] time: 0:04:30.071698\n",
      "(10, 128, 128, 3)\n",
      "0.87835884\n",
      "[Epoch 0/10] [Batch 573/1081] [D loss: 2.408416] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.069267] time: 0:04:30.559061\n",
      "(10, 128, 128, 3)\n",
      "0.86786366\n",
      "[Epoch 0/10] [Batch 574/1081] [D loss: 2.407766] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.820557] time: 0:04:31.088076\n",
      "(10, 128, 128, 3)\n",
      "0.8779842\n",
      "[Epoch 0/10] [Batch 575/1081] [D loss: 2.405794] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.545189] time: 0:04:31.634414\n",
      "(10, 128, 128, 3)\n",
      "0.8696871\n",
      "[Epoch 0/10] [Batch 576/1081] [D loss: 2.526179] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 39.470444] time: 0:04:32.126097\n",
      "(10, 128, 128, 3)\n",
      "0.89155704\n",
      "[Epoch 0/10] [Batch 577/1081] [D loss: 2.461839] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.642838] time: 0:04:32.622099\n",
      "(10, 128, 128, 3)\n",
      "0.8992744\n",
      "[Epoch 0/10] [Batch 578/1081] [D loss: 2.403125] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.706837] time: 0:04:33.114102\n",
      "(10, 128, 128, 3)\n",
      "0.88517386\n",
      "[Epoch 0/10] [Batch 579/1081] [D loss: 2.608812] [D acc: 0.65 (1.00 real, 0.30 fake)] [G loss: 39.366692] time: 0:04:33.600046\n",
      "(10, 128, 128, 3)\n",
      "0.8857107\n",
      "[Epoch 0/10] [Batch 580/1081] [D loss: 2.419714] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.073219] time: 0:04:34.098548\n",
      "(10, 128, 128, 3)\n",
      "0.84210783\n",
      "[Epoch 0/10] [Batch 581/1081] [D loss: 2.401869] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.648624] time: 0:04:34.608380\n",
      "(10, 128, 128, 3)\n",
      "0.919527\n",
      "[Epoch 0/10] [Batch 582/1081] [D loss: 2.405043] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.333839] time: 0:04:35.098403\n",
      "(10, 128, 128, 3)\n",
      "0.8983614\n",
      "[Epoch 0/10] [Batch 583/1081] [D loss: 2.398546] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.815079] time: 0:04:35.624643\n",
      "(10, 128, 128, 3)\n",
      "0.903871\n",
      "[Epoch 0/10] [Batch 584/1081] [D loss: 2.395917] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.537823] time: 0:04:36.149132\n",
      "(10, 128, 128, 3)\n",
      "0.9159065\n",
      "[Epoch 0/10] [Batch 585/1081] [D loss: 2.394049] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.734589] time: 0:04:36.640809\n",
      "(10, 128, 128, 3)\n",
      "0.8539197\n",
      "[Epoch 0/10] [Batch 586/1081] [D loss: 2.396936] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.974312] time: 0:04:37.121473\n",
      "(10, 128, 128, 3)\n",
      "0.90847105\n",
      "[Epoch 0/10] [Batch 587/1081] [D loss: 2.393455] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 41.617416] time: 0:04:37.633591\n",
      "(10, 128, 128, 3)\n",
      "0.92067003\n",
      "[Epoch 0/10] [Batch 588/1081] [D loss: 2.389007] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.652569] time: 0:04:38.116328\n",
      "(10, 128, 128, 3)\n",
      "0.9440486\n",
      "[Epoch 0/10] [Batch 589/1081] [D loss: 2.385937] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.997684] time: 0:04:38.608082\n",
      "(10, 128, 128, 3)\n",
      "0.86303073\n",
      "[Epoch 0/10] [Batch 590/1081] [D loss: 2.470440] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.750702] time: 0:04:39.072714\n",
      "(10, 128, 128, 3)\n",
      "0.8868727\n",
      "[Epoch 0/10] [Batch 591/1081] [D loss: 2.395697] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.250885] time: 0:04:39.591027\n",
      "(10, 128, 128, 3)\n",
      "0.8433425\n",
      "[Epoch 0/10] [Batch 592/1081] [D loss: 2.392276] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.434837] time: 0:04:40.096367\n",
      "(10, 128, 128, 3)\n",
      "0.8872971\n",
      "[Epoch 0/10] [Batch 593/1081] [D loss: 2.388585] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.902557] time: 0:04:40.614446\n",
      "(10, 128, 128, 3)\n",
      "0.80617243\n",
      "[Epoch 0/10] [Batch 594/1081] [D loss: 2.380780] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.826263] time: 0:04:41.130017\n",
      "(10, 128, 128, 3)\n",
      "0.850995\n",
      "[Epoch 0/10] [Batch 595/1081] [D loss: 2.379341] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.305046] time: 0:04:41.643856\n",
      "(10, 128, 128, 3)\n",
      "0.91477275\n",
      "[Epoch 0/10] [Batch 596/1081] [D loss: 2.380576] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.198700] time: 0:04:42.148979\n",
      "(10, 128, 128, 3)\n",
      "0.8893781\n",
      "[Epoch 0/10] [Batch 597/1081] [D loss: 2.378555] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.396011] time: 0:04:42.630433\n",
      "(10, 128, 128, 3)\n",
      "0.8855985\n",
      "[Epoch 0/10] [Batch 598/1081] [D loss: 2.372469] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.034630] time: 0:04:43.112935\n",
      "(10, 128, 128, 3)\n",
      "0.93367535\n",
      "[Epoch 0/10] [Batch 599/1081] [D loss: 2.375990] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.013454] time: 0:04:43.598121\n",
      "(10, 128, 128, 3)\n",
      "0.808841\n",
      "[Epoch 0/10] [Batch 600/1081] [D loss: 2.370615] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.926876] time: 0:04:44.080840\n",
      "(10, 128, 128, 3)\n",
      "0.91966766\n",
      "[Epoch 0/10] [Batch 601/1081] [D loss: 2.368482] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.063637] time: 0:04:44.584015\n",
      "(10, 128, 128, 3)\n",
      "0.86056644\n",
      "[Epoch 0/10] [Batch 602/1081] [D loss: 2.370645] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.648438] time: 0:04:45.086695\n",
      "(10, 128, 128, 3)\n",
      "0.9299786\n",
      "[Epoch 0/10] [Batch 603/1081] [D loss: 2.363803] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.357185] time: 0:04:45.608848\n",
      "(10, 128, 128, 3)\n",
      "0.888033\n",
      "[Epoch 0/10] [Batch 604/1081] [D loss: 2.366435] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.066319] time: 0:04:46.091242\n",
      "(10, 128, 128, 3)\n",
      "0.8953374\n",
      "[Epoch 0/10] [Batch 605/1081] [D loss: 2.362038] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.803890] time: 0:04:46.588767\n",
      "(10, 128, 128, 3)\n",
      "0.87879056\n",
      "[Epoch 0/10] [Batch 606/1081] [D loss: 2.362315] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.405190] time: 0:04:47.139250\n",
      "(10, 128, 128, 3)\n",
      "0.89129144\n",
      "[Epoch 0/10] [Batch 607/1081] [D loss: 2.358899] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.044022] time: 0:04:47.676540\n",
      "(10, 128, 128, 3)\n",
      "0.90343857\n",
      "[Epoch 0/10] [Batch 608/1081] [D loss: 2.358632] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.775520] time: 0:04:48.210976\n",
      "(10, 128, 128, 3)\n",
      "0.8637597\n",
      "[Epoch 0/10] [Batch 609/1081] [D loss: 2.356212] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.402302] time: 0:04:48.679438\n",
      "(10, 128, 128, 3)\n",
      "0.8677134\n",
      "[Epoch 0/10] [Batch 610/1081] [D loss: 2.361423] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.683250] time: 0:04:49.202287\n",
      "(10, 128, 128, 3)\n",
      "0.8803722\n",
      "[Epoch 0/10] [Batch 611/1081] [D loss: 2.354556] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.309650] time: 0:04:49.717444\n",
      "(10, 128, 128, 3)\n",
      "0.92179465\n",
      "[Epoch 0/10] [Batch 612/1081] [D loss: 2.354218] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.575470] time: 0:04:50.221460\n",
      "(10, 128, 128, 3)\n",
      "0.9250467\n",
      "[Epoch 0/10] [Batch 613/1081] [D loss: 2.351994] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.886135] time: 0:04:50.731951\n",
      "(10, 128, 128, 3)\n",
      "0.9137697\n",
      "[Epoch 0/10] [Batch 614/1081] [D loss: 2.347095] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.293686] time: 0:04:51.253589\n",
      "(10, 128, 128, 3)\n",
      "0.9066391\n",
      "[Epoch 0/10] [Batch 615/1081] [D loss: 2.346806] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.688122] time: 0:04:51.777195\n",
      "(10, 128, 128, 3)\n",
      "0.8420162\n",
      "[Epoch 0/10] [Batch 616/1081] [D loss: 2.346359] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.715866] time: 0:04:52.291015\n",
      "(10, 128, 128, 3)\n",
      "0.8154092\n",
      "[Epoch 0/10] [Batch 617/1081] [D loss: 2.345392] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.210285] time: 0:04:52.802044\n",
      "(10, 128, 128, 3)\n",
      "0.8311661\n",
      "[Epoch 0/10] [Batch 618/1081] [D loss: 2.343344] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.910992] time: 0:04:53.309779\n",
      "(10, 128, 128, 3)\n",
      "0.8881397\n",
      "[Epoch 0/10] [Batch 619/1081] [D loss: 2.339372] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.779789] time: 0:04:53.811255\n",
      "(10, 128, 128, 3)\n",
      "0.86803293\n",
      "[Epoch 0/10] [Batch 620/1081] [D loss: 2.341516] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.529888] time: 0:04:54.271155\n",
      "(10, 128, 128, 3)\n",
      "0.8961603\n",
      "[Epoch 0/10] [Batch 621/1081] [D loss: 2.338696] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.303272] time: 0:04:54.777555\n",
      "(10, 128, 128, 3)\n",
      "0.8701098\n",
      "[Epoch 0/10] [Batch 622/1081] [D loss: 2.335792] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.516903] time: 0:04:55.282533\n",
      "(10, 128, 128, 3)\n",
      "0.8974013\n",
      "[Epoch 0/10] [Batch 623/1081] [D loss: 2.333361] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.515190] time: 0:04:55.785230\n",
      "(10, 128, 128, 3)\n",
      "0.879486\n",
      "[Epoch 0/10] [Batch 624/1081] [D loss: 2.330890] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.823959] time: 0:04:56.312260\n",
      "(10, 128, 128, 3)\n",
      "0.8185539\n",
      "[Epoch 0/10] [Batch 625/1081] [D loss: 2.330078] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.462215] time: 0:04:56.814284\n",
      "(10, 128, 128, 3)\n",
      "0.87554353\n",
      "[Epoch 0/10] [Batch 626/1081] [D loss: 2.328450] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.600780] time: 0:04:57.311422\n",
      "(10, 128, 128, 3)\n",
      "0.90745044\n",
      "[Epoch 0/10] [Batch 627/1081] [D loss: 2.327264] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.801048] time: 0:04:57.807247\n",
      "(10, 128, 128, 3)\n",
      "0.89583516\n",
      "[Epoch 0/10] [Batch 628/1081] [D loss: 2.346470] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.653427] time: 0:04:58.254192\n",
      "(10, 128, 128, 3)\n",
      "0.89281017\n",
      "[Epoch 0/10] [Batch 629/1081] [D loss: 2.327499] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.067474] time: 0:04:58.667272\n",
      "(10, 128, 128, 3)\n",
      "0.91999817\n",
      "[Epoch 0/10] [Batch 630/1081] [D loss: 2.321588] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.430367] time: 0:04:59.096554\n",
      "(10, 128, 128, 3)\n",
      "0.8622139\n",
      "[Epoch 0/10] [Batch 631/1081] [D loss: 2.321730] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.580429] time: 0:04:59.507462\n",
      "(10, 128, 128, 3)\n",
      "0.88055706\n",
      "[Epoch 0/10] [Batch 632/1081] [D loss: 2.321827] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.897003] time: 0:04:59.963532\n",
      "(10, 128, 128, 3)\n",
      "0.9267357\n",
      "[Epoch 0/10] [Batch 633/1081] [D loss: 2.321416] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.462097] time: 0:05:00.383797\n",
      "(10, 128, 128, 3)\n",
      "0.81590587\n",
      "[Epoch 0/10] [Batch 634/1081] [D loss: 2.317224] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.850555] time: 0:05:00.830023\n",
      "(10, 128, 128, 3)\n",
      "0.85166407\n",
      "[Epoch 0/10] [Batch 635/1081] [D loss: 2.314980] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.505989] time: 0:05:01.266919\n",
      "(10, 128, 128, 3)\n",
      "0.91059256\n",
      "[Epoch 0/10] [Batch 636/1081] [D loss: 2.312715] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.694572] time: 0:05:01.694594\n",
      "(10, 128, 128, 3)\n",
      "0.9140137\n",
      "[Epoch 0/10] [Batch 637/1081] [D loss: 2.311701] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.009388] time: 0:05:02.139785\n",
      "(10, 128, 128, 3)\n",
      "0.86157006\n",
      "[Epoch 0/10] [Batch 638/1081] [D loss: 2.310094] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.366413] time: 0:05:02.581363\n",
      "(10, 128, 128, 3)\n",
      "0.9010856\n",
      "[Epoch 0/10] [Batch 639/1081] [D loss: 2.308482] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.798584] time: 0:05:03.000802\n",
      "(10, 128, 128, 3)\n",
      "0.853638\n",
      "[Epoch 0/10] [Batch 640/1081] [D loss: 2.315968] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.044746] time: 0:05:03.446286\n",
      "(10, 128, 128, 3)\n",
      "0.8919234\n",
      "[Epoch 0/10] [Batch 641/1081] [D loss: 2.316556] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.019123] time: 0:05:03.866805\n",
      "(10, 128, 128, 3)\n",
      "0.8902196\n",
      "[Epoch 0/10] [Batch 642/1081] [D loss: 2.303650] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.996624] time: 0:05:04.308441\n",
      "(10, 128, 128, 3)\n",
      "0.87994266\n",
      "[Epoch 0/10] [Batch 643/1081] [D loss: 2.306189] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.500069] time: 0:05:04.733758\n",
      "(10, 128, 128, 3)\n",
      "0.8626483\n",
      "[Epoch 0/10] [Batch 644/1081] [D loss: 2.301513] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.324211] time: 0:05:05.178787\n",
      "(10, 128, 128, 3)\n",
      "0.89216167\n",
      "[Epoch 0/10] [Batch 645/1081] [D loss: 2.300615] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.965446] time: 0:05:05.621487\n",
      "(10, 128, 128, 3)\n",
      "0.85908645\n",
      "[Epoch 0/10] [Batch 646/1081] [D loss: 2.298889] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.612251] time: 0:05:06.030885\n",
      "(10, 128, 128, 3)\n",
      "0.91120696\n",
      "[Epoch 0/10] [Batch 647/1081] [D loss: 2.303290] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.863380] time: 0:05:06.476573\n",
      "(10, 128, 128, 3)\n",
      "0.8773913\n",
      "[Epoch 0/10] [Batch 648/1081] [D loss: 2.296984] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.792542] time: 0:05:06.887330\n",
      "(10, 128, 128, 3)\n",
      "0.8318796\n",
      "[Epoch 0/10] [Batch 649/1081] [D loss: 2.293260] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 40.103996] time: 0:05:07.329496\n",
      "(10, 128, 128, 3)\n",
      "0.8816522\n",
      "[Epoch 0/10] [Batch 650/1081] [D loss: 2.293969] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.992176] time: 0:05:07.748104\n",
      "(10, 128, 128, 3)\n",
      "0.9324276\n",
      "[Epoch 0/10] [Batch 651/1081] [D loss: 2.289531] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.373642] time: 0:05:08.210091\n",
      "(10, 128, 128, 3)\n",
      "0.8935156\n",
      "[Epoch 0/10] [Batch 652/1081] [D loss: 2.312800] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.793507] time: 0:05:08.631917\n",
      "(10, 128, 128, 3)\n",
      "0.93867946\n",
      "[Epoch 0/10] [Batch 653/1081] [D loss: 2.289244] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.433365] time: 0:05:09.061818\n",
      "(10, 128, 128, 3)\n",
      "0.8519806\n",
      "[Epoch 0/10] [Batch 654/1081] [D loss: 2.290285] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.093071] time: 0:05:09.503474\n",
      "(10, 128, 128, 3)\n",
      "0.858979\n",
      "[Epoch 0/10] [Batch 655/1081] [D loss: 2.286169] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.185501] time: 0:05:09.952475\n",
      "(10, 128, 128, 3)\n",
      "0.87699103\n",
      "[Epoch 0/10] [Batch 656/1081] [D loss: 2.288293] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.006439] time: 0:05:10.391413\n",
      "(10, 128, 128, 3)\n",
      "0.88765305\n",
      "[Epoch 0/10] [Batch 657/1081] [D loss: 2.283200] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.174232] time: 0:05:10.814967\n",
      "(10, 128, 128, 3)\n",
      "0.8885751\n",
      "[Epoch 0/10] [Batch 658/1081] [D loss: 2.280086] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.571846] time: 0:05:11.240684\n",
      "(10, 128, 128, 3)\n",
      "0.85535115\n",
      "[Epoch 0/10] [Batch 659/1081] [D loss: 2.283284] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.508823] time: 0:05:11.668073\n",
      "(10, 128, 128, 3)\n",
      "0.86088663\n",
      "[Epoch 0/10] [Batch 660/1081] [D loss: 2.277604] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.660030] time: 0:05:12.102857\n",
      "(10, 128, 128, 3)\n",
      "0.86389595\n",
      "[Epoch 0/10] [Batch 661/1081] [D loss: 2.274942] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.272846] time: 0:05:12.518197\n",
      "(10, 128, 128, 3)\n",
      "0.8954115\n",
      "[Epoch 0/10] [Batch 662/1081] [D loss: 2.273600] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.387352] time: 0:05:12.945156\n",
      "(10, 128, 128, 3)\n",
      "0.9281071\n",
      "[Epoch 0/10] [Batch 663/1081] [D loss: 2.271223] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.506943] time: 0:05:13.391606\n",
      "(10, 128, 128, 3)\n",
      "0.8643477\n",
      "[Epoch 0/10] [Batch 664/1081] [D loss: 2.271494] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.991104] time: 0:05:13.790059\n",
      "(10, 128, 128, 3)\n",
      "0.86739016\n",
      "[Epoch 0/10] [Batch 665/1081] [D loss: 2.269469] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.856323] time: 0:05:14.206968\n",
      "(10, 128, 128, 3)\n",
      "0.95437974\n",
      "[Epoch 0/10] [Batch 666/1081] [D loss: 2.271758] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.460495] time: 0:05:14.631299\n",
      "(10, 128, 128, 3)\n",
      "0.88333446\n",
      "[Epoch 0/10] [Batch 667/1081] [D loss: 2.265704] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.951740] time: 0:05:15.057692\n",
      "(10, 128, 128, 3)\n",
      "0.9054398\n",
      "[Epoch 0/10] [Batch 668/1081] [D loss: 2.264413] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.544117] time: 0:05:15.492025\n",
      "(10, 128, 128, 3)\n",
      "0.9050185\n",
      "[Epoch 0/10] [Batch 669/1081] [D loss: 2.265458] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.515972] time: 0:05:15.919546\n",
      "(10, 128, 128, 3)\n",
      "0.8954776\n",
      "[Epoch 0/10] [Batch 670/1081] [D loss: 2.262806] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.615829] time: 0:05:16.401882\n",
      "(10, 128, 128, 3)\n",
      "0.8989528\n",
      "[Epoch 0/10] [Batch 671/1081] [D loss: 2.258383] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.704346] time: 0:05:16.890398\n",
      "(10, 128, 128, 3)\n",
      "0.821938\n",
      "[Epoch 0/10] [Batch 672/1081] [D loss: 2.258290] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.821877] time: 0:05:17.378346\n",
      "(10, 128, 128, 3)\n",
      "0.8378956\n",
      "[Epoch 0/10] [Batch 673/1081] [D loss: 2.256489] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.048664] time: 0:05:17.882776\n",
      "(10, 128, 128, 3)\n",
      "0.8974692\n",
      "[Epoch 0/10] [Batch 674/1081] [D loss: 2.253991] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.754726] time: 0:05:18.412639\n",
      "(10, 128, 128, 3)\n",
      "0.89590544\n",
      "[Epoch 0/10] [Batch 675/1081] [D loss: 2.253953] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.705326] time: 0:05:18.921323\n",
      "(10, 128, 128, 3)\n",
      "0.8963778\n",
      "[Epoch 0/10] [Batch 676/1081] [D loss: 2.250821] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.876526] time: 0:05:19.441575\n",
      "(10, 128, 128, 3)\n",
      "0.8321225\n",
      "[Epoch 0/10] [Batch 677/1081] [D loss: 2.251240] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.965012] time: 0:05:19.934780\n",
      "(10, 128, 128, 3)\n",
      "0.86611956\n",
      "[Epoch 0/10] [Batch 678/1081] [D loss: 2.248675] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.012360] time: 0:05:20.442946\n",
      "(10, 128, 128, 3)\n",
      "0.8936233\n",
      "[Epoch 0/10] [Batch 679/1081] [D loss: 2.250247] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.883724] time: 0:05:20.967582\n",
      "(10, 128, 128, 3)\n",
      "0.8810021\n",
      "[Epoch 0/10] [Batch 680/1081] [D loss: 2.246297] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.076138] time: 0:05:21.493462\n",
      "(10, 128, 128, 3)\n",
      "0.93543595\n",
      "[Epoch 0/10] [Batch 681/1081] [D loss: 2.243061] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.476486] time: 0:05:21.966765\n",
      "(10, 128, 128, 3)\n",
      "0.90629977\n",
      "[Epoch 0/10] [Batch 682/1081] [D loss: 2.243755] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.619003] time: 0:05:22.448231\n",
      "(10, 128, 128, 3)\n",
      "0.7990138\n",
      "[Epoch 0/10] [Batch 683/1081] [D loss: 2.240737] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.372826] time: 0:05:22.944626\n",
      "(10, 128, 128, 3)\n",
      "0.88721675\n",
      "[Epoch 0/10] [Batch 684/1081] [D loss: 2.237677] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.454266] time: 0:05:23.465578\n",
      "(10, 128, 128, 3)\n",
      "0.88814086\n",
      "[Epoch 0/10] [Batch 685/1081] [D loss: 2.237960] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.785698] time: 0:05:23.972638\n",
      "(10, 128, 128, 3)\n",
      "0.89076066\n",
      "[Epoch 0/10] [Batch 686/1081] [D loss: 2.234328] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.242516] time: 0:05:24.468463\n",
      "(10, 128, 128, 3)\n",
      "0.94413066\n",
      "[Epoch 0/10] [Batch 687/1081] [D loss: 2.234576] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.602509] time: 0:05:24.982883\n",
      "(10, 128, 128, 3)\n",
      "0.8947467\n",
      "[Epoch 0/10] [Batch 688/1081] [D loss: 2.231442] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.881027] time: 0:05:25.495106\n",
      "(10, 128, 128, 3)\n",
      "0.93552786\n",
      "[Epoch 0/10] [Batch 689/1081] [D loss: 2.230840] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.862587] time: 0:05:26.024847\n",
      "(10, 128, 128, 3)\n",
      "0.86373216\n",
      "[Epoch 0/10] [Batch 690/1081] [D loss: 2.228067] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.464001] time: 0:05:26.506719\n",
      "(10, 128, 128, 3)\n",
      "0.84905845\n",
      "[Epoch 0/10] [Batch 691/1081] [D loss: 2.227189] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.485542] time: 0:05:26.992611\n",
      "(10, 128, 128, 3)\n",
      "0.90376306\n",
      "[Epoch 0/10] [Batch 692/1081] [D loss: 2.229067] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.447449] time: 0:05:27.490830\n",
      "(10, 128, 128, 3)\n",
      "0.86621976\n",
      "[Epoch 0/10] [Batch 693/1081] [D loss: 2.223973] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.752968] time: 0:05:27.993466\n",
      "(10, 128, 128, 3)\n",
      "0.9124844\n",
      "[Epoch 0/10] [Batch 694/1081] [D loss: 2.223464] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.609192] time: 0:05:28.500666\n",
      "(10, 128, 128, 3)\n",
      "0.9399326\n",
      "[Epoch 0/10] [Batch 695/1081] [D loss: 2.220586] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.572994] time: 0:05:29.025543\n",
      "(10, 128, 128, 3)\n",
      "0.87219644\n",
      "[Epoch 0/10] [Batch 696/1081] [D loss: 2.218886] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.068943] time: 0:05:29.500544\n",
      "(10, 128, 128, 3)\n",
      "0.87804824\n",
      "[Epoch 0/10] [Batch 697/1081] [D loss: 2.217537] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.020813] time: 0:05:29.973059\n",
      "(10, 128, 128, 3)\n",
      "0.8915737\n",
      "[Epoch 0/10] [Batch 698/1081] [D loss: 2.215666] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.627476] time: 0:05:30.486002\n",
      "(10, 128, 128, 3)\n",
      "0.9096965\n",
      "[Epoch 0/10] [Batch 699/1081] [D loss: 2.213397] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.540276] time: 0:05:30.981132\n",
      "(10, 128, 128, 3)\n",
      "0.8289452\n",
      "[Epoch 0/10] [Batch 700/1081] [D loss: 2.211809] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.651615] time: 0:05:31.485331\n",
      "(10, 128, 128, 3)\n",
      "0.87717456\n",
      "[Epoch 0/10] [Batch 701/1081] [D loss: 2.210515] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.534595] time: 0:05:31.972592\n",
      "(10, 128, 128, 3)\n",
      "0.8836972\n",
      "[Epoch 0/10] [Batch 702/1081] [D loss: 2.208761] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.144592] time: 0:05:32.464449\n",
      "(10, 128, 128, 3)\n",
      "0.86229485\n",
      "[Epoch 0/10] [Batch 703/1081] [D loss: 2.207751] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.581051] time: 0:05:32.988265\n",
      "(10, 128, 128, 3)\n",
      "0.9175796\n",
      "[Epoch 0/10] [Batch 704/1081] [D loss: 2.206834] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.408154] time: 0:05:33.499779\n",
      "(10, 128, 128, 3)\n",
      "0.9047313\n",
      "[Epoch 0/10] [Batch 705/1081] [D loss: 2.204552] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.132759] time: 0:05:34.008011\n",
      "(10, 128, 128, 3)\n",
      "0.9136801\n",
      "[Epoch 0/10] [Batch 706/1081] [D loss: 2.202349] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.812279] time: 0:05:34.482226\n",
      "(10, 128, 128, 3)\n",
      "0.8906924\n",
      "[Epoch 0/10] [Batch 707/1081] [D loss: 2.202902] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.180973] time: 0:05:35.015141\n",
      "(10, 128, 128, 3)\n",
      "0.83329064\n",
      "[Epoch 0/10] [Batch 708/1081] [D loss: 2.200082] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.404926] time: 0:05:35.511612\n",
      "(10, 128, 128, 3)\n",
      "0.91208047\n",
      "[Epoch 0/10] [Batch 709/1081] [D loss: 2.198321] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 38.011078] time: 0:05:36.026908\n",
      "(10, 128, 128, 3)\n",
      "0.90908426\n",
      "[Epoch 0/10] [Batch 710/1081] [D loss: 2.196862] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.890263] time: 0:05:36.503080\n",
      "(10, 128, 128, 3)\n",
      "0.8823356\n",
      "[Epoch 0/10] [Batch 711/1081] [D loss: 2.194344] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.330021] time: 0:05:37.010189\n",
      "(10, 128, 128, 3)\n",
      "0.92648476\n",
      "[Epoch 0/10] [Batch 712/1081] [D loss: 2.194364] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.507240] time: 0:05:37.476746\n",
      "(10, 128, 128, 3)\n",
      "0.8797715\n",
      "[Epoch 0/10] [Batch 713/1081] [D loss: 2.191256] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.671150] time: 0:05:37.979058\n",
      "(10, 128, 128, 3)\n",
      "0.9182252\n",
      "[Epoch 0/10] [Batch 714/1081] [D loss: 2.192253] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.391262] time: 0:05:38.451560\n",
      "(10, 128, 128, 3)\n",
      "0.88822645\n",
      "[Epoch 0/10] [Batch 715/1081] [D loss: 2.188350] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.136322] time: 0:05:38.967820\n",
      "(10, 128, 128, 3)\n",
      "0.89426804\n",
      "[Epoch 0/10] [Batch 716/1081] [D loss: 2.188873] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.406136] time: 0:05:39.471853\n",
      "(10, 128, 128, 3)\n",
      "0.8847327\n",
      "[Epoch 0/10] [Batch 717/1081] [D loss: 2.185851] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.114933] time: 0:05:39.922854\n",
      "(10, 128, 128, 3)\n",
      "0.8848491\n",
      "[Epoch 0/10] [Batch 718/1081] [D loss: 2.183768] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.607803] time: 0:05:40.415673\n",
      "(10, 128, 128, 3)\n",
      "0.9266353\n",
      "[Epoch 0/10] [Batch 719/1081] [D loss: 2.181899] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.627342] time: 0:05:40.902706\n",
      "(10, 128, 128, 3)\n",
      "0.8782234\n",
      "[Epoch 0/10] [Batch 720/1081] [D loss: 2.180424] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.783623] time: 0:05:41.420905\n",
      "(10, 128, 128, 3)\n",
      "0.8939759\n",
      "[Epoch 0/10] [Batch 721/1081] [D loss: 2.178816] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.395569] time: 0:05:41.930648\n",
      "(10, 128, 128, 3)\n",
      "0.867043\n",
      "[Epoch 0/10] [Batch 722/1081] [D loss: 2.178306] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.702305] time: 0:05:42.417584\n",
      "(10, 128, 128, 3)\n",
      "0.86583966\n",
      "[Epoch 0/10] [Batch 723/1081] [D loss: 2.176553] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.808311] time: 0:05:42.923540\n",
      "(10, 128, 128, 3)\n",
      "0.8611875\n",
      "[Epoch 0/10] [Batch 724/1081] [D loss: 2.174131] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.940506] time: 0:05:43.415581\n",
      "(10, 128, 128, 3)\n",
      "0.8950005\n",
      "[Epoch 0/10] [Batch 725/1081] [D loss: 2.172195] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.429169] time: 0:05:43.949263\n",
      "(10, 128, 128, 3)\n",
      "0.8582163\n",
      "[Epoch 0/10] [Batch 726/1081] [D loss: 2.170977] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.446457] time: 0:05:44.454566\n",
      "(10, 128, 128, 3)\n",
      "0.8169277\n",
      "[Epoch 0/10] [Batch 727/1081] [D loss: 2.169420] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.913944] time: 0:05:44.972890\n",
      "(10, 128, 128, 3)\n",
      "0.92369336\n",
      "[Epoch 0/10] [Batch 728/1081] [D loss: 2.168022] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.045444] time: 0:05:45.474442\n",
      "(10, 128, 128, 3)\n",
      "0.9218008\n",
      "[Epoch 0/10] [Batch 729/1081] [D loss: 2.167146] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.750015] time: 0:05:45.934683\n",
      "(10, 128, 128, 3)\n",
      "0.9111951\n",
      "[Epoch 0/10] [Batch 730/1081] [D loss: 2.167315] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.893669] time: 0:05:46.433048\n",
      "(10, 128, 128, 3)\n",
      "0.8997238\n",
      "[Epoch 0/10] [Batch 731/1081] [D loss: 2.164766] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.711777] time: 0:05:46.934554\n",
      "(10, 128, 128, 3)\n",
      "0.9157631\n",
      "[Epoch 0/10] [Batch 732/1081] [D loss: 2.163026] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.284405] time: 0:05:47.407510\n",
      "(10, 128, 128, 3)\n",
      "0.86488014\n",
      "[Epoch 0/10] [Batch 733/1081] [D loss: 2.160431] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.214451] time: 0:05:47.886762\n",
      "(10, 128, 128, 3)\n",
      "0.8576119\n",
      "[Epoch 0/10] [Batch 734/1081] [D loss: 2.160090] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.485512] time: 0:05:48.378411\n",
      "(10, 128, 128, 3)\n",
      "0.7912819\n",
      "[Epoch 0/10] [Batch 735/1081] [D loss: 2.157539] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.661255] time: 0:05:48.887824\n",
      "(10, 128, 128, 3)\n",
      "0.8581276\n",
      "[Epoch 0/10] [Batch 736/1081] [D loss: 2.155476] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.269760] time: 0:05:49.374083\n",
      "(10, 128, 128, 3)\n",
      "0.9134979\n",
      "[Epoch 0/10] [Batch 737/1081] [D loss: 2.153514] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.658794] time: 0:05:49.872711\n",
      "(10, 128, 128, 3)\n",
      "0.88039523\n",
      "[Epoch 0/10] [Batch 738/1081] [D loss: 2.152195] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.326172] time: 0:05:50.353369\n",
      "(10, 128, 128, 3)\n",
      "0.8027485\n",
      "[Epoch 0/10] [Batch 739/1081] [D loss: 2.151910] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.629936] time: 0:05:50.855554\n",
      "(10, 128, 128, 3)\n",
      "0.8402836\n",
      "[Epoch 0/10] [Batch 740/1081] [D loss: 2.152360] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.606537] time: 0:05:51.351866\n",
      "(10, 128, 128, 3)\n",
      "0.89756745\n",
      "[Epoch 0/10] [Batch 741/1081] [D loss: 2.146678] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.390755] time: 0:05:51.857019\n",
      "(10, 128, 128, 3)\n",
      "0.90316004\n",
      "[Epoch 0/10] [Batch 742/1081] [D loss: 2.149432] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.851780] time: 0:05:52.380173\n",
      "(10, 128, 128, 3)\n",
      "0.88099986\n",
      "[Epoch 0/10] [Batch 743/1081] [D loss: 2.143982] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.880756] time: 0:05:52.906405\n",
      "(10, 128, 128, 3)\n",
      "0.8870141\n",
      "[Epoch 0/10] [Batch 744/1081] [D loss: 2.142881] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.684574] time: 0:05:53.394689\n",
      "(10, 128, 128, 3)\n",
      "0.9241672\n",
      "[Epoch 0/10] [Batch 745/1081] [D loss: 2.140229] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.074295] time: 0:05:53.900391\n",
      "(10, 128, 128, 3)\n",
      "0.88831806\n",
      "[Epoch 0/10] [Batch 746/1081] [D loss: 2.139537] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.782211] time: 0:05:54.412405\n",
      "(10, 128, 128, 3)\n",
      "0.8774476\n",
      "[Epoch 0/10] [Batch 747/1081] [D loss: 2.138105] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.764843] time: 0:05:54.904624\n",
      "(10, 128, 128, 3)\n",
      "0.92090195\n",
      "[Epoch 0/10] [Batch 748/1081] [D loss: 2.135910] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.045395] time: 0:05:55.398150\n",
      "(10, 128, 128, 3)\n",
      "0.8689749\n",
      "[Epoch 0/10] [Batch 749/1081] [D loss: 2.135941] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.531296] time: 0:05:55.913355\n",
      "(10, 128, 128, 3)\n",
      "0.87529546\n",
      "[Epoch 0/10] [Batch 750/1081] [D loss: 2.132751] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.450893] time: 0:05:56.406873\n",
      "(10, 128, 128, 3)\n",
      "0.9245998\n",
      "[Epoch 0/10] [Batch 751/1081] [D loss: 2.130706] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.487144] time: 0:05:56.933130\n",
      "(10, 128, 128, 3)\n",
      "0.899164\n",
      "[Epoch 0/10] [Batch 752/1081] [D loss: 2.129512] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.276958] time: 0:05:57.421077\n",
      "(10, 128, 128, 3)\n",
      "0.9583948\n",
      "[Epoch 0/10] [Batch 753/1081] [D loss: 2.259566] [D acc: 0.70 (1.00 real, 0.40 fake)] [G loss: 39.015514] time: 0:05:57.905161\n",
      "(10, 128, 128, 3)\n",
      "0.89387876\n",
      "[Epoch 0/10] [Batch 754/1081] [D loss: 2.232572] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 39.019623] time: 0:05:58.395640\n",
      "(10, 128, 128, 3)\n",
      "0.8818486\n",
      "[Epoch 0/10] [Batch 755/1081] [D loss: 2.151239] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.548775] time: 0:05:58.884514\n",
      "(10, 128, 128, 3)\n",
      "0.79815483\n",
      "[Epoch 0/10] [Batch 756/1081] [D loss: 2.131108] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.556477] time: 0:05:59.360318\n",
      "(10, 128, 128, 3)\n",
      "0.9079829\n",
      "[Epoch 0/10] [Batch 757/1081] [D loss: 2.246025] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 36.270691] time: 0:05:59.829812\n",
      "(10, 128, 128, 3)\n",
      "0.8680776\n",
      "[Epoch 0/10] [Batch 758/1081] [D loss: 2.158303] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.024582] time: 0:06:00.328088\n",
      "(10, 128, 128, 3)\n",
      "0.917034\n",
      "[Epoch 0/10] [Batch 759/1081] [D loss: 2.130578] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.043232] time: 0:06:00.822084\n",
      "(10, 128, 128, 3)\n",
      "0.9333182\n",
      "[Epoch 0/10] [Batch 760/1081] [D loss: 2.120528] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.845417] time: 0:06:01.306859\n",
      "(10, 128, 128, 3)\n",
      "0.89582396\n",
      "[Epoch 0/10] [Batch 761/1081] [D loss: 2.116028] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.541321] time: 0:06:01.790807\n",
      "(10, 128, 128, 3)\n",
      "0.9201522\n",
      "[Epoch 0/10] [Batch 762/1081] [D loss: 2.116167] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.333401] time: 0:06:02.253058\n",
      "(10, 128, 128, 3)\n",
      "0.8831888\n",
      "[Epoch 0/10] [Batch 763/1081] [D loss: 2.111748] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.465900] time: 0:06:02.722411\n",
      "(10, 128, 128, 3)\n",
      "0.8383584\n",
      "[Epoch 0/10] [Batch 764/1081] [D loss: 2.166017] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.175056] time: 0:06:03.196598\n",
      "(10, 128, 128, 3)\n",
      "0.8910157\n",
      "[Epoch 0/10] [Batch 765/1081] [D loss: 2.116644] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.690746] time: 0:06:03.686733\n",
      "(10, 128, 128, 3)\n",
      "0.8826902\n",
      "[Epoch 0/10] [Batch 766/1081] [D loss: 2.109813] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.809402] time: 0:06:04.193822\n",
      "(10, 128, 128, 3)\n",
      "0.93677545\n",
      "[Epoch 0/10] [Batch 767/1081] [D loss: 2.106669] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.359230] time: 0:06:04.683451\n",
      "(10, 128, 128, 3)\n",
      "0.8871846\n",
      "[Epoch 0/10] [Batch 768/1081] [D loss: 2.106393] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.434113] time: 0:06:05.171627\n",
      "(10, 128, 128, 3)\n",
      "0.8720897\n",
      "[Epoch 0/10] [Batch 769/1081] [D loss: 2.103341] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.931248] time: 0:06:05.657738\n",
      "(10, 128, 128, 3)\n",
      "0.9299703\n",
      "[Epoch 0/10] [Batch 770/1081] [D loss: 2.102224] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.315063] time: 0:06:06.163950\n",
      "(10, 128, 128, 3)\n",
      "0.83994037\n",
      "[Epoch 0/10] [Batch 771/1081] [D loss: 2.099250] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.521587] time: 0:06:06.665762\n",
      "(10, 128, 128, 3)\n",
      "0.86358213\n",
      "[Epoch 0/10] [Batch 772/1081] [D loss: 2.099609] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.996704] time: 0:06:07.214385\n",
      "(10, 128, 128, 3)\n",
      "0.923327\n",
      "[Epoch 0/10] [Batch 773/1081] [D loss: 2.101354] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.581688] time: 0:06:07.726127\n",
      "(10, 128, 128, 3)\n",
      "0.8178172\n",
      "[Epoch 0/10] [Batch 774/1081] [D loss: 2.098440] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.304604] time: 0:06:08.222830\n",
      "(10, 128, 128, 3)\n",
      "0.8941219\n",
      "[Epoch 0/10] [Batch 775/1081] [D loss: 2.094635] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.122177] time: 0:06:08.760796\n",
      "(10, 128, 128, 3)\n",
      "0.9340039\n",
      "[Epoch 0/10] [Batch 776/1081] [D loss: 2.092373] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.680180] time: 0:06:09.276319\n",
      "(10, 128, 128, 3)\n",
      "0.8923071\n",
      "[Epoch 0/10] [Batch 777/1081] [D loss: 2.090607] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.958916] time: 0:06:09.777837\n",
      "(10, 128, 128, 3)\n",
      "0.84917575\n",
      "[Epoch 0/10] [Batch 778/1081] [D loss: 2.098014] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.535793] time: 0:06:10.298494\n",
      "(10, 128, 128, 3)\n",
      "0.94007355\n",
      "[Epoch 0/10] [Batch 779/1081] [D loss: 2.087358] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.639771] time: 0:06:10.801881\n",
      "(10, 128, 128, 3)\n",
      "0.9111658\n",
      "[Epoch 0/10] [Batch 780/1081] [D loss: 2.086572] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.822990] time: 0:06:11.322395\n",
      "(10, 128, 128, 3)\n",
      "0.88257694\n",
      "[Epoch 0/10] [Batch 781/1081] [D loss: 2.083971] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.524441] time: 0:06:11.810437\n",
      "(10, 128, 128, 3)\n",
      "0.86163205\n",
      "[Epoch 0/10] [Batch 782/1081] [D loss: 2.087294] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.180695] time: 0:06:12.310387\n",
      "(10, 128, 128, 3)\n",
      "0.884974\n",
      "[Epoch 0/10] [Batch 783/1081] [D loss: 2.081543] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.915474] time: 0:06:12.806047\n",
      "(10, 128, 128, 3)\n",
      "0.9189543\n",
      "[Epoch 0/10] [Batch 784/1081] [D loss: 2.084673] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.836536] time: 0:06:13.304593\n",
      "(10, 128, 128, 3)\n",
      "0.8727613\n",
      "[Epoch 0/10] [Batch 785/1081] [D loss: 2.080752] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.043343] time: 0:06:13.797226\n",
      "(10, 128, 128, 3)\n",
      "0.8664341\n",
      "[Epoch 0/10] [Batch 786/1081] [D loss: 2.082945] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.175034] time: 0:06:14.275579\n",
      "(10, 128, 128, 3)\n",
      "0.9213557\n",
      "[Epoch 0/10] [Batch 787/1081] [D loss: 2.083097] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.792732] time: 0:06:14.785483\n",
      "(10, 128, 128, 3)\n",
      "0.8590328\n",
      "[Epoch 0/10] [Batch 788/1081] [D loss: 2.076132] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.768120] time: 0:06:15.302487\n",
      "(10, 128, 128, 3)\n",
      "0.88539773\n",
      "[Epoch 0/10] [Batch 789/1081] [D loss: 2.074732] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.229446] time: 0:06:15.770974\n",
      "(10, 128, 128, 3)\n",
      "0.88879794\n",
      "[Epoch 0/10] [Batch 790/1081] [D loss: 2.072935] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.523777] time: 0:06:16.240530\n",
      "(10, 128, 128, 3)\n",
      "0.88071686\n",
      "[Epoch 0/10] [Batch 791/1081] [D loss: 2.068546] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.831043] time: 0:06:16.732445\n",
      "(10, 128, 128, 3)\n",
      "0.9091608\n",
      "[Epoch 0/10] [Batch 792/1081] [D loss: 2.562925] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 36.515656] time: 0:06:17.246448\n",
      "(10, 128, 128, 3)\n",
      "0.8999739\n",
      "[Epoch 0/10] [Batch 793/1081] [D loss: 2.159916] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 36.298042] time: 0:06:17.725884\n",
      "(10, 128, 128, 3)\n",
      "0.90825343\n",
      "[Epoch 0/10] [Batch 794/1081] [D loss: 2.315830] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 34.694820] time: 0:06:18.221953\n",
      "(10, 128, 128, 3)\n",
      "0.9446716\n",
      "[Epoch 0/10] [Batch 795/1081] [D loss: 2.105252] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.799744] time: 0:06:18.720123\n",
      "(10, 128, 128, 3)\n",
      "0.93035775\n",
      "[Epoch 0/10] [Batch 796/1081] [D loss: 2.147033] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.685974] time: 0:06:19.206692\n",
      "(10, 128, 128, 3)\n",
      "0.90543866\n",
      "[Epoch 0/10] [Batch 797/1081] [D loss: 2.088805] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.130981] time: 0:06:19.683315\n",
      "(10, 128, 128, 3)\n",
      "0.83751625\n",
      "[Epoch 0/10] [Batch 798/1081] [D loss: 2.066251] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.354687] time: 0:06:20.142426\n",
      "(10, 128, 128, 3)\n",
      "0.8706548\n",
      "[Epoch 0/10] [Batch 799/1081] [D loss: 2.060130] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.230415] time: 0:06:20.651227\n",
      "(10, 128, 128, 3)\n",
      "0.8546234\n",
      "[Epoch 0/10] [Batch 800/1081] [D loss: 2.072521] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 37.125355] time: 0:06:21.161677\n",
      "(10, 128, 128, 3)\n",
      "0.9065118\n",
      "[Epoch 0/10] [Batch 801/1081] [D loss: 2.060060] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.963997] time: 0:06:21.650443\n",
      "(10, 128, 128, 3)\n",
      "0.9571986\n",
      "[Epoch 0/10] [Batch 802/1081] [D loss: 2.052496] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.063736] time: 0:06:22.107230\n",
      "(10, 128, 128, 3)\n",
      "0.8955861\n",
      "[Epoch 0/10] [Batch 803/1081] [D loss: 2.048009] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.601490] time: 0:06:22.598375\n",
      "(10, 128, 128, 3)\n",
      "0.82381934\n",
      "[Epoch 0/10] [Batch 804/1081] [D loss: 2.051495] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.447479] time: 0:06:23.072587\n",
      "(10, 128, 128, 3)\n",
      "0.92079383\n",
      "[Epoch 0/10] [Batch 805/1081] [D loss: 2.045909] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.850445] time: 0:06:23.579849\n",
      "(10, 128, 128, 3)\n",
      "0.8647594\n",
      "[Epoch 0/10] [Batch 806/1081] [D loss: 2.054356] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.945713] time: 0:06:24.077921\n",
      "(10, 128, 128, 3)\n",
      "0.94382066\n",
      "[Epoch 0/10] [Batch 807/1081] [D loss: 2.041918] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.633209] time: 0:06:24.614687\n",
      "(10, 128, 128, 3)\n",
      "0.90522164\n",
      "[Epoch 0/10] [Batch 808/1081] [D loss: 2.051617] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.000248] time: 0:06:25.127346\n",
      "(10, 128, 128, 3)\n",
      "0.8821911\n",
      "[Epoch 0/10] [Batch 809/1081] [D loss: 2.043333] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.642914] time: 0:06:25.645162\n",
      "(10, 128, 128, 3)\n",
      "0.9384125\n",
      "[Epoch 0/10] [Batch 810/1081] [D loss: 2.040684] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.307373] time: 0:06:26.133488\n",
      "(10, 128, 128, 3)\n",
      "0.93479866\n",
      "[Epoch 0/10] [Batch 811/1081] [D loss: 2.036709] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.493378] time: 0:06:26.607281\n",
      "(10, 128, 128, 3)\n",
      "0.90720457\n",
      "[Epoch 0/10] [Batch 812/1081] [D loss: 2.034436] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.698681] time: 0:06:27.082858\n",
      "(10, 128, 128, 3)\n",
      "0.89361\n",
      "[Epoch 0/10] [Batch 813/1081] [D loss: 2.034262] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.501740] time: 0:06:27.583158\n",
      "(10, 128, 128, 3)\n",
      "0.9124492\n",
      "[Epoch 0/10] [Batch 814/1081] [D loss: 2.034641] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.202843] time: 0:06:28.057012\n",
      "(10, 128, 128, 3)\n",
      "0.92196614\n",
      "[Epoch 0/10] [Batch 815/1081] [D loss: 2.038854] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.304733] time: 0:06:28.565628\n",
      "(10, 128, 128, 3)\n",
      "0.83831\n",
      "[Epoch 0/10] [Batch 816/1081] [D loss: 2.028477] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.339073] time: 0:06:29.031193\n",
      "(10, 128, 128, 3)\n",
      "0.8730622\n",
      "[Epoch 0/10] [Batch 817/1081] [D loss: 2.029001] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.579041] time: 0:06:29.514754\n",
      "(10, 128, 128, 3)\n",
      "0.8329497\n",
      "[Epoch 0/10] [Batch 818/1081] [D loss: 2.025086] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.375877] time: 0:06:29.984846\n",
      "(10, 128, 128, 3)\n",
      "0.8655968\n",
      "[Epoch 0/10] [Batch 819/1081] [D loss: 2.023189] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.426128] time: 0:06:30.499866\n",
      "(10, 128, 128, 3)\n",
      "0.87597364\n",
      "[Epoch 0/10] [Batch 820/1081] [D loss: 2.021209] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.346264] time: 0:06:31.010604\n",
      "(10, 128, 128, 3)\n",
      "0.8583107\n",
      "[Epoch 0/10] [Batch 821/1081] [D loss: 2.018905] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.529926] time: 0:06:31.472705\n",
      "(10, 128, 128, 3)\n",
      "0.8890309\n",
      "[Epoch 0/10] [Batch 822/1081] [D loss: 2.020162] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.322567] time: 0:06:31.953439\n",
      "(10, 128, 128, 3)\n",
      "0.93911237\n",
      "[Epoch 0/10] [Batch 823/1081] [D loss: 2.016689] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.320518] time: 0:06:32.445719\n",
      "(10, 128, 128, 3)\n",
      "0.88653463\n",
      "[Epoch 0/10] [Batch 824/1081] [D loss: 2.015893] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.445148] time: 0:06:32.977119\n",
      "(10, 128, 128, 3)\n",
      "0.9052554\n",
      "[Epoch 0/10] [Batch 825/1081] [D loss: 2.014572] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.722309] time: 0:06:33.469338\n",
      "(10, 128, 128, 3)\n",
      "0.9541485\n",
      "[Epoch 0/10] [Batch 826/1081] [D loss: 2.010899] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.915089] time: 0:06:33.958473\n",
      "(10, 128, 128, 3)\n",
      "0.8580572\n",
      "[Epoch 0/10] [Batch 827/1081] [D loss: 2.010135] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.218979] time: 0:06:34.422324\n",
      "(10, 128, 128, 3)\n",
      "0.8916023\n",
      "[Epoch 0/10] [Batch 828/1081] [D loss: 2.705362] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 33.524200] time: 0:06:34.919107\n",
      "(10, 128, 128, 3)\n",
      "0.8984954\n",
      "[Epoch 0/10] [Batch 829/1081] [D loss: 2.031003] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.224174] time: 0:06:35.419822\n",
      "(10, 128, 128, 3)\n",
      "0.9182082\n",
      "[Epoch 0/10] [Batch 830/1081] [D loss: 2.011173] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.551224] time: 0:06:35.907628\n",
      "(10, 128, 128, 3)\n",
      "0.9365499\n",
      "[Epoch 0/10] [Batch 831/1081] [D loss: 2.018137] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.439888] time: 0:06:36.386529\n",
      "(10, 128, 128, 3)\n",
      "0.8800153\n",
      "[Epoch 0/10] [Batch 832/1081] [D loss: 2.008653] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.215908] time: 0:06:36.877222\n",
      "(10, 128, 128, 3)\n",
      "0.90413713\n",
      "[Epoch 0/10] [Batch 833/1081] [D loss: 2.049718] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.917641] time: 0:06:37.373581\n",
      "(10, 128, 128, 3)\n",
      "0.88773394\n",
      "[Epoch 0/10] [Batch 834/1081] [D loss: 2.025229] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.622669] time: 0:06:37.905712\n",
      "(10, 128, 128, 3)\n",
      "0.802751\n",
      "[Epoch 0/10] [Batch 835/1081] [D loss: 1.998043] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.440418] time: 0:06:38.406409\n",
      "(10, 128, 128, 3)\n",
      "0.86533815\n",
      "[Epoch 0/10] [Batch 836/1081] [D loss: 2.018662] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.580341] time: 0:06:38.917630\n",
      "(10, 128, 128, 3)\n",
      "0.8591241\n",
      "[Epoch 0/10] [Batch 837/1081] [D loss: 2.009663] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.909264] time: 0:06:39.440158\n",
      "(10, 128, 128, 3)\n",
      "0.9159239\n",
      "[Epoch 0/10] [Batch 838/1081] [D loss: 2.007154] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 34.115685] time: 0:06:39.981968\n",
      "(10, 128, 128, 3)\n",
      "0.88740164\n",
      "[Epoch 0/10] [Batch 839/1081] [D loss: 1.991763] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.812263] time: 0:06:40.520868\n",
      "(10, 128, 128, 3)\n",
      "0.92561954\n",
      "[Epoch 0/10] [Batch 840/1081] [D loss: 1.990811] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.440598] time: 0:06:41.006414\n",
      "(10, 128, 128, 3)\n",
      "0.88697267\n",
      "[Epoch 0/10] [Batch 841/1081] [D loss: 1.989809] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.507122] time: 0:06:41.486444\n",
      "(10, 128, 128, 3)\n",
      "0.8807518\n",
      "[Epoch 0/10] [Batch 842/1081] [D loss: 1.998023] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.425209] time: 0:06:41.967786\n",
      "(10, 128, 128, 3)\n",
      "0.86362123\n",
      "[Epoch 0/10] [Batch 843/1081] [D loss: 1.985866] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.083611] time: 0:06:42.474420\n",
      "(10, 128, 128, 3)\n",
      "0.9125571\n",
      "[Epoch 0/10] [Batch 844/1081] [D loss: 2.004415] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 34.482594] time: 0:06:42.982140\n",
      "(10, 128, 128, 3)\n",
      "0.9255107\n",
      "[Epoch 0/10] [Batch 845/1081] [D loss: 1.990695] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.281631] time: 0:06:43.467506\n",
      "(10, 128, 128, 3)\n",
      "0.88049465\n",
      "[Epoch 0/10] [Batch 846/1081] [D loss: 1.981749] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.344009] time: 0:06:43.933920\n",
      "(10, 128, 128, 3)\n",
      "0.8607574\n",
      "[Epoch 0/10] [Batch 847/1081] [D loss: 1.982693] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.987850] time: 0:06:44.441389\n",
      "(10, 128, 128, 3)\n",
      "0.86127156\n",
      "[Epoch 0/10] [Batch 848/1081] [D loss: 1.985889] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.843117] time: 0:06:44.926355\n",
      "(10, 128, 128, 3)\n",
      "0.9038897\n",
      "[Epoch 0/10] [Batch 849/1081] [D loss: 1.981083] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.370037] time: 0:06:45.440782\n",
      "(10, 128, 128, 3)\n",
      "0.88972217\n",
      "[Epoch 0/10] [Batch 850/1081] [D loss: 1.977182] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.262547] time: 0:06:45.930437\n",
      "(10, 128, 128, 3)\n",
      "0.9417572\n",
      "[Epoch 0/10] [Batch 851/1081] [D loss: 1.974533] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.735092] time: 0:06:46.415490\n",
      "(10, 128, 128, 3)\n",
      "0.89256066\n",
      "[Epoch 0/10] [Batch 852/1081] [D loss: 1.971273] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.028400] time: 0:06:46.904762\n",
      "(10, 128, 128, 3)\n",
      "0.9131233\n",
      "[Epoch 0/10] [Batch 853/1081] [D loss: 1.981879] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.318825] time: 0:06:47.412971\n",
      "(10, 128, 128, 3)\n",
      "0.8944761\n",
      "[Epoch 0/10] [Batch 854/1081] [D loss: 1.969741] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.300041] time: 0:06:47.915449\n",
      "(10, 128, 128, 3)\n",
      "0.90667766\n",
      "[Epoch 0/10] [Batch 855/1081] [D loss: 1.967519] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.764935] time: 0:06:48.414382\n",
      "(10, 128, 128, 3)\n",
      "0.917404\n",
      "[Epoch 0/10] [Batch 856/1081] [D loss: 1.970902] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.254440] time: 0:06:48.879998\n",
      "(10, 128, 128, 3)\n",
      "0.88921976\n",
      "[Epoch 0/10] [Batch 857/1081] [D loss: 1.966105] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.467510] time: 0:06:49.358445\n",
      "(10, 128, 128, 3)\n",
      "0.9088061\n",
      "[Epoch 0/10] [Batch 858/1081] [D loss: 1.964857] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.394905] time: 0:06:49.841785\n",
      "(10, 128, 128, 3)\n",
      "0.8451163\n",
      "[Epoch 0/10] [Batch 859/1081] [D loss: 1.963067] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.722786] time: 0:06:50.377131\n",
      "(10, 128, 128, 3)\n",
      "0.91304\n",
      "[Epoch 0/10] [Batch 860/1081] [D loss: 1.959292] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.402557] time: 0:06:50.877447\n",
      "(10, 128, 128, 3)\n",
      "0.86261374\n",
      "[Epoch 0/10] [Batch 861/1081] [D loss: 1.956522] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.544563] time: 0:06:51.402643\n",
      "(10, 128, 128, 3)\n",
      "0.9287067\n",
      "[Epoch 0/10] [Batch 862/1081] [D loss: 1.954691] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.282921] time: 0:06:51.887512\n",
      "(10, 128, 128, 3)\n",
      "0.9383063\n",
      "[Epoch 0/10] [Batch 863/1081] [D loss: 1.953217] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.508789] time: 0:06:52.395337\n",
      "(10, 128, 128, 3)\n",
      "0.9196122\n",
      "[Epoch 0/10] [Batch 864/1081] [D loss: 1.950966] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.483803] time: 0:06:52.876245\n",
      "(10, 128, 128, 3)\n",
      "0.87890357\n",
      "[Epoch 0/10] [Batch 865/1081] [D loss: 1.951508] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.417313] time: 0:06:53.372885\n",
      "(10, 128, 128, 3)\n",
      "0.8726132\n",
      "[Epoch 0/10] [Batch 866/1081] [D loss: 1.947948] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.968578] time: 0:06:53.881391\n",
      "(10, 128, 128, 3)\n",
      "0.8704497\n",
      "[Epoch 0/10] [Batch 867/1081] [D loss: 1.948128] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 36.363125] time: 0:06:54.398463\n",
      "(10, 128, 128, 3)\n",
      "0.92574626\n",
      "[Epoch 0/10] [Batch 868/1081] [D loss: 1.947149] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.116440] time: 0:06:54.892938\n",
      "(10, 128, 128, 3)\n",
      "0.92181\n",
      "[Epoch 0/10] [Batch 869/1081] [D loss: 1.946526] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.427555] time: 0:06:55.347783\n",
      "(10, 128, 128, 3)\n",
      "0.91524416\n",
      "[Epoch 0/10] [Batch 870/1081] [D loss: 1.941948] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.036583] time: 0:06:55.818136\n",
      "(10, 128, 128, 3)\n",
      "0.88749075\n",
      "[Epoch 0/10] [Batch 871/1081] [D loss: 1.944409] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.965218] time: 0:06:56.307016\n",
      "(10, 128, 128, 3)\n",
      "0.8970732\n",
      "[Epoch 0/10] [Batch 872/1081] [D loss: 1.941533] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.152840] time: 0:06:56.804531\n",
      "(10, 128, 128, 3)\n",
      "0.8948508\n",
      "[Epoch 0/10] [Batch 873/1081] [D loss: 1.938080] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.672436] time: 0:06:57.278613\n",
      "(10, 128, 128, 3)\n",
      "0.9039595\n",
      "[Epoch 0/10] [Batch 874/1081] [D loss: 1.935713] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.222233] time: 0:06:57.755485\n",
      "(10, 128, 128, 3)\n",
      "0.8495481\n",
      "[Epoch 0/10] [Batch 875/1081] [D loss: 1.933669] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.506592] time: 0:06:58.268431\n",
      "(10, 128, 128, 3)\n",
      "0.85969424\n",
      "[Epoch 0/10] [Batch 876/1081] [D loss: 1.934594] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.851360] time: 0:06:58.760498\n",
      "(10, 128, 128, 3)\n",
      "0.8837716\n",
      "[Epoch 0/10] [Batch 877/1081] [D loss: 1.930171] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.267830] time: 0:06:59.257965\n",
      "(10, 128, 128, 3)\n",
      "0.9079089\n",
      "[Epoch 0/10] [Batch 878/1081] [D loss: 1.928579] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.217247] time: 0:06:59.772558\n",
      "(10, 128, 128, 3)\n",
      "0.8753666\n",
      "[Epoch 0/10] [Batch 879/1081] [D loss: 1.927036] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.642506] time: 0:07:00.268552\n",
      "(10, 128, 128, 3)\n",
      "0.859212\n",
      "[Epoch 0/10] [Batch 880/1081] [D loss: 1.926868] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.830208] time: 0:07:00.754419\n",
      "(10, 128, 128, 3)\n",
      "0.87981623\n",
      "[Epoch 0/10] [Batch 881/1081] [D loss: 1.925006] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.498928] time: 0:07:01.253433\n",
      "(10, 128, 128, 3)\n",
      "0.8793686\n",
      "[Epoch 0/10] [Batch 882/1081] [D loss: 1.922105] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 35.139858] time: 0:07:01.733256\n",
      "(10, 128, 128, 3)\n",
      "0.92869467\n",
      "[Epoch 0/10] [Batch 883/1081] [D loss: 1.923810] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.003822] time: 0:07:02.211505\n",
      "(10, 128, 128, 3)\n",
      "0.92788154\n",
      "[Epoch 0/10] [Batch 884/1081] [D loss: 1.920879] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.154697] time: 0:07:02.680123\n",
      "(10, 128, 128, 3)\n",
      "0.9613908\n",
      "[Epoch 0/10] [Batch 885/1081] [D loss: 1.918307] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.504166] time: 0:07:03.163599\n",
      "(10, 128, 128, 3)\n",
      "0.9383933\n",
      "[Epoch 0/10] [Batch 886/1081] [D loss: 1.918954] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.361122] time: 0:07:03.656739\n",
      "(10, 128, 128, 3)\n",
      "0.8837001\n",
      "[Epoch 0/10] [Batch 887/1081] [D loss: 1.913895] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.260857] time: 0:07:04.147292\n",
      "(10, 128, 128, 3)\n",
      "0.9242725\n",
      "[Epoch 0/10] [Batch 888/1081] [D loss: 1.915237] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.418045] time: 0:07:04.651893\n",
      "(10, 128, 128, 3)\n",
      "0.919015\n",
      "[Epoch 0/10] [Batch 889/1081] [D loss: 1.911527] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.219223] time: 0:07:05.141247\n",
      "(10, 128, 128, 3)\n",
      "0.90371585\n",
      "[Epoch 0/10] [Batch 890/1081] [D loss: 1.909925] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.544903] time: 0:07:05.634765\n",
      "(10, 128, 128, 3)\n",
      "0.8786661\n",
      "[Epoch 0/10] [Batch 891/1081] [D loss: 1.908083] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.985992] time: 0:07:06.144945\n",
      "(10, 128, 128, 3)\n",
      "0.89039725\n",
      "[Epoch 0/10] [Batch 892/1081] [D loss: 1.906204] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.149422] time: 0:07:06.645803\n",
      "(10, 128, 128, 3)\n",
      "0.93749005\n",
      "[Epoch 0/10] [Batch 893/1081] [D loss: 1.907007] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.710251] time: 0:07:07.158952\n",
      "(10, 128, 128, 3)\n",
      "0.9132876\n",
      "[Epoch 0/10] [Batch 894/1081] [D loss: 1.905964] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.025543] time: 0:07:07.630224\n",
      "(10, 128, 128, 3)\n",
      "0.93218726\n",
      "[Epoch 0/10] [Batch 895/1081] [D loss: 1.902878] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.134338] time: 0:07:08.151443\n",
      "(10, 128, 128, 3)\n",
      "0.88791245\n",
      "[Epoch 0/10] [Batch 896/1081] [D loss: 1.900565] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.435730] time: 0:07:08.628749\n",
      "(10, 128, 128, 3)\n",
      "0.9192806\n",
      "[Epoch 0/10] [Batch 897/1081] [D loss: 1.897898] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.542374] time: 0:07:09.146763\n",
      "(10, 128, 128, 3)\n",
      "0.8596856\n",
      "[Epoch 0/10] [Batch 898/1081] [D loss: 1.897180] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.612083] time: 0:07:09.636513\n",
      "(10, 128, 128, 3)\n",
      "0.8928091\n",
      "[Epoch 0/10] [Batch 899/1081] [D loss: 1.894903] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.731922] time: 0:07:10.120081\n",
      "(10, 128, 128, 3)\n",
      "0.8664171\n",
      "[Epoch 0/10] [Batch 900/1081] [D loss: 1.893216] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.552994] time: 0:07:10.597066\n",
      "(10, 128, 128, 3)\n",
      "0.9110935\n",
      "[Epoch 0/10] [Batch 901/1081] [D loss: 1.892609] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.309528] time: 0:07:11.126279\n",
      "(10, 128, 128, 3)\n",
      "0.9102187\n",
      "[Epoch 0/10] [Batch 902/1081] [D loss: 1.891063] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.294178] time: 0:07:11.608985\n",
      "(10, 128, 128, 3)\n",
      "0.936217\n",
      "[Epoch 0/10] [Batch 903/1081] [D loss: 1.888580] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.061092] time: 0:07:12.145552\n",
      "(10, 128, 128, 3)\n",
      "0.91236144\n",
      "[Epoch 0/10] [Batch 904/1081] [D loss: 1.888380] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.805565] time: 0:07:12.641185\n",
      "(10, 128, 128, 3)\n",
      "0.8835055\n",
      "[Epoch 0/10] [Batch 905/1081] [D loss: 1.886611] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.552734] time: 0:07:13.181753\n",
      "(10, 128, 128, 3)\n",
      "0.8848769\n",
      "[Epoch 0/10] [Batch 906/1081] [D loss: 1.884027] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.291218] time: 0:07:13.705950\n",
      "(10, 128, 128, 3)\n",
      "0.86496305\n",
      "[Epoch 0/10] [Batch 907/1081] [D loss: 1.883804] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.792381] time: 0:07:14.192037\n",
      "(10, 128, 128, 3)\n",
      "0.8752714\n",
      "[Epoch 0/10] [Batch 908/1081] [D loss: 1.880274] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.415634] time: 0:07:14.715067\n",
      "(10, 128, 128, 3)\n",
      "0.90020293\n",
      "[Epoch 0/10] [Batch 909/1081] [D loss: 1.884659] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.077610] time: 0:07:15.188425\n",
      "(10, 128, 128, 3)\n",
      "0.899834\n",
      "[Epoch 0/10] [Batch 910/1081] [D loss: 1.877828] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.804241] time: 0:07:15.687289\n",
      "(10, 128, 128, 3)\n",
      "0.93770474\n",
      "[Epoch 0/10] [Batch 911/1081] [D loss: 1.877819] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.153774] time: 0:07:16.206764\n",
      "(10, 128, 128, 3)\n",
      "0.89098334\n",
      "[Epoch 0/10] [Batch 912/1081] [D loss: 1.874429] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.056961] time: 0:07:16.682231\n",
      "(10, 128, 128, 3)\n",
      "0.9372091\n",
      "[Epoch 0/10] [Batch 913/1081] [D loss: 1.872561] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.237499] time: 0:07:17.159197\n",
      "(10, 128, 128, 3)\n",
      "0.8757952\n",
      "[Epoch 0/10] [Batch 914/1081] [D loss: 1.871005] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.616142] time: 0:07:17.616057\n",
      "(10, 128, 128, 3)\n",
      "0.8876186\n",
      "[Epoch 0/10] [Batch 915/1081] [D loss: 1.871464] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.217602] time: 0:07:18.122222\n",
      "(10, 128, 128, 3)\n",
      "0.9131722\n",
      "[Epoch 0/10] [Batch 916/1081] [D loss: 1.868146] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.298576] time: 0:07:18.615456\n",
      "(10, 128, 128, 3)\n",
      "0.88444287\n",
      "[Epoch 0/10] [Batch 917/1081] [D loss: 1.867129] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.131138] time: 0:07:19.104080\n",
      "(10, 128, 128, 3)\n",
      "0.90187025\n",
      "[Epoch 0/10] [Batch 918/1081] [D loss: 1.865514] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.287842] time: 0:07:19.589777\n",
      "(10, 128, 128, 3)\n",
      "0.91042274\n",
      "[Epoch 0/10] [Batch 919/1081] [D loss: 1.863407] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.702499] time: 0:07:20.077619\n",
      "(10, 128, 128, 3)\n",
      "0.8905687\n",
      "[Epoch 0/10] [Batch 920/1081] [D loss: 1.862126] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 34.472485] time: 0:07:20.541675\n",
      "(10, 128, 128, 3)\n",
      "0.9065172\n",
      "[Epoch 0/10] [Batch 921/1081] [D loss: 1.859900] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.921852] time: 0:07:21.039453\n",
      "(10, 128, 128, 3)\n",
      "0.87489706\n",
      "[Epoch 0/10] [Batch 922/1081] [D loss: 1.858632] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.154598] time: 0:07:21.539133\n",
      "(10, 128, 128, 3)\n",
      "0.8975005\n",
      "[Epoch 0/10] [Batch 923/1081] [D loss: 1.856538] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.877430] time: 0:07:22.045966\n",
      "(10, 128, 128, 3)\n",
      "0.9254041\n",
      "[Epoch 0/10] [Batch 924/1081] [D loss: 1.855108] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.233215] time: 0:07:22.536970\n",
      "(10, 128, 128, 3)\n",
      "0.8728923\n",
      "[Epoch 0/10] [Batch 925/1081] [D loss: 1.853354] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.965221] time: 0:07:23.038574\n",
      "(10, 128, 128, 3)\n",
      "0.88719875\n",
      "[Epoch 0/10] [Batch 926/1081] [D loss: 1.860827] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.253738] time: 0:07:23.525069\n",
      "(10, 128, 128, 3)\n",
      "0.9023052\n",
      "[Epoch 0/10] [Batch 927/1081] [D loss: 1.850950] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.338348] time: 0:07:24.041784\n",
      "(10, 128, 128, 3)\n",
      "0.9284269\n",
      "[Epoch 0/10] [Batch 928/1081] [D loss: 1.848684] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.332703] time: 0:07:24.523718\n",
      "(10, 128, 128, 3)\n",
      "0.90304446\n",
      "[Epoch 0/10] [Batch 929/1081] [D loss: 1.848768] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.461891] time: 0:07:24.991733\n",
      "(10, 128, 128, 3)\n",
      "0.8706147\n",
      "[Epoch 0/10] [Batch 930/1081] [D loss: 1.845666] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.405785] time: 0:07:25.506310\n",
      "(10, 128, 128, 3)\n",
      "0.9184484\n",
      "[Epoch 0/10] [Batch 931/1081] [D loss: 1.846510] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.083172] time: 0:07:25.989295\n",
      "(10, 128, 128, 3)\n",
      "0.90105945\n",
      "[Epoch 0/10] [Batch 932/1081] [D loss: 1.841914] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.453835] time: 0:07:26.472969\n",
      "(10, 128, 128, 3)\n",
      "0.86489344\n",
      "[Epoch 0/10] [Batch 933/1081] [D loss: 1.840773] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.750633] time: 0:07:26.936752\n",
      "(10, 128, 128, 3)\n",
      "0.9039658\n",
      "[Epoch 0/10] [Batch 934/1081] [D loss: 1.839771] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.927929] time: 0:07:27.466326\n",
      "(10, 128, 128, 3)\n",
      "0.886682\n",
      "[Epoch 0/10] [Batch 935/1081] [D loss: 1.837844] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.690723] time: 0:07:27.980217\n",
      "(10, 128, 128, 3)\n",
      "0.88284343\n",
      "[Epoch 0/10] [Batch 936/1081] [D loss: 1.836603] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.565006] time: 0:07:28.482760\n",
      "(10, 128, 128, 3)\n",
      "0.9657567\n",
      "[Epoch 0/10] [Batch 937/1081] [D loss: 1.834415] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.289116] time: 0:07:28.990878\n",
      "(10, 128, 128, 3)\n",
      "0.89650744\n",
      "[Epoch 0/10] [Batch 938/1081] [D loss: 1.832579] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.390816] time: 0:07:29.478743\n",
      "(10, 128, 128, 3)\n",
      "0.8534779\n",
      "[Epoch 0/10] [Batch 939/1081] [D loss: 1.854140] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.940485] time: 0:07:29.968836\n",
      "(10, 128, 128, 3)\n",
      "0.8757877\n",
      "[Epoch 0/10] [Batch 940/1081] [D loss: 1.837236] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.274269] time: 0:07:30.452138\n",
      "(10, 128, 128, 3)\n",
      "0.90822977\n",
      "[Epoch 0/10] [Batch 941/1081] [D loss: 1.828332] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.073467] time: 0:07:30.956599\n",
      "(10, 128, 128, 3)\n",
      "0.86480683\n",
      "[Epoch 0/10] [Batch 942/1081] [D loss: 1.827637] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.546009] time: 0:07:31.444515\n",
      "(10, 128, 128, 3)\n",
      "0.91427976\n",
      "[Epoch 0/10] [Batch 943/1081] [D loss: 1.825045] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.864710] time: 0:07:31.934994\n",
      "(10, 128, 128, 3)\n",
      "0.8634855\n",
      "[Epoch 0/10] [Batch 944/1081] [D loss: 1.823525] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.417641] time: 0:07:32.403198\n",
      "(10, 128, 128, 3)\n",
      "0.91170555\n",
      "[Epoch 0/10] [Batch 945/1081] [D loss: 1.822532] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.076168] time: 0:07:32.916094\n",
      "(10, 128, 128, 3)\n",
      "0.8844459\n",
      "[Epoch 0/10] [Batch 946/1081] [D loss: 1.823151] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.663528] time: 0:07:33.404386\n",
      "(10, 128, 128, 3)\n",
      "0.92647725\n",
      "[Epoch 0/10] [Batch 947/1081] [D loss: 1.818021] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.046425] time: 0:07:33.891149\n",
      "(10, 128, 128, 3)\n",
      "0.895139\n",
      "[Epoch 0/10] [Batch 948/1081] [D loss: 1.817708] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.797424] time: 0:07:34.355031\n",
      "(10, 128, 128, 3)\n",
      "0.8981915\n",
      "[Epoch 0/10] [Batch 949/1081] [D loss: 1.814640] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.215801] time: 0:07:34.848746\n",
      "(10, 128, 128, 3)\n",
      "0.89795256\n",
      "[Epoch 0/10] [Batch 950/1081] [D loss: 1.814136] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.040070] time: 0:07:35.312048\n",
      "(10, 128, 128, 3)\n",
      "0.91821176\n",
      "[Epoch 0/10] [Batch 951/1081] [D loss: 1.812046] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.732708] time: 0:07:35.775738\n",
      "(10, 128, 128, 3)\n",
      "0.88403136\n",
      "[Epoch 0/10] [Batch 952/1081] [D loss: 1.810647] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.658060] time: 0:07:36.255728\n",
      "(10, 128, 128, 3)\n",
      "0.8693409\n",
      "[Epoch 0/10] [Batch 953/1081] [D loss: 1.808531] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.736340] time: 0:07:36.750000\n",
      "(10, 128, 128, 3)\n",
      "0.88823843\n",
      "[Epoch 0/10] [Batch 954/1081] [D loss: 1.808622] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.647526] time: 0:07:37.223006\n",
      "(10, 128, 128, 3)\n",
      "0.87893224\n",
      "[Epoch 0/10] [Batch 955/1081] [D loss: 1.805998] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.684944] time: 0:07:37.712897\n",
      "(10, 128, 128, 3)\n",
      "0.9101558\n",
      "[Epoch 0/10] [Batch 956/1081] [D loss: 1.803565] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.196949] time: 0:07:38.133916\n",
      "(10, 128, 128, 3)\n",
      "0.9341979\n",
      "[Epoch 0/10] [Batch 957/1081] [D loss: 1.802741] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.301128] time: 0:07:38.555003\n",
      "(10, 128, 128, 3)\n",
      "0.8831422\n",
      "[Epoch 0/10] [Batch 958/1081] [D loss: 1.800457] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.536444] time: 0:07:38.979756\n",
      "(10, 128, 128, 3)\n",
      "0.9447928\n",
      "[Epoch 0/10] [Batch 959/1081] [D loss: 1.800666] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.736217] time: 0:07:39.463712\n",
      "(10, 128, 128, 3)\n",
      "0.8744979\n",
      "[Epoch 0/10] [Batch 960/1081] [D loss: 1.800462] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.798626] time: 0:07:39.875931\n",
      "(10, 128, 128, 3)\n",
      "0.8001742\n",
      "[Epoch 0/10] [Batch 961/1081] [D loss: 1.799257] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.868046] time: 0:07:40.281980\n",
      "(10, 128, 128, 3)\n",
      "0.8565132\n",
      "[Epoch 0/10] [Batch 962/1081] [D loss: 1.794686] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 33.465248] time: 0:07:40.702291\n",
      "(10, 128, 128, 3)\n",
      "0.8833179\n",
      "[Epoch 0/10] [Batch 963/1081] [D loss: 1.795406] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.258045] time: 0:07:41.166110\n",
      "(10, 128, 128, 3)\n",
      "0.92314285\n",
      "[Epoch 0/10] [Batch 964/1081] [D loss: 1.792635] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.652760] time: 0:07:41.603601\n",
      "(10, 128, 128, 3)\n",
      "0.88710016\n",
      "[Epoch 0/10] [Batch 965/1081] [D loss: 1.789824] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.678244] time: 0:07:42.029690\n",
      "(10, 128, 128, 3)\n",
      "0.91533256\n",
      "[Epoch 0/10] [Batch 966/1081] [D loss: 1.789153] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.852283] time: 0:07:42.448129\n",
      "(10, 128, 128, 3)\n",
      "0.8996263\n",
      "[Epoch 0/10] [Batch 967/1081] [D loss: 1.786253] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.552105] time: 0:07:42.876934\n",
      "(10, 128, 128, 3)\n",
      "0.84110945\n",
      "[Epoch 0/10] [Batch 968/1081] [D loss: 1.784212] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.770123] time: 0:07:43.295671\n",
      "(10, 128, 128, 3)\n",
      "0.9086234\n",
      "[Epoch 0/10] [Batch 969/1081] [D loss: 1.782586] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.405167] time: 0:07:43.732415\n",
      "(10, 128, 128, 3)\n",
      "0.9138658\n",
      "[Epoch 0/10] [Batch 970/1081] [D loss: 1.781411] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.357006] time: 0:07:44.165703\n",
      "(10, 128, 128, 3)\n",
      "0.9109526\n",
      "[Epoch 0/10] [Batch 971/1081] [D loss: 1.781128] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.462500] time: 0:07:44.604706\n",
      "(10, 128, 128, 3)\n",
      "0.8814346\n",
      "[Epoch 0/10] [Batch 972/1081] [D loss: 1.778800] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.160912] time: 0:07:44.996433\n",
      "(10, 128, 128, 3)\n",
      "0.8764978\n",
      "[Epoch 0/10] [Batch 973/1081] [D loss: 1.776513] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.945187] time: 0:07:45.397934\n",
      "(10, 128, 128, 3)\n",
      "0.8408325\n",
      "[Epoch 0/10] [Batch 974/1081] [D loss: 1.775339] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.191189] time: 0:07:45.819409\n",
      "(10, 128, 128, 3)\n",
      "0.87926644\n",
      "[Epoch 0/10] [Batch 975/1081] [D loss: 1.773562] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.352074] time: 0:07:46.245390\n",
      "(10, 128, 128, 3)\n",
      "0.9148186\n",
      "[Epoch 0/10] [Batch 976/1081] [D loss: 1.771397] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.313835] time: 0:07:46.652238\n",
      "(10, 128, 128, 3)\n",
      "0.849323\n",
      "[Epoch 0/10] [Batch 977/1081] [D loss: 1.770512] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.570015] time: 0:07:47.067397\n",
      "(10, 128, 128, 3)\n",
      "0.8325975\n",
      "[Epoch 0/10] [Batch 978/1081] [D loss: 1.768615] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.122551] time: 0:07:47.476609\n",
      "(10, 128, 128, 3)\n",
      "0.9064751\n",
      "[Epoch 0/10] [Batch 979/1081] [D loss: 1.766803] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.390842] time: 0:07:47.893506\n",
      "(10, 128, 128, 3)\n",
      "0.8878062\n",
      "[Epoch 0/10] [Batch 980/1081] [D loss: 1.767172] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.588829] time: 0:07:48.316318\n",
      "(10, 128, 128, 3)\n",
      "0.8801082\n",
      "[Epoch 0/10] [Batch 981/1081] [D loss: 1.765083] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.525196] time: 0:07:48.742577\n",
      "(10, 128, 128, 3)\n",
      "0.90048766\n",
      "[Epoch 0/10] [Batch 982/1081] [D loss: 1.762725] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.229046] time: 0:07:49.168677\n",
      "(10, 128, 128, 3)\n",
      "0.909975\n",
      "[Epoch 0/10] [Batch 983/1081] [D loss: 1.760785] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.554691] time: 0:07:49.630142\n",
      "(10, 128, 128, 3)\n",
      "0.93758947\n",
      "[Epoch 0/10] [Batch 984/1081] [D loss: 1.758804] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.893229] time: 0:07:50.290897\n",
      "(10, 128, 128, 3)\n",
      "0.90636474\n",
      "[Epoch 0/10] [Batch 985/1081] [D loss: 1.758572] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.667456] time: 0:07:50.702518\n",
      "(10, 128, 128, 3)\n",
      "0.8130993\n",
      "[Epoch 0/10] [Batch 986/1081] [D loss: 1.756573] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.434517] time: 0:07:51.116683\n",
      "(10, 128, 128, 3)\n",
      "0.9155969\n",
      "[Epoch 0/10] [Batch 987/1081] [D loss: 1.754239] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.909184] time: 0:07:51.569151\n",
      "(10, 128, 128, 3)\n",
      "0.8637156\n",
      "[Epoch 0/10] [Batch 988/1081] [D loss: 1.752605] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.945862] time: 0:07:51.993178\n",
      "(10, 128, 128, 3)\n",
      "0.90356725\n",
      "[Epoch 0/10] [Batch 989/1081] [D loss: 1.751460] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.415203] time: 0:07:52.422753\n",
      "(10, 128, 128, 3)\n",
      "0.9405138\n",
      "[Epoch 0/10] [Batch 990/1081] [D loss: 1.750011] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.251728] time: 0:07:52.852473\n",
      "(10, 128, 128, 3)\n",
      "0.86605763\n",
      "[Epoch 0/10] [Batch 991/1081] [D loss: 1.748809] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.569530] time: 0:07:53.277933\n",
      "(10, 128, 128, 3)\n",
      "0.916943\n",
      "[Epoch 0/10] [Batch 992/1081] [D loss: 1.746763] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.640476] time: 0:07:53.725081\n",
      "(10, 128, 128, 3)\n",
      "0.919611\n",
      "[Epoch 0/10] [Batch 993/1081] [D loss: 1.744790] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.939785] time: 0:07:54.139449\n",
      "(10, 128, 128, 3)\n",
      "0.8460043\n",
      "[Epoch 0/10] [Batch 994/1081] [D loss: 1.742974] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.785686] time: 0:07:54.558601\n",
      "(10, 128, 128, 3)\n",
      "0.9084231\n",
      "[Epoch 0/10] [Batch 995/1081] [D loss: 1.741921] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.284494] time: 0:07:54.994300\n",
      "(10, 128, 128, 3)\n",
      "0.87395984\n",
      "[Epoch 0/10] [Batch 996/1081] [D loss: 1.742091] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.960682] time: 0:07:55.445504\n",
      "(10, 128, 128, 3)\n",
      "0.8042636\n",
      "[Epoch 0/10] [Batch 997/1081] [D loss: 1.739435] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.112099] time: 0:07:55.933631\n",
      "(10, 128, 128, 3)\n",
      "0.8811675\n",
      "[Epoch 0/10] [Batch 998/1081] [D loss: 1.737149] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.251968] time: 0:07:56.404409\n",
      "(10, 128, 128, 3)\n",
      "0.9032921\n",
      "[Epoch 0/10] [Batch 999/1081] [D loss: 1.735135] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.396240] time: 0:07:56.886441\n",
      "(10, 128, 128, 3)\n",
      "0.8981269\n",
      "[Epoch 0/10] [Batch 1000/1081] [D loss: 1.733395] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.596176] time: 0:07:57.377131\n",
      "(10, 128, 128, 3)\n",
      "0.89890546\n",
      "[Epoch 0/10] [Batch 1001/1081] [D loss: 1.732080] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.769711] time: 0:07:57.857666\n",
      "(10, 128, 128, 3)\n",
      "0.91927975\n",
      "[Epoch 0/10] [Batch 1002/1081] [D loss: 1.730417] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.859997] time: 0:07:58.355726\n",
      "(10, 128, 128, 3)\n",
      "0.86794776\n",
      "[Epoch 0/10] [Batch 1003/1081] [D loss: 1.729278] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.999989] time: 0:07:58.851800\n",
      "(10, 128, 128, 3)\n",
      "0.89486307\n",
      "[Epoch 0/10] [Batch 1004/1081] [D loss: 1.727781] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.461353] time: 0:07:59.328842\n",
      "(10, 128, 128, 3)\n",
      "0.88622826\n",
      "[Epoch 0/10] [Batch 1005/1081] [D loss: 1.726772] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.205490] time: 0:07:59.807264\n",
      "(10, 128, 128, 3)\n",
      "0.8959058\n",
      "[Epoch 0/10] [Batch 1006/1081] [D loss: 1.723936] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.233776] time: 0:08:00.299595\n",
      "(10, 128, 128, 3)\n",
      "0.87394863\n",
      "[Epoch 0/10] [Batch 1007/1081] [D loss: 1.722686] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.506983] time: 0:08:00.766880\n",
      "(10, 128, 128, 3)\n",
      "0.9041896\n",
      "[Epoch 0/10] [Batch 1008/1081] [D loss: 1.721541] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.299343] time: 0:08:01.272420\n",
      "(10, 128, 128, 3)\n",
      "0.9021625\n",
      "[Epoch 0/10] [Batch 1009/1081] [D loss: 1.719273] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.896580] time: 0:08:01.733030\n",
      "(10, 128, 128, 3)\n",
      "0.926862\n",
      "[Epoch 0/10] [Batch 1010/1081] [D loss: 1.718850] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.852631] time: 0:08:02.209723\n",
      "(10, 128, 128, 3)\n",
      "0.8775602\n",
      "[Epoch 0/10] [Batch 1011/1081] [D loss: 1.716076] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.055569] time: 0:08:02.683479\n",
      "(10, 128, 128, 3)\n",
      "0.91306853\n",
      "[Epoch 0/10] [Batch 1012/1081] [D loss: 1.714325] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.015957] time: 0:08:03.182978\n",
      "(10, 128, 128, 3)\n",
      "0.9617676\n",
      "[Epoch 0/10] [Batch 1013/1081] [D loss: 1.712551] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.749584] time: 0:08:03.684956\n",
      "(10, 128, 128, 3)\n",
      "0.94287187\n",
      "[Epoch 0/10] [Batch 1014/1081] [D loss: 1.711420] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.633041] time: 0:08:04.154490\n",
      "(10, 128, 128, 3)\n",
      "0.9116561\n",
      "[Epoch 0/10] [Batch 1015/1081] [D loss: 1.709705] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.838465] time: 0:08:04.621057\n",
      "(10, 128, 128, 3)\n",
      "0.86932564\n",
      "[Epoch 0/10] [Batch 1016/1081] [D loss: 1.708434] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.489151] time: 0:08:05.136695\n",
      "(10, 128, 128, 3)\n",
      "0.89611036\n",
      "[Epoch 0/10] [Batch 1017/1081] [D loss: 1.706379] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.297718] time: 0:08:05.619323\n",
      "(10, 128, 128, 3)\n",
      "0.89483625\n",
      "[Epoch 0/10] [Batch 1018/1081] [D loss: 1.705593] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.578327] time: 0:08:06.094242\n",
      "(10, 128, 128, 3)\n",
      "0.91194695\n",
      "[Epoch 0/10] [Batch 1019/1081] [D loss: 1.703461] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.365818] time: 0:08:06.588824\n",
      "(10, 128, 128, 3)\n",
      "0.9137333\n",
      "[Epoch 0/10] [Batch 1020/1081] [D loss: 1.701691] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.967991] time: 0:08:07.138045\n",
      "(10, 128, 128, 3)\n",
      "0.8799357\n",
      "[Epoch 0/10] [Batch 1021/1081] [D loss: 1.701296] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.064327] time: 0:08:07.633667\n",
      "(10, 128, 128, 3)\n",
      "0.9103996\n",
      "[Epoch 0/10] [Batch 1022/1081] [D loss: 1.698972] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.146328] time: 0:08:08.146699\n",
      "(10, 128, 128, 3)\n",
      "0.9161971\n",
      "[Epoch 0/10] [Batch 1023/1081] [D loss: 1.697214] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.124378] time: 0:08:08.626359\n",
      "(10, 128, 128, 3)\n",
      "0.836732\n",
      "[Epoch 0/10] [Batch 1024/1081] [D loss: 1.695462] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.055733] time: 0:08:09.114496\n",
      "(10, 128, 128, 3)\n",
      "0.92708606\n",
      "[Epoch 0/10] [Batch 1025/1081] [D loss: 1.697327] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.568600] time: 0:08:09.602781\n",
      "(10, 128, 128, 3)\n",
      "0.8652324\n",
      "[Epoch 0/10] [Batch 1026/1081] [D loss: 1.692613] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.318813] time: 0:08:10.086752\n",
      "(10, 128, 128, 3)\n",
      "0.87150127\n",
      "[Epoch 0/10] [Batch 1027/1081] [D loss: 1.691861] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.567959] time: 0:08:10.571527\n",
      "(10, 128, 128, 3)\n",
      "0.9323632\n",
      "[Epoch 0/10] [Batch 1028/1081] [D loss: 1.690032] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.394169] time: 0:08:11.056438\n",
      "(10, 128, 128, 3)\n",
      "0.8237093\n",
      "[Epoch 0/10] [Batch 1029/1081] [D loss: 1.689103] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.949381] time: 0:08:11.539371\n",
      "(10, 128, 128, 3)\n",
      "0.8896964\n",
      "[Epoch 0/10] [Batch 1030/1081] [D loss: 1.685775] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.355469] time: 0:08:12.038097\n",
      "(10, 128, 128, 3)\n",
      "0.907831\n",
      "[Epoch 0/10] [Batch 1031/1081] [D loss: 1.684132] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.738266] time: 0:08:12.551605\n",
      "(10, 128, 128, 3)\n",
      "0.9323873\n",
      "[Epoch 0/10] [Batch 1032/1081] [D loss: 1.682616] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.722672] time: 0:08:13.049572\n",
      "(10, 128, 128, 3)\n",
      "0.911864\n",
      "[Epoch 0/10] [Batch 1033/1081] [D loss: 1.682048] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.342365] time: 0:08:13.565082\n",
      "(10, 128, 128, 3)\n",
      "0.9235487\n",
      "[Epoch 0/10] [Batch 1034/1081] [D loss: 1.680090] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.794743] time: 0:08:14.046994\n",
      "(10, 128, 128, 3)\n",
      "0.9023981\n",
      "[Epoch 0/10] [Batch 1035/1081] [D loss: 1.678439] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 32.144932] time: 0:08:14.536910\n",
      "(10, 128, 128, 3)\n",
      "0.9096887\n",
      "[Epoch 0/10] [Batch 1036/1081] [D loss: 1.676714] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.139816] time: 0:08:15.067844\n",
      "(10, 128, 128, 3)\n",
      "0.91803694\n",
      "[Epoch 0/10] [Batch 1037/1081] [D loss: 1.675037] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.418493] time: 0:08:15.550056\n",
      "(10, 128, 128, 3)\n",
      "0.8700699\n",
      "[Epoch 0/10] [Batch 1038/1081] [D loss: 1.674250] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.277838] time: 0:08:16.052947\n",
      "(10, 128, 128, 3)\n",
      "0.8872969\n",
      "[Epoch 0/10] [Batch 1039/1081] [D loss: 1.672058] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.582531] time: 0:08:16.518636\n",
      "(10, 128, 128, 3)\n",
      "0.92254096\n",
      "[Epoch 0/10] [Batch 1040/1081] [D loss: 1.670879] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.486938] time: 0:08:17.035446\n",
      "(10, 128, 128, 3)\n",
      "0.91925746\n",
      "[Epoch 0/10] [Batch 1041/1081] [D loss: 1.668726] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.162226] time: 0:08:17.553908\n",
      "(10, 128, 128, 3)\n",
      "0.8864531\n",
      "[Epoch 0/10] [Batch 1042/1081] [D loss: 1.666879] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.192417] time: 0:08:18.046658\n",
      "(10, 128, 128, 3)\n",
      "0.9357767\n",
      "[Epoch 0/10] [Batch 1043/1081] [D loss: 1.666473] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.719090] time: 0:08:18.545908\n",
      "(10, 128, 128, 3)\n",
      "0.9538668\n",
      "[Epoch 0/10] [Batch 1044/1081] [D loss: 1.663529] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.193506] time: 0:08:19.018659\n",
      "(10, 128, 128, 3)\n",
      "0.8911619\n",
      "[Epoch 0/10] [Batch 1045/1081] [D loss: 1.662777] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.802021] time: 0:08:19.518238\n",
      "(10, 128, 128, 3)\n",
      "0.89046687\n",
      "[Epoch 0/10] [Batch 1046/1081] [D loss: 1.660695] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.340809] time: 0:08:20.002294\n",
      "(10, 128, 128, 3)\n",
      "0.90023136\n",
      "[Epoch 0/10] [Batch 1047/1081] [D loss: 1.659582] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.827946] time: 0:08:20.457417\n",
      "(10, 128, 128, 3)\n",
      "0.91570145\n",
      "[Epoch 0/10] [Batch 1048/1081] [D loss: 1.657775] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.658039] time: 0:08:20.989505\n",
      "(10, 128, 128, 3)\n",
      "0.95758504\n",
      "[Epoch 0/10] [Batch 1049/1081] [D loss: 1.656193] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.709339] time: 0:08:21.469878\n",
      "(10, 128, 128, 3)\n",
      "0.89536357\n",
      "[Epoch 0/10] [Batch 1050/1081] [D loss: 1.654161] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.211079] time: 0:08:21.932640\n",
      "(10, 128, 128, 3)\n",
      "0.8218076\n",
      "[Epoch 0/10] [Batch 1051/1081] [D loss: 1.654820] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.250927] time: 0:08:22.425722\n",
      "(10, 128, 128, 3)\n",
      "0.88191897\n",
      "[Epoch 0/10] [Batch 1052/1081] [D loss: 1.650959] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.195553] time: 0:08:22.954658\n",
      "(10, 128, 128, 3)\n",
      "0.9057378\n",
      "[Epoch 0/10] [Batch 1053/1081] [D loss: 1.652726] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.435452] time: 0:08:23.442874\n",
      "(10, 128, 128, 3)\n",
      "0.9376178\n",
      "[Epoch 0/10] [Batch 1054/1081] [D loss: 1.647924] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.522985] time: 0:08:23.920162\n",
      "(10, 128, 128, 3)\n",
      "0.85888547\n",
      "[Epoch 0/10] [Batch 1055/1081] [D loss: 1.646452] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.193256] time: 0:08:24.409352\n",
      "(10, 128, 128, 3)\n",
      "0.90915585\n",
      "[Epoch 0/10] [Batch 1056/1081] [D loss: 1.644775] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.237320] time: 0:08:24.943809\n",
      "(10, 128, 128, 3)\n",
      "0.9599704\n",
      "[Epoch 0/10] [Batch 1057/1081] [D loss: 1.643771] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.106089] time: 0:08:25.435547\n",
      "(10, 128, 128, 3)\n",
      "0.8585632\n",
      "[Epoch 0/10] [Batch 1058/1081] [D loss: 1.641820] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.482548] time: 0:08:25.895554\n",
      "(10, 128, 128, 3)\n",
      "0.8940396\n",
      "[Epoch 0/10] [Batch 1059/1081] [D loss: 1.640244] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.297684] time: 0:08:26.394113\n",
      "(10, 128, 128, 3)\n",
      "0.9140532\n",
      "[Epoch 0/10] [Batch 1060/1081] [D loss: 1.639217] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.646198] time: 0:08:26.890956\n",
      "(10, 128, 128, 3)\n",
      "0.87731034\n",
      "[Epoch 0/10] [Batch 1061/1081] [D loss: 1.636966] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.388531] time: 0:08:27.372151\n",
      "(10, 128, 128, 3)\n",
      "0.8915043\n",
      "[Epoch 0/10] [Batch 1062/1081] [D loss: 1.635411] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.321346] time: 0:08:27.876769\n",
      "(10, 128, 128, 3)\n",
      "0.9191329\n",
      "[Epoch 0/10] [Batch 1063/1081] [D loss: 1.636189] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.835720] time: 0:08:28.354579\n",
      "(10, 128, 128, 3)\n",
      "0.9106671\n",
      "[Epoch 0/10] [Batch 1064/1081] [D loss: 1.632449] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.887690] time: 0:08:28.839115\n",
      "(10, 128, 128, 3)\n",
      "0.90088797\n",
      "[Epoch 0/10] [Batch 1065/1081] [D loss: 1.631882] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.500702] time: 0:08:29.366862\n",
      "(10, 128, 128, 3)\n",
      "0.86176807\n",
      "[Epoch 0/10] [Batch 1066/1081] [D loss: 1.630584] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.411510] time: 0:08:29.858829\n",
      "(10, 128, 128, 3)\n",
      "0.82089204\n",
      "[Epoch 0/10] [Batch 1067/1081] [D loss: 1.627438] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.514416] time: 0:08:30.377857\n",
      "(10, 128, 128, 3)\n",
      "0.9209946\n",
      "[Epoch 0/10] [Batch 1068/1081] [D loss: 1.626014] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.594700] time: 0:08:30.874739\n",
      "(10, 128, 128, 3)\n",
      "0.8959189\n",
      "[Epoch 0/10] [Batch 1069/1081] [D loss: 1.624363] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.438610] time: 0:08:31.338220\n",
      "(10, 128, 128, 3)\n",
      "0.8985668\n",
      "[Epoch 0/10] [Batch 1070/1081] [D loss: 1.624327] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.956776] time: 0:08:31.821445\n",
      "(10, 128, 128, 3)\n",
      "0.89050025\n",
      "[Epoch 0/10] [Batch 1071/1081] [D loss: 1.621339] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.928432] time: 0:08:32.321983\n",
      "(10, 128, 128, 3)\n",
      "0.9556141\n",
      "[Epoch 0/10] [Batch 1072/1081] [D loss: 1.619638] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.825922] time: 0:08:32.818778\n",
      "(10, 128, 128, 3)\n",
      "0.8989534\n",
      "[Epoch 0/10] [Batch 1073/1081] [D loss: 1.618596] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.730473] time: 0:08:33.288579\n",
      "(10, 128, 128, 3)\n",
      "0.88638717\n",
      "[Epoch 0/10] [Batch 1074/1081] [D loss: 1.616901] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.470051] time: 0:08:33.744799\n",
      "(10, 128, 128, 3)\n",
      "0.90209574\n",
      "[Epoch 0/10] [Batch 1075/1081] [D loss: 1.615361] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.072941] time: 0:08:34.202182\n",
      "(10, 128, 128, 3)\n",
      "0.95641273\n",
      "[Epoch 0/10] [Batch 1076/1081] [D loss: 1.613328] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.543186] time: 0:08:34.693761\n",
      "(10, 128, 128, 3)\n",
      "0.9156871\n",
      "[Epoch 0/10] [Batch 1077/1081] [D loss: 1.611925] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.777039] time: 0:08:35.218482\n",
      "(10, 128, 128, 3)\n",
      "0.8924744\n",
      "[Epoch 0/10] [Batch 1078/1081] [D loss: 1.611182] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.713642] time: 0:08:35.695696\n",
      "(10, 128, 128, 3)\n",
      "0.904233\n",
      "[Epoch 0/10] [Batch 1079/1081] [D loss: 1.609004] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.621023] time: 0:08:36.149591\n",
      "############ VALIDATION OF EPOCH 0 ############\n",
      "############ TRAINING OF EPOCH 1 ############\n",
      "(10, 128, 128, 3)\n",
      "0.8434729\n",
      "[Epoch 1/10] [Batch 0/1081] [D loss: 1.607380] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.317097] time: 0:09:31.270346\n",
      "(10, 128, 128, 3)\n",
      "0.88719946\n",
      "[Epoch 1/10] [Batch 1/1081] [D loss: 1.605723] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.627157] time: 0:09:31.762300\n",
      "(10, 128, 128, 3)\n",
      "0.90302366\n",
      "[Epoch 1/10] [Batch 2/1081] [D loss: 1.606818] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.018127] time: 0:09:32.245055\n",
      "(10, 128, 128, 3)\n",
      "0.9126194\n",
      "[Epoch 1/10] [Batch 3/1081] [D loss: 1.604780] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 31.279261] time: 0:09:32.693348\n",
      "(10, 128, 128, 3)\n",
      "0.9212127\n",
      "[Epoch 1/10] [Batch 4/1081] [D loss: 1.601276] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.245228] time: 0:09:33.198423\n",
      "(10, 128, 128, 3)\n",
      "0.89183635\n",
      "[Epoch 1/10] [Batch 5/1081] [D loss: 1.600250] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.178396] time: 0:09:33.709691\n",
      "(10, 128, 128, 3)\n",
      "0.86763096\n",
      "[Epoch 1/10] [Batch 6/1081] [D loss: 1.597951] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.028234] time: 0:09:34.172680\n",
      "(10, 128, 128, 3)\n",
      "0.91232705\n",
      "[Epoch 1/10] [Batch 7/1081] [D loss: 1.596531] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.938009] time: 0:09:34.654426\n",
      "(10, 128, 128, 3)\n",
      "0.8734729\n",
      "[Epoch 1/10] [Batch 8/1081] [D loss: 1.594939] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.225163] time: 0:09:35.159624\n",
      "(10, 128, 128, 3)\n",
      "0.8342903\n",
      "[Epoch 1/10] [Batch 9/1081] [D loss: 1.593751] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.628567] time: 0:09:35.657395\n",
      "(10, 128, 128, 3)\n",
      "0.8640688\n",
      "[Epoch 1/10] [Batch 10/1081] [D loss: 1.592187] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.659967] time: 0:09:36.119548\n",
      "(10, 128, 128, 3)\n",
      "0.88810444\n",
      "[Epoch 1/10] [Batch 11/1081] [D loss: 1.590830] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.975794] time: 0:09:36.606437\n",
      "(10, 128, 128, 3)\n",
      "0.9532071\n",
      "[Epoch 1/10] [Batch 12/1081] [D loss: 1.588816] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.015707] time: 0:09:37.120633\n",
      "(10, 128, 128, 3)\n",
      "0.8770489\n",
      "[Epoch 1/10] [Batch 13/1081] [D loss: 1.588463] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.851505] time: 0:09:37.594521\n",
      "(10, 128, 128, 3)\n",
      "0.97075754\n",
      "[Epoch 1/10] [Batch 14/1081] [D loss: 1.585258] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.341909] time: 0:09:38.069953\n",
      "(10, 128, 128, 3)\n",
      "0.94888884\n",
      "[Epoch 1/10] [Batch 15/1081] [D loss: 1.584590] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.135077] time: 0:09:38.546159\n",
      "(10, 128, 128, 3)\n",
      "0.91391724\n",
      "[Epoch 1/10] [Batch 16/1081] [D loss: 1.582280] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.876657] time: 0:09:39.054042\n",
      "(10, 128, 128, 3)\n",
      "0.9006777\n",
      "[Epoch 1/10] [Batch 17/1081] [D loss: 1.580849] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.919704] time: 0:09:39.537923\n",
      "(10, 128, 128, 3)\n",
      "0.92354685\n",
      "[Epoch 1/10] [Batch 18/1081] [D loss: 1.579262] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.793299] time: 0:09:39.982436\n",
      "(10, 128, 128, 3)\n",
      "0.9012453\n",
      "[Epoch 1/10] [Batch 19/1081] [D loss: 1.578193] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.225275] time: 0:09:40.480531\n",
      "(10, 128, 128, 3)\n",
      "0.9179016\n",
      "[Epoch 1/10] [Batch 20/1081] [D loss: 1.576268] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.456217] time: 0:09:40.974666\n",
      "(10, 128, 128, 3)\n",
      "0.90545225\n",
      "[Epoch 1/10] [Batch 21/1081] [D loss: 1.575308] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.005203] time: 0:09:41.461327\n",
      "(10, 128, 128, 3)\n",
      "0.9058554\n",
      "[Epoch 1/10] [Batch 22/1081] [D loss: 1.574239] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.088856] time: 0:09:41.967270\n",
      "(10, 128, 128, 3)\n",
      "0.87854034\n",
      "[Epoch 1/10] [Batch 23/1081] [D loss: 1.573174] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.463568] time: 0:09:42.471919\n",
      "(10, 128, 128, 3)\n",
      "0.9438873\n",
      "[Epoch 1/10] [Batch 24/1081] [D loss: 1.570995] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.454029] time: 0:09:42.980190\n",
      "(10, 128, 128, 3)\n",
      "0.8611004\n",
      "[Epoch 1/10] [Batch 25/1081] [D loss: 1.568334] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.293064] time: 0:09:43.472625\n",
      "(10, 128, 128, 3)\n",
      "0.8917244\n",
      "[Epoch 1/10] [Batch 26/1081] [D loss: 1.568111] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.857126] time: 0:09:43.990180\n",
      "(10, 128, 128, 3)\n",
      "0.96645004\n",
      "[Epoch 1/10] [Batch 27/1081] [D loss: 1.567646] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.839828] time: 0:09:44.452614\n",
      "(10, 128, 128, 3)\n",
      "0.87926817\n",
      "[Epoch 1/10] [Batch 28/1081] [D loss: 1.565222] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.674469] time: 0:09:44.926975\n",
      "(10, 128, 128, 3)\n",
      "0.83799464\n",
      "[Epoch 1/10] [Batch 29/1081] [D loss: 1.563599] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.644627] time: 0:09:45.416760\n",
      "(10, 128, 128, 3)\n",
      "0.8808939\n",
      "[Epoch 1/10] [Batch 30/1081] [D loss: 1.560877] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.615061] time: 0:09:45.883484\n",
      "(10, 128, 128, 3)\n",
      "0.9482983\n",
      "[Epoch 1/10] [Batch 31/1081] [D loss: 1.559367] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.743809] time: 0:09:46.378704\n",
      "(10, 128, 128, 3)\n",
      "0.9064436\n",
      "[Epoch 1/10] [Batch 32/1081] [D loss: 1.647326] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 30.589508] time: 0:09:46.868080\n",
      "(10, 128, 128, 3)\n",
      "0.8859272\n",
      "[Epoch 1/10] [Batch 33/1081] [D loss: 1.622775] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.449528] time: 0:09:47.326423\n",
      "(10, 128, 128, 3)\n",
      "0.8734455\n",
      "[Epoch 1/10] [Batch 34/1081] [D loss: 2.462398] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 28.692249] time: 0:09:47.814332\n",
      "(10, 128, 128, 3)\n",
      "0.9002406\n",
      "[Epoch 1/10] [Batch 35/1081] [D loss: 1.880899] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 29.260681] time: 0:09:48.315722\n",
      "(10, 128, 128, 3)\n",
      "0.8627822\n",
      "[Epoch 1/10] [Batch 36/1081] [D loss: 1.854985] [D acc: 0.30 (0.20 real, 0.40 fake)] [G loss: 28.678122] time: 0:09:48.802651\n",
      "(10, 128, 128, 3)\n",
      "0.91463965\n",
      "[Epoch 1/10] [Batch 37/1081] [D loss: 1.816758] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 29.186443] time: 0:09:49.282077\n",
      "(10, 128, 128, 3)\n",
      "0.8816131\n",
      "[Epoch 1/10] [Batch 38/1081] [D loss: 1.757633] [D acc: 0.55 (0.20 real, 0.90 fake)] [G loss: 29.180502] time: 0:09:49.739822\n",
      "(10, 128, 128, 3)\n",
      "0.9053182\n",
      "[Epoch 1/10] [Batch 39/1081] [D loss: 1.781463] [D acc: 0.60 (1.00 real, 0.20 fake)] [G loss: 29.951412] time: 0:09:50.223474\n",
      "(10, 128, 128, 3)\n",
      "0.89752084\n",
      "[Epoch 1/10] [Batch 40/1081] [D loss: 1.611477] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.043671] time: 0:09:50.692446\n",
      "(10, 128, 128, 3)\n",
      "0.9037316\n",
      "[Epoch 1/10] [Batch 41/1081] [D loss: 1.647167] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 28.975433] time: 0:09:51.177148\n",
      "(10, 128, 128, 3)\n",
      "0.9517166\n",
      "[Epoch 1/10] [Batch 42/1081] [D loss: 1.582197] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.829254] time: 0:09:51.668133\n",
      "(10, 128, 128, 3)\n",
      "0.8623776\n",
      "[Epoch 1/10] [Batch 43/1081] [D loss: 1.560211] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.325977] time: 0:09:52.163536\n",
      "(10, 128, 128, 3)\n",
      "0.91450405\n",
      "[Epoch 1/10] [Batch 44/1081] [D loss: 1.584495] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.903748] time: 0:09:52.663551\n",
      "(10, 128, 128, 3)\n",
      "0.9088239\n",
      "[Epoch 1/10] [Batch 45/1081] [D loss: 1.571169] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.049076] time: 0:09:53.141021\n",
      "(10, 128, 128, 3)\n",
      "0.8632674\n",
      "[Epoch 1/10] [Batch 46/1081] [D loss: 1.550965] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.266830] time: 0:09:53.629708\n",
      "(10, 128, 128, 3)\n",
      "0.8628223\n",
      "[Epoch 1/10] [Batch 47/1081] [D loss: 1.547826] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.455938] time: 0:09:54.116929\n",
      "(10, 128, 128, 3)\n",
      "0.9210634\n",
      "[Epoch 1/10] [Batch 48/1081] [D loss: 1.541325] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.243763] time: 0:09:54.626830\n",
      "(10, 128, 128, 3)\n",
      "0.9360531\n",
      "[Epoch 1/10] [Batch 49/1081] [D loss: 1.544747] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 30.690472] time: 0:09:55.106415\n",
      "(10, 128, 128, 3)\n",
      "0.8825321\n",
      "[Epoch 1/10] [Batch 50/1081] [D loss: 1.553102] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.435184] time: 0:09:55.573558\n",
      "(10, 128, 128, 3)\n",
      "0.893318\n",
      "[Epoch 1/10] [Batch 51/1081] [D loss: 1.615202] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.879330] time: 0:09:56.072783\n",
      "(10, 128, 128, 3)\n",
      "0.85869503\n",
      "[Epoch 1/10] [Batch 52/1081] [D loss: 1.574192] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.407658] time: 0:09:56.589693\n",
      "(10, 128, 128, 3)\n",
      "0.87979394\n",
      "[Epoch 1/10] [Batch 53/1081] [D loss: 1.616102] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 29.604883] time: 0:09:57.076996\n",
      "(10, 128, 128, 3)\n",
      "0.90656394\n",
      "[Epoch 1/10] [Batch 54/1081] [D loss: 1.544707] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.758595] time: 0:09:57.559313\n",
      "(10, 128, 128, 3)\n",
      "0.9203627\n",
      "[Epoch 1/10] [Batch 55/1081] [D loss: 1.572532] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.978424] time: 0:09:58.027248\n",
      "(10, 128, 128, 3)\n",
      "0.8805866\n",
      "[Epoch 1/10] [Batch 56/1081] [D loss: 1.532597] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.013073] time: 0:09:58.553915\n",
      "(10, 128, 128, 3)\n",
      "0.9033627\n",
      "[Epoch 1/10] [Batch 57/1081] [D loss: 1.543238] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.510845] time: 0:09:59.049783\n",
      "(10, 128, 128, 3)\n",
      "0.9001198\n",
      "[Epoch 1/10] [Batch 58/1081] [D loss: 1.589082] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 29.599613] time: 0:09:59.510942\n",
      "(10, 128, 128, 3)\n",
      "0.8924625\n",
      "[Epoch 1/10] [Batch 59/1081] [D loss: 1.566355] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.367813] time: 0:10:00.002872\n",
      "(10, 128, 128, 3)\n",
      "0.880169\n",
      "[Epoch 1/10] [Batch 60/1081] [D loss: 1.543908] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.396709] time: 0:10:00.532586\n",
      "(10, 128, 128, 3)\n",
      "0.9028544\n",
      "[Epoch 1/10] [Batch 61/1081] [D loss: 1.525981] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.925512] time: 0:10:01.030080\n",
      "(10, 128, 128, 3)\n",
      "0.88272315\n",
      "[Epoch 1/10] [Batch 62/1081] [D loss: 1.520070] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.632746] time: 0:10:01.506045\n",
      "(10, 128, 128, 3)\n",
      "0.89775395\n",
      "[Epoch 1/10] [Batch 63/1081] [D loss: 1.530547] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 28.568399] time: 0:10:01.965196\n",
      "(10, 128, 128, 3)\n",
      "0.85568625\n",
      "[Epoch 1/10] [Batch 64/1081] [D loss: 1.515701] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.191797] time: 0:10:02.486644\n",
      "(10, 128, 128, 3)\n",
      "0.8645466\n",
      "[Epoch 1/10] [Batch 65/1081] [D loss: 1.517956] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.337727] time: 0:10:02.999356\n",
      "(10, 128, 128, 3)\n",
      "0.8852156\n",
      "[Epoch 1/10] [Batch 66/1081] [D loss: 1.518312] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.505428] time: 0:10:03.482288\n",
      "(10, 128, 128, 3)\n",
      "0.9160702\n",
      "[Epoch 1/10] [Batch 67/1081] [D loss: 1.508291] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.737524] time: 0:10:03.971180\n",
      "(10, 128, 128, 3)\n",
      "0.88469905\n",
      "[Epoch 1/10] [Batch 68/1081] [D loss: 1.511973] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.709408] time: 0:10:04.444283\n",
      "(10, 128, 128, 3)\n",
      "0.90262014\n",
      "[Epoch 1/10] [Batch 69/1081] [D loss: 1.512645] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.223511] time: 0:10:04.946293\n",
      "(10, 128, 128, 3)\n",
      "0.9086609\n",
      "[Epoch 1/10] [Batch 70/1081] [D loss: 1.511563] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.337414] time: 0:10:05.471426\n",
      "(10, 128, 128, 3)\n",
      "0.92550427\n",
      "[Epoch 1/10] [Batch 71/1081] [D loss: 1.504625] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.062281] time: 0:10:05.946276\n",
      "(10, 128, 128, 3)\n",
      "0.89347833\n",
      "[Epoch 1/10] [Batch 72/1081] [D loss: 1.501075] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.330570] time: 0:10:06.460997\n",
      "(10, 128, 128, 3)\n",
      "0.93555874\n",
      "[Epoch 1/10] [Batch 73/1081] [D loss: 1.500503] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.283585] time: 0:10:06.949813\n",
      "(10, 128, 128, 3)\n",
      "0.8935415\n",
      "[Epoch 1/10] [Batch 74/1081] [D loss: 1.500699] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.210815] time: 0:10:07.401112\n",
      "(10, 128, 128, 3)\n",
      "0.8952768\n",
      "[Epoch 1/10] [Batch 75/1081] [D loss: 1.499357] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.781275] time: 0:10:07.875552\n",
      "(10, 128, 128, 3)\n",
      "0.86339855\n",
      "[Epoch 1/10] [Batch 76/1081] [D loss: 1.501228] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.472589] time: 0:10:08.358553\n",
      "(10, 128, 128, 3)\n",
      "0.9347455\n",
      "[Epoch 1/10] [Batch 77/1081] [D loss: 1.494452] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.161724] time: 0:10:08.878260\n",
      "(10, 128, 128, 3)\n",
      "0.7974806\n",
      "[Epoch 1/10] [Batch 78/1081] [D loss: 1.493854] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.916912] time: 0:10:09.374776\n",
      "(10, 128, 128, 3)\n",
      "0.9055729\n",
      "[Epoch 1/10] [Batch 79/1081] [D loss: 1.490220] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.545116] time: 0:10:09.873838\n",
      "(10, 128, 128, 3)\n",
      "0.87560457\n",
      "[Epoch 1/10] [Batch 80/1081] [D loss: 1.492620] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.722668] time: 0:10:10.393769\n",
      "(10, 128, 128, 3)\n",
      "0.9186465\n",
      "[Epoch 1/10] [Batch 81/1081] [D loss: 1.488690] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.196661] time: 0:10:10.873203\n",
      "(10, 128, 128, 3)\n",
      "0.8863142\n",
      "[Epoch 1/10] [Batch 82/1081] [D loss: 1.489277] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.309093] time: 0:10:11.330832\n",
      "(10, 128, 128, 3)\n",
      "0.8930536\n",
      "[Epoch 1/10] [Batch 83/1081] [D loss: 1.498188] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.656021] time: 0:10:11.804026\n",
      "(10, 128, 128, 3)\n",
      "0.91969866\n",
      "[Epoch 1/10] [Batch 84/1081] [D loss: 1.493463] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.119980] time: 0:10:12.302166\n",
      "(10, 128, 128, 3)\n",
      "0.8805849\n",
      "[Epoch 1/10] [Batch 85/1081] [D loss: 1.481309] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.967001] time: 0:10:12.771352\n",
      "(10, 128, 128, 3)\n",
      "0.88988954\n",
      "[Epoch 1/10] [Batch 86/1081] [D loss: 1.480923] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.579617] time: 0:10:13.264121\n",
      "(10, 128, 128, 3)\n",
      "0.8888993\n",
      "[Epoch 1/10] [Batch 87/1081] [D loss: 1.489978] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.394903] time: 0:10:13.770505\n",
      "(10, 128, 128, 3)\n",
      "0.90629965\n",
      "[Epoch 1/10] [Batch 88/1081] [D loss: 1.479399] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.941982] time: 0:10:14.263945\n",
      "(10, 128, 128, 3)\n",
      "0.8886826\n",
      "[Epoch 1/10] [Batch 89/1081] [D loss: 1.474899] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.298878] time: 0:10:14.720553\n",
      "(10, 128, 128, 3)\n",
      "0.9131894\n",
      "[Epoch 1/10] [Batch 90/1081] [D loss: 1.476243] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.152828] time: 0:10:15.230654\n",
      "(10, 128, 128, 3)\n",
      "0.8907152\n",
      "[Epoch 1/10] [Batch 91/1081] [D loss: 1.473588] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.326557] time: 0:10:15.685249\n",
      "(10, 128, 128, 3)\n",
      "0.91061133\n",
      "[Epoch 1/10] [Batch 92/1081] [D loss: 1.472803] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.161366] time: 0:10:16.159162\n",
      "(10, 128, 128, 3)\n",
      "0.92044455\n",
      "[Epoch 1/10] [Batch 93/1081] [D loss: 1.489523] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.551121] time: 0:10:16.688345\n",
      "(10, 128, 128, 3)\n",
      "0.91016036\n",
      "[Epoch 1/10] [Batch 94/1081] [D loss: 1.476363] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.433109] time: 0:10:17.113098\n",
      "(10, 128, 128, 3)\n",
      "0.9237242\n",
      "[Epoch 1/10] [Batch 95/1081] [D loss: 1.470923] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.632580] time: 0:10:17.527022\n",
      "(10, 128, 128, 3)\n",
      "0.8574442\n",
      "[Epoch 1/10] [Batch 96/1081] [D loss: 1.466024] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.966183] time: 0:10:17.956022\n",
      "(10, 128, 128, 3)\n",
      "0.8499787\n",
      "[Epoch 1/10] [Batch 97/1081] [D loss: 1.464665] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.748072] time: 0:10:18.396881\n",
      "(10, 128, 128, 3)\n",
      "0.91986245\n",
      "[Epoch 1/10] [Batch 98/1081] [D loss: 1.461976] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.478291] time: 0:10:18.853741\n",
      "(10, 128, 128, 3)\n",
      "0.9254973\n",
      "[Epoch 1/10] [Batch 99/1081] [D loss: 1.461234] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.615234] time: 0:10:19.293351\n",
      "(10, 128, 128, 3)\n",
      "0.9488941\n",
      "[Epoch 1/10] [Batch 100/1081] [D loss: 1.459213] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.424221] time: 0:10:19.706981\n",
      "(10, 128, 128, 3)\n",
      "0.8707406\n",
      "[Epoch 1/10] [Batch 101/1081] [D loss: 1.458234] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.807526] time: 0:10:20.084999\n",
      "(10, 128, 128, 3)\n",
      "0.9228491\n",
      "[Epoch 1/10] [Batch 102/1081] [D loss: 1.458458] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.652552] time: 0:10:20.492744\n",
      "(10, 128, 128, 3)\n",
      "0.91556835\n",
      "[Epoch 1/10] [Batch 103/1081] [D loss: 1.457503] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.391018] time: 0:10:20.917071\n",
      "(10, 128, 128, 3)\n",
      "0.90877324\n",
      "[Epoch 1/10] [Batch 104/1081] [D loss: 1.454120] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.837696] time: 0:10:21.360585\n",
      "(10, 128, 128, 3)\n",
      "0.9110231\n",
      "[Epoch 1/10] [Batch 105/1081] [D loss: 1.453442] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.197439] time: 0:10:21.796070\n",
      "(10, 128, 128, 3)\n",
      "0.88896847\n",
      "[Epoch 1/10] [Batch 106/1081] [D loss: 1.451851] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.493000] time: 0:10:22.221163\n",
      "(10, 128, 128, 3)\n",
      "0.9273879\n",
      "[Epoch 1/10] [Batch 107/1081] [D loss: 1.448625] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.429163] time: 0:10:22.632392\n",
      "(10, 128, 128, 3)\n",
      "0.8768777\n",
      "[Epoch 1/10] [Batch 108/1081] [D loss: 1.448229] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.929859] time: 0:10:23.055992\n",
      "(10, 128, 128, 3)\n",
      "0.9171841\n",
      "[Epoch 1/10] [Batch 109/1081] [D loss: 1.445975] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.353714] time: 0:10:23.474788\n",
      "(10, 128, 128, 3)\n",
      "0.8325297\n",
      "[Epoch 1/10] [Batch 110/1081] [D loss: 1.446746] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.608511] time: 0:10:23.902748\n",
      "(10, 128, 128, 3)\n",
      "0.8871104\n",
      "[Epoch 1/10] [Batch 111/1081] [D loss: 1.444933] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.257166] time: 0:10:24.312518\n",
      "(10, 128, 128, 3)\n",
      "0.8914068\n",
      "[Epoch 1/10] [Batch 112/1081] [D loss: 1.441702] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.753576] time: 0:10:24.735108\n",
      "(10, 128, 128, 3)\n",
      "0.9457515\n",
      "[Epoch 1/10] [Batch 113/1081] [D loss: 1.441417] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.331074] time: 0:10:25.158156\n",
      "(10, 128, 128, 3)\n",
      "0.91685027\n",
      "[Epoch 1/10] [Batch 114/1081] [D loss: 1.441460] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.008846] time: 0:10:25.557004\n",
      "(10, 128, 128, 3)\n",
      "0.90251756\n",
      "[Epoch 1/10] [Batch 115/1081] [D loss: 1.438966] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.759542] time: 0:10:25.984678\n",
      "(10, 128, 128, 3)\n",
      "0.8639043\n",
      "[Epoch 1/10] [Batch 116/1081] [D loss: 1.435704] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.376499] time: 0:10:26.383912\n",
      "(10, 128, 128, 3)\n",
      "0.90529037\n",
      "[Epoch 1/10] [Batch 117/1081] [D loss: 1.433994] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.558939] time: 0:10:26.801658\n",
      "(10, 128, 128, 3)\n",
      "0.9328346\n",
      "[Epoch 1/10] [Batch 118/1081] [D loss: 1.432139] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.980646] time: 0:10:27.233594\n",
      "(10, 128, 128, 3)\n",
      "0.9147728\n",
      "[Epoch 1/10] [Batch 119/1081] [D loss: 1.431041] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.362524] time: 0:10:27.622658\n",
      "(10, 128, 128, 3)\n",
      "0.9084742\n",
      "[Epoch 1/10] [Batch 120/1081] [D loss: 1.430270] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.269466] time: 0:10:28.031045\n",
      "(10, 128, 128, 3)\n",
      "0.9157098\n",
      "[Epoch 1/10] [Batch 121/1081] [D loss: 1.428916] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.885952] time: 0:10:28.436676\n",
      "(10, 128, 128, 3)\n",
      "0.921288\n",
      "[Epoch 1/10] [Batch 122/1081] [D loss: 1.426452] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.214615] time: 0:10:28.856836\n",
      "(10, 128, 128, 3)\n",
      "0.9555607\n",
      "[Epoch 1/10] [Batch 123/1081] [D loss: 1.425723] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.018566] time: 0:10:29.278882\n",
      "(10, 128, 128, 3)\n",
      "0.90806645\n",
      "[Epoch 1/10] [Batch 124/1081] [D loss: 1.423469] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.067829] time: 0:10:29.659188\n",
      "(10, 128, 128, 3)\n",
      "0.9057725\n",
      "[Epoch 1/10] [Batch 125/1081] [D loss: 1.422001] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.234888] time: 0:10:30.093107\n",
      "(10, 128, 128, 3)\n",
      "0.95276374\n",
      "[Epoch 1/10] [Batch 126/1081] [D loss: 1.421645] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.989588] time: 0:10:30.498688\n",
      "(10, 128, 128, 3)\n",
      "0.9066739\n",
      "[Epoch 1/10] [Batch 127/1081] [D loss: 1.419725] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.823193] time: 0:10:30.896228\n",
      "(10, 128, 128, 3)\n",
      "0.92583036\n",
      "[Epoch 1/10] [Batch 128/1081] [D loss: 1.419118] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.038006] time: 0:10:31.297535\n",
      "(10, 128, 128, 3)\n",
      "0.8701014\n",
      "[Epoch 1/10] [Batch 129/1081] [D loss: 1.429104] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.992886] time: 0:10:31.711533\n",
      "(10, 128, 128, 3)\n",
      "0.91949916\n",
      "[Epoch 1/10] [Batch 130/1081] [D loss: 1.419392] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.420399] time: 0:10:32.144489\n",
      "(10, 128, 128, 3)\n",
      "0.94813293\n",
      "[Epoch 1/10] [Batch 131/1081] [D loss: 1.417129] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.762274] time: 0:10:32.530618\n",
      "(10, 128, 128, 3)\n",
      "0.89655304\n",
      "[Epoch 1/10] [Batch 132/1081] [D loss: 1.412676] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.071207] time: 0:10:32.939928\n",
      "(10, 128, 128, 3)\n",
      "0.8242128\n",
      "[Epoch 1/10] [Batch 133/1081] [D loss: 1.411045] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.358356] time: 0:10:33.356142\n",
      "(10, 128, 128, 3)\n",
      "0.91104984\n",
      "[Epoch 1/10] [Batch 134/1081] [D loss: 1.410145] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.899429] time: 0:10:33.766689\n",
      "(10, 128, 128, 3)\n",
      "0.86697346\n",
      "[Epoch 1/10] [Batch 135/1081] [D loss: 1.408206] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.598120] time: 0:10:34.180853\n",
      "(10, 128, 128, 3)\n",
      "0.87761146\n",
      "[Epoch 1/10] [Batch 136/1081] [D loss: 1.406095] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.090099] time: 0:10:34.643977\n",
      "(10, 128, 128, 3)\n",
      "0.8545905\n",
      "[Epoch 1/10] [Batch 137/1081] [D loss: 1.404557] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.106039] time: 0:10:35.132125\n",
      "(10, 128, 128, 3)\n",
      "0.8566599\n",
      "[Epoch 1/10] [Batch 138/1081] [D loss: 1.403503] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.058756] time: 0:10:35.583688\n",
      "(10, 128, 128, 3)\n",
      "0.8829059\n",
      "[Epoch 1/10] [Batch 139/1081] [D loss: 1.403851] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.110531] time: 0:10:36.059261\n",
      "(10, 128, 128, 3)\n",
      "0.9366827\n",
      "[Epoch 1/10] [Batch 140/1081] [D loss: 1.402072] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.573013] time: 0:10:36.562419\n",
      "(10, 128, 128, 3)\n",
      "0.90704995\n",
      "[Epoch 1/10] [Batch 141/1081] [D loss: 1.402263] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.142385] time: 0:10:37.021191\n",
      "(10, 128, 128, 3)\n",
      "0.91391444\n",
      "[Epoch 1/10] [Batch 142/1081] [D loss: 1.399626] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.905582] time: 0:10:37.493752\n",
      "(10, 128, 128, 3)\n",
      "0.9215622\n",
      "[Epoch 1/10] [Batch 143/1081] [D loss: 1.397717] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.179127] time: 0:10:37.941596\n",
      "(10, 128, 128, 3)\n",
      "0.8904824\n",
      "[Epoch 1/10] [Batch 144/1081] [D loss: 1.394822] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.552166] time: 0:10:38.428915\n",
      "(10, 128, 128, 3)\n",
      "0.9320628\n",
      "[Epoch 1/10] [Batch 145/1081] [D loss: 1.395854] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.244745] time: 0:10:38.920365\n",
      "(10, 128, 128, 3)\n",
      "0.9423044\n",
      "[Epoch 1/10] [Batch 146/1081] [D loss: 1.392202] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.491690] time: 0:10:39.385698\n",
      "(10, 128, 128, 3)\n",
      "0.926621\n",
      "[Epoch 1/10] [Batch 147/1081] [D loss: 1.390996] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.492367] time: 0:10:39.855816\n",
      "(10, 128, 128, 3)\n",
      "0.8358831\n",
      "[Epoch 1/10] [Batch 148/1081] [D loss: 1.389574] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.362972] time: 0:10:40.384930\n",
      "(10, 128, 128, 3)\n",
      "0.92340904\n",
      "[Epoch 1/10] [Batch 149/1081] [D loss: 1.387548] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.121624] time: 0:10:40.856483\n",
      "(10, 128, 128, 3)\n",
      "0.91280717\n",
      "[Epoch 1/10] [Batch 150/1081] [D loss: 1.385713] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.529242] time: 0:10:41.327275\n",
      "(10, 128, 128, 3)\n",
      "0.89616776\n",
      "[Epoch 1/10] [Batch 151/1081] [D loss: 1.384543] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.388515] time: 0:10:41.818812\n",
      "(10, 128, 128, 3)\n",
      "0.88935065\n",
      "[Epoch 1/10] [Batch 152/1081] [D loss: 1.383108] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.677765] time: 0:10:42.333055\n",
      "(10, 128, 128, 3)\n",
      "0.8622039\n",
      "[Epoch 1/10] [Batch 153/1081] [D loss: 1.381570] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.979420] time: 0:10:42.853215\n",
      "(10, 128, 128, 3)\n",
      "0.9202333\n",
      "[Epoch 1/10] [Batch 154/1081] [D loss: 1.381660] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.595745] time: 0:10:43.364139\n",
      "(10, 128, 128, 3)\n",
      "0.8845195\n",
      "[Epoch 1/10] [Batch 155/1081] [D loss: 1.383852] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.558935] time: 0:10:43.836139\n",
      "(10, 128, 128, 3)\n",
      "0.88682646\n",
      "[Epoch 1/10] [Batch 156/1081] [D loss: 1.377174] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.155594] time: 0:10:44.297589\n",
      "(10, 128, 128, 3)\n",
      "0.9388841\n",
      "[Epoch 1/10] [Batch 157/1081] [D loss: 1.376448] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.883234] time: 0:10:44.806157\n",
      "(10, 128, 128, 3)\n",
      "0.85119385\n",
      "[Epoch 1/10] [Batch 158/1081] [D loss: 1.375407] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.109171] time: 0:10:45.282458\n",
      "(10, 128, 128, 3)\n",
      "0.8518391\n",
      "[Epoch 1/10] [Batch 159/1081] [D loss: 1.373366] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.660181] time: 0:10:45.741629\n",
      "(10, 128, 128, 3)\n",
      "0.91380674\n",
      "[Epoch 1/10] [Batch 160/1081] [D loss: 1.381342] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.455856] time: 0:10:46.234485\n",
      "(10, 128, 128, 3)\n",
      "0.8940006\n",
      "[Epoch 1/10] [Batch 161/1081] [D loss: 1.371650] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.922022] time: 0:10:46.700327\n",
      "(10, 128, 128, 3)\n",
      "0.9090604\n",
      "[Epoch 1/10] [Batch 162/1081] [D loss: 1.370992] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.368082] time: 0:10:47.194684\n",
      "(10, 128, 128, 3)\n",
      "0.96414375\n",
      "[Epoch 1/10] [Batch 163/1081] [D loss: 1.370755] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.106762] time: 0:10:47.657072\n",
      "(10, 128, 128, 3)\n",
      "0.8915699\n",
      "[Epoch 1/10] [Batch 164/1081] [D loss: 1.367043] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.952988] time: 0:10:48.151470\n",
      "(10, 128, 128, 3)\n",
      "0.9088834\n",
      "[Epoch 1/10] [Batch 165/1081] [D loss: 1.365212] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.355862] time: 0:10:48.635969\n",
      "(10, 128, 128, 3)\n",
      "0.9033513\n",
      "[Epoch 1/10] [Batch 166/1081] [D loss: 1.362929] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.614035] time: 0:10:49.118225\n",
      "(10, 128, 128, 3)\n",
      "0.91762924\n",
      "[Epoch 1/10] [Batch 167/1081] [D loss: 1.362176] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.163122] time: 0:10:49.609736\n",
      "(10, 128, 128, 3)\n",
      "0.84178495\n",
      "[Epoch 1/10] [Batch 168/1081] [D loss: 1.367487] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.320766] time: 0:10:50.077712\n",
      "(10, 128, 128, 3)\n",
      "0.91175956\n",
      "[Epoch 1/10] [Batch 169/1081] [D loss: 1.365512] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.481176] time: 0:10:50.587252\n",
      "(10, 128, 128, 3)\n",
      "0.8254683\n",
      "[Epoch 1/10] [Batch 170/1081] [D loss: 1.357990] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.266842] time: 0:10:51.072456\n",
      "(10, 128, 128, 3)\n",
      "0.8804037\n",
      "[Epoch 1/10] [Batch 171/1081] [D loss: 1.356164] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.057034] time: 0:10:51.571468\n",
      "(10, 128, 128, 3)\n",
      "0.938299\n",
      "[Epoch 1/10] [Batch 172/1081] [D loss: 1.354960] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.933727] time: 0:10:52.046696\n",
      "(10, 128, 128, 3)\n",
      "0.8741605\n",
      "[Epoch 1/10] [Batch 173/1081] [D loss: 1.354062] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.822805] time: 0:10:52.507352\n",
      "(10, 128, 128, 3)\n",
      "0.893559\n",
      "[Epoch 1/10] [Batch 174/1081] [D loss: 1.351788] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.688030] time: 0:10:53.009450\n",
      "(10, 128, 128, 3)\n",
      "0.94504213\n",
      "[Epoch 1/10] [Batch 175/1081] [D loss: 1.349951] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.000706] time: 0:10:53.453233\n",
      "(10, 128, 128, 3)\n",
      "0.90103054\n",
      "[Epoch 1/10] [Batch 176/1081] [D loss: 1.348471] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.614025] time: 0:10:53.913728\n",
      "(10, 128, 128, 3)\n",
      "0.92750055\n",
      "[Epoch 1/10] [Batch 177/1081] [D loss: 1.349045] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.974243] time: 0:10:54.401047\n",
      "(10, 128, 128, 3)\n",
      "0.8858588\n",
      "[Epoch 1/10] [Batch 178/1081] [D loss: 1.346687] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.462336] time: 0:10:54.884842\n",
      "(10, 128, 128, 3)\n",
      "0.925404\n",
      "[Epoch 1/10] [Batch 179/1081] [D loss: 1.345107] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.396152] time: 0:10:55.400139\n",
      "(10, 128, 128, 3)\n",
      "0.91662025\n",
      "[Epoch 1/10] [Batch 180/1081] [D loss: 1.344041] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.064402] time: 0:10:55.862140\n",
      "(10, 128, 128, 3)\n",
      "0.9087293\n",
      "[Epoch 1/10] [Batch 181/1081] [D loss: 1.341687] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.322128] time: 0:10:56.335526\n",
      "(10, 128, 128, 3)\n",
      "0.9008231\n",
      "[Epoch 1/10] [Batch 182/1081] [D loss: 1.339919] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.401382] time: 0:10:56.813453\n",
      "(10, 128, 128, 3)\n",
      "0.96049404\n",
      "[Epoch 1/10] [Batch 183/1081] [D loss: 1.339324] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.839390] time: 0:10:57.290734\n",
      "(10, 128, 128, 3)\n",
      "0.91952306\n",
      "[Epoch 1/10] [Batch 184/1081] [D loss: 1.340210] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.823828] time: 0:10:57.762426\n",
      "(10, 128, 128, 3)\n",
      "0.90997463\n",
      "[Epoch 1/10] [Batch 185/1081] [D loss: 1.336727] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.617268] time: 0:10:58.236648\n",
      "(10, 128, 128, 3)\n",
      "0.95552117\n",
      "[Epoch 1/10] [Batch 186/1081] [D loss: 1.334694] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.794046] time: 0:10:58.707634\n",
      "(10, 128, 128, 3)\n",
      "0.90600276\n",
      "[Epoch 1/10] [Batch 187/1081] [D loss: 1.333062] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.367289] time: 0:10:59.151666\n",
      "(10, 128, 128, 3)\n",
      "0.8862956\n",
      "[Epoch 1/10] [Batch 188/1081] [D loss: 1.331414] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.918880] time: 0:10:59.661762\n",
      "(10, 128, 128, 3)\n",
      "0.87785214\n",
      "[Epoch 1/10] [Batch 189/1081] [D loss: 1.330044] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.169125] time: 0:11:00.135101\n",
      "(10, 128, 128, 3)\n",
      "0.9375394\n",
      "[Epoch 1/10] [Batch 190/1081] [D loss: 1.328367] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.264460] time: 0:11:00.597838\n",
      "(10, 128, 128, 3)\n",
      "0.9129591\n",
      "[Epoch 1/10] [Batch 191/1081] [D loss: 1.327529] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.702261] time: 0:11:01.125195\n",
      "(10, 128, 128, 3)\n",
      "0.8882477\n",
      "[Epoch 1/10] [Batch 192/1081] [D loss: 1.325697] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.707745] time: 0:11:01.607420\n",
      "(10, 128, 128, 3)\n",
      "0.92857045\n",
      "[Epoch 1/10] [Batch 193/1081] [D loss: 1.324786] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.469732] time: 0:11:02.075459\n",
      "(10, 128, 128, 3)\n",
      "0.9226947\n",
      "[Epoch 1/10] [Batch 194/1081] [D loss: 1.323150] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.104176] time: 0:11:02.565287\n",
      "(10, 128, 128, 3)\n",
      "0.87950987\n",
      "[Epoch 1/10] [Batch 195/1081] [D loss: 1.321898] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.022236] time: 0:11:03.039934\n",
      "(10, 128, 128, 3)\n",
      "0.9206979\n",
      "[Epoch 1/10] [Batch 196/1081] [D loss: 1.320971] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.931187] time: 0:11:03.509082\n",
      "(10, 128, 128, 3)\n",
      "0.92137665\n",
      "[Epoch 1/10] [Batch 197/1081] [D loss: 1.319759] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.052765] time: 0:11:04.001179\n",
      "(10, 128, 128, 3)\n",
      "0.95279026\n",
      "[Epoch 1/10] [Batch 198/1081] [D loss: 1.317114] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.566814] time: 0:11:04.459782\n",
      "(10, 128, 128, 3)\n",
      "0.90744996\n",
      "[Epoch 1/10] [Batch 199/1081] [D loss: 1.316877] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.589199] time: 0:11:04.912179\n",
      "(10, 128, 128, 3)\n",
      "0.8815189\n",
      "[Epoch 1/10] [Batch 200/1081] [D loss: 1.314822] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.911869] time: 0:11:05.397536\n",
      "(10, 128, 128, 3)\n",
      "0.92049235\n",
      "[Epoch 1/10] [Batch 201/1081] [D loss: 1.313841] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.129461] time: 0:11:05.862305\n",
      "(10, 128, 128, 3)\n",
      "0.9332004\n",
      "[Epoch 1/10] [Batch 202/1081] [D loss: 1.311611] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.512241] time: 0:11:06.338551\n",
      "(10, 128, 128, 3)\n",
      "0.8797377\n",
      "[Epoch 1/10] [Batch 203/1081] [D loss: 1.310296] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.033810] time: 0:11:06.808005\n",
      "(10, 128, 128, 3)\n",
      "0.94492817\n",
      "[Epoch 1/10] [Batch 204/1081] [D loss: 1.309158] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.124340] time: 0:11:07.271474\n",
      "(10, 128, 128, 3)\n",
      "0.89906406\n",
      "[Epoch 1/10] [Batch 205/1081] [D loss: 1.307571] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.169285] time: 0:11:07.753100\n",
      "(10, 128, 128, 3)\n",
      "0.8905623\n",
      "[Epoch 1/10] [Batch 206/1081] [D loss: 1.305843] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.532511] time: 0:11:08.222235\n",
      "(10, 128, 128, 3)\n",
      "0.92013496\n",
      "[Epoch 1/10] [Batch 207/1081] [D loss: 1.304402] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.124640] time: 0:11:08.666429\n",
      "(10, 128, 128, 3)\n",
      "0.95884234\n",
      "[Epoch 1/10] [Batch 208/1081] [D loss: 1.303720] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.825943] time: 0:11:09.178438\n",
      "(10, 128, 128, 3)\n",
      "0.94137377\n",
      "[Epoch 1/10] [Batch 209/1081] [D loss: 1.302380] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.367514] time: 0:11:09.668403\n",
      "(10, 128, 128, 3)\n",
      "0.88871527\n",
      "[Epoch 1/10] [Batch 210/1081] [D loss: 1.300319] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.612499] time: 0:11:10.152935\n",
      "(10, 128, 128, 3)\n",
      "0.93718\n",
      "[Epoch 1/10] [Batch 211/1081] [D loss: 1.298809] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.238791] time: 0:11:10.638375\n",
      "(10, 128, 128, 3)\n",
      "0.9228427\n",
      "[Epoch 1/10] [Batch 212/1081] [D loss: 1.297920] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.392710] time: 0:11:11.123759\n",
      "(10, 128, 128, 3)\n",
      "0.8733185\n",
      "[Epoch 1/10] [Batch 213/1081] [D loss: 1.296401] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.096537] time: 0:11:11.617170\n",
      "(10, 128, 128, 3)\n",
      "0.9214042\n",
      "[Epoch 1/10] [Batch 214/1081] [D loss: 1.295185] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.370203] time: 0:11:12.120555\n",
      "(10, 128, 128, 3)\n",
      "0.87583345\n",
      "[Epoch 1/10] [Batch 215/1081] [D loss: 1.294625] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.108242] time: 0:11:12.608411\n",
      "(10, 128, 128, 3)\n",
      "0.89491796\n",
      "[Epoch 1/10] [Batch 216/1081] [D loss: 1.801652] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 26.257935] time: 0:11:13.094422\n",
      "(10, 128, 128, 3)\n",
      "0.90558726\n",
      "[Epoch 1/10] [Batch 217/1081] [D loss: 1.383524] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.645626] time: 0:11:13.576619\n",
      "(10, 128, 128, 3)\n",
      "0.86737585\n",
      "[Epoch 1/10] [Batch 218/1081] [D loss: 1.318425] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.812103] time: 0:11:14.046461\n",
      "(10, 128, 128, 3)\n",
      "0.8972075\n",
      "[Epoch 1/10] [Batch 219/1081] [D loss: 1.365165] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.754658] time: 0:11:14.554515\n",
      "(10, 128, 128, 3)\n",
      "0.8532758\n",
      "[Epoch 1/10] [Batch 220/1081] [D loss: 1.352894] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.903284] time: 0:11:15.042788\n",
      "(10, 128, 128, 3)\n",
      "0.8811598\n",
      "[Epoch 1/10] [Batch 221/1081] [D loss: 1.354477] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.149103] time: 0:11:15.522564\n",
      "(10, 128, 128, 3)\n",
      "0.91876477\n",
      "[Epoch 1/10] [Batch 222/1081] [D loss: 1.295347] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.868763] time: 0:11:15.995667\n",
      "(10, 128, 128, 3)\n",
      "0.92153937\n",
      "[Epoch 1/10] [Batch 223/1081] [D loss: 1.286460] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.057205] time: 0:11:16.475866\n",
      "(10, 128, 128, 3)\n",
      "0.8773766\n",
      "[Epoch 1/10] [Batch 224/1081] [D loss: 1.284504] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.705637] time: 0:11:16.943754\n",
      "(10, 128, 128, 3)\n",
      "0.86573315\n",
      "[Epoch 1/10] [Batch 225/1081] [D loss: 1.280873] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.188374] time: 0:11:17.435584\n",
      "(10, 128, 128, 3)\n",
      "0.867115\n",
      "[Epoch 1/10] [Batch 226/1081] [D loss: 1.279417] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.072311] time: 0:11:17.926786\n",
      "(10, 128, 128, 3)\n",
      "0.90479475\n",
      "[Epoch 1/10] [Batch 227/1081] [D loss: 1.287534] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.237705] time: 0:11:18.434286\n",
      "(10, 128, 128, 3)\n",
      "0.91053206\n",
      "[Epoch 1/10] [Batch 228/1081] [D loss: 1.278579] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.868610] time: 0:11:18.924945\n",
      "(10, 128, 128, 3)\n",
      "0.841634\n",
      "[Epoch 1/10] [Batch 229/1081] [D loss: 1.274918] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.747808] time: 0:11:19.380949\n",
      "(10, 128, 128, 3)\n",
      "0.86162704\n",
      "[Epoch 1/10] [Batch 230/1081] [D loss: 1.285658] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.281225] time: 0:11:19.842118\n",
      "(10, 128, 128, 3)\n",
      "0.84148663\n",
      "[Epoch 1/10] [Batch 231/1081] [D loss: 1.276158] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.554773] time: 0:11:20.307907\n",
      "(10, 128, 128, 3)\n",
      "0.9030151\n",
      "[Epoch 1/10] [Batch 232/1081] [D loss: 1.276650] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.629070] time: 0:11:20.823993\n",
      "(10, 128, 128, 3)\n",
      "0.90673447\n",
      "[Epoch 1/10] [Batch 233/1081] [D loss: 1.574943] [D acc: 0.50 (0.90 real, 0.10 fake)] [G loss: 26.053314] time: 0:11:21.290537\n",
      "(10, 128, 128, 3)\n",
      "0.9547889\n",
      "[Epoch 1/10] [Batch 234/1081] [D loss: 1.279689] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.772495] time: 0:11:21.746068\n",
      "(10, 128, 128, 3)\n",
      "0.86071634\n",
      "[Epoch 1/10] [Batch 235/1081] [D loss: 1.281241] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.180847] time: 0:11:22.215824\n",
      "(10, 128, 128, 3)\n",
      "0.8924868\n",
      "[Epoch 1/10] [Batch 236/1081] [D loss: 1.270461] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.952032] time: 0:11:22.666276\n",
      "(10, 128, 128, 3)\n",
      "0.921814\n",
      "[Epoch 1/10] [Batch 237/1081] [D loss: 1.271795] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.466503] time: 0:11:23.159955\n",
      "(10, 128, 128, 3)\n",
      "0.920943\n",
      "[Epoch 1/10] [Batch 238/1081] [D loss: 1.264715] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.106695] time: 0:11:23.666112\n",
      "(10, 128, 128, 3)\n",
      "0.88978624\n",
      "[Epoch 1/10] [Batch 239/1081] [D loss: 1.263562] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.335962] time: 0:11:24.145198\n",
      "(10, 128, 128, 3)\n",
      "0.87731177\n",
      "[Epoch 1/10] [Batch 240/1081] [D loss: 1.263552] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.033157] time: 0:11:24.623813\n",
      "(10, 128, 128, 3)\n",
      "0.9108796\n",
      "[Epoch 1/10] [Batch 241/1081] [D loss: 1.291008] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 25.460670] time: 0:11:25.089434\n",
      "(10, 128, 128, 3)\n",
      "0.8465317\n",
      "[Epoch 1/10] [Batch 242/1081] [D loss: 1.259166] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.057398] time: 0:11:25.547753\n",
      "(10, 128, 128, 3)\n",
      "0.8722537\n",
      "[Epoch 1/10] [Batch 243/1081] [D loss: 1.263636] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.484524] time: 0:11:26.056677\n",
      "(10, 128, 128, 3)\n",
      "0.9344427\n",
      "[Epoch 1/10] [Batch 244/1081] [D loss: 1.258297] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.304352] time: 0:11:26.533110\n",
      "(10, 128, 128, 3)\n",
      "0.9010601\n",
      "[Epoch 1/10] [Batch 245/1081] [D loss: 1.258033] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.099697] time: 0:11:27.021192\n",
      "(10, 128, 128, 3)\n",
      "0.86083895\n",
      "[Epoch 1/10] [Batch 246/1081] [D loss: 1.274378] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.760443] time: 0:11:27.493843\n",
      "(10, 128, 128, 3)\n",
      "0.87403446\n",
      "[Epoch 1/10] [Batch 247/1081] [D loss: 1.273683] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.873684] time: 0:11:27.971920\n",
      "(10, 128, 128, 3)\n",
      "0.91594714\n",
      "[Epoch 1/10] [Batch 248/1081] [D loss: 1.257947] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.554928] time: 0:11:28.456962\n",
      "(10, 128, 128, 3)\n",
      "0.897625\n",
      "[Epoch 1/10] [Batch 249/1081] [D loss: 1.255459] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.305689] time: 0:11:28.918434\n",
      "(10, 128, 128, 3)\n",
      "0.87979794\n",
      "[Epoch 1/10] [Batch 250/1081] [D loss: 1.249594] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.997746] time: 0:11:29.400150\n",
      "(10, 128, 128, 3)\n",
      "0.930007\n",
      "[Epoch 1/10] [Batch 251/1081] [D loss: 1.248504] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.216345] time: 0:11:29.917309\n",
      "(10, 128, 128, 3)\n",
      "0.9229768\n",
      "[Epoch 1/10] [Batch 252/1081] [D loss: 1.252010] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.458118] time: 0:11:30.426982\n",
      "(10, 128, 128, 3)\n",
      "0.93006325\n",
      "[Epoch 1/10] [Batch 253/1081] [D loss: 1.244426] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.940922] time: 0:11:30.905565\n",
      "(10, 128, 128, 3)\n",
      "0.86169034\n",
      "[Epoch 1/10] [Batch 254/1081] [D loss: 1.244134] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.263840] time: 0:11:31.386497\n",
      "(10, 128, 128, 3)\n",
      "0.9075996\n",
      "[Epoch 1/10] [Batch 255/1081] [D loss: 1.263856] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.620737] time: 0:11:31.881950\n",
      "(10, 128, 128, 3)\n",
      "0.90486985\n",
      "[Epoch 1/10] [Batch 256/1081] [D loss: 1.242482] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.370874] time: 0:11:32.383190\n",
      "(10, 128, 128, 3)\n",
      "0.94750524\n",
      "[Epoch 1/10] [Batch 257/1081] [D loss: 1.243309] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.026585] time: 0:11:32.853178\n",
      "(10, 128, 128, 3)\n",
      "0.8841575\n",
      "[Epoch 1/10] [Batch 258/1081] [D loss: 1.240448] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.179230] time: 0:11:33.347553\n",
      "(10, 128, 128, 3)\n",
      "0.9689695\n",
      "[Epoch 1/10] [Batch 259/1081] [D loss: 1.237897] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.980282] time: 0:11:33.838834\n",
      "(10, 128, 128, 3)\n",
      "0.91143924\n",
      "[Epoch 1/10] [Batch 260/1081] [D loss: 1.235850] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.714752] time: 0:11:34.305138\n",
      "(10, 128, 128, 3)\n",
      "0.88645834\n",
      "[Epoch 1/10] [Batch 261/1081] [D loss: 1.236430] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.891748] time: 0:11:34.774173\n",
      "(10, 128, 128, 3)\n",
      "0.8726055\n",
      "[Epoch 1/10] [Batch 262/1081] [D loss: 1.234833] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.189331] time: 0:11:35.279515\n",
      "(10, 128, 128, 3)\n",
      "0.91146755\n",
      "[Epoch 1/10] [Batch 263/1081] [D loss: 1.231179] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.927099] time: 0:11:35.791266\n",
      "(10, 128, 128, 3)\n",
      "0.9313583\n",
      "[Epoch 1/10] [Batch 264/1081] [D loss: 1.229967] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.401033] time: 0:11:36.306689\n",
      "(10, 128, 128, 3)\n",
      "0.93319684\n",
      "[Epoch 1/10] [Batch 265/1081] [D loss: 1.228612] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.363928] time: 0:11:36.783570\n",
      "(10, 128, 128, 3)\n",
      "0.86618406\n",
      "[Epoch 1/10] [Batch 266/1081] [D loss: 1.228146] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.574863] time: 0:11:37.252744\n",
      "(10, 128, 128, 3)\n",
      "0.8863546\n",
      "[Epoch 1/10] [Batch 267/1081] [D loss: 1.229620] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.132055] time: 0:11:37.759377\n",
      "(10, 128, 128, 3)\n",
      "0.89993924\n",
      "[Epoch 1/10] [Batch 268/1081] [D loss: 1.225109] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.303333] time: 0:11:38.273543\n",
      "(10, 128, 128, 3)\n",
      "0.9170642\n",
      "[Epoch 1/10] [Batch 269/1081] [D loss: 1.223103] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.843460] time: 0:11:38.767903\n",
      "(10, 128, 128, 3)\n",
      "0.92299557\n",
      "[Epoch 1/10] [Batch 270/1081] [D loss: 1.221262] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.190815] time: 0:11:39.236183\n",
      "(10, 128, 128, 3)\n",
      "0.8961497\n",
      "[Epoch 1/10] [Batch 271/1081] [D loss: 1.219571] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.762609] time: 0:11:39.710578\n",
      "(10, 128, 128, 3)\n",
      "0.9687915\n",
      "[Epoch 1/10] [Batch 272/1081] [D loss: 1.219360] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.012690] time: 0:11:40.192265\n",
      "(10, 128, 128, 3)\n",
      "0.93175864\n",
      "[Epoch 1/10] [Batch 273/1081] [D loss: 1.217562] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.675365] time: 0:11:40.657935\n",
      "(10, 128, 128, 3)\n",
      "0.94478184\n",
      "[Epoch 1/10] [Batch 274/1081] [D loss: 1.215952] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.329823] time: 0:11:41.141084\n",
      "(10, 128, 128, 3)\n",
      "0.90345573\n",
      "[Epoch 1/10] [Batch 275/1081] [D loss: 1.215170] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 28.045139] time: 0:11:41.626620\n",
      "(10, 128, 128, 3)\n",
      "0.87458706\n",
      "[Epoch 1/10] [Batch 276/1081] [D loss: 1.217188] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.807056] time: 0:11:42.133462\n",
      "(10, 128, 128, 3)\n",
      "0.9148271\n",
      "[Epoch 1/10] [Batch 277/1081] [D loss: 1.222838] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.425983] time: 0:11:42.641949\n",
      "(10, 128, 128, 3)\n",
      "0.92587274\n",
      "[Epoch 1/10] [Batch 278/1081] [D loss: 1.224818] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.302437] time: 0:11:43.114847\n",
      "(10, 128, 128, 3)\n",
      "0.8909227\n",
      "[Epoch 1/10] [Batch 279/1081] [D loss: 1.209278] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.049475] time: 0:11:43.603074\n",
      "(10, 128, 128, 3)\n",
      "0.86716723\n",
      "[Epoch 1/10] [Batch 280/1081] [D loss: 1.208828] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.546066] time: 0:11:44.093434\n",
      "(10, 128, 128, 3)\n",
      "0.89692336\n",
      "[Epoch 1/10] [Batch 281/1081] [D loss: 1.208747] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.420092] time: 0:11:44.587996\n",
      "(10, 128, 128, 3)\n",
      "0.9244008\n",
      "[Epoch 1/10] [Batch 282/1081] [D loss: 1.206736] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.199299] time: 0:11:45.112817\n",
      "(10, 128, 128, 3)\n",
      "0.8937616\n",
      "[Epoch 1/10] [Batch 283/1081] [D loss: 1.205047] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.885782] time: 0:11:45.595671\n",
      "(10, 128, 128, 3)\n",
      "0.9007771\n",
      "[Epoch 1/10] [Batch 284/1081] [D loss: 1.203388] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.144886] time: 0:11:46.079794\n",
      "(10, 128, 128, 3)\n",
      "0.925205\n",
      "[Epoch 1/10] [Batch 285/1081] [D loss: 1.201106] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.810129] time: 0:11:46.573362\n",
      "(10, 128, 128, 3)\n",
      "0.89615655\n",
      "[Epoch 1/10] [Batch 286/1081] [D loss: 1.200519] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.374479] time: 0:11:47.068823\n",
      "(10, 128, 128, 3)\n",
      "0.8640492\n",
      "[Epoch 1/10] [Batch 287/1081] [D loss: 1.198544] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.863117] time: 0:11:47.575017\n",
      "(10, 128, 128, 3)\n",
      "0.89188594\n",
      "[Epoch 1/10] [Batch 288/1081] [D loss: 1.197526] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.208042] time: 0:11:48.097526\n",
      "(10, 128, 128, 3)\n",
      "0.9079678\n",
      "[Epoch 1/10] [Batch 289/1081] [D loss: 1.196440] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.167622] time: 0:11:48.610423\n",
      "(10, 128, 128, 3)\n",
      "0.9203114\n",
      "[Epoch 1/10] [Batch 290/1081] [D loss: 1.195792] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.388550] time: 0:11:49.100226\n",
      "(10, 128, 128, 3)\n",
      "0.89487094\n",
      "[Epoch 1/10] [Batch 291/1081] [D loss: 1.193536] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.875294] time: 0:11:49.598244\n",
      "(10, 128, 128, 3)\n",
      "0.86968225\n",
      "[Epoch 1/10] [Batch 292/1081] [D loss: 1.192228] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.339556] time: 0:11:50.098401\n",
      "(10, 128, 128, 3)\n",
      "0.9054966\n",
      "[Epoch 1/10] [Batch 293/1081] [D loss: 1.190893] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.050760] time: 0:11:50.577703\n",
      "(10, 128, 128, 3)\n",
      "0.88502556\n",
      "[Epoch 1/10] [Batch 294/1081] [D loss: 1.189688] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.215839] time: 0:11:51.045802\n",
      "(10, 128, 128, 3)\n",
      "0.8937947\n",
      "[Epoch 1/10] [Batch 295/1081] [D loss: 1.189292] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.181906] time: 0:11:51.522441\n",
      "(10, 128, 128, 3)\n",
      "0.8823499\n",
      "[Epoch 1/10] [Batch 296/1081] [D loss: 1.188543] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.974512] time: 0:11:52.033412\n",
      "(10, 128, 128, 3)\n",
      "0.8962083\n",
      "[Epoch 1/10] [Batch 297/1081] [D loss: 1.186057] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.647070] time: 0:11:52.514565\n",
      "(10, 128, 128, 3)\n",
      "0.8709107\n",
      "[Epoch 1/10] [Batch 298/1081] [D loss: 1.184573] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.550591] time: 0:11:52.971341\n",
      "(10, 128, 128, 3)\n",
      "0.9061653\n",
      "[Epoch 1/10] [Batch 299/1081] [D loss: 1.183182] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.992085] time: 0:11:53.467690\n",
      "(10, 128, 128, 3)\n",
      "0.8672356\n",
      "[Epoch 1/10] [Batch 300/1081] [D loss: 1.184133] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.583082] time: 0:11:53.979181\n",
      "(10, 128, 128, 3)\n",
      "0.8945809\n",
      "[Epoch 1/10] [Batch 301/1081] [D loss: 1.182179] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.363234] time: 0:11:54.473791\n",
      "(10, 128, 128, 3)\n",
      "0.9100178\n",
      "[Epoch 1/10] [Batch 302/1081] [D loss: 1.218779] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.420780] time: 0:11:54.957545\n",
      "(10, 128, 128, 3)\n",
      "0.8904822\n",
      "[Epoch 1/10] [Batch 303/1081] [D loss: 1.181717] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.536064] time: 0:11:55.430294\n",
      "(10, 128, 128, 3)\n",
      "0.92290884\n",
      "[Epoch 1/10] [Batch 304/1081] [D loss: 1.177310] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.026028] time: 0:11:55.920733\n",
      "(10, 128, 128, 3)\n",
      "0.845125\n",
      "[Epoch 1/10] [Batch 305/1081] [D loss: 1.176573] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.727245] time: 0:11:56.408841\n",
      "(10, 128, 128, 3)\n",
      "0.83008844\n",
      "[Epoch 1/10] [Batch 306/1081] [D loss: 1.180231] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.337988] time: 0:11:56.884609\n",
      "(10, 128, 128, 3)\n",
      "0.8912371\n",
      "[Epoch 1/10] [Batch 307/1081] [D loss: 1.183396] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.487644] time: 0:11:57.388562\n",
      "(10, 128, 128, 3)\n",
      "0.89419174\n",
      "[Epoch 1/10] [Batch 308/1081] [D loss: 1.175190] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.711571] time: 0:11:57.891106\n",
      "(10, 128, 128, 3)\n",
      "0.8440755\n",
      "[Epoch 1/10] [Batch 309/1081] [D loss: 1.170098] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.185303] time: 0:11:58.363969\n",
      "(10, 128, 128, 3)\n",
      "0.9130116\n",
      "[Epoch 1/10] [Batch 310/1081] [D loss: 1.170965] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.072849] time: 0:11:58.894884\n",
      "(10, 128, 128, 3)\n",
      "0.88679105\n",
      "[Epoch 1/10] [Batch 311/1081] [D loss: 1.169060] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.513664] time: 0:11:59.415846\n",
      "(10, 128, 128, 3)\n",
      "0.92606926\n",
      "[Epoch 1/10] [Batch 312/1081] [D loss: 1.165891] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.621204] time: 0:11:59.926714\n",
      "(10, 128, 128, 3)\n",
      "0.92814547\n",
      "[Epoch 1/10] [Batch 313/1081] [D loss: 1.165103] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.646566] time: 0:12:00.416121\n",
      "(10, 128, 128, 3)\n",
      "0.90664786\n",
      "[Epoch 1/10] [Batch 314/1081] [D loss: 1.163730] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.902302] time: 0:12:00.881058\n",
      "(10, 128, 128, 3)\n",
      "0.9301729\n",
      "[Epoch 1/10] [Batch 315/1081] [D loss: 1.162129] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.028301] time: 0:12:01.339801\n",
      "(10, 128, 128, 3)\n",
      "0.8963843\n",
      "[Epoch 1/10] [Batch 316/1081] [D loss: 1.161574] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.296024] time: 0:12:01.840600\n",
      "(10, 128, 128, 3)\n",
      "0.9318955\n",
      "[Epoch 1/10] [Batch 317/1081] [D loss: 1.164164] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.593872] time: 0:12:02.339034\n",
      "(10, 128, 128, 3)\n",
      "0.9380412\n",
      "[Epoch 1/10] [Batch 318/1081] [D loss: 1.160081] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.790020] time: 0:12:02.822093\n",
      "(10, 128, 128, 3)\n",
      "0.8932364\n",
      "[Epoch 1/10] [Batch 319/1081] [D loss: 1.157303] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.944296] time: 0:12:03.267054\n",
      "(10, 128, 128, 3)\n",
      "0.9107638\n",
      "[Epoch 1/10] [Batch 320/1081] [D loss: 1.156861] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.640621] time: 0:12:03.765659\n",
      "(10, 128, 128, 3)\n",
      "0.89360756\n",
      "[Epoch 1/10] [Batch 321/1081] [D loss: 1.156742] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.347319] time: 0:12:04.265326\n",
      "(10, 128, 128, 3)\n",
      "0.91231614\n",
      "[Epoch 1/10] [Batch 322/1081] [D loss: 1.154478] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.465984] time: 0:12:04.777647\n",
      "(10, 128, 128, 3)\n",
      "0.911611\n",
      "[Epoch 1/10] [Batch 323/1081] [D loss: 1.153855] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.339630] time: 0:12:05.272030\n",
      "(10, 128, 128, 3)\n",
      "0.88022923\n",
      "[Epoch 1/10] [Batch 324/1081] [D loss: 1.151736] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.633327] time: 0:12:05.770607\n",
      "(10, 128, 128, 3)\n",
      "0.8998831\n",
      "[Epoch 1/10] [Batch 325/1081] [D loss: 1.149576] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.426399] time: 0:12:06.260025\n",
      "(10, 128, 128, 3)\n",
      "0.92931104\n",
      "[Epoch 1/10] [Batch 326/1081] [D loss: 1.149224] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.778515] time: 0:12:06.743958\n",
      "(10, 128, 128, 3)\n",
      "0.92353386\n",
      "[Epoch 1/10] [Batch 327/1081] [D loss: 1.148089] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.795620] time: 0:12:07.216897\n",
      "(10, 128, 128, 3)\n",
      "0.9218301\n",
      "[Epoch 1/10] [Batch 328/1081] [D loss: 1.145689] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.965845] time: 0:12:07.694896\n",
      "(10, 128, 128, 3)\n",
      "0.95518106\n",
      "[Epoch 1/10] [Batch 329/1081] [D loss: 1.147733] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.990051] time: 0:12:08.181274\n",
      "(10, 128, 128, 3)\n",
      "0.93593425\n",
      "[Epoch 1/10] [Batch 330/1081] [D loss: 1.145420] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.225998] time: 0:12:08.656787\n",
      "(10, 128, 128, 3)\n",
      "0.9065301\n",
      "[Epoch 1/10] [Batch 331/1081] [D loss: 1.144049] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.354818] time: 0:12:09.130508\n",
      "(10, 128, 128, 3)\n",
      "0.89439946\n",
      "[Epoch 1/10] [Batch 332/1081] [D loss: 1.144097] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.585232] time: 0:12:09.609904\n",
      "(10, 128, 128, 3)\n",
      "0.9192257\n",
      "[Epoch 1/10] [Batch 333/1081] [D loss: 1.141786] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.380957] time: 0:12:10.097818\n",
      "(10, 128, 128, 3)\n",
      "0.8818944\n",
      "[Epoch 1/10] [Batch 334/1081] [D loss: 1.140636] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.243843] time: 0:12:10.577987\n",
      "(10, 128, 128, 3)\n",
      "0.94542366\n",
      "[Epoch 1/10] [Batch 335/1081] [D loss: 1.137604] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.493374] time: 0:12:11.082923\n",
      "(10, 128, 128, 3)\n",
      "0.84788865\n",
      "[Epoch 1/10] [Batch 336/1081] [D loss: 1.135879] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.172440] time: 0:12:11.586053\n",
      "(10, 128, 128, 3)\n",
      "0.92476183\n",
      "[Epoch 1/10] [Batch 337/1081] [D loss: 1.135819] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.809977] time: 0:12:12.082018\n",
      "(10, 128, 128, 3)\n",
      "0.91516477\n",
      "[Epoch 1/10] [Batch 338/1081] [D loss: 1.135657] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.670752] time: 0:12:12.556055\n",
      "(10, 128, 128, 3)\n",
      "0.8761835\n",
      "[Epoch 1/10] [Batch 339/1081] [D loss: 1.135211] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.451630] time: 0:12:13.017283\n",
      "(10, 128, 128, 3)\n",
      "0.9111492\n",
      "[Epoch 1/10] [Batch 340/1081] [D loss: 1.311505] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 30.442007] time: 0:12:14.155666\n",
      "(10, 128, 128, 3)\n",
      "0.9396804\n",
      "[Epoch 1/10] [Batch 341/1081] [D loss: 1.176848] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 29.333851] time: 0:12:14.650431\n",
      "(10, 128, 128, 3)\n",
      "0.8884012\n",
      "[Epoch 1/10] [Batch 342/1081] [D loss: 1.141684] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.914373] time: 0:12:15.130343\n",
      "(10, 128, 128, 3)\n",
      "0.9352034\n",
      "[Epoch 1/10] [Batch 343/1081] [D loss: 1.131682] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.966778] time: 0:12:15.603895\n",
      "(10, 128, 128, 3)\n",
      "0.87884164\n",
      "[Epoch 1/10] [Batch 344/1081] [D loss: 1.128784] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.602068] time: 0:12:16.083412\n",
      "(10, 128, 128, 3)\n",
      "0.8814931\n",
      "[Epoch 1/10] [Batch 345/1081] [D loss: 1.130739] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.099987] time: 0:12:16.574341\n",
      "(10, 128, 128, 3)\n",
      "0.91249114\n",
      "[Epoch 1/10] [Batch 346/1081] [D loss: 1.173803] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.418308] time: 0:12:17.026631\n",
      "(10, 128, 128, 3)\n",
      "0.8771743\n",
      "[Epoch 1/10] [Batch 347/1081] [D loss: 1.126572] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.132257] time: 0:12:17.515297\n",
      "(10, 128, 128, 3)\n",
      "0.9129583\n",
      "[Epoch 1/10] [Batch 348/1081] [D loss: 1.124053] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.899275] time: 0:12:18.061974\n",
      "(10, 128, 128, 3)\n",
      "0.86969155\n",
      "[Epoch 1/10] [Batch 349/1081] [D loss: 1.127409] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.813192] time: 0:12:18.551212\n",
      "(10, 128, 128, 3)\n",
      "0.8976984\n",
      "[Epoch 1/10] [Batch 350/1081] [D loss: 1.123909] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.091507] time: 0:12:19.040592\n",
      "(10, 128, 128, 3)\n",
      "0.92354655\n",
      "[Epoch 1/10] [Batch 351/1081] [D loss: 1.122133] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.374996] time: 0:12:19.512271\n",
      "(10, 128, 128, 3)\n",
      "0.9030693\n",
      "[Epoch 1/10] [Batch 352/1081] [D loss: 1.842572] [D acc: 0.10 (0.00 real, 0.20 fake)] [G loss: 24.651562] time: 0:12:19.995885\n",
      "(10, 128, 128, 3)\n",
      "0.8969414\n",
      "[Epoch 1/10] [Batch 353/1081] [D loss: 1.221966] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.580317] time: 0:12:20.495193\n",
      "(10, 128, 128, 3)\n",
      "0.8998399\n",
      "[Epoch 1/10] [Batch 354/1081] [D loss: 1.130693] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.379900] time: 0:12:21.003089\n",
      "(10, 128, 128, 3)\n",
      "0.9341702\n",
      "[Epoch 1/10] [Batch 355/1081] [D loss: 1.118988] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 27.101414] time: 0:12:21.482320\n",
      "(10, 128, 128, 3)\n",
      "0.8986595\n",
      "[Epoch 1/10] [Batch 356/1081] [D loss: 1.117090] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.810385] time: 0:12:21.967316\n",
      "(10, 128, 128, 3)\n",
      "0.9012889\n",
      "[Epoch 1/10] [Batch 357/1081] [D loss: 1.112050] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.520695] time: 0:12:22.479380\n",
      "(10, 128, 128, 3)\n",
      "0.93610567\n",
      "[Epoch 1/10] [Batch 358/1081] [D loss: 1.672390] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 24.234879] time: 0:12:22.962030\n",
      "(10, 128, 128, 3)\n",
      "0.9218063\n",
      "[Epoch 1/10] [Batch 359/1081] [D loss: 1.118317] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.096901] time: 0:12:23.436701\n",
      "(10, 128, 128, 3)\n",
      "0.89829665\n",
      "[Epoch 1/10] [Batch 360/1081] [D loss: 1.113233] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.108480] time: 0:12:23.903573\n",
      "(10, 128, 128, 3)\n",
      "0.87849855\n",
      "[Epoch 1/10] [Batch 361/1081] [D loss: 1.108329] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.233139] time: 0:12:24.407825\n",
      "(10, 128, 128, 3)\n",
      "0.9297996\n",
      "[Epoch 1/10] [Batch 362/1081] [D loss: 1.115305] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.286480] time: 0:12:24.931092\n",
      "(10, 128, 128, 3)\n",
      "0.92954516\n",
      "[Epoch 1/10] [Batch 363/1081] [D loss: 1.106888] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.525265] time: 0:12:25.402076\n",
      "(10, 128, 128, 3)\n",
      "0.95262355\n",
      "[Epoch 1/10] [Batch 364/1081] [D loss: 1.111675] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.760695] time: 0:12:25.900581\n",
      "(10, 128, 128, 3)\n",
      "0.920873\n",
      "[Epoch 1/10] [Batch 365/1081] [D loss: 1.110799] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.299654] time: 0:12:26.366496\n",
      "(10, 128, 128, 3)\n",
      "0.9291175\n",
      "[Epoch 1/10] [Batch 366/1081] [D loss: 1.108190] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.511154] time: 0:12:26.861920\n",
      "(10, 128, 128, 3)\n",
      "0.9674411\n",
      "[Epoch 1/10] [Batch 367/1081] [D loss: 1.105738] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.626791] time: 0:12:27.342480\n",
      "(10, 128, 128, 3)\n",
      "0.9099736\n",
      "[Epoch 1/10] [Batch 368/1081] [D loss: 1.102646] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.813370] time: 0:12:27.848283\n",
      "(10, 128, 128, 3)\n",
      "0.9714678\n",
      "[Epoch 1/10] [Batch 369/1081] [D loss: 1.101880] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.765329] time: 0:12:28.323648\n",
      "(10, 128, 128, 3)\n",
      "0.9082253\n",
      "[Epoch 1/10] [Batch 370/1081] [D loss: 1.097590] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.622883] time: 0:12:28.809454\n",
      "(10, 128, 128, 3)\n",
      "0.9128521\n",
      "[Epoch 1/10] [Batch 371/1081] [D loss: 1.099181] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.579340] time: 0:12:29.264700\n",
      "(10, 128, 128, 3)\n",
      "0.8788691\n",
      "[Epoch 1/10] [Batch 372/1081] [D loss: 1.093808] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.974934] time: 0:12:29.778445\n",
      "(10, 128, 128, 3)\n",
      "0.88463324\n",
      "[Epoch 1/10] [Batch 373/1081] [D loss: 1.093104] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.975693] time: 0:12:30.259684\n",
      "(10, 128, 128, 3)\n",
      "0.894754\n",
      "[Epoch 1/10] [Batch 374/1081] [D loss: 1.092517] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.344873] time: 0:12:30.783987\n",
      "(10, 128, 128, 3)\n",
      "0.9106417\n",
      "[Epoch 1/10] [Batch 375/1081] [D loss: 1.090245] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.856960] time: 0:12:31.291972\n",
      "(10, 128, 128, 3)\n",
      "0.93936276\n",
      "[Epoch 1/10] [Batch 376/1081] [D loss: 1.088800] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.151594] time: 0:12:31.791296\n",
      "(10, 128, 128, 3)\n",
      "0.88372\n",
      "[Epoch 1/10] [Batch 377/1081] [D loss: 1.088242] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.623436] time: 0:12:32.277103\n",
      "(10, 128, 128, 3)\n",
      "0.892988\n",
      "[Epoch 1/10] [Batch 378/1081] [D loss: 1.091152] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.450758] time: 0:12:32.754017\n",
      "(10, 128, 128, 3)\n",
      "0.9010818\n",
      "[Epoch 1/10] [Batch 379/1081] [D loss: 1.085972] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.325464] time: 0:12:33.233071\n",
      "(10, 128, 128, 3)\n",
      "0.8926007\n",
      "[Epoch 1/10] [Batch 380/1081] [D loss: 1.085998] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.055828] time: 0:12:33.717664\n",
      "(10, 128, 128, 3)\n",
      "0.9020653\n",
      "[Epoch 1/10] [Batch 381/1081] [D loss: 1.139489] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.825167] time: 0:12:34.213626\n",
      "(10, 128, 128, 3)\n",
      "0.8814659\n",
      "[Epoch 1/10] [Batch 382/1081] [D loss: 1.090162] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.569817] time: 0:12:34.714082\n",
      "(10, 128, 128, 3)\n",
      "0.8515037\n",
      "[Epoch 1/10] [Batch 383/1081] [D loss: 1.080419] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.590479] time: 0:12:35.192844\n",
      "(10, 128, 128, 3)\n",
      "0.9040125\n",
      "[Epoch 1/10] [Batch 384/1081] [D loss: 1.083896] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.195860] time: 0:12:35.694214\n",
      "(10, 128, 128, 3)\n",
      "0.896185\n",
      "[Epoch 1/10] [Batch 385/1081] [D loss: 1.094398] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.655205] time: 0:12:36.147651\n",
      "(10, 128, 128, 3)\n",
      "0.9192156\n",
      "[Epoch 1/10] [Batch 386/1081] [D loss: 1.080131] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.261181] time: 0:12:36.639898\n",
      "(10, 128, 128, 3)\n",
      "0.9106223\n",
      "[Epoch 1/10] [Batch 387/1081] [D loss: 1.082207] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.825634] time: 0:12:37.124286\n",
      "(10, 128, 128, 3)\n",
      "0.9405044\n",
      "[Epoch 1/10] [Batch 388/1081] [D loss: 1.079806] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.825972] time: 0:12:37.628712\n",
      "(10, 128, 128, 3)\n",
      "0.88362473\n",
      "[Epoch 1/10] [Batch 389/1081] [D loss: 1.082382] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.526894] time: 0:12:38.127887\n",
      "(10, 128, 128, 3)\n",
      "0.9052153\n",
      "[Epoch 1/10] [Batch 390/1081] [D loss: 1.074469] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.174471] time: 0:12:38.634297\n",
      "(10, 128, 128, 3)\n",
      "0.94279116\n",
      "[Epoch 1/10] [Batch 391/1081] [D loss: 1.070464] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.209606] time: 0:12:39.146087\n",
      "(10, 128, 128, 3)\n",
      "0.96122056\n",
      "[Epoch 1/10] [Batch 392/1081] [D loss: 1.071456] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.871891] time: 0:12:39.633895\n",
      "(10, 128, 128, 3)\n",
      "0.93214744\n",
      "[Epoch 1/10] [Batch 393/1081] [D loss: 1.075983] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.744635] time: 0:12:40.142136\n",
      "(10, 128, 128, 3)\n",
      "0.9151831\n",
      "[Epoch 1/10] [Batch 394/1081] [D loss: 1.081212] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.401333] time: 0:12:40.622246\n",
      "(10, 128, 128, 3)\n",
      "0.8963892\n",
      "[Epoch 1/10] [Batch 395/1081] [D loss: 1.076517] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.362429] time: 0:12:41.091553\n",
      "(10, 128, 128, 3)\n",
      "0.9231031\n",
      "[Epoch 1/10] [Batch 396/1081] [D loss: 1.067160] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.886002] time: 0:12:41.598235\n",
      "(10, 128, 128, 3)\n",
      "0.9007387\n",
      "[Epoch 1/10] [Batch 397/1081] [D loss: 1.063856] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.419270] time: 0:12:42.076807\n",
      "(10, 128, 128, 3)\n",
      "0.9268887\n",
      "[Epoch 1/10] [Batch 398/1081] [D loss: 1.062264] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.671934] time: 0:12:42.537990\n",
      "(10, 128, 128, 3)\n",
      "0.8626892\n",
      "[Epoch 1/10] [Batch 399/1081] [D loss: 1.064156] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.686913] time: 0:12:43.011243\n",
      "(10, 128, 128, 3)\n",
      "0.952796\n",
      "[Epoch 1/10] [Batch 400/1081] [D loss: 1.061434] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.417004] time: 0:12:43.518540\n",
      "(10, 128, 128, 3)\n",
      "0.8697271\n",
      "[Epoch 1/10] [Batch 401/1081] [D loss: 1.060273] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.807169] time: 0:12:43.986804\n",
      "(10, 128, 128, 3)\n",
      "0.9082045\n",
      "[Epoch 1/10] [Batch 402/1081] [D loss: 1.058358] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.639593] time: 0:12:44.485804\n",
      "(10, 128, 128, 3)\n",
      "0.9039573\n",
      "[Epoch 1/10] [Batch 403/1081] [D loss: 1.056828] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.117481] time: 0:12:44.979416\n",
      "(10, 128, 128, 3)\n",
      "0.91293526\n",
      "[Epoch 1/10] [Batch 404/1081] [D loss: 1.054839] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.253830] time: 0:12:45.520596\n",
      "(10, 128, 128, 3)\n",
      "0.9304121\n",
      "[Epoch 1/10] [Batch 405/1081] [D loss: 1.054826] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.240055] time: 0:12:46.017205\n",
      "(10, 128, 128, 3)\n",
      "0.8919191\n",
      "[Epoch 1/10] [Batch 406/1081] [D loss: 1.052982] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.119024] time: 0:12:46.506519\n",
      "(10, 128, 128, 3)\n",
      "0.8995455\n",
      "[Epoch 1/10] [Batch 407/1081] [D loss: 1.051862] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.202072] time: 0:12:46.980266\n",
      "(10, 128, 128, 3)\n",
      "0.96937805\n",
      "[Epoch 1/10] [Batch 408/1081] [D loss: 1.052445] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.383255] time: 0:12:47.475969\n",
      "(10, 128, 128, 3)\n",
      "0.9009606\n",
      "[Epoch 1/10] [Batch 409/1081] [D loss: 1.050208] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.128326] time: 0:12:47.961680\n",
      "(10, 128, 128, 3)\n",
      "0.93442875\n",
      "[Epoch 1/10] [Batch 410/1081] [D loss: 1.049567] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.406643] time: 0:12:48.446719\n",
      "(10, 128, 128, 3)\n",
      "0.8829573\n",
      "[Epoch 1/10] [Batch 411/1081] [D loss: 1.047616] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.263697] time: 0:12:48.915859\n",
      "(10, 128, 128, 3)\n",
      "0.8814235\n",
      "[Epoch 1/10] [Batch 412/1081] [D loss: 1.112919] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 23.383150] time: 0:12:49.398267\n",
      "(10, 128, 128, 3)\n",
      "0.87525725\n",
      "[Epoch 1/10] [Batch 413/1081] [D loss: 1.057750] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.366066] time: 0:12:49.903049\n",
      "(10, 128, 128, 3)\n",
      "0.9292312\n",
      "[Epoch 1/10] [Batch 414/1081] [D loss: 1.045064] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.541945] time: 0:12:50.392361\n",
      "(10, 128, 128, 3)\n",
      "0.8651189\n",
      "[Epoch 1/10] [Batch 415/1081] [D loss: 1.043342] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.968275] time: 0:12:50.840869\n",
      "(10, 128, 128, 3)\n",
      "0.9390258\n",
      "[Epoch 1/10] [Batch 416/1081] [D loss: 1.043076] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.084249] time: 0:12:51.353346\n",
      "(10, 128, 128, 3)\n",
      "0.8742389\n",
      "[Epoch 1/10] [Batch 417/1081] [D loss: 1.041556] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.894644] time: 0:12:51.824126\n",
      "(10, 128, 128, 3)\n",
      "0.89283544\n",
      "[Epoch 1/10] [Batch 418/1081] [D loss: 1.040233] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.426519] time: 0:12:52.311437\n",
      "(10, 128, 128, 3)\n",
      "0.8900011\n",
      "[Epoch 1/10] [Batch 419/1081] [D loss: 1.037763] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.613356] time: 0:12:52.779047\n",
      "(10, 128, 128, 3)\n",
      "0.8608563\n",
      "[Epoch 1/10] [Batch 420/1081] [D loss: 1.036255] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.893816] time: 0:12:53.290369\n",
      "(10, 128, 128, 3)\n",
      "0.9399522\n",
      "[Epoch 1/10] [Batch 421/1081] [D loss: 1.036675] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.631245] time: 0:12:53.745306\n",
      "(10, 128, 128, 3)\n",
      "0.9067839\n",
      "[Epoch 1/10] [Batch 422/1081] [D loss: 1.034369] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.718510] time: 0:12:54.217836\n",
      "(10, 128, 128, 3)\n",
      "0.91053766\n",
      "[Epoch 1/10] [Batch 423/1081] [D loss: 1.033653] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.463486] time: 0:12:54.703092\n",
      "(10, 128, 128, 3)\n",
      "0.9600437\n",
      "[Epoch 1/10] [Batch 424/1081] [D loss: 1.031554] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.722942] time: 0:12:55.139099\n",
      "(10, 128, 128, 3)\n",
      "0.8858052\n",
      "[Epoch 1/10] [Batch 425/1081] [D loss: 1.031409] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.926001] time: 0:12:55.568643\n",
      "(10, 128, 128, 3)\n",
      "0.9275033\n",
      "[Epoch 1/10] [Batch 426/1081] [D loss: 1.029494] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.830677] time: 0:12:55.984405\n",
      "(10, 128, 128, 3)\n",
      "0.921238\n",
      "[Epoch 1/10] [Batch 427/1081] [D loss: 1.030671] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.724361] time: 0:12:56.389174\n",
      "(10, 128, 128, 3)\n",
      "0.9648443\n",
      "[Epoch 1/10] [Batch 428/1081] [D loss: 1.027215] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.928984] time: 0:12:56.792876\n",
      "(10, 128, 128, 3)\n",
      "0.8671623\n",
      "[Epoch 1/10] [Batch 429/1081] [D loss: 1.027044] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.858255] time: 0:12:57.179834\n",
      "(10, 128, 128, 3)\n",
      "0.89691204\n",
      "[Epoch 1/10] [Batch 430/1081] [D loss: 1.024989] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.534203] time: 0:12:57.622367\n",
      "(10, 128, 128, 3)\n",
      "0.8959398\n",
      "[Epoch 1/10] [Batch 431/1081] [D loss: 1.023630] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.429924] time: 0:12:58.069702\n",
      "(10, 128, 128, 3)\n",
      "0.87773925\n",
      "[Epoch 1/10] [Batch 432/1081] [D loss: 1.022252] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.518654] time: 0:12:58.505250\n",
      "(10, 128, 128, 3)\n",
      "0.9341168\n",
      "[Epoch 1/10] [Batch 433/1081] [D loss: 1.021744] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.029188] time: 0:12:58.923198\n",
      "(10, 128, 128, 3)\n",
      "0.9319064\n",
      "[Epoch 1/10] [Batch 434/1081] [D loss: 1.019834] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.511786] time: 0:12:59.331318\n",
      "(10, 128, 128, 3)\n",
      "0.8581545\n",
      "[Epoch 1/10] [Batch 435/1081] [D loss: 1.019130] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.527485] time: 0:12:59.736531\n",
      "(10, 128, 128, 3)\n",
      "0.92697674\n",
      "[Epoch 1/10] [Batch 436/1081] [D loss: 1.017719] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.399868] time: 0:13:00.186773\n",
      "(10, 128, 128, 3)\n",
      "0.89059687\n",
      "[Epoch 1/10] [Batch 437/1081] [D loss: 1.016891] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.713972] time: 0:13:00.618469\n",
      "(10, 128, 128, 3)\n",
      "0.87205034\n",
      "[Epoch 1/10] [Batch 438/1081] [D loss: 1.015413] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.629564] time: 0:13:01.038327\n",
      "(10, 128, 128, 3)\n",
      "0.928047\n",
      "[Epoch 1/10] [Batch 439/1081] [D loss: 1.015493] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.345867] time: 0:13:01.447677\n",
      "(10, 128, 128, 3)\n",
      "0.87901133\n",
      "[Epoch 1/10] [Batch 440/1081] [D loss: 1.013447] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.243553] time: 0:13:01.897101\n",
      "(10, 128, 128, 3)\n",
      "0.8871134\n",
      "[Epoch 1/10] [Batch 441/1081] [D loss: 1.012397] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.247597] time: 0:13:02.319993\n",
      "(10, 128, 128, 3)\n",
      "0.8955137\n",
      "[Epoch 1/10] [Batch 442/1081] [D loss: 1.010855] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.589218] time: 0:13:02.734669\n",
      "(10, 128, 128, 3)\n",
      "0.91853166\n",
      "[Epoch 1/10] [Batch 443/1081] [D loss: 1.009467] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.510727] time: 0:13:03.172565\n",
      "(10, 128, 128, 3)\n",
      "0.8999749\n",
      "[Epoch 1/10] [Batch 444/1081] [D loss: 1.009681] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.975224] time: 0:13:03.599226\n",
      "(10, 128, 128, 3)\n",
      "0.93514055\n",
      "[Epoch 1/10] [Batch 445/1081] [D loss: 1.007273] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.256504] time: 0:13:04.018035\n",
      "(10, 128, 128, 3)\n",
      "0.93392634\n",
      "[Epoch 1/10] [Batch 446/1081] [D loss: 1.006602] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.706636] time: 0:13:04.436754\n",
      "(10, 128, 128, 3)\n",
      "0.92240256\n",
      "[Epoch 1/10] [Batch 447/1081] [D loss: 1.005773] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.481159] time: 0:13:04.853694\n",
      "(10, 128, 128, 3)\n",
      "0.8871593\n",
      "[Epoch 1/10] [Batch 448/1081] [D loss: 1.003598] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.274616] time: 0:13:05.279106\n",
      "(10, 128, 128, 3)\n",
      "0.9261525\n",
      "[Epoch 1/10] [Batch 449/1081] [D loss: 1.003634] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.426550] time: 0:13:05.716333\n",
      "(10, 128, 128, 3)\n",
      "0.9240437\n",
      "[Epoch 1/10] [Batch 450/1081] [D loss: 1.003990] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.551487] time: 0:13:06.144806\n",
      "(10, 128, 128, 3)\n",
      "0.8692817\n",
      "[Epoch 1/10] [Batch 451/1081] [D loss: 1.000597] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.958662] time: 0:13:06.581347\n",
      "(10, 128, 128, 3)\n",
      "0.9041832\n",
      "[Epoch 1/10] [Batch 452/1081] [D loss: 1.000071] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.273062] time: 0:13:07.023164\n",
      "(10, 128, 128, 3)\n",
      "0.914792\n",
      "[Epoch 1/10] [Batch 453/1081] [D loss: 1.005001] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.648232] time: 0:13:07.454734\n",
      "(10, 128, 128, 3)\n",
      "0.93045765\n",
      "[Epoch 1/10] [Batch 454/1081] [D loss: 0.999993] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.646921] time: 0:13:07.881253\n",
      "(10, 128, 128, 3)\n",
      "0.9354755\n",
      "[Epoch 1/10] [Batch 455/1081] [D loss: 0.999863] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.932816] time: 0:13:08.311887\n",
      "(10, 128, 128, 3)\n",
      "0.89393187\n",
      "[Epoch 1/10] [Batch 456/1081] [D loss: 0.996600] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.102734] time: 0:13:08.767120\n",
      "(10, 128, 128, 3)\n",
      "0.9352829\n",
      "[Epoch 1/10] [Batch 457/1081] [D loss: 0.995225] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.130810] time: 0:13:09.192471\n",
      "(10, 128, 128, 3)\n",
      "0.85486656\n",
      "[Epoch 1/10] [Batch 458/1081] [D loss: 0.993267] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.036896] time: 0:13:09.638352\n",
      "(10, 128, 128, 3)\n",
      "0.95646524\n",
      "[Epoch 1/10] [Batch 459/1081] [D loss: 0.992352] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.299152] time: 0:13:10.103873\n",
      "(10, 128, 128, 3)\n",
      "0.87561226\n",
      "[Epoch 1/10] [Batch 460/1081] [D loss: 0.991395] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.123571] time: 0:13:10.539133\n",
      "(10, 128, 128, 3)\n",
      "0.96221775\n",
      "[Epoch 1/10] [Batch 461/1081] [D loss: 0.988949] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.498098] time: 0:13:10.958213\n",
      "(10, 128, 128, 3)\n",
      "0.90681386\n",
      "[Epoch 1/10] [Batch 462/1081] [D loss: 0.990225] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.259754] time: 0:13:11.379357\n",
      "(10, 128, 128, 3)\n",
      "0.8972661\n",
      "[Epoch 1/10] [Batch 463/1081] [D loss: 0.986908] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.859589] time: 0:13:11.815125\n",
      "(10, 128, 128, 3)\n",
      "0.9195247\n",
      "[Epoch 1/10] [Batch 464/1081] [D loss: 1.238079] [D acc: 0.55 (1.00 real, 0.10 fake)] [G loss: 24.478416] time: 0:13:12.239874\n",
      "(10, 128, 128, 3)\n",
      "0.91061854\n",
      "[Epoch 1/10] [Batch 465/1081] [D loss: 1.033755] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.753448] time: 0:13:12.701094\n",
      "(10, 128, 128, 3)\n",
      "0.9301072\n",
      "[Epoch 1/10] [Batch 466/1081] [D loss: 0.996859] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.014404] time: 0:13:13.156214\n",
      "(10, 128, 128, 3)\n",
      "0.8866882\n",
      "[Epoch 1/10] [Batch 467/1081] [D loss: 0.984225] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.362671] time: 0:13:13.633349\n",
      "(10, 128, 128, 3)\n",
      "0.93421346\n",
      "[Epoch 1/10] [Batch 468/1081] [D loss: 1.036712] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.913450] time: 0:13:14.108001\n",
      "(10, 128, 128, 3)\n",
      "0.8456783\n",
      "[Epoch 1/10] [Batch 469/1081] [D loss: 0.983887] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.395638] time: 0:13:14.604136\n",
      "(10, 128, 128, 3)\n",
      "0.9269709\n",
      "[Epoch 1/10] [Batch 470/1081] [D loss: 0.990309] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.152079] time: 0:13:15.116189\n",
      "(10, 128, 128, 3)\n",
      "0.9139531\n",
      "[Epoch 1/10] [Batch 471/1081] [D loss: 0.981427] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.242393] time: 0:13:15.600506\n",
      "(10, 128, 128, 3)\n",
      "0.9141557\n",
      "[Epoch 1/10] [Batch 472/1081] [D loss: 0.999923] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.504536] time: 0:13:16.087731\n",
      "(10, 128, 128, 3)\n",
      "0.9143011\n",
      "[Epoch 1/10] [Batch 473/1081] [D loss: 0.988736] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.451740] time: 0:13:16.542570\n",
      "(10, 128, 128, 3)\n",
      "0.886666\n",
      "[Epoch 1/10] [Batch 474/1081] [D loss: 0.976326] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.904366] time: 0:13:17.055087\n",
      "(10, 128, 128, 3)\n",
      "0.91261125\n",
      "[Epoch 1/10] [Batch 475/1081] [D loss: 0.975289] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.867500] time: 0:13:17.557550\n",
      "(10, 128, 128, 3)\n",
      "0.94273275\n",
      "[Epoch 1/10] [Batch 476/1081] [D loss: 0.976783] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.416761] time: 0:13:18.074293\n",
      "(10, 128, 128, 3)\n",
      "0.9177136\n",
      "[Epoch 1/10] [Batch 477/1081] [D loss: 0.974220] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.719131] time: 0:13:18.586996\n",
      "(10, 128, 128, 3)\n",
      "0.90992695\n",
      "[Epoch 1/10] [Batch 478/1081] [D loss: 0.970795] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.582729] time: 0:13:19.044337\n",
      "(10, 128, 128, 3)\n",
      "0.87320775\n",
      "[Epoch 1/10] [Batch 479/1081] [D loss: 0.970303] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.525087] time: 0:13:19.523998\n",
      "(10, 128, 128, 3)\n",
      "0.9047348\n",
      "[Epoch 1/10] [Batch 480/1081] [D loss: 0.969903] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.955971] time: 0:13:20.014153\n",
      "(10, 128, 128, 3)\n",
      "0.875664\n",
      "[Epoch 1/10] [Batch 481/1081] [D loss: 0.968722] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.047443] time: 0:13:20.503587\n",
      "(10, 128, 128, 3)\n",
      "0.87417555\n",
      "[Epoch 1/10] [Batch 482/1081] [D loss: 0.971016] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.612553] time: 0:13:20.974707\n",
      "(10, 128, 128, 3)\n",
      "0.91965127\n",
      "[Epoch 1/10] [Batch 483/1081] [D loss: 0.966252] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.009680] time: 0:13:21.459083\n",
      "(10, 128, 128, 3)\n",
      "0.9465397\n",
      "[Epoch 1/10] [Batch 484/1081] [D loss: 0.970971] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.683426] time: 0:13:21.945185\n",
      "(10, 128, 128, 3)\n",
      "0.8755428\n",
      "[Epoch 1/10] [Batch 485/1081] [D loss: 0.975797] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.134863] time: 0:13:22.422608\n",
      "(10, 128, 128, 3)\n",
      "0.9288129\n",
      "[Epoch 1/10] [Batch 486/1081] [D loss: 0.965323] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.864458] time: 0:13:22.878437\n",
      "(10, 128, 128, 3)\n",
      "0.91598296\n",
      "[Epoch 1/10] [Batch 487/1081] [D loss: 0.965845] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.502493] time: 0:13:23.375444\n",
      "(10, 128, 128, 3)\n",
      "0.89122087\n",
      "[Epoch 1/10] [Batch 488/1081] [D loss: 1.189841] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 23.286173] time: 0:13:23.874942\n",
      "(10, 128, 128, 3)\n",
      "0.86419064\n",
      "[Epoch 1/10] [Batch 489/1081] [D loss: 1.045162] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.496761] time: 0:13:24.334584\n",
      "(10, 128, 128, 3)\n",
      "0.9172568\n",
      "[Epoch 1/10] [Batch 490/1081] [D loss: 0.968407] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.257561] time: 0:13:24.807741\n",
      "(10, 128, 128, 3)\n",
      "0.892296\n",
      "[Epoch 1/10] [Batch 491/1081] [D loss: 0.957568] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.893040] time: 0:13:25.268606\n",
      "(10, 128, 128, 3)\n",
      "0.8701542\n",
      "[Epoch 1/10] [Batch 492/1081] [D loss: 0.959802] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.027905] time: 0:13:25.762411\n",
      "(10, 128, 128, 3)\n",
      "0.94533163\n",
      "[Epoch 1/10] [Batch 493/1081] [D loss: 0.964412] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.573067] time: 0:13:26.241974\n",
      "(10, 128, 128, 3)\n",
      "0.8981674\n",
      "[Epoch 1/10] [Batch 494/1081] [D loss: 0.991486] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.519949] time: 0:13:26.706093\n",
      "(10, 128, 128, 3)\n",
      "0.9119601\n",
      "[Epoch 1/10] [Batch 495/1081] [D loss: 0.961256] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.820393] time: 0:13:27.149328\n",
      "(10, 128, 128, 3)\n",
      "0.94254833\n",
      "[Epoch 1/10] [Batch 496/1081] [D loss: 0.962250] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.999071] time: 0:13:27.619561\n",
      "(10, 128, 128, 3)\n",
      "0.91513807\n",
      "[Epoch 1/10] [Batch 497/1081] [D loss: 0.960404] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.919472] time: 0:13:28.079260\n",
      "(10, 128, 128, 3)\n",
      "0.93373805\n",
      "[Epoch 1/10] [Batch 498/1081] [D loss: 0.963025] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.891987] time: 0:13:28.576030\n",
      "(10, 128, 128, 3)\n",
      "0.9270313\n",
      "[Epoch 1/10] [Batch 499/1081] [D loss: 0.954916] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.258089] time: 0:13:29.062064\n",
      "(10, 128, 128, 3)\n",
      "0.84084815\n",
      "[Epoch 1/10] [Batch 500/1081] [D loss: 0.949256] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.198505] time: 0:13:29.554350\n",
      "(10, 128, 128, 3)\n",
      "0.9432637\n",
      "[Epoch 1/10] [Batch 501/1081] [D loss: 0.948425] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 24.267956] time: 0:13:30.028292\n",
      "(10, 128, 128, 3)\n",
      "0.9535598\n",
      "[Epoch 1/10] [Batch 502/1081] [D loss: 0.978142] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 22.431683] time: 0:13:30.514441\n",
      "(10, 128, 128, 3)\n",
      "0.8810318\n",
      "[Epoch 1/10] [Batch 503/1081] [D loss: 0.961813] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.246588] time: 0:13:31.015776\n",
      "(10, 128, 128, 3)\n",
      "0.94928855\n",
      "[Epoch 1/10] [Batch 504/1081] [D loss: 0.950664] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.959627] time: 0:13:31.519490\n",
      "(10, 128, 128, 3)\n",
      "0.91758233\n",
      "[Epoch 1/10] [Batch 505/1081] [D loss: 0.954165] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.858204] time: 0:13:32.006569\n",
      "(10, 128, 128, 3)\n",
      "0.89107484\n",
      "[Epoch 1/10] [Batch 506/1081] [D loss: 0.945466] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.844452] time: 0:13:32.481049\n",
      "(10, 128, 128, 3)\n",
      "0.9352636\n",
      "[Epoch 1/10] [Batch 507/1081] [D loss: 0.941858] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.933861] time: 0:13:32.973761\n",
      "(10, 128, 128, 3)\n",
      "0.9141454\n",
      "[Epoch 1/10] [Batch 508/1081] [D loss: 0.941452] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.845978] time: 0:13:33.492246\n",
      "(10, 128, 128, 3)\n",
      "0.8418422\n",
      "[Epoch 1/10] [Batch 509/1081] [D loss: 0.938322] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.908495] time: 0:13:33.953386\n",
      "(10, 128, 128, 3)\n",
      "0.9395694\n",
      "[Epoch 1/10] [Batch 510/1081] [D loss: 0.938197] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.363873] time: 0:13:34.455656\n",
      "(10, 128, 128, 3)\n",
      "0.91180927\n",
      "[Epoch 1/10] [Batch 511/1081] [D loss: 0.937071] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.583544] time: 0:13:34.918902\n",
      "(10, 128, 128, 3)\n",
      "0.94235355\n",
      "[Epoch 1/10] [Batch 512/1081] [D loss: 0.934829] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.340405] time: 0:13:35.399612\n",
      "(10, 128, 128, 3)\n",
      "0.8822158\n",
      "[Epoch 1/10] [Batch 513/1081] [D loss: 0.934971] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.852720] time: 0:13:35.873900\n",
      "(10, 128, 128, 3)\n",
      "0.87483144\n",
      "[Epoch 1/10] [Batch 514/1081] [D loss: 0.933390] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.848034] time: 0:13:36.357594\n",
      "(10, 128, 128, 3)\n",
      "0.9272764\n",
      "[Epoch 1/10] [Batch 515/1081] [D loss: 0.933574] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.382851] time: 0:13:36.871469\n",
      "(10, 128, 128, 3)\n",
      "0.9337035\n",
      "[Epoch 1/10] [Batch 516/1081] [D loss: 0.937594] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.049097] time: 0:13:37.355500\n",
      "(10, 128, 128, 3)\n",
      "0.90366644\n",
      "[Epoch 1/10] [Batch 517/1081] [D loss: 0.933054] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.300133] time: 0:13:37.838536\n",
      "(10, 128, 128, 3)\n",
      "0.917689\n",
      "[Epoch 1/10] [Batch 518/1081] [D loss: 0.931198] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.722675] time: 0:13:38.335112\n",
      "(10, 128, 128, 3)\n",
      "0.9343454\n",
      "[Epoch 1/10] [Batch 519/1081] [D loss: 0.930012] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.701149] time: 0:13:38.830582\n",
      "(10, 128, 128, 3)\n",
      "0.85866475\n",
      "[Epoch 1/10] [Batch 520/1081] [D loss: 0.928264] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.896177] time: 0:13:39.304397\n",
      "(10, 128, 128, 3)\n",
      "0.93440694\n",
      "[Epoch 1/10] [Batch 521/1081] [D loss: 0.926447] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.977434] time: 0:13:39.785044\n",
      "(10, 128, 128, 3)\n",
      "0.90015286\n",
      "[Epoch 1/10] [Batch 522/1081] [D loss: 0.924453] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.995119] time: 0:13:40.260656\n",
      "(10, 128, 128, 3)\n",
      "0.8661251\n",
      "[Epoch 1/10] [Batch 523/1081] [D loss: 0.927130] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.992210] time: 0:13:40.734463\n",
      "(10, 128, 128, 3)\n",
      "0.8811064\n",
      "[Epoch 1/10] [Batch 524/1081] [D loss: 0.924293] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 25.424742] time: 0:13:41.182146\n",
      "(10, 128, 128, 3)\n",
      "0.90918726\n",
      "[Epoch 1/10] [Batch 525/1081] [D loss: 0.922773] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.415293] time: 0:13:41.667144\n",
      "(10, 128, 128, 3)\n",
      "0.94594353\n",
      "[Epoch 1/10] [Batch 526/1081] [D loss: 0.922569] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.188204] time: 0:13:42.139590\n",
      "(10, 128, 128, 3)\n",
      "0.9309383\n",
      "[Epoch 1/10] [Batch 527/1081] [D loss: 0.920424] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.150406] time: 0:13:42.613915\n",
      "(10, 128, 128, 3)\n",
      "0.93957806\n",
      "[Epoch 1/10] [Batch 528/1081] [D loss: 0.918719] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.078695] time: 0:13:43.090424\n",
      "(10, 128, 128, 3)\n",
      "0.9460129\n",
      "[Epoch 1/10] [Batch 529/1081] [D loss: 0.918115] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.935942] time: 0:13:43.557477\n",
      "(10, 128, 128, 3)\n",
      "0.8915104\n",
      "[Epoch 1/10] [Batch 530/1081] [D loss: 0.916719] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.608015] time: 0:13:44.047216\n",
      "(10, 128, 128, 3)\n",
      "0.8563712\n",
      "[Epoch 1/10] [Batch 531/1081] [D loss: 0.915654] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.748222] time: 0:13:44.529113\n",
      "(10, 128, 128, 3)\n",
      "0.8926771\n",
      "[Epoch 1/10] [Batch 532/1081] [D loss: 0.914424] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.871767] time: 0:13:44.990965\n",
      "(10, 128, 128, 3)\n",
      "0.8851107\n",
      "[Epoch 1/10] [Batch 533/1081] [D loss: 0.912658] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.196867] time: 0:13:45.470946\n",
      "(10, 128, 128, 3)\n",
      "0.903465\n",
      "[Epoch 1/10] [Batch 534/1081] [D loss: 0.912661] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.337799] time: 0:13:45.982612\n",
      "(10, 128, 128, 3)\n",
      "0.9481848\n",
      "[Epoch 1/10] [Batch 535/1081] [D loss: 0.912017] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.349243] time: 0:13:46.450511\n",
      "(10, 128, 128, 3)\n",
      "0.9074188\n",
      "[Epoch 1/10] [Batch 536/1081] [D loss: 0.909576] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.832592] time: 0:13:46.926313\n",
      "(10, 128, 128, 3)\n",
      "0.9152946\n",
      "[Epoch 1/10] [Batch 537/1081] [D loss: 0.911969] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.347536] time: 0:13:47.425072\n",
      "(10, 128, 128, 3)\n",
      "0.8909717\n",
      "[Epoch 1/10] [Batch 538/1081] [D loss: 0.911267] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.943119] time: 0:13:47.878946\n",
      "(10, 128, 128, 3)\n",
      "0.9241738\n",
      "[Epoch 1/10] [Batch 539/1081] [D loss: 0.906482] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.294197] time: 0:13:48.384759\n",
      "(10, 128, 128, 3)\n",
      "0.9236636\n",
      "[Epoch 1/10] [Batch 540/1081] [D loss: 0.905672] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.271809] time: 0:13:48.882617\n",
      "(10, 128, 128, 3)\n",
      "0.9252208\n",
      "[Epoch 1/10] [Batch 541/1081] [D loss: 0.905289] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.994322] time: 0:13:49.363342\n",
      "(10, 128, 128, 3)\n",
      "0.9015656\n",
      "[Epoch 1/10] [Batch 542/1081] [D loss: 0.903506] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.123388] time: 0:13:49.824605\n",
      "(10, 128, 128, 3)\n",
      "0.870382\n",
      "[Epoch 1/10] [Batch 543/1081] [D loss: 0.902925] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.042976] time: 0:13:50.322706\n",
      "(10, 128, 128, 3)\n",
      "0.9335503\n",
      "[Epoch 1/10] [Batch 544/1081] [D loss: 0.901778] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.936199] time: 0:13:50.831930\n",
      "(10, 128, 128, 3)\n",
      "0.9151416\n",
      "[Epoch 1/10] [Batch 545/1081] [D loss: 0.900480] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.429655] time: 0:13:51.289437\n",
      "(10, 128, 128, 3)\n",
      "0.862459\n",
      "[Epoch 1/10] [Batch 546/1081] [D loss: 0.899091] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.894409] time: 0:13:51.760261\n",
      "(10, 128, 128, 3)\n",
      "0.9102454\n",
      "[Epoch 1/10] [Batch 547/1081] [D loss: 0.898055] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.668900] time: 0:13:52.231528\n",
      "(10, 128, 128, 3)\n",
      "0.92036873\n",
      "[Epoch 1/10] [Batch 548/1081] [D loss: 0.897983] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.697058] time: 0:13:52.703225\n",
      "(10, 128, 128, 3)\n",
      "0.89591223\n",
      "[Epoch 1/10] [Batch 549/1081] [D loss: 0.896091] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.091578] time: 0:13:53.158439\n",
      "(10, 128, 128, 3)\n",
      "0.90722984\n",
      "[Epoch 1/10] [Batch 550/1081] [D loss: 0.895833] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.851316] time: 0:13:53.628224\n",
      "(10, 128, 128, 3)\n",
      "0.9164545\n",
      "[Epoch 1/10] [Batch 551/1081] [D loss: 0.894722] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.361759] time: 0:13:54.086464\n",
      "(10, 128, 128, 3)\n",
      "0.86020017\n",
      "[Epoch 1/10] [Batch 552/1081] [D loss: 0.893796] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.819902] time: 0:13:54.574153\n",
      "(10, 128, 128, 3)\n",
      "0.92369634\n",
      "[Epoch 1/10] [Batch 553/1081] [D loss: 0.892255] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.196400] time: 0:13:55.042077\n",
      "(10, 128, 128, 3)\n",
      "0.9330904\n",
      "[Epoch 1/10] [Batch 554/1081] [D loss: 0.891586] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.379944] time: 0:13:55.520854\n",
      "(10, 128, 128, 3)\n",
      "0.9456396\n",
      "[Epoch 1/10] [Batch 555/1081] [D loss: 0.891619] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.100758] time: 0:13:56.015122\n",
      "(10, 128, 128, 3)\n",
      "0.9202594\n",
      "[Epoch 1/10] [Batch 556/1081] [D loss: 0.888665] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.760111] time: 0:13:56.480288\n",
      "(10, 128, 128, 3)\n",
      "0.8901391\n",
      "[Epoch 1/10] [Batch 557/1081] [D loss: 0.887787] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.193291] time: 0:13:56.971594\n",
      "(10, 128, 128, 3)\n",
      "0.9321925\n",
      "[Epoch 1/10] [Batch 558/1081] [D loss: 0.888272] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.816778] time: 0:13:57.440841\n",
      "(10, 128, 128, 3)\n",
      "0.8958613\n",
      "[Epoch 1/10] [Batch 559/1081] [D loss: 0.885536] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.214573] time: 0:13:57.906150\n",
      "(10, 128, 128, 3)\n",
      "0.906544\n",
      "[Epoch 1/10] [Batch 560/1081] [D loss: 0.885449] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.308487] time: 0:13:58.395945\n",
      "(10, 128, 128, 3)\n",
      "0.8757555\n",
      "[Epoch 1/10] [Batch 561/1081] [D loss: 0.884540] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.977604] time: 0:13:58.887562\n",
      "(10, 128, 128, 3)\n",
      "0.94435763\n",
      "[Epoch 1/10] [Batch 562/1081] [D loss: 0.883974] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.337269] time: 0:13:59.357988\n",
      "(10, 128, 128, 3)\n",
      "0.9294184\n",
      "[Epoch 1/10] [Batch 563/1081] [D loss: 0.881774] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.077927] time: 0:13:59.841264\n",
      "(10, 128, 128, 3)\n",
      "0.8633814\n",
      "[Epoch 1/10] [Batch 564/1081] [D loss: 0.880696] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.452303] time: 0:14:00.312328\n",
      "(10, 128, 128, 3)\n",
      "0.95656353\n",
      "[Epoch 1/10] [Batch 565/1081] [D loss: 0.880659] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.822880] time: 0:14:00.759609\n",
      "(10, 128, 128, 3)\n",
      "0.8800799\n",
      "[Epoch 1/10] [Batch 566/1081] [D loss: 0.878184] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.644463] time: 0:14:01.255974\n",
      "(10, 128, 128, 3)\n",
      "0.9317983\n",
      "[Epoch 1/10] [Batch 567/1081] [D loss: 0.877329] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.864483] time: 0:14:01.724018\n",
      "(10, 128, 128, 3)\n",
      "0.91397244\n",
      "[Epoch 1/10] [Batch 568/1081] [D loss: 0.876229] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.607071] time: 0:14:02.180266\n",
      "(10, 128, 128, 3)\n",
      "0.90899676\n",
      "[Epoch 1/10] [Batch 569/1081] [D loss: 0.875428] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.432549] time: 0:14:02.687908\n",
      "(10, 128, 128, 3)\n",
      "0.91842836\n",
      "[Epoch 1/10] [Batch 570/1081] [D loss: 0.874358] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.671869] time: 0:14:03.142525\n",
      "(10, 128, 128, 3)\n",
      "0.8795829\n",
      "[Epoch 1/10] [Batch 571/1081] [D loss: 0.873757] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.528572] time: 0:14:03.614411\n",
      "(10, 128, 128, 3)\n",
      "0.8705265\n",
      "[Epoch 1/10] [Batch 572/1081] [D loss: 0.874106] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.251316] time: 0:14:04.080667\n",
      "(10, 128, 128, 3)\n",
      "0.9273813\n",
      "[Epoch 1/10] [Batch 573/1081] [D loss: 0.871974] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.187157] time: 0:14:04.550032\n",
      "(10, 128, 128, 3)\n",
      "0.9161508\n",
      "[Epoch 1/10] [Batch 574/1081] [D loss: 0.870427] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.358452] time: 0:14:05.013963\n",
      "(10, 128, 128, 3)\n",
      "0.9029327\n",
      "[Epoch 1/10] [Batch 575/1081] [D loss: 0.868928] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.499983] time: 0:14:05.501166\n",
      "(10, 128, 128, 3)\n",
      "0.8357275\n",
      "[Epoch 1/10] [Batch 576/1081] [D loss: 0.868479] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.334122] time: 0:14:05.979357\n",
      "(10, 128, 128, 3)\n",
      "0.85898894\n",
      "[Epoch 1/10] [Batch 577/1081] [D loss: 0.867361] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.049316] time: 0:14:06.465959\n",
      "(10, 128, 128, 3)\n",
      "0.8915622\n",
      "[Epoch 1/10] [Batch 578/1081] [D loss: 0.866683] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.031403] time: 0:14:06.949708\n",
      "(10, 128, 128, 3)\n",
      "0.9066913\n",
      "[Epoch 1/10] [Batch 579/1081] [D loss: 0.865165] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.484648] time: 0:14:07.417042\n",
      "(10, 128, 128, 3)\n",
      "0.9095581\n",
      "[Epoch 1/10] [Batch 580/1081] [D loss: 0.864273] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.016500] time: 0:14:07.893507\n",
      "(10, 128, 128, 3)\n",
      "0.9409313\n",
      "[Epoch 1/10] [Batch 581/1081] [D loss: 0.862941] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.438227] time: 0:14:08.351843\n",
      "(10, 128, 128, 3)\n",
      "0.87706065\n",
      "[Epoch 1/10] [Batch 582/1081] [D loss: 0.862102] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.655987] time: 0:14:08.797435\n",
      "(10, 128, 128, 3)\n",
      "0.9021508\n",
      "[Epoch 1/10] [Batch 583/1081] [D loss: 0.861328] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.487524] time: 0:14:09.264197\n",
      "(10, 128, 128, 3)\n",
      "0.90507936\n",
      "[Epoch 1/10] [Batch 584/1081] [D loss: 0.861122] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.438604] time: 0:14:09.784398\n",
      "(10, 128, 128, 3)\n",
      "0.9028366\n",
      "[Epoch 1/10] [Batch 585/1081] [D loss: 0.858983] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.898922] time: 0:14:10.241629\n",
      "(10, 128, 128, 3)\n",
      "0.94364476\n",
      "[Epoch 1/10] [Batch 586/1081] [D loss: 0.860989] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.553154] time: 0:14:10.703447\n",
      "(10, 128, 128, 3)\n",
      "0.8875249\n",
      "[Epoch 1/10] [Batch 587/1081] [D loss: 0.857633] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.118486] time: 0:14:11.165830\n",
      "(10, 128, 128, 3)\n",
      "0.95656747\n",
      "[Epoch 1/10] [Batch 588/1081] [D loss: 0.856187] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.284170] time: 0:14:11.646170\n",
      "(10, 128, 128, 3)\n",
      "0.92336375\n",
      "[Epoch 1/10] [Batch 589/1081] [D loss: 0.854959] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.661480] time: 0:14:12.126080\n",
      "(10, 128, 128, 3)\n",
      "0.91338056\n",
      "[Epoch 1/10] [Batch 590/1081] [D loss: 0.854074] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.226627] time: 0:14:12.591832\n",
      "(10, 128, 128, 3)\n",
      "0.8989149\n",
      "[Epoch 1/10] [Batch 591/1081] [D loss: 0.853560] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.347786] time: 0:14:13.073532\n",
      "(10, 128, 128, 3)\n",
      "0.9048369\n",
      "[Epoch 1/10] [Batch 592/1081] [D loss: 0.853019] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.530773] time: 0:14:13.569703\n",
      "(10, 128, 128, 3)\n",
      "0.9415748\n",
      "[Epoch 1/10] [Batch 593/1081] [D loss: 0.851310] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.353748] time: 0:14:14.044804\n",
      "(10, 128, 128, 3)\n",
      "0.8760765\n",
      "[Epoch 1/10] [Batch 594/1081] [D loss: 0.851329] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.752560] time: 0:14:14.505164\n",
      "(10, 128, 128, 3)\n",
      "0.92907095\n",
      "[Epoch 1/10] [Batch 595/1081] [D loss: 0.850084] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.094826] time: 0:14:14.967877\n",
      "(10, 128, 128, 3)\n",
      "0.92044854\n",
      "[Epoch 1/10] [Batch 596/1081] [D loss: 0.848180] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.141237] time: 0:14:15.457534\n",
      "(10, 128, 128, 3)\n",
      "0.97218806\n",
      "[Epoch 1/10] [Batch 597/1081] [D loss: 0.848537] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.976706] time: 0:14:15.927686\n",
      "(10, 128, 128, 3)\n",
      "0.8847849\n",
      "[Epoch 1/10] [Batch 598/1081] [D loss: 0.847691] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.645674] time: 0:14:16.395222\n",
      "(10, 128, 128, 3)\n",
      "0.9259109\n",
      "[Epoch 1/10] [Batch 599/1081] [D loss: 0.844834] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.953083] time: 0:14:16.864785\n",
      "(10, 128, 128, 3)\n",
      "0.9133091\n",
      "[Epoch 1/10] [Batch 600/1081] [D loss: 0.843737] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.900490] time: 0:14:17.341592\n",
      "(10, 128, 128, 3)\n",
      "0.93623257\n",
      "[Epoch 1/10] [Batch 601/1081] [D loss: 0.844490] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.307791] time: 0:14:17.813348\n",
      "(10, 128, 128, 3)\n",
      "0.9112496\n",
      "[Epoch 1/10] [Batch 602/1081] [D loss: 0.841654] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.007900] time: 0:14:18.302327\n",
      "(10, 128, 128, 3)\n",
      "0.94695944\n",
      "[Epoch 1/10] [Batch 603/1081] [D loss: 0.841123] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.980253] time: 0:14:18.771106\n",
      "(10, 128, 128, 3)\n",
      "0.92244846\n",
      "[Epoch 1/10] [Batch 604/1081] [D loss: 0.840279] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.293522] time: 0:14:19.237123\n",
      "(10, 128, 128, 3)\n",
      "0.9183466\n",
      "[Epoch 1/10] [Batch 605/1081] [D loss: 0.839218] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.594397] time: 0:14:19.715670\n",
      "(10, 128, 128, 3)\n",
      "0.9268956\n",
      "[Epoch 1/10] [Batch 606/1081] [D loss: 0.838495] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.827339] time: 0:14:20.222114\n",
      "(10, 128, 128, 3)\n",
      "0.910446\n",
      "[Epoch 1/10] [Batch 607/1081] [D loss: 0.836887] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.399611] time: 0:14:20.681087\n",
      "(10, 128, 128, 3)\n",
      "0.9103408\n",
      "[Epoch 1/10] [Batch 608/1081] [D loss: 0.836065] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.390455] time: 0:14:21.151469\n",
      "(10, 128, 128, 3)\n",
      "0.9103239\n",
      "[Epoch 1/10] [Batch 609/1081] [D loss: 0.835102] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.934523] time: 0:14:21.615851\n",
      "(10, 128, 128, 3)\n",
      "0.9431031\n",
      "[Epoch 1/10] [Batch 610/1081] [D loss: 0.834254] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.565720] time: 0:14:22.059488\n",
      "(10, 128, 128, 3)\n",
      "0.89834255\n",
      "[Epoch 1/10] [Batch 611/1081] [D loss: 0.833248] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.973778] time: 0:14:22.548984\n",
      "(10, 128, 128, 3)\n",
      "0.8906253\n",
      "[Epoch 1/10] [Batch 612/1081] [D loss: 0.834694] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.833536] time: 0:14:23.046486\n",
      "(10, 128, 128, 3)\n",
      "0.87345934\n",
      "[Epoch 1/10] [Batch 613/1081] [D loss: 0.831420] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.315062] time: 0:14:23.484526\n",
      "(10, 128, 128, 3)\n",
      "0.9119356\n",
      "[Epoch 1/10] [Batch 614/1081] [D loss: 0.830102] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.215925] time: 0:14:23.940064\n",
      "(10, 128, 128, 3)\n",
      "0.92752534\n",
      "[Epoch 1/10] [Batch 615/1081] [D loss: 0.828967] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.134491] time: 0:14:24.395400\n",
      "(10, 128, 128, 3)\n",
      "0.8523798\n",
      "[Epoch 1/10] [Batch 616/1081] [D loss: 0.829052] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.235666] time: 0:14:24.870982\n",
      "(10, 128, 128, 3)\n",
      "0.91007906\n",
      "[Epoch 1/10] [Batch 617/1081] [D loss: 0.827406] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.588575] time: 0:14:25.322322\n",
      "(10, 128, 128, 3)\n",
      "0.8624529\n",
      "[Epoch 1/10] [Batch 618/1081] [D loss: 0.826501] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.603882] time: 0:14:25.790483\n",
      "(10, 128, 128, 3)\n",
      "0.9268925\n",
      "[Epoch 1/10] [Batch 619/1081] [D loss: 0.824873] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.107082] time: 0:14:26.257323\n",
      "(10, 128, 128, 3)\n",
      "0.9790018\n",
      "[Epoch 1/10] [Batch 620/1081] [D loss: 0.824020] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.477947] time: 0:14:26.716500\n",
      "(10, 128, 128, 3)\n",
      "0.88007116\n",
      "[Epoch 1/10] [Batch 621/1081] [D loss: 0.823597] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.714029] time: 0:14:27.182573\n",
      "(10, 128, 128, 3)\n",
      "0.93098027\n",
      "[Epoch 1/10] [Batch 622/1081] [D loss: 0.821988] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.754213] time: 0:14:27.660434\n",
      "(10, 128, 128, 3)\n",
      "0.82991904\n",
      "[Epoch 1/10] [Batch 623/1081] [D loss: 0.821263] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.335567] time: 0:14:28.125364\n",
      "(10, 128, 128, 3)\n",
      "0.8438545\n",
      "[Epoch 1/10] [Batch 624/1081] [D loss: 0.822289] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.441650] time: 0:14:28.607313\n",
      "(10, 128, 128, 3)\n",
      "0.92418236\n",
      "[Epoch 1/10] [Batch 625/1081] [D loss: 0.819690] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.115789] time: 0:14:29.101766\n",
      "(10, 128, 128, 3)\n",
      "0.9049341\n",
      "[Epoch 1/10] [Batch 626/1081] [D loss: 0.818181] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.602501] time: 0:14:29.593180\n",
      "(10, 128, 128, 3)\n",
      "0.9361195\n",
      "[Epoch 1/10] [Batch 627/1081] [D loss: 0.817117] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.229382] time: 0:14:30.100438\n",
      "(10, 128, 128, 3)\n",
      "0.91367906\n",
      "[Epoch 1/10] [Batch 628/1081] [D loss: 0.816062] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.414410] time: 0:14:30.597596\n",
      "(10, 128, 128, 3)\n",
      "0.90849406\n",
      "[Epoch 1/10] [Batch 629/1081] [D loss: 0.815495] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.636108] time: 0:14:31.079107\n",
      "(10, 128, 128, 3)\n",
      "0.92659813\n",
      "[Epoch 1/10] [Batch 630/1081] [D loss: 0.814215] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.213133] time: 0:14:31.552220\n",
      "(10, 128, 128, 3)\n",
      "0.9220753\n",
      "[Epoch 1/10] [Batch 631/1081] [D loss: 0.813258] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.335224] time: 0:14:32.030714\n",
      "(10, 128, 128, 3)\n",
      "0.8900245\n",
      "[Epoch 1/10] [Batch 632/1081] [D loss: 0.812779] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.116753] time: 0:14:32.509613\n",
      "(10, 128, 128, 3)\n",
      "0.91609126\n",
      "[Epoch 1/10] [Batch 633/1081] [D loss: 0.811489] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.067301] time: 0:14:32.963717\n",
      "(10, 128, 128, 3)\n",
      "0.88560516\n",
      "[Epoch 1/10] [Batch 634/1081] [D loss: 0.810221] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.874113] time: 0:14:33.434394\n",
      "(10, 128, 128, 3)\n",
      "0.95091015\n",
      "[Epoch 1/10] [Batch 635/1081] [D loss: 0.809981] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.695019] time: 0:14:33.881569\n",
      "(10, 128, 128, 3)\n",
      "0.93219537\n",
      "[Epoch 1/10] [Batch 636/1081] [D loss: 0.808457] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.340622] time: 0:14:34.426729\n",
      "(10, 128, 128, 3)\n",
      "0.91066\n",
      "[Epoch 1/10] [Batch 637/1081] [D loss: 0.807783] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.027687] time: 0:14:34.925450\n",
      "(10, 128, 128, 3)\n",
      "0.92736644\n",
      "[Epoch 1/10] [Batch 638/1081] [D loss: 0.806357] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.862789] time: 0:14:35.386873\n",
      "(10, 128, 128, 3)\n",
      "0.92989564\n",
      "[Epoch 1/10] [Batch 639/1081] [D loss: 0.805338] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.155052] time: 0:14:35.866565\n",
      "(10, 128, 128, 3)\n",
      "0.927222\n",
      "[Epoch 1/10] [Batch 640/1081] [D loss: 0.804702] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.928778] time: 0:14:36.339432\n",
      "(10, 128, 128, 3)\n",
      "0.86731845\n",
      "[Epoch 1/10] [Batch 641/1081] [D loss: 0.804069] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.009951] time: 0:14:36.805759\n",
      "(10, 128, 128, 3)\n",
      "0.876456\n",
      "[Epoch 1/10] [Batch 642/1081] [D loss: 0.803363] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.683308] time: 0:14:37.281689\n",
      "(10, 128, 128, 3)\n",
      "0.9128659\n",
      "[Epoch 1/10] [Batch 643/1081] [D loss: 0.802087] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.595427] time: 0:14:37.751059\n",
      "(10, 128, 128, 3)\n",
      "0.913433\n",
      "[Epoch 1/10] [Batch 644/1081] [D loss: 0.800736] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.197878] time: 0:14:38.205038\n",
      "(10, 128, 128, 3)\n",
      "0.91837555\n",
      "[Epoch 1/10] [Batch 645/1081] [D loss: 0.799508] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.635284] time: 0:14:38.664708\n",
      "(10, 128, 128, 3)\n",
      "0.8976596\n",
      "[Epoch 1/10] [Batch 646/1081] [D loss: 0.799306] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.445206] time: 0:14:39.135278\n",
      "(10, 128, 128, 3)\n",
      "0.89715225\n",
      "[Epoch 1/10] [Batch 647/1081] [D loss: 0.798688] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.425652] time: 0:14:39.581003\n",
      "(10, 128, 128, 3)\n",
      "0.9306383\n",
      "[Epoch 1/10] [Batch 648/1081] [D loss: 0.797844] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.920048] time: 0:14:40.041272\n",
      "(10, 128, 128, 3)\n",
      "0.89885783\n",
      "[Epoch 1/10] [Batch 649/1081] [D loss: 0.796814] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.188112] time: 0:14:40.530401\n",
      "(10, 128, 128, 3)\n",
      "0.9362877\n",
      "[Epoch 1/10] [Batch 650/1081] [D loss: 0.794955] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.962364] time: 0:14:40.987810\n",
      "(10, 128, 128, 3)\n",
      "0.88735884\n",
      "[Epoch 1/10] [Batch 651/1081] [D loss: 0.793976] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.283186] time: 0:14:41.485235\n",
      "(10, 128, 128, 3)\n",
      "0.8819499\n",
      "[Epoch 1/10] [Batch 652/1081] [D loss: 0.792935] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.171110] time: 0:14:41.971185\n",
      "(10, 128, 128, 3)\n",
      "0.92865306\n",
      "[Epoch 1/10] [Batch 653/1081] [D loss: 0.792148] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.989799] time: 0:14:42.491660\n",
      "(10, 128, 128, 3)\n",
      "0.8691017\n",
      "[Epoch 1/10] [Batch 654/1081] [D loss: 0.791080] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.271894] time: 0:14:42.956829\n",
      "(10, 128, 128, 3)\n",
      "0.92407674\n",
      "[Epoch 1/10] [Batch 655/1081] [D loss: 0.790409] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.791170] time: 0:14:43.436890\n",
      "(10, 128, 128, 3)\n",
      "0.89720184\n",
      "[Epoch 1/10] [Batch 656/1081] [D loss: 0.789436] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.658958] time: 0:14:43.890991\n",
      "(10, 128, 128, 3)\n",
      "0.87940973\n",
      "[Epoch 1/10] [Batch 657/1081] [D loss: 0.789004] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.724075] time: 0:14:44.375866\n",
      "(10, 128, 128, 3)\n",
      "0.9273543\n",
      "[Epoch 1/10] [Batch 658/1081] [D loss: 0.787970] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.004059] time: 0:14:44.876308\n",
      "(10, 128, 128, 3)\n",
      "0.9140323\n",
      "[Epoch 1/10] [Batch 659/1081] [D loss: 0.786519] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.692398] time: 0:14:45.339446\n",
      "(10, 128, 128, 3)\n",
      "0.95522434\n",
      "[Epoch 1/10] [Batch 660/1081] [D loss: 0.785295] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.939709] time: 0:14:45.790289\n",
      "(10, 128, 128, 3)\n",
      "0.8986786\n",
      "[Epoch 1/10] [Batch 661/1081] [D loss: 0.784640] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.750557] time: 0:14:46.247166\n",
      "(10, 128, 128, 3)\n",
      "0.94896364\n",
      "[Epoch 1/10] [Batch 662/1081] [D loss: 0.783677] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.716187] time: 0:14:46.736071\n",
      "(10, 128, 128, 3)\n",
      "0.9215805\n",
      "[Epoch 1/10] [Batch 663/1081] [D loss: 0.782800] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.126797] time: 0:14:47.184375\n",
      "(10, 128, 128, 3)\n",
      "0.93697053\n",
      "[Epoch 1/10] [Batch 664/1081] [D loss: 0.781993] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.149590] time: 0:14:47.658073\n",
      "(10, 128, 128, 3)\n",
      "0.8908345\n",
      "[Epoch 1/10] [Batch 665/1081] [D loss: 0.781364] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.488577] time: 0:14:48.104101\n",
      "(10, 128, 128, 3)\n",
      "0.8826811\n",
      "[Epoch 1/10] [Batch 666/1081] [D loss: 0.780709] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.004995] time: 0:14:48.569285\n",
      "(10, 128, 128, 3)\n",
      "0.9315198\n",
      "[Epoch 1/10] [Batch 667/1081] [D loss: 0.778611] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.258175] time: 0:14:49.034580\n",
      "(10, 128, 128, 3)\n",
      "0.890143\n",
      "[Epoch 1/10] [Batch 668/1081] [D loss: 0.778564] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.950834] time: 0:14:49.493246\n",
      "(10, 128, 128, 3)\n",
      "0.931009\n",
      "[Epoch 1/10] [Batch 669/1081] [D loss: 0.777118] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.389954] time: 0:14:49.955949\n",
      "(10, 128, 128, 3)\n",
      "0.87591034\n",
      "[Epoch 1/10] [Batch 670/1081] [D loss: 0.775975] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.264555] time: 0:14:50.407911\n",
      "(10, 128, 128, 3)\n",
      "0.8964949\n",
      "[Epoch 1/10] [Batch 671/1081] [D loss: 0.776391] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.860783] time: 0:14:50.888407\n",
      "(10, 128, 128, 3)\n",
      "0.91978365\n",
      "[Epoch 1/10] [Batch 672/1081] [D loss: 0.774763] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.892630] time: 0:14:51.359508\n",
      "(10, 128, 128, 3)\n",
      "0.93571955\n",
      "[Epoch 1/10] [Batch 673/1081] [D loss: 0.773328] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.322382] time: 0:14:51.815132\n",
      "(10, 128, 128, 3)\n",
      "0.86843723\n",
      "[Epoch 1/10] [Batch 674/1081] [D loss: 0.772222] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.387613] time: 0:14:52.312542\n",
      "(10, 128, 128, 3)\n",
      "0.9477344\n",
      "[Epoch 1/10] [Batch 675/1081] [D loss: 0.771800] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.267269] time: 0:14:52.771322\n",
      "(10, 128, 128, 3)\n",
      "0.91857886\n",
      "[Epoch 1/10] [Batch 676/1081] [D loss: 0.770524] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.686272] time: 0:14:53.237994\n",
      "(10, 128, 128, 3)\n",
      "0.9018638\n",
      "[Epoch 1/10] [Batch 677/1081] [D loss: 0.769350] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.414627] time: 0:14:53.705109\n",
      "(10, 128, 128, 3)\n",
      "0.9218609\n",
      "[Epoch 1/10] [Batch 678/1081] [D loss: 0.768488] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.199966] time: 0:14:54.153412\n",
      "(10, 128, 128, 3)\n",
      "0.8933099\n",
      "[Epoch 1/10] [Batch 679/1081] [D loss: 0.767521] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.054554] time: 0:14:54.645910\n",
      "(10, 128, 128, 3)\n",
      "0.8869348\n",
      "[Epoch 1/10] [Batch 680/1081] [D loss: 0.766817] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.899065] time: 0:14:55.122427\n",
      "(10, 128, 128, 3)\n",
      "0.8961174\n",
      "[Epoch 1/10] [Batch 681/1081] [D loss: 0.765578] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.903709] time: 0:14:55.578999\n",
      "(10, 128, 128, 3)\n",
      "0.904928\n",
      "[Epoch 1/10] [Batch 682/1081] [D loss: 0.764896] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.896843] time: 0:14:56.073446\n",
      "(10, 128, 128, 3)\n",
      "0.8925945\n",
      "[Epoch 1/10] [Batch 683/1081] [D loss: 0.764150] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.019306] time: 0:14:56.559487\n",
      "(10, 128, 128, 3)\n",
      "0.87168044\n",
      "[Epoch 1/10] [Batch 684/1081] [D loss: 0.763283] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.401218] time: 0:14:57.031898\n",
      "(10, 128, 128, 3)\n",
      "0.9362449\n",
      "[Epoch 1/10] [Batch 685/1081] [D loss: 0.761932] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.467344] time: 0:14:57.526343\n",
      "(10, 128, 128, 3)\n",
      "0.9360631\n",
      "[Epoch 1/10] [Batch 686/1081] [D loss: 0.761052] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.214226] time: 0:14:57.977319\n",
      "(10, 128, 128, 3)\n",
      "0.8746446\n",
      "[Epoch 1/10] [Batch 687/1081] [D loss: 0.760271] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.353331] time: 0:14:58.454346\n",
      "(10, 128, 128, 3)\n",
      "0.91930574\n",
      "[Epoch 1/10] [Batch 688/1081] [D loss: 0.759315] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.057955] time: 0:14:58.934285\n",
      "(10, 128, 128, 3)\n",
      "0.8965638\n",
      "[Epoch 1/10] [Batch 689/1081] [D loss: 0.758194] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.509075] time: 0:14:59.405145\n",
      "(10, 128, 128, 3)\n",
      "0.90992075\n",
      "[Epoch 1/10] [Batch 690/1081] [D loss: 0.757406] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.876490] time: 0:14:59.879727\n",
      "(10, 128, 128, 3)\n",
      "0.8688765\n",
      "[Epoch 1/10] [Batch 691/1081] [D loss: 0.756447] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.223045] time: 0:15:00.333768\n",
      "(10, 128, 128, 3)\n",
      "0.90316325\n",
      "[Epoch 1/10] [Batch 692/1081] [D loss: 0.755521] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.223600] time: 0:15:00.793360\n",
      "(10, 128, 128, 3)\n",
      "0.9105673\n",
      "[Epoch 1/10] [Batch 693/1081] [D loss: 0.754715] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.504072] time: 0:15:01.284431\n",
      "(10, 128, 128, 3)\n",
      "0.97814465\n",
      "[Epoch 1/10] [Batch 694/1081] [D loss: 0.754197] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.286343] time: 0:15:01.778177\n",
      "(10, 128, 128, 3)\n",
      "0.89963716\n",
      "[Epoch 1/10] [Batch 695/1081] [D loss: 0.752623] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.410999] time: 0:15:02.236762\n",
      "(10, 128, 128, 3)\n",
      "0.89800805\n",
      "[Epoch 1/10] [Batch 696/1081] [D loss: 0.751857] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.588694] time: 0:15:02.713912\n",
      "(10, 128, 128, 3)\n",
      "0.9433746\n",
      "[Epoch 1/10] [Batch 697/1081] [D loss: 0.752572] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.370512] time: 0:15:03.168615\n",
      "(10, 128, 128, 3)\n",
      "0.8978515\n",
      "[Epoch 1/10] [Batch 698/1081] [D loss: 0.750311] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.484068] time: 0:15:03.654683\n",
      "(10, 128, 128, 3)\n",
      "0.9415365\n",
      "[Epoch 1/10] [Batch 699/1081] [D loss: 0.748919] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.275011] time: 0:15:04.157732\n",
      "(10, 128, 128, 3)\n",
      "0.84486216\n",
      "[Epoch 1/10] [Batch 700/1081] [D loss: 0.751744] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.750036] time: 0:15:04.625194\n",
      "(10, 128, 128, 3)\n",
      "0.9291559\n",
      "[Epoch 1/10] [Batch 701/1081] [D loss: 0.748546] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.164665] time: 0:15:05.096803\n",
      "(10, 128, 128, 3)\n",
      "0.87031716\n",
      "[Epoch 1/10] [Batch 702/1081] [D loss: 0.746243] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.144541] time: 0:15:05.572201\n",
      "(10, 128, 128, 3)\n",
      "0.9293186\n",
      "[Epoch 1/10] [Batch 703/1081] [D loss: 0.746941] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.804968] time: 0:15:06.030429\n",
      "(10, 128, 128, 3)\n",
      "0.9158978\n",
      "[Epoch 1/10] [Batch 704/1081] [D loss: 0.744804] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.670849] time: 0:15:06.516140\n",
      "(10, 128, 128, 3)\n",
      "0.9388208\n",
      "[Epoch 1/10] [Batch 705/1081] [D loss: 0.743604] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.378551] time: 0:15:06.999691\n",
      "(10, 128, 128, 3)\n",
      "0.91707426\n",
      "[Epoch 1/10] [Batch 706/1081] [D loss: 0.742653] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.768129] time: 0:15:07.461565\n",
      "(10, 128, 128, 3)\n",
      "0.93726945\n",
      "[Epoch 1/10] [Batch 707/1081] [D loss: 0.742124] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.810246] time: 0:15:07.953102\n",
      "(10, 128, 128, 3)\n",
      "0.9508042\n",
      "[Epoch 1/10] [Batch 708/1081] [D loss: 0.741961] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.354536] time: 0:15:08.412570\n",
      "(10, 128, 128, 3)\n",
      "0.9196767\n",
      "[Epoch 1/10] [Batch 709/1081] [D loss: 0.740181] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.255695] time: 0:15:08.878788\n",
      "(10, 128, 128, 3)\n",
      "0.95644265\n",
      "[Epoch 1/10] [Batch 710/1081] [D loss: 1.553367] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 20.171339] time: 0:15:09.330841\n",
      "(10, 128, 128, 3)\n",
      "0.8951643\n",
      "[Epoch 1/10] [Batch 711/1081] [D loss: 0.964305] [D acc: 0.60 (1.00 real, 0.20 fake)] [G loss: 20.727535] time: 0:15:09.807923\n",
      "(10, 128, 128, 3)\n",
      "0.9320741\n",
      "[Epoch 1/10] [Batch 712/1081] [D loss: 1.090879] [D acc: 0.15 (0.00 real, 0.30 fake)] [G loss: 21.310638] time: 0:15:10.291369\n",
      "(10, 128, 128, 3)\n",
      "0.8714617\n",
      "[Epoch 1/10] [Batch 713/1081] [D loss: 1.042629] [D acc: 0.25 (0.10 real, 0.40 fake)] [G loss: 20.772451] time: 0:15:10.731878\n",
      "(10, 128, 128, 3)\n",
      "0.9272744\n",
      "[Epoch 1/10] [Batch 714/1081] [D loss: 0.931213] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 20.203154] time: 0:15:11.198483\n",
      "(10, 128, 128, 3)\n",
      "0.9046393\n",
      "[Epoch 1/10] [Batch 715/1081] [D loss: 1.021160] [D acc: 0.40 (0.60 real, 0.20 fake)] [G loss: 21.701719] time: 0:15:11.650798\n",
      "(10, 128, 128, 3)\n",
      "0.937761\n",
      "[Epoch 1/10] [Batch 716/1081] [D loss: 1.035284] [D acc: 0.45 (0.20 real, 0.70 fake)] [G loss: 21.068768] time: 0:15:12.164592\n",
      "(10, 128, 128, 3)\n",
      "0.89366084\n",
      "[Epoch 1/10] [Batch 717/1081] [D loss: 1.013208] [D acc: 0.20 (0.20 real, 0.20 fake)] [G loss: 21.282797] time: 0:15:12.620666\n",
      "(10, 128, 128, 3)\n",
      "0.96326256\n",
      "[Epoch 1/10] [Batch 718/1081] [D loss: 0.933245] [D acc: 0.75 (0.90 real, 0.60 fake)] [G loss: 20.270420] time: 0:15:13.085533\n",
      "(10, 128, 128, 3)\n",
      "0.93202144\n",
      "[Epoch 1/10] [Batch 719/1081] [D loss: 0.910514] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 21.033966] time: 0:15:13.554385\n",
      "(10, 128, 128, 3)\n",
      "0.8971138\n",
      "[Epoch 1/10] [Batch 720/1081] [D loss: 1.001593] [D acc: 0.65 (0.80 real, 0.50 fake)] [G loss: 21.073704] time: 0:15:14.022898\n",
      "(10, 128, 128, 3)\n",
      "0.9093309\n",
      "[Epoch 1/10] [Batch 721/1081] [D loss: 1.013300] [D acc: 0.60 (0.20 real, 1.00 fake)] [G loss: 21.399925] time: 0:15:14.482058\n",
      "(10, 128, 128, 3)\n",
      "0.8966479\n",
      "[Epoch 1/10] [Batch 722/1081] [D loss: 1.000180] [D acc: 0.45 (0.70 real, 0.20 fake)] [G loss: 20.238228] time: 0:15:14.967229\n",
      "(10, 128, 128, 3)\n",
      "0.94355226\n",
      "[Epoch 1/10] [Batch 723/1081] [D loss: 0.848482] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.032843] time: 0:15:15.425121\n",
      "(10, 128, 128, 3)\n",
      "0.89048004\n",
      "[Epoch 1/10] [Batch 724/1081] [D loss: 0.911005] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 20.810648] time: 0:15:15.862137\n",
      "(10, 128, 128, 3)\n",
      "0.91876745\n",
      "[Epoch 1/10] [Batch 725/1081] [D loss: 0.775948] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.542997] time: 0:15:16.338429\n",
      "(10, 128, 128, 3)\n",
      "0.969079\n",
      "[Epoch 1/10] [Batch 726/1081] [D loss: 0.946355] [D acc: 0.70 (0.80 real, 0.60 fake)] [G loss: 20.226526] time: 0:15:16.789533\n",
      "(10, 128, 128, 3)\n",
      "0.9389371\n",
      "[Epoch 1/10] [Batch 727/1081] [D loss: 0.764833] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.983372] time: 0:15:17.236067\n",
      "(10, 128, 128, 3)\n",
      "0.89326674\n",
      "[Epoch 1/10] [Batch 728/1081] [D loss: 0.777435] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.358288] time: 0:15:17.694417\n",
      "(10, 128, 128, 3)\n",
      "0.88537437\n",
      "[Epoch 1/10] [Batch 729/1081] [D loss: 0.779537] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.874722] time: 0:15:18.177539\n",
      "(10, 128, 128, 3)\n",
      "0.9163997\n",
      "[Epoch 1/10] [Batch 730/1081] [D loss: 0.740093] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.312494] time: 0:15:18.638178\n",
      "(10, 128, 128, 3)\n",
      "0.93320173\n",
      "[Epoch 1/10] [Batch 731/1081] [D loss: 0.732175] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.591705] time: 0:15:19.113553\n",
      "(10, 128, 128, 3)\n",
      "0.8769221\n",
      "[Epoch 1/10] [Batch 732/1081] [D loss: 0.771677] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 20.533604] time: 0:15:19.591084\n",
      "(10, 128, 128, 3)\n",
      "0.9278908\n",
      "[Epoch 1/10] [Batch 733/1081] [D loss: 0.945057] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.599615] time: 0:15:20.046242\n",
      "(10, 128, 128, 3)\n",
      "0.9431762\n",
      "[Epoch 1/10] [Batch 734/1081] [D loss: 0.884225] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 21.760031] time: 0:15:20.527977\n",
      "(10, 128, 128, 3)\n",
      "0.90329\n",
      "[Epoch 1/10] [Batch 735/1081] [D loss: 0.837688] [D acc: 0.90 (0.90 real, 0.90 fake)] [G loss: 20.875385] time: 0:15:21.028264\n",
      "(10, 128, 128, 3)\n",
      "0.9192702\n",
      "[Epoch 1/10] [Batch 736/1081] [D loss: 0.740094] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.722792] time: 0:15:21.527224\n",
      "(10, 128, 128, 3)\n",
      "0.9265564\n",
      "[Epoch 1/10] [Batch 737/1081] [D loss: 0.745436] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.499638] time: 0:15:21.996262\n",
      "(10, 128, 128, 3)\n",
      "0.8127735\n",
      "[Epoch 1/10] [Batch 738/1081] [D loss: 0.740543] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.873785] time: 0:15:22.506070\n",
      "(10, 128, 128, 3)\n",
      "0.8964348\n",
      "[Epoch 1/10] [Batch 739/1081] [D loss: 0.965944] [D acc: 0.40 (0.40 real, 0.40 fake)] [G loss: 29.081341] time: 0:15:22.982444\n",
      "(10, 128, 128, 3)\n",
      "0.9354399\n",
      "[Epoch 1/10] [Batch 740/1081] [D loss: 0.739344] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.448490] time: 0:15:23.465452\n",
      "(10, 128, 128, 3)\n",
      "0.87776214\n",
      "[Epoch 1/10] [Batch 741/1081] [D loss: 0.779883] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 20.952236] time: 0:15:23.923365\n",
      "(10, 128, 128, 3)\n",
      "0.9384017\n",
      "[Epoch 1/10] [Batch 742/1081] [D loss: 0.737533] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 26.333710] time: 0:15:24.421880\n",
      "(10, 128, 128, 3)\n",
      "0.90957993\n",
      "[Epoch 1/10] [Batch 743/1081] [D loss: 0.744961] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 23.373003] time: 0:15:24.902454\n",
      "(10, 128, 128, 3)\n",
      "0.87307304\n",
      "[Epoch 1/10] [Batch 744/1081] [D loss: 0.942879] [D acc: 0.45 (0.80 real, 0.10 fake)] [G loss: 26.505157] time: 0:15:25.376667\n",
      "(10, 128, 128, 3)\n",
      "0.8786681\n",
      "[Epoch 1/10] [Batch 745/1081] [D loss: 0.874911] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 20.156172] time: 0:15:25.851908\n",
      "(10, 128, 128, 3)\n",
      "0.9195754\n",
      "[Epoch 1/10] [Batch 746/1081] [D loss: 1.128202] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 21.546902] time: 0:15:26.335190\n",
      "(10, 128, 128, 3)\n",
      "0.91846484\n",
      "[Epoch 1/10] [Batch 747/1081] [D loss: 0.835477] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 21.805908] time: 0:15:26.811514\n",
      "(10, 128, 128, 3)\n",
      "0.90218824\n",
      "[Epoch 1/10] [Batch 748/1081] [D loss: 0.775635] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 20.736849] time: 0:15:27.295692\n",
      "(10, 128, 128, 3)\n",
      "0.9166054\n",
      "[Epoch 1/10] [Batch 749/1081] [D loss: 0.835097] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 21.320183] time: 0:15:27.755350\n",
      "(10, 128, 128, 3)\n",
      "0.9437147\n",
      "[Epoch 1/10] [Batch 750/1081] [D loss: 0.769995] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.734055] time: 0:15:28.239192\n",
      "(10, 128, 128, 3)\n",
      "0.8624187\n",
      "[Epoch 1/10] [Batch 751/1081] [D loss: 0.717425] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.472914] time: 0:15:28.698165\n",
      "(10, 128, 128, 3)\n",
      "0.9142904\n",
      "[Epoch 1/10] [Batch 752/1081] [D loss: 0.745851] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.377592] time: 0:15:29.197427\n",
      "(10, 128, 128, 3)\n",
      "0.9181126\n",
      "[Epoch 1/10] [Batch 753/1081] [D loss: 0.723040] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.158228] time: 0:15:29.700752\n",
      "(10, 128, 128, 3)\n",
      "0.9280891\n",
      "[Epoch 1/10] [Batch 754/1081] [D loss: 0.732521] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.204630] time: 0:15:30.206442\n",
      "(10, 128, 128, 3)\n",
      "0.97457695\n",
      "[Epoch 1/10] [Batch 755/1081] [D loss: 0.721677] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.502922] time: 0:15:30.644651\n",
      "(10, 128, 128, 3)\n",
      "0.8956879\n",
      "[Epoch 1/10] [Batch 756/1081] [D loss: 0.718352] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.281921] time: 0:15:31.133931\n",
      "(10, 128, 128, 3)\n",
      "0.88904524\n",
      "[Epoch 1/10] [Batch 757/1081] [D loss: 0.716676] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.807508] time: 0:15:31.620749\n",
      "(10, 128, 128, 3)\n",
      "0.94040006\n",
      "[Epoch 1/10] [Batch 758/1081] [D loss: 0.714558] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.482464] time: 0:15:32.109573\n",
      "(10, 128, 128, 3)\n",
      "0.93746954\n",
      "[Epoch 1/10] [Batch 759/1081] [D loss: 0.711356] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.403587] time: 0:15:32.600607\n",
      "(10, 128, 128, 3)\n",
      "0.87983966\n",
      "[Epoch 1/10] [Batch 760/1081] [D loss: 0.710887] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.723202] time: 0:15:33.113985\n",
      "(10, 128, 128, 3)\n",
      "0.90499926\n",
      "[Epoch 1/10] [Batch 761/1081] [D loss: 0.712651] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.883743] time: 0:15:33.562366\n",
      "(10, 128, 128, 3)\n",
      "0.8567286\n",
      "[Epoch 1/10] [Batch 762/1081] [D loss: 0.720963] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.528940] time: 0:15:33.971530\n",
      "(10, 128, 128, 3)\n",
      "0.86916023\n",
      "[Epoch 1/10] [Batch 763/1081] [D loss: 0.730644] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.813560] time: 0:15:34.341759\n",
      "(10, 128, 128, 3)\n",
      "0.9376178\n",
      "[Epoch 1/10] [Batch 764/1081] [D loss: 0.703269] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.624657] time: 0:15:34.751355\n",
      "(10, 128, 128, 3)\n",
      "0.9232356\n",
      "[Epoch 1/10] [Batch 765/1081] [D loss: 0.703681] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.127346] time: 0:15:35.153311\n",
      "(10, 128, 128, 3)\n",
      "0.9732588\n",
      "[Epoch 1/10] [Batch 766/1081] [D loss: 0.714934] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 22.104086] time: 0:15:35.568379\n",
      "(10, 128, 128, 3)\n",
      "0.9223754\n",
      "[Epoch 1/10] [Batch 767/1081] [D loss: 0.700137] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.296589] time: 0:15:35.981548\n",
      "(10, 128, 128, 3)\n",
      "0.9415248\n",
      "[Epoch 1/10] [Batch 768/1081] [D loss: 0.717803] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.916712] time: 0:15:36.400288\n",
      "(10, 128, 128, 3)\n",
      "0.884564\n",
      "[Epoch 1/10] [Batch 769/1081] [D loss: 0.715848] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.835295] time: 0:15:36.784035\n",
      "(10, 128, 128, 3)\n",
      "0.8977899\n",
      "[Epoch 1/10] [Batch 770/1081] [D loss: 0.716890] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.940954] time: 0:15:37.188072\n",
      "(10, 128, 128, 3)\n",
      "0.9034834\n",
      "[Epoch 1/10] [Batch 771/1081] [D loss: 0.712282] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.953199] time: 0:15:37.598391\n",
      "(10, 128, 128, 3)\n",
      "0.8716906\n",
      "[Epoch 1/10] [Batch 772/1081] [D loss: 0.715091] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.095631] time: 0:15:38.004419\n",
      "(10, 128, 128, 3)\n",
      "0.92337936\n",
      "[Epoch 1/10] [Batch 773/1081] [D loss: 0.757549] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.407593] time: 0:15:38.416598\n",
      "(10, 128, 128, 3)\n",
      "0.91173124\n",
      "[Epoch 1/10] [Batch 774/1081] [D loss: 0.729255] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.122169] time: 0:15:38.806180\n",
      "(10, 128, 128, 3)\n",
      "0.92252094\n",
      "[Epoch 1/10] [Batch 775/1081] [D loss: 0.957838] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 20.343058] time: 0:15:39.215665\n",
      "(10, 128, 128, 3)\n",
      "0.9344778\n",
      "[Epoch 1/10] [Batch 776/1081] [D loss: 1.431383] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 19.583757] time: 0:15:39.628695\n",
      "(10, 128, 128, 3)\n",
      "0.9028199\n",
      "[Epoch 1/10] [Batch 777/1081] [D loss: 0.931754] [D acc: 0.60 (1.00 real, 0.20 fake)] [G loss: 21.446608] time: 0:15:40.021486\n",
      "(10, 128, 128, 3)\n",
      "0.90217966\n",
      "[Epoch 1/10] [Batch 778/1081] [D loss: 0.976328] [D acc: 0.45 (0.20 real, 0.70 fake)] [G loss: 21.480373] time: 0:15:40.439122\n",
      "(10, 128, 128, 3)\n",
      "0.8952995\n",
      "[Epoch 1/10] [Batch 779/1081] [D loss: 1.151999] [D acc: 0.10 (0.20 real, 0.00 fake)] [G loss: 20.158363] time: 0:15:40.850086\n",
      "(10, 128, 128, 3)\n",
      "0.93339723\n",
      "[Epoch 1/10] [Batch 780/1081] [D loss: 0.951458] [D acc: 0.45 (0.40 real, 0.50 fake)] [G loss: 20.138218] time: 0:15:41.258284\n",
      "(10, 128, 128, 3)\n",
      "0.88549685\n",
      "[Epoch 1/10] [Batch 781/1081] [D loss: 1.040254] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 21.826691] time: 0:15:41.645055\n",
      "(10, 128, 128, 3)\n",
      "0.92572784\n",
      "[Epoch 1/10] [Batch 782/1081] [D loss: 1.092336] [D acc: 0.05 (0.00 real, 0.10 fake)] [G loss: 19.702545] time: 0:15:42.061319\n",
      "(10, 128, 128, 3)\n",
      "0.9245632\n",
      "[Epoch 1/10] [Batch 783/1081] [D loss: 0.902878] [D acc: 0.60 (0.90 real, 0.30 fake)] [G loss: 20.252474] time: 0:15:42.455528\n",
      "(10, 128, 128, 3)\n",
      "0.9040584\n",
      "[Epoch 1/10] [Batch 784/1081] [D loss: 1.075214] [D acc: 0.15 (0.30 real, 0.00 fake)] [G loss: 19.681705] time: 0:15:42.845754\n",
      "(10, 128, 128, 3)\n",
      "0.9226823\n",
      "[Epoch 1/10] [Batch 785/1081] [D loss: 0.928941] [D acc: 0.60 (0.50 real, 0.70 fake)] [G loss: 21.523514] time: 0:15:43.228887\n",
      "(10, 128, 128, 3)\n",
      "0.924139\n",
      "[Epoch 1/10] [Batch 786/1081] [D loss: 1.006109] [D acc: 0.30 (0.60 real, 0.00 fake)] [G loss: 20.153244] time: 0:15:43.626348\n",
      "(10, 128, 128, 3)\n",
      "0.91069746\n",
      "[Epoch 1/10] [Batch 787/1081] [D loss: 1.012262] [D acc: 0.15 (0.10 real, 0.20 fake)] [G loss: 19.738777] time: 0:15:44.005871\n",
      "(10, 128, 128, 3)\n",
      "0.94141144\n",
      "[Epoch 1/10] [Batch 788/1081] [D loss: 0.939131] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 21.259369] time: 0:15:44.412675\n",
      "(10, 128, 128, 3)\n",
      "0.92213947\n",
      "[Epoch 1/10] [Batch 789/1081] [D loss: 0.945773] [D acc: 0.45 (0.00 real, 0.90 fake)] [G loss: 21.407009] time: 0:15:44.805480\n",
      "(10, 128, 128, 3)\n",
      "0.9147355\n",
      "[Epoch 1/10] [Batch 790/1081] [D loss: 0.957348] [D acc: 0.30 (0.20 real, 0.40 fake)] [G loss: 20.290974] time: 0:15:45.230543\n",
      "(10, 128, 128, 3)\n",
      "0.89669997\n",
      "[Epoch 1/10] [Batch 791/1081] [D loss: 0.963582] [D acc: 0.55 (1.00 real, 0.10 fake)] [G loss: 20.117779] time: 0:15:45.651381\n",
      "(10, 128, 128, 3)\n",
      "0.8901288\n",
      "[Epoch 1/10] [Batch 792/1081] [D loss: 1.003325] [D acc: 0.45 (0.00 real, 0.90 fake)] [G loss: 20.124439] time: 0:15:46.075715\n",
      "(10, 128, 128, 3)\n",
      "0.9258525\n",
      "[Epoch 1/10] [Batch 793/1081] [D loss: 0.921098] [D acc: 0.60 (0.30 real, 0.90 fake)] [G loss: 21.205673] time: 0:15:46.483542\n",
      "(10, 128, 128, 3)\n",
      "0.96340793\n",
      "[Epoch 1/10] [Batch 794/1081] [D loss: 0.925373] [D acc: 0.30 (0.30 real, 0.30 fake)] [G loss: 19.808193] time: 0:15:46.862071\n",
      "(10, 128, 128, 3)\n",
      "0.9113655\n",
      "[Epoch 1/10] [Batch 795/1081] [D loss: 0.909466] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 21.218925] time: 0:15:47.270413\n",
      "(10, 128, 128, 3)\n",
      "0.90878606\n",
      "[Epoch 1/10] [Batch 796/1081] [D loss: 0.979182] [D acc: 0.50 (0.40 real, 0.60 fake)] [G loss: 19.966068] time: 0:15:47.697665\n",
      "(10, 128, 128, 3)\n",
      "0.9082897\n",
      "[Epoch 1/10] [Batch 797/1081] [D loss: 0.924032] [D acc: 0.55 (0.50 real, 0.60 fake)] [G loss: 19.663134] time: 0:15:48.097464\n",
      "(10, 128, 128, 3)\n",
      "0.93133014\n",
      "[Epoch 1/10] [Batch 798/1081] [D loss: 0.795200] [D acc: 0.90 (0.90 real, 0.90 fake)] [G loss: 20.479359] time: 0:15:48.508128\n",
      "(10, 128, 128, 3)\n",
      "0.9297934\n",
      "[Epoch 1/10] [Batch 799/1081] [D loss: 0.881477] [D acc: 0.70 (1.00 real, 0.40 fake)] [G loss: 20.593859] time: 0:15:48.907886\n",
      "(10, 128, 128, 3)\n",
      "0.9089686\n",
      "[Epoch 1/10] [Batch 800/1081] [D loss: 0.945182] [D acc: 0.50 (0.30 real, 0.70 fake)] [G loss: 19.841566] time: 0:15:49.291198\n",
      "(10, 128, 128, 3)\n",
      "0.9531534\n",
      "[Epoch 1/10] [Batch 801/1081] [D loss: 0.709334] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.245426] time: 0:15:49.714044\n",
      "(10, 128, 128, 3)\n",
      "0.92761\n",
      "[Epoch 1/10] [Batch 802/1081] [D loss: 0.916253] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 19.420193] time: 0:15:50.115988\n",
      "(10, 128, 128, 3)\n",
      "0.89843917\n",
      "[Epoch 1/10] [Batch 803/1081] [D loss: 0.778577] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.441626] time: 0:15:50.521763\n",
      "(10, 128, 128, 3)\n",
      "0.8962825\n",
      "[Epoch 1/10] [Batch 804/1081] [D loss: 0.923929] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 19.656942] time: 0:15:50.930982\n",
      "(10, 128, 128, 3)\n",
      "0.9721859\n",
      "[Epoch 1/10] [Batch 805/1081] [D loss: 0.767110] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 20.350029] time: 0:15:51.325902\n",
      "(10, 128, 128, 3)\n",
      "0.91323966\n",
      "[Epoch 1/10] [Batch 806/1081] [D loss: 0.760787] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 20.834705] time: 0:15:51.742079\n",
      "(10, 128, 128, 3)\n",
      "0.9215105\n",
      "[Epoch 1/10] [Batch 807/1081] [D loss: 0.737677] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 20.345098] time: 0:15:52.141169\n",
      "(10, 128, 128, 3)\n",
      "0.9186826\n",
      "[Epoch 1/10] [Batch 808/1081] [D loss: 0.708463] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.157036] time: 0:15:52.562807\n",
      "(10, 128, 128, 3)\n",
      "0.94404906\n",
      "[Epoch 1/10] [Batch 809/1081] [D loss: 0.717501] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.616661] time: 0:15:52.950459\n",
      "(10, 128, 128, 3)\n",
      "0.84958696\n",
      "[Epoch 1/10] [Batch 810/1081] [D loss: 0.693366] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.492693] time: 0:15:53.350843\n",
      "(10, 128, 128, 3)\n",
      "0.88836724\n",
      "[Epoch 1/10] [Batch 811/1081] [D loss: 0.713029] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.797022] time: 0:15:53.730920\n",
      "(10, 128, 128, 3)\n",
      "0.90884286\n",
      "[Epoch 1/10] [Batch 812/1081] [D loss: 0.676731] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.422756] time: 0:15:54.142749\n",
      "(10, 128, 128, 3)\n",
      "0.9088909\n",
      "[Epoch 1/10] [Batch 813/1081] [D loss: 0.672066] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.955900] time: 0:15:54.519782\n",
      "(10, 128, 128, 3)\n",
      "0.91125274\n",
      "[Epoch 1/10] [Batch 814/1081] [D loss: 0.673956] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.679800] time: 0:15:54.936946\n",
      "(10, 128, 128, 3)\n",
      "0.9010968\n",
      "[Epoch 1/10] [Batch 815/1081] [D loss: 0.689845] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 20.996895] time: 0:15:55.352034\n",
      "(10, 128, 128, 3)\n",
      "0.9282055\n",
      "[Epoch 1/10] [Batch 816/1081] [D loss: 0.672682] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.016886] time: 0:15:55.774012\n",
      "(10, 128, 128, 3)\n",
      "0.9329826\n",
      "[Epoch 1/10] [Batch 817/1081] [D loss: 0.690296] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.479895] time: 0:15:56.164626\n",
      "(10, 128, 128, 3)\n",
      "0.9240698\n",
      "[Epoch 1/10] [Batch 818/1081] [D loss: 0.668923] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.009869] time: 0:15:56.592598\n",
      "(10, 128, 128, 3)\n",
      "0.9215634\n",
      "[Epoch 1/10] [Batch 819/1081] [D loss: 0.685559] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.336706] time: 0:15:56.997245\n",
      "(10, 128, 128, 3)\n",
      "0.91566354\n",
      "[Epoch 1/10] [Batch 820/1081] [D loss: 0.666633] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.371580] time: 0:15:57.396878\n",
      "(10, 128, 128, 3)\n",
      "0.9240859\n",
      "[Epoch 1/10] [Batch 821/1081] [D loss: 0.669276] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.160503] time: 0:15:57.790970\n",
      "(10, 128, 128, 3)\n",
      "0.9121646\n",
      "[Epoch 1/10] [Batch 822/1081] [D loss: 0.668198] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.279568] time: 0:15:58.185003\n",
      "(10, 128, 128, 3)\n",
      "0.8711817\n",
      "[Epoch 1/10] [Batch 823/1081] [D loss: 0.676787] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.277685] time: 0:15:58.600610\n",
      "(10, 128, 128, 3)\n",
      "0.884063\n",
      "[Epoch 1/10] [Batch 824/1081] [D loss: 0.666326] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.844591] time: 0:15:59.008242\n",
      "(10, 128, 128, 3)\n",
      "0.9396024\n",
      "[Epoch 1/10] [Batch 825/1081] [D loss: 0.667791] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.948877] time: 0:15:59.431677\n",
      "(10, 128, 128, 3)\n",
      "0.9495954\n",
      "[Epoch 1/10] [Batch 826/1081] [D loss: 0.716880] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.748499] time: 0:15:59.829876\n",
      "(10, 128, 128, 3)\n",
      "0.93869823\n",
      "[Epoch 1/10] [Batch 827/1081] [D loss: 0.736620] [D acc: 0.90 (1.00 real, 0.80 fake)] [G loss: 20.481575] time: 0:16:00.217745\n",
      "(10, 128, 128, 3)\n",
      "0.8991437\n",
      "[Epoch 1/10] [Batch 828/1081] [D loss: 0.711953] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.538795] time: 0:16:00.611973\n",
      "(10, 128, 128, 3)\n",
      "0.9617286\n",
      "[Epoch 1/10] [Batch 829/1081] [D loss: 0.776005] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.445938] time: 0:16:01.030737\n",
      "(10, 128, 128, 3)\n",
      "0.92439795\n",
      "[Epoch 1/10] [Batch 830/1081] [D loss: 0.819046] [D acc: 0.70 (0.40 real, 1.00 fake)] [G loss: 19.806883] time: 0:16:01.434231\n",
      "(10, 128, 128, 3)\n",
      "0.9424854\n",
      "[Epoch 1/10] [Batch 831/1081] [D loss: 0.770019] [D acc: 0.90 (1.00 real, 0.80 fake)] [G loss: 20.522964] time: 0:16:01.845720\n",
      "(10, 128, 128, 3)\n",
      "0.9037102\n",
      "[Epoch 1/10] [Batch 832/1081] [D loss: 0.688839] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.492924] time: 0:16:02.261693\n",
      "(10, 128, 128, 3)\n",
      "0.90077305\n",
      "[Epoch 1/10] [Batch 833/1081] [D loss: 0.676740] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.703402] time: 0:16:02.663695\n",
      "(10, 128, 128, 3)\n",
      "0.8761125\n",
      "[Epoch 1/10] [Batch 834/1081] [D loss: 0.663460] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.791208] time: 0:16:03.068172\n",
      "(10, 128, 128, 3)\n",
      "0.9331903\n",
      "[Epoch 1/10] [Batch 835/1081] [D loss: 0.656203] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.322296] time: 0:16:03.472557\n",
      "(10, 128, 128, 3)\n",
      "0.8958058\n",
      "[Epoch 1/10] [Batch 836/1081] [D loss: 0.672373] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.649729] time: 0:16:03.866431\n",
      "(10, 128, 128, 3)\n",
      "0.90710336\n",
      "[Epoch 1/10] [Batch 837/1081] [D loss: 0.669837] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 21.593361] time: 0:16:04.251137\n",
      "(10, 128, 128, 3)\n",
      "0.91923475\n",
      "[Epoch 1/10] [Batch 838/1081] [D loss: 0.657099] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.333652] time: 0:16:04.649218\n",
      "(10, 128, 128, 3)\n",
      "0.85440534\n",
      "[Epoch 1/10] [Batch 839/1081] [D loss: 0.659223] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.055170] time: 0:16:05.069747\n",
      "(10, 128, 128, 3)\n",
      "0.9252203\n",
      "[Epoch 1/10] [Batch 840/1081] [D loss: 0.656387] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.963072] time: 0:16:05.493145\n",
      "(10, 128, 128, 3)\n",
      "0.8471082\n",
      "[Epoch 1/10] [Batch 841/1081] [D loss: 0.656094] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.175419] time: 0:16:05.883972\n",
      "(10, 128, 128, 3)\n",
      "0.88104445\n",
      "[Epoch 1/10] [Batch 842/1081] [D loss: 0.671127] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.260363] time: 0:16:06.286661\n",
      "(10, 128, 128, 3)\n",
      "0.9044407\n",
      "[Epoch 1/10] [Batch 843/1081] [D loss: 0.662006] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.647381] time: 0:16:06.700040\n",
      "(10, 128, 128, 3)\n",
      "0.90620685\n",
      "[Epoch 1/10] [Batch 844/1081] [D loss: 0.649867] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.064529] time: 0:16:07.117418\n",
      "(10, 128, 128, 3)\n",
      "0.9290212\n",
      "[Epoch 1/10] [Batch 845/1081] [D loss: 0.653125] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.276434] time: 0:16:07.515806\n",
      "(10, 128, 128, 3)\n",
      "0.9347172\n",
      "[Epoch 1/10] [Batch 846/1081] [D loss: 0.806774] [D acc: 0.85 (1.00 real, 0.70 fake)] [G loss: 19.504795] time: 0:16:07.913749\n",
      "(10, 128, 128, 3)\n",
      "0.9291549\n",
      "[Epoch 1/10] [Batch 847/1081] [D loss: 0.659303] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 21.524925] time: 0:16:08.318012\n",
      "(10, 128, 128, 3)\n",
      "0.89952254\n",
      "[Epoch 1/10] [Batch 848/1081] [D loss: 0.668919] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.420853] time: 0:16:08.731765\n",
      "(10, 128, 128, 3)\n",
      "0.93393093\n",
      "[Epoch 1/10] [Batch 849/1081] [D loss: 0.649778] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.118664] time: 0:16:09.130284\n",
      "(10, 128, 128, 3)\n",
      "0.874813\n",
      "[Epoch 1/10] [Batch 850/1081] [D loss: 0.650698] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.257526] time: 0:16:09.527077\n",
      "(10, 128, 128, 3)\n",
      "0.8659718\n",
      "[Epoch 1/10] [Batch 851/1081] [D loss: 0.649880] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.661352] time: 0:16:09.919383\n",
      "(10, 128, 128, 3)\n",
      "0.8791919\n",
      "[Epoch 1/10] [Batch 852/1081] [D loss: 0.645612] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.316833] time: 0:16:10.328595\n",
      "(10, 128, 128, 3)\n",
      "0.8589348\n",
      "[Epoch 1/10] [Batch 853/1081] [D loss: 0.643672] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.786232] time: 0:16:10.741194\n",
      "(10, 128, 128, 3)\n",
      "0.9370442\n",
      "[Epoch 1/10] [Batch 854/1081] [D loss: 0.642614] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.354420] time: 0:16:11.125637\n",
      "(10, 128, 128, 3)\n",
      "0.9262862\n",
      "[Epoch 1/10] [Batch 855/1081] [D loss: 0.650499] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.338779] time: 0:16:11.515279\n",
      "(10, 128, 128, 3)\n",
      "0.8962572\n",
      "[Epoch 1/10] [Batch 856/1081] [D loss: 0.641175] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.218504] time: 0:16:11.927860\n",
      "(10, 128, 128, 3)\n",
      "0.93136865\n",
      "[Epoch 1/10] [Batch 857/1081] [D loss: 0.641231] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.808542] time: 0:16:12.340274\n",
      "(10, 128, 128, 3)\n",
      "0.8749035\n",
      "[Epoch 1/10] [Batch 858/1081] [D loss: 0.639863] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.955027] time: 0:16:12.740429\n",
      "(10, 128, 128, 3)\n",
      "0.9176977\n",
      "[Epoch 1/10] [Batch 859/1081] [D loss: 0.639751] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.866653] time: 0:16:13.151037\n",
      "(10, 128, 128, 3)\n",
      "0.85317165\n",
      "[Epoch 1/10] [Batch 860/1081] [D loss: 0.638948] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.117529] time: 0:16:13.561930\n",
      "(10, 128, 128, 3)\n",
      "0.92409986\n",
      "[Epoch 1/10] [Batch 861/1081] [D loss: 0.640060] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.167019] time: 0:16:13.976300\n",
      "(10, 128, 128, 3)\n",
      "0.8664891\n",
      "[Epoch 1/10] [Batch 862/1081] [D loss: 0.637693] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.478130] time: 0:16:14.414917\n",
      "(10, 128, 128, 3)\n",
      "0.94070077\n",
      "[Epoch 1/10] [Batch 863/1081] [D loss: 0.636014] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.293203] time: 0:16:14.787641\n",
      "(10, 128, 128, 3)\n",
      "0.8957755\n",
      "[Epoch 1/10] [Batch 864/1081] [D loss: 0.638189] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.268032] time: 0:16:15.179306\n",
      "(10, 128, 128, 3)\n",
      "0.90544134\n",
      "[Epoch 1/10] [Batch 865/1081] [D loss: 0.641219] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.195930] time: 0:16:15.589069\n",
      "(10, 128, 128, 3)\n",
      "0.9797333\n",
      "[Epoch 1/10] [Batch 866/1081] [D loss: 0.635070] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.722439] time: 0:16:15.964250\n",
      "(10, 128, 128, 3)\n",
      "0.90586084\n",
      "[Epoch 1/10] [Batch 867/1081] [D loss: 0.634019] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.804451] time: 0:16:16.362515\n",
      "(10, 128, 128, 3)\n",
      "0.89728546\n",
      "[Epoch 1/10] [Batch 868/1081] [D loss: 0.633325] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.059315] time: 0:16:16.756487\n",
      "(10, 128, 128, 3)\n",
      "0.90595484\n",
      "[Epoch 1/10] [Batch 869/1081] [D loss: 0.634677] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.321526] time: 0:16:17.131899\n",
      "(10, 128, 128, 3)\n",
      "0.9149321\n",
      "[Epoch 1/10] [Batch 870/1081] [D loss: 0.630648] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.958511] time: 0:16:17.536946\n",
      "(10, 128, 128, 3)\n",
      "0.915165\n",
      "[Epoch 1/10] [Batch 871/1081] [D loss: 0.630869] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.900856] time: 0:16:17.935957\n",
      "(10, 128, 128, 3)\n",
      "0.86395425\n",
      "[Epoch 1/10] [Batch 872/1081] [D loss: 0.628799] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.772211] time: 0:16:18.357227\n",
      "(10, 128, 128, 3)\n",
      "0.93239826\n",
      "[Epoch 1/10] [Batch 873/1081] [D loss: 0.629037] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.147835] time: 0:16:18.778520\n",
      "(10, 128, 128, 3)\n",
      "0.9095325\n",
      "[Epoch 1/10] [Batch 874/1081] [D loss: 0.627925] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.999996] time: 0:16:19.159060\n",
      "(10, 128, 128, 3)\n",
      "0.91952187\n",
      "[Epoch 1/10] [Batch 875/1081] [D loss: 0.630230] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.084349] time: 0:16:19.555397\n",
      "(10, 128, 128, 3)\n",
      "0.88302666\n",
      "[Epoch 1/10] [Batch 876/1081] [D loss: 0.626103] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.232161] time: 0:16:19.982737\n",
      "(10, 128, 128, 3)\n",
      "0.88496023\n",
      "[Epoch 1/10] [Batch 877/1081] [D loss: 0.627932] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.339104] time: 0:16:20.391343\n",
      "(10, 128, 128, 3)\n",
      "0.89700514\n",
      "[Epoch 1/10] [Batch 878/1081] [D loss: 0.626840] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.432816] time: 0:16:20.806366\n",
      "(10, 128, 128, 3)\n",
      "0.94332504\n",
      "[Epoch 1/10] [Batch 879/1081] [D loss: 0.624119] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.418653] time: 0:16:21.191021\n",
      "(10, 128, 128, 3)\n",
      "0.92592984\n",
      "[Epoch 1/10] [Batch 880/1081] [D loss: 1.110229] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 19.042229] time: 0:16:21.567268\n",
      "(10, 128, 128, 3)\n",
      "0.94776106\n",
      "[Epoch 1/10] [Batch 881/1081] [D loss: 0.647720] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.590487] time: 0:16:21.952588\n",
      "(10, 128, 128, 3)\n",
      "0.9285288\n",
      "[Epoch 1/10] [Batch 882/1081] [D loss: 0.631949] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.453072] time: 0:16:22.357620\n",
      "(10, 128, 128, 3)\n",
      "0.93342763\n",
      "[Epoch 1/10] [Batch 883/1081] [D loss: 0.624293] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.510706] time: 0:16:22.752000\n",
      "(10, 128, 128, 3)\n",
      "0.8540492\n",
      "[Epoch 1/10] [Batch 884/1081] [D loss: 0.624777] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.903908] time: 0:16:23.160171\n",
      "(10, 128, 128, 3)\n",
      "0.8777384\n",
      "[Epoch 1/10] [Batch 885/1081] [D loss: 0.623123] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.922249] time: 0:16:23.556733\n",
      "(10, 128, 128, 3)\n",
      "0.8857947\n",
      "[Epoch 1/10] [Batch 886/1081] [D loss: 0.629959] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.368271] time: 0:16:23.960788\n",
      "(10, 128, 128, 3)\n",
      "0.89536434\n",
      "[Epoch 1/10] [Batch 887/1081] [D loss: 0.631097] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.198124] time: 0:16:24.384294\n",
      "(10, 128, 128, 3)\n",
      "0.9065196\n",
      "[Epoch 1/10] [Batch 888/1081] [D loss: 0.630103] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.345617] time: 0:16:24.788549\n",
      "(10, 128, 128, 3)\n",
      "0.89101344\n",
      "[Epoch 1/10] [Batch 889/1081] [D loss: 0.622034] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.177147] time: 0:16:25.200889\n",
      "(10, 128, 128, 3)\n",
      "0.88292676\n",
      "[Epoch 1/10] [Batch 890/1081] [D loss: 0.621146] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.299402] time: 0:16:25.595708\n",
      "(10, 128, 128, 3)\n",
      "0.9380255\n",
      "[Epoch 1/10] [Batch 891/1081] [D loss: 0.619036] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.690258] time: 0:16:26.005810\n",
      "(10, 128, 128, 3)\n",
      "0.97258496\n",
      "[Epoch 1/10] [Batch 892/1081] [D loss: 0.616083] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.305145] time: 0:16:26.406840\n",
      "(10, 128, 128, 3)\n",
      "0.96054286\n",
      "[Epoch 1/10] [Batch 893/1081] [D loss: 0.618734] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.289509] time: 0:16:26.782705\n",
      "(10, 128, 128, 3)\n",
      "0.93158364\n",
      "[Epoch 1/10] [Batch 894/1081] [D loss: 0.616791] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.865040] time: 0:16:27.217547\n",
      "(10, 128, 128, 3)\n",
      "0.90096587\n",
      "[Epoch 1/10] [Batch 895/1081] [D loss: 0.615820] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.339401] time: 0:16:27.604695\n",
      "(10, 128, 128, 3)\n",
      "0.8400278\n",
      "[Epoch 1/10] [Batch 896/1081] [D loss: 0.612486] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.475895] time: 0:16:27.993230\n",
      "(10, 128, 128, 3)\n",
      "0.945937\n",
      "[Epoch 1/10] [Batch 897/1081] [D loss: 0.614486] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.591370] time: 0:16:28.431244\n",
      "(10, 128, 128, 3)\n",
      "0.9341914\n",
      "[Epoch 1/10] [Batch 898/1081] [D loss: 0.613575] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.936020] time: 0:16:28.813072\n",
      "(10, 128, 128, 3)\n",
      "0.918776\n",
      "[Epoch 1/10] [Batch 899/1081] [D loss: 0.611161] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.454660] time: 0:16:29.217010\n",
      "(10, 128, 128, 3)\n",
      "0.8825844\n",
      "[Epoch 1/10] [Batch 900/1081] [D loss: 0.610814] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.132488] time: 0:16:29.603120\n",
      "(10, 128, 128, 3)\n",
      "0.9064143\n",
      "[Epoch 1/10] [Batch 901/1081] [D loss: 0.609541] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.367664] time: 0:16:30.006421\n",
      "(10, 128, 128, 3)\n",
      "0.93529695\n",
      "[Epoch 1/10] [Batch 902/1081] [D loss: 0.609092] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.646162] time: 0:16:30.381996\n",
      "(10, 128, 128, 3)\n",
      "0.9293446\n",
      "[Epoch 1/10] [Batch 903/1081] [D loss: 0.608911] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.508945] time: 0:16:30.791190\n",
      "(10, 128, 128, 3)\n",
      "0.90495926\n",
      "[Epoch 1/10] [Batch 904/1081] [D loss: 0.608505] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.730614] time: 0:16:31.194919\n",
      "(10, 128, 128, 3)\n",
      "0.88907903\n",
      "[Epoch 1/10] [Batch 905/1081] [D loss: 0.608399] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.786985] time: 0:16:31.590769\n",
      "(10, 128, 128, 3)\n",
      "0.9346929\n",
      "[Epoch 1/10] [Batch 906/1081] [D loss: 0.606257] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.353130] time: 0:16:32.017293\n",
      "(10, 128, 128, 3)\n",
      "0.9277961\n",
      "[Epoch 1/10] [Batch 907/1081] [D loss: 0.605949] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.550793] time: 0:16:32.451081\n",
      "(10, 128, 128, 3)\n",
      "0.90210676\n",
      "[Epoch 1/10] [Batch 908/1081] [D loss: 0.604441] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.835037] time: 0:16:32.890088\n",
      "(10, 128, 128, 3)\n",
      "0.906571\n",
      "[Epoch 1/10] [Batch 909/1081] [D loss: 0.606824] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.534235] time: 0:16:33.333822\n",
      "(10, 128, 128, 3)\n",
      "0.9647329\n",
      "[Epoch 1/10] [Batch 910/1081] [D loss: 0.608976] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.963081] time: 0:16:33.721926\n",
      "(10, 128, 128, 3)\n",
      "0.887039\n",
      "[Epoch 1/10] [Batch 911/1081] [D loss: 0.605153] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.729431] time: 0:16:34.128267\n",
      "(10, 128, 128, 3)\n",
      "0.92604274\n",
      "[Epoch 1/10] [Batch 912/1081] [D loss: 0.602322] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.467464] time: 0:16:34.533099\n",
      "(10, 128, 128, 3)\n",
      "0.9410947\n",
      "[Epoch 1/10] [Batch 913/1081] [D loss: 0.602597] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.932924] time: 0:16:34.925858\n",
      "(10, 128, 128, 3)\n",
      "0.8804949\n",
      "[Epoch 1/10] [Batch 914/1081] [D loss: 0.601528] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.704027] time: 0:16:35.324518\n",
      "(10, 128, 128, 3)\n",
      "0.93722373\n",
      "[Epoch 1/10] [Batch 915/1081] [D loss: 0.600022] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.381260] time: 0:16:35.742350\n",
      "(10, 128, 128, 3)\n",
      "0.9232697\n",
      "[Epoch 1/10] [Batch 916/1081] [D loss: 0.599101] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.556089] time: 0:16:36.130964\n",
      "(10, 128, 128, 3)\n",
      "0.8751063\n",
      "[Epoch 1/10] [Batch 917/1081] [D loss: 0.600759] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.051271] time: 0:16:36.553682\n",
      "(10, 128, 128, 3)\n",
      "0.90038544\n",
      "[Epoch 1/10] [Batch 918/1081] [D loss: 0.598054] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.729717] time: 0:16:36.963673\n",
      "(10, 128, 128, 3)\n",
      "0.94766647\n",
      "[Epoch 1/10] [Batch 919/1081] [D loss: 1.282671] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 18.444338] time: 0:16:37.378810\n",
      "(10, 128, 128, 3)\n",
      "0.90070033\n",
      "[Epoch 1/10] [Batch 920/1081] [D loss: 0.682523] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.935726] time: 0:16:37.784439\n",
      "(10, 128, 128, 3)\n",
      "0.9403843\n",
      "[Epoch 1/10] [Batch 921/1081] [D loss: 0.607712] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.888685] time: 0:16:38.203519\n",
      "(10, 128, 128, 3)\n",
      "0.9083428\n",
      "[Epoch 1/10] [Batch 922/1081] [D loss: 0.607443] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.770086] time: 0:16:38.604025\n",
      "(10, 128, 128, 3)\n",
      "0.9051457\n",
      "[Epoch 1/10] [Batch 923/1081] [D loss: 0.598739] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.914461] time: 0:16:39.009209\n",
      "(10, 128, 128, 3)\n",
      "0.8753724\n",
      "[Epoch 1/10] [Batch 924/1081] [D loss: 0.598180] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.105898] time: 0:16:39.393812\n",
      "(10, 128, 128, 3)\n",
      "0.94033796\n",
      "[Epoch 1/10] [Batch 925/1081] [D loss: 0.593330] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.795059] time: 0:16:39.855579\n",
      "(10, 128, 128, 3)\n",
      "0.90771365\n",
      "[Epoch 1/10] [Batch 926/1081] [D loss: 0.593400] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.230976] time: 0:16:40.257406\n",
      "(10, 128, 128, 3)\n",
      "0.8948925\n",
      "[Epoch 1/10] [Batch 927/1081] [D loss: 0.592582] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.163092] time: 0:16:40.668002\n",
      "(10, 128, 128, 3)\n",
      "0.9526892\n",
      "[Epoch 1/10] [Batch 928/1081] [D loss: 0.592731] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.991268] time: 0:16:41.051794\n",
      "(10, 128, 128, 3)\n",
      "0.9095699\n",
      "[Epoch 1/10] [Batch 929/1081] [D loss: 0.592779] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.036753] time: 0:16:41.460169\n",
      "(10, 128, 128, 3)\n",
      "0.94262165\n",
      "[Epoch 1/10] [Batch 930/1081] [D loss: 0.591653] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.476059] time: 0:16:41.839212\n",
      "(10, 128, 128, 3)\n",
      "0.94078404\n",
      "[Epoch 1/10] [Batch 931/1081] [D loss: 0.589369] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.284208] time: 0:16:42.272259\n",
      "(10, 128, 128, 3)\n",
      "0.96538645\n",
      "[Epoch 1/10] [Batch 932/1081] [D loss: 0.589360] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.965155] time: 0:16:42.675572\n",
      "(10, 128, 128, 3)\n",
      "0.9145438\n",
      "[Epoch 1/10] [Batch 933/1081] [D loss: 0.588244] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.487185] time: 0:16:43.108785\n",
      "(10, 128, 128, 3)\n",
      "0.97154665\n",
      "[Epoch 1/10] [Batch 934/1081] [D loss: 0.589844] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 20.147657] time: 0:16:43.516781\n",
      "(10, 128, 128, 3)\n",
      "0.9175244\n",
      "[Epoch 1/10] [Batch 935/1081] [D loss: 0.588492] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.744652] time: 0:16:43.916416\n",
      "(10, 128, 128, 3)\n",
      "0.8761155\n",
      "[Epoch 1/10] [Batch 936/1081] [D loss: 0.590470] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.828972] time: 0:16:44.348164\n",
      "(10, 128, 128, 3)\n",
      "0.8878847\n",
      "[Epoch 1/10] [Batch 937/1081] [D loss: 0.586051] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.751869] time: 0:16:44.741451\n",
      "(10, 128, 128, 3)\n",
      "0.9442267\n",
      "[Epoch 1/10] [Batch 938/1081] [D loss: 0.585681] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.395840] time: 0:16:45.149242\n",
      "(10, 128, 128, 3)\n",
      "0.8699439\n",
      "[Epoch 1/10] [Batch 939/1081] [D loss: 0.584383] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.677999] time: 0:16:45.554929\n",
      "(10, 128, 128, 3)\n",
      "0.90924615\n",
      "[Epoch 1/10] [Batch 940/1081] [D loss: 0.583536] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.573502] time: 0:16:45.964973\n",
      "(10, 128, 128, 3)\n",
      "0.92868614\n",
      "[Epoch 1/10] [Batch 941/1081] [D loss: 0.583172] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.437765] time: 0:16:46.359085\n",
      "(10, 128, 128, 3)\n",
      "0.87499124\n",
      "[Epoch 1/10] [Batch 942/1081] [D loss: 0.584104] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.274103] time: 0:16:46.743399\n",
      "(10, 128, 128, 3)\n",
      "0.9413093\n",
      "[Epoch 1/10] [Batch 943/1081] [D loss: 0.582114] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.937572] time: 0:16:47.163290\n",
      "(10, 128, 128, 3)\n",
      "0.8815387\n",
      "[Epoch 1/10] [Batch 944/1081] [D loss: 0.580938] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.885298] time: 0:16:47.575540\n",
      "(10, 128, 128, 3)\n",
      "0.9598879\n",
      "[Epoch 1/10] [Batch 945/1081] [D loss: 0.587733] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.721764] time: 0:16:47.996114\n",
      "(10, 128, 128, 3)\n",
      "0.9040788\n",
      "[Epoch 1/10] [Batch 946/1081] [D loss: 0.583682] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.577286] time: 0:16:48.389735\n",
      "(10, 128, 128, 3)\n",
      "0.93097466\n",
      "[Epoch 1/10] [Batch 947/1081] [D loss: 0.581077] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.990936] time: 0:16:48.781814\n",
      "(10, 128, 128, 3)\n",
      "0.92782766\n",
      "[Epoch 1/10] [Batch 948/1081] [D loss: 0.578593] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.389488] time: 0:16:49.216853\n",
      "(10, 128, 128, 3)\n",
      "0.93252844\n",
      "[Epoch 1/10] [Batch 949/1081] [D loss: 0.579037] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.416956] time: 0:16:49.629384\n",
      "(10, 128, 128, 3)\n",
      "0.8772474\n",
      "[Epoch 1/10] [Batch 950/1081] [D loss: 0.577205] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.603045] time: 0:16:50.044205\n",
      "(10, 128, 128, 3)\n",
      "0.8906874\n",
      "[Epoch 1/10] [Batch 951/1081] [D loss: 0.577124] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.138746] time: 0:16:50.431500\n",
      "(10, 128, 128, 3)\n",
      "0.8804362\n",
      "[Epoch 1/10] [Batch 952/1081] [D loss: 0.577419] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.638281] time: 0:16:50.840446\n",
      "(10, 128, 128, 3)\n",
      "0.9129111\n",
      "[Epoch 1/10] [Batch 953/1081] [D loss: 0.576980] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.584797] time: 0:16:51.260407\n",
      "(10, 128, 128, 3)\n",
      "0.95162535\n",
      "[Epoch 1/10] [Batch 954/1081] [D loss: 0.579809] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.567856] time: 0:16:51.642642\n",
      "(10, 128, 128, 3)\n",
      "0.90329283\n",
      "[Epoch 1/10] [Batch 955/1081] [D loss: 0.574892] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.732555] time: 0:16:52.070477\n",
      "(10, 128, 128, 3)\n",
      "0.90664744\n",
      "[Epoch 1/10] [Batch 956/1081] [D loss: 0.574397] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.012306] time: 0:16:52.488090\n",
      "(10, 128, 128, 3)\n",
      "0.9393833\n",
      "[Epoch 1/10] [Batch 957/1081] [D loss: 0.572440] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.364174] time: 0:16:52.895039\n",
      "(10, 128, 128, 3)\n",
      "0.86435133\n",
      "[Epoch 1/10] [Batch 958/1081] [D loss: 0.572001] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.949276] time: 0:16:53.306007\n",
      "(10, 128, 128, 3)\n",
      "0.9150885\n",
      "[Epoch 1/10] [Batch 959/1081] [D loss: 0.570946] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.288681] time: 0:16:53.699907\n",
      "(10, 128, 128, 3)\n",
      "0.82373875\n",
      "[Epoch 1/10] [Batch 960/1081] [D loss: 0.570460] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.467569] time: 0:16:54.085899\n",
      "(10, 128, 128, 3)\n",
      "0.9363454\n",
      "[Epoch 1/10] [Batch 961/1081] [D loss: 0.572676] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.418381] time: 0:16:54.506088\n",
      "(10, 128, 128, 3)\n",
      "0.9040287\n",
      "[Epoch 1/10] [Batch 962/1081] [D loss: 0.645761] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.200520] time: 0:16:54.939021\n",
      "(10, 128, 128, 3)\n",
      "0.9090654\n",
      "[Epoch 1/10] [Batch 963/1081] [D loss: 0.582573] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.482548] time: 0:16:55.342074\n",
      "(10, 128, 128, 3)\n",
      "0.94347787\n",
      "[Epoch 1/10] [Batch 964/1081] [D loss: 0.573603] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.617222] time: 0:16:55.748804\n",
      "(10, 128, 128, 3)\n",
      "0.9480636\n",
      "[Epoch 1/10] [Batch 965/1081] [D loss: 0.609494] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.280352] time: 0:16:56.153103\n",
      "(10, 128, 128, 3)\n",
      "0.9369943\n",
      "[Epoch 1/10] [Batch 966/1081] [D loss: 0.576549] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.643305] time: 0:16:56.555221\n",
      "(10, 128, 128, 3)\n",
      "0.8686188\n",
      "[Epoch 1/10] [Batch 967/1081] [D loss: 0.569004] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.092403] time: 0:16:56.991763\n",
      "(10, 128, 128, 3)\n",
      "0.9362691\n",
      "[Epoch 1/10] [Batch 968/1081] [D loss: 0.566976] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.593365] time: 0:16:57.400346\n",
      "(10, 128, 128, 3)\n",
      "0.9320562\n",
      "[Epoch 1/10] [Batch 969/1081] [D loss: 0.568054] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.397064] time: 0:16:57.832224\n",
      "(10, 128, 128, 3)\n",
      "0.9292066\n",
      "[Epoch 1/10] [Batch 970/1081] [D loss: 0.566060] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.252773] time: 0:16:58.246423\n",
      "(10, 128, 128, 3)\n",
      "0.8964839\n",
      "[Epoch 1/10] [Batch 971/1081] [D loss: 0.566014] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.316080] time: 0:16:58.662501\n",
      "(10, 128, 128, 3)\n",
      "0.9373083\n",
      "[Epoch 1/10] [Batch 972/1081] [D loss: 0.565159] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.034132] time: 0:16:59.079221\n",
      "(10, 128, 128, 3)\n",
      "0.95789284\n",
      "[Epoch 1/10] [Batch 973/1081] [D loss: 0.564670] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.936300] time: 0:16:59.482482\n",
      "(10, 128, 128, 3)\n",
      "0.92156535\n",
      "[Epoch 1/10] [Batch 974/1081] [D loss: 0.563550] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.554653] time: 0:16:59.882273\n",
      "(10, 128, 128, 3)\n",
      "0.90207857\n",
      "[Epoch 1/10] [Batch 975/1081] [D loss: 0.568152] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.483921] time: 0:17:00.307826\n",
      "(10, 128, 128, 3)\n",
      "0.8952422\n",
      "[Epoch 1/10] [Batch 976/1081] [D loss: 0.574087] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.731808] time: 0:17:00.700892\n",
      "(10, 128, 128, 3)\n",
      "0.90419894\n",
      "[Epoch 1/10] [Batch 977/1081] [D loss: 0.582746] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.969845] time: 0:17:01.122870\n",
      "(10, 128, 128, 3)\n",
      "0.9787326\n",
      "[Epoch 1/10] [Batch 978/1081] [D loss: 0.565125] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.989330] time: 0:17:01.555399\n",
      "(10, 128, 128, 3)\n",
      "0.9337476\n",
      "[Epoch 1/10] [Batch 979/1081] [D loss: 0.561944] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.353046] time: 0:17:01.957167\n",
      "(10, 128, 128, 3)\n",
      "0.89326835\n",
      "[Epoch 1/10] [Batch 980/1081] [D loss: 0.567317] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.894985] time: 0:17:02.363994\n",
      "(10, 128, 128, 3)\n",
      "0.9291816\n",
      "[Epoch 1/10] [Batch 981/1081] [D loss: 0.559574] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.483543] time: 0:17:02.751431\n",
      "(10, 128, 128, 3)\n",
      "0.9403822\n",
      "[Epoch 1/10] [Batch 982/1081] [D loss: 0.558574] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.802597] time: 0:17:03.136309\n",
      "(10, 128, 128, 3)\n",
      "0.8893308\n",
      "[Epoch 1/10] [Batch 983/1081] [D loss: 0.558882] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.764194] time: 0:17:03.529959\n",
      "(10, 128, 128, 3)\n",
      "0.9078843\n",
      "[Epoch 1/10] [Batch 984/1081] [D loss: 0.555741] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.875940] time: 0:17:03.921835\n",
      "(10, 128, 128, 3)\n",
      "0.8865871\n",
      "[Epoch 1/10] [Batch 985/1081] [D loss: 0.555326] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.559629] time: 0:17:04.331513\n",
      "(10, 128, 128, 3)\n",
      "0.95671177\n",
      "[Epoch 1/10] [Batch 986/1081] [D loss: 0.555096] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.795912] time: 0:17:04.766636\n",
      "(10, 128, 128, 3)\n",
      "0.90750724\n",
      "[Epoch 1/10] [Batch 987/1081] [D loss: 0.554545] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.673697] time: 0:17:05.183212\n",
      "(10, 128, 128, 3)\n",
      "0.8466788\n",
      "[Epoch 1/10] [Batch 988/1081] [D loss: 0.553540] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.719166] time: 0:17:05.593434\n",
      "(10, 128, 128, 3)\n",
      "0.9213667\n",
      "[Epoch 1/10] [Batch 989/1081] [D loss: 0.553931] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.476307] time: 0:17:06.002920\n",
      "(10, 128, 128, 3)\n",
      "0.8788261\n",
      "[Epoch 1/10] [Batch 990/1081] [D loss: 0.552193] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.372602] time: 0:17:06.398105\n",
      "(10, 128, 128, 3)\n",
      "0.921832\n",
      "[Epoch 1/10] [Batch 991/1081] [D loss: 0.552356] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.873703] time: 0:17:06.818342\n",
      "(10, 128, 128, 3)\n",
      "0.8867262\n",
      "[Epoch 1/10] [Batch 992/1081] [D loss: 0.551392] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.239435] time: 0:17:07.214897\n",
      "(10, 128, 128, 3)\n",
      "0.9361419\n",
      "[Epoch 1/10] [Batch 993/1081] [D loss: 0.552769] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.738190] time: 0:17:07.633299\n",
      "(10, 128, 128, 3)\n",
      "0.90034133\n",
      "[Epoch 1/10] [Batch 994/1081] [D loss: 0.550816] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.936670] time: 0:17:08.025315\n",
      "(10, 128, 128, 3)\n",
      "0.92930204\n",
      "[Epoch 1/10] [Batch 995/1081] [D loss: 0.549458] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.571325] time: 0:17:08.430957\n",
      "(10, 128, 128, 3)\n",
      "0.89827734\n",
      "[Epoch 1/10] [Batch 996/1081] [D loss: 0.549641] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.457859] time: 0:17:08.842613\n",
      "(10, 128, 128, 3)\n",
      "0.90584546\n",
      "[Epoch 1/10] [Batch 997/1081] [D loss: 0.548532] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.050434] time: 0:17:09.238719\n",
      "(10, 128, 128, 3)\n",
      "0.9317352\n",
      "[Epoch 1/10] [Batch 998/1081] [D loss: 0.547706] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.504602] time: 0:17:09.631815\n",
      "(10, 128, 128, 3)\n",
      "0.90581495\n",
      "[Epoch 1/10] [Batch 999/1081] [D loss: 0.548177] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.609558] time: 0:17:10.034736\n",
      "(10, 128, 128, 3)\n",
      "0.93485016\n",
      "[Epoch 1/10] [Batch 1000/1081] [D loss: 0.546264] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.517872] time: 0:17:10.440174\n",
      "(10, 128, 128, 3)\n",
      "0.90757895\n",
      "[Epoch 1/10] [Batch 1001/1081] [D loss: 0.545133] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.038517] time: 0:17:10.832426\n",
      "(10, 128, 128, 3)\n",
      "0.87697786\n",
      "[Epoch 1/10] [Batch 1002/1081] [D loss: 0.549579] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.347502] time: 0:17:11.261021\n",
      "(10, 128, 128, 3)\n",
      "0.8815854\n",
      "[Epoch 1/10] [Batch 1003/1081] [D loss: 0.547254] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.665316] time: 0:17:11.700214\n",
      "(10, 128, 128, 3)\n",
      "0.9400372\n",
      "[Epoch 1/10] [Batch 1004/1081] [D loss: 0.545296] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.247278] time: 0:17:12.460868\n",
      "(10, 128, 128, 3)\n",
      "0.95246166\n",
      "[Epoch 1/10] [Batch 1005/1081] [D loss: 0.544200] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.807518] time: 0:17:12.859986\n",
      "(10, 128, 128, 3)\n",
      "0.9295776\n",
      "[Epoch 1/10] [Batch 1006/1081] [D loss: 0.543197] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.256760] time: 0:17:13.275633\n",
      "(10, 128, 128, 3)\n",
      "0.89033884\n",
      "[Epoch 1/10] [Batch 1007/1081] [D loss: 0.542665] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.730885] time: 0:17:13.699299\n",
      "(10, 128, 128, 3)\n",
      "0.8633477\n",
      "[Epoch 1/10] [Batch 1008/1081] [D loss: 0.542377] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.669188] time: 0:17:14.134582\n",
      "(10, 128, 128, 3)\n",
      "0.8811903\n",
      "[Epoch 1/10] [Batch 1009/1081] [D loss: 0.559247] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.834511] time: 0:17:14.531683\n",
      "(10, 128, 128, 3)\n",
      "0.870815\n",
      "[Epoch 1/10] [Batch 1010/1081] [D loss: 0.543497] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.583521] time: 0:17:14.953526\n",
      "(10, 128, 128, 3)\n",
      "0.93317205\n",
      "[Epoch 1/10] [Batch 1011/1081] [D loss: 0.555458] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.678343] time: 0:17:15.367108\n",
      "(10, 128, 128, 3)\n",
      "0.8956371\n",
      "[Epoch 1/10] [Batch 1012/1081] [D loss: 0.539071] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.257700] time: 0:17:15.780862\n",
      "(10, 128, 128, 3)\n",
      "0.84477234\n",
      "[Epoch 1/10] [Batch 1013/1081] [D loss: 0.542080] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.597811] time: 0:17:16.180511\n",
      "(10, 128, 128, 3)\n",
      "0.86407834\n",
      "[Epoch 1/10] [Batch 1014/1081] [D loss: 0.539135] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.497597] time: 0:17:16.574338\n",
      "(10, 128, 128, 3)\n",
      "0.9056415\n",
      "[Epoch 1/10] [Batch 1015/1081] [D loss: 0.536915] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.191586] time: 0:17:16.955127\n",
      "(10, 128, 128, 3)\n",
      "0.8731243\n",
      "[Epoch 1/10] [Batch 1016/1081] [D loss: 0.536148] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.045944] time: 0:17:17.360254\n",
      "(10, 128, 128, 3)\n",
      "0.92515725\n",
      "[Epoch 1/10] [Batch 1017/1081] [D loss: 0.536862] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.772440] time: 0:17:17.758026\n",
      "(10, 128, 128, 3)\n",
      "0.9007898\n",
      "[Epoch 1/10] [Batch 1018/1081] [D loss: 0.535467] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.048679] time: 0:17:18.186847\n",
      "(10, 128, 128, 3)\n",
      "0.9364111\n",
      "[Epoch 1/10] [Batch 1019/1081] [D loss: 0.534799] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.785715] time: 0:17:18.604426\n",
      "(10, 128, 128, 3)\n",
      "0.90717536\n",
      "[Epoch 1/10] [Batch 1020/1081] [D loss: 0.534765] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.109814] time: 0:17:18.988932\n",
      "(10, 128, 128, 3)\n",
      "0.9308055\n",
      "[Epoch 1/10] [Batch 1021/1081] [D loss: 0.536248] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.183315] time: 0:17:19.378894\n",
      "(10, 128, 128, 3)\n",
      "0.88629764\n",
      "[Epoch 1/10] [Batch 1022/1081] [D loss: 0.532384] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.674004] time: 0:17:19.769263\n",
      "(10, 128, 128, 3)\n",
      "0.9088629\n",
      "[Epoch 1/10] [Batch 1023/1081] [D loss: 0.532981] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.720482] time: 0:17:20.236704\n",
      "(10, 128, 128, 3)\n",
      "0.89600164\n",
      "[Epoch 1/10] [Batch 1024/1081] [D loss: 0.533580] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.160229] time: 0:17:20.679064\n",
      "(10, 128, 128, 3)\n",
      "0.9023368\n",
      "[Epoch 1/10] [Batch 1025/1081] [D loss: 0.531336] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.069029] time: 0:17:21.105844\n",
      "(10, 128, 128, 3)\n",
      "0.8858411\n",
      "[Epoch 1/10] [Batch 1026/1081] [D loss: 0.530737] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.483212] time: 0:17:21.517938\n",
      "(10, 128, 128, 3)\n",
      "0.90405935\n",
      "[Epoch 1/10] [Batch 1027/1081] [D loss: 0.531311] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.152559] time: 0:17:21.958268\n",
      "(10, 128, 128, 3)\n",
      "0.93961686\n",
      "[Epoch 1/10] [Batch 1028/1081] [D loss: 0.528931] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.339535] time: 0:17:22.402454\n",
      "(10, 128, 128, 3)\n",
      "0.88842016\n",
      "[Epoch 1/10] [Batch 1029/1081] [D loss: 0.528341] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.934368] time: 0:17:22.789926\n",
      "(10, 128, 128, 3)\n",
      "0.91926664\n",
      "[Epoch 1/10] [Batch 1030/1081] [D loss: 0.530634] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.351845] time: 0:17:23.212029\n",
      "(10, 128, 128, 3)\n",
      "0.94618636\n",
      "[Epoch 1/10] [Batch 1031/1081] [D loss: 0.529547] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.296307] time: 0:17:23.615608\n",
      "(10, 128, 128, 3)\n",
      "0.92115855\n",
      "[Epoch 1/10] [Batch 1032/1081] [D loss: 0.526220] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.147717] time: 0:17:24.013486\n",
      "(10, 128, 128, 3)\n",
      "0.9113829\n",
      "[Epoch 1/10] [Batch 1033/1081] [D loss: 0.526572] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.724777] time: 0:17:24.415475\n",
      "(10, 128, 128, 3)\n",
      "0.9219336\n",
      "[Epoch 1/10] [Batch 1034/1081] [D loss: 0.527390] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.193787] time: 0:17:24.840475\n",
      "(10, 128, 128, 3)\n",
      "0.89812547\n",
      "[Epoch 1/10] [Batch 1035/1081] [D loss: 0.524784] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.261364] time: 0:17:25.239676\n",
      "(10, 128, 128, 3)\n",
      "0.9301974\n",
      "[Epoch 1/10] [Batch 1036/1081] [D loss: 0.525545] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.941174] time: 0:17:25.660741\n",
      "(10, 128, 128, 3)\n",
      "0.9334986\n",
      "[Epoch 1/10] [Batch 1037/1081] [D loss: 0.523505] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.984612] time: 0:17:26.072877\n",
      "(10, 128, 128, 3)\n",
      "0.890745\n",
      "[Epoch 1/10] [Batch 1038/1081] [D loss: 0.524048] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.712156] time: 0:17:26.470135\n",
      "(10, 128, 128, 3)\n",
      "0.86445093\n",
      "[Epoch 1/10] [Batch 1039/1081] [D loss: 0.523232] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.643944] time: 0:17:26.864115\n",
      "(10, 128, 128, 3)\n",
      "0.8643002\n",
      "[Epoch 1/10] [Batch 1040/1081] [D loss: 0.522185] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.015589] time: 0:17:27.283404\n",
      "(10, 128, 128, 3)\n",
      "0.9132045\n",
      "[Epoch 1/10] [Batch 1041/1081] [D loss: 0.521744] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.137627] time: 0:17:27.718817\n",
      "(10, 128, 128, 3)\n",
      "0.9385218\n",
      "[Epoch 1/10] [Batch 1042/1081] [D loss: 0.520910] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.561588] time: 0:17:28.148268\n",
      "(10, 128, 128, 3)\n",
      "0.92730165\n",
      "[Epoch 1/10] [Batch 1043/1081] [D loss: 0.520665] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.221567] time: 0:17:28.552068\n",
      "(10, 128, 128, 3)\n",
      "0.87526256\n",
      "[Epoch 1/10] [Batch 1044/1081] [D loss: 0.519498] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.176313] time: 0:17:28.964094\n",
      "(10, 128, 128, 3)\n",
      "0.95943695\n",
      "[Epoch 1/10] [Batch 1045/1081] [D loss: 0.519722] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.663246] time: 0:17:29.345022\n",
      "(10, 128, 128, 3)\n",
      "0.88513064\n",
      "[Epoch 1/10] [Batch 1046/1081] [D loss: 0.520385] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.587627] time: 0:17:29.783877\n",
      "(10, 128, 128, 3)\n",
      "0.9227043\n",
      "[Epoch 1/10] [Batch 1047/1081] [D loss: 0.527369] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.687933] time: 0:17:30.190717\n",
      "(10, 128, 128, 3)\n",
      "0.91022587\n",
      "[Epoch 1/10] [Batch 1048/1081] [D loss: 0.517557] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.436426] time: 0:17:30.651317\n",
      "(10, 128, 128, 3)\n",
      "0.8805924\n",
      "[Epoch 1/10] [Batch 1049/1081] [D loss: 0.517111] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.099987] time: 0:17:31.059468\n",
      "(10, 128, 128, 3)\n",
      "0.9280483\n",
      "[Epoch 1/10] [Batch 1050/1081] [D loss: 0.517480] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.237968] time: 0:17:31.463242\n",
      "(10, 128, 128, 3)\n",
      "0.8693859\n",
      "[Epoch 1/10] [Batch 1051/1081] [D loss: 0.515680] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.068249] time: 0:17:31.858433\n",
      "(10, 128, 128, 3)\n",
      "0.90711623\n",
      "[Epoch 1/10] [Batch 1052/1081] [D loss: 0.515602] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.047750] time: 0:17:32.265984\n",
      "(10, 128, 128, 3)\n",
      "0.90556496\n",
      "[Epoch 1/10] [Batch 1053/1081] [D loss: 0.514111] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.705542] time: 0:17:32.656627\n",
      "(10, 128, 128, 3)\n",
      "0.9331877\n",
      "[Epoch 1/10] [Batch 1054/1081] [D loss: 0.514266] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.272831] time: 0:17:33.072155\n",
      "(10, 128, 128, 3)\n",
      "0.9171252\n",
      "[Epoch 1/10] [Batch 1055/1081] [D loss: 0.513117] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.890381] time: 0:17:33.462076\n",
      "(10, 128, 128, 3)\n",
      "0.86971426\n",
      "[Epoch 1/10] [Batch 1056/1081] [D loss: 0.517024] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.782858] time: 0:17:33.886434\n",
      "(10, 128, 128, 3)\n",
      "0.9054757\n",
      "[Epoch 1/10] [Batch 1057/1081] [D loss: 0.512440] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.963619] time: 0:17:34.330474\n",
      "(10, 128, 128, 3)\n",
      "0.91690236\n",
      "[Epoch 1/10] [Batch 1058/1081] [D loss: 0.512001] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.788376] time: 0:17:34.713393\n",
      "(10, 128, 128, 3)\n",
      "0.9207131\n",
      "[Epoch 1/10] [Batch 1059/1081] [D loss: 0.510436] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.920570] time: 0:17:35.118614\n",
      "(10, 128, 128, 3)\n",
      "0.8889552\n",
      "[Epoch 1/10] [Batch 1060/1081] [D loss: 0.509980] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.810989] time: 0:17:35.542544\n",
      "(10, 128, 128, 3)\n",
      "0.9614053\n",
      "[Epoch 1/10] [Batch 1061/1081] [D loss: 0.509519] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.675449] time: 0:17:35.973052\n",
      "(10, 128, 128, 3)\n",
      "0.9096355\n",
      "[Epoch 1/10] [Batch 1062/1081] [D loss: 0.508942] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.412716] time: 0:17:36.381275\n",
      "(10, 128, 128, 3)\n",
      "0.8676726\n",
      "[Epoch 1/10] [Batch 1063/1081] [D loss: 0.508793] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.980209] time: 0:17:36.789899\n",
      "(10, 128, 128, 3)\n",
      "0.8592229\n",
      "[Epoch 1/10] [Batch 1064/1081] [D loss: 0.508219] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.911831] time: 0:17:37.198970\n",
      "(10, 128, 128, 3)\n",
      "0.9158399\n",
      "[Epoch 1/10] [Batch 1065/1081] [D loss: 0.506934] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.180517] time: 0:17:37.601480\n",
      "(10, 128, 128, 3)\n",
      "0.98011255\n",
      "[Epoch 1/10] [Batch 1066/1081] [D loss: 0.506371] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.557783] time: 0:17:38.052127\n",
      "(10, 128, 128, 3)\n",
      "0.9520695\n",
      "[Epoch 1/10] [Batch 1067/1081] [D loss: 0.505874] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.321873] time: 0:17:38.448527\n",
      "(10, 128, 128, 3)\n",
      "0.9334893\n",
      "[Epoch 1/10] [Batch 1068/1081] [D loss: 0.505683] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.309124] time: 0:17:38.842662\n",
      "(10, 128, 128, 3)\n",
      "0.91396254\n",
      "[Epoch 1/10] [Batch 1069/1081] [D loss: 0.504944] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.644581] time: 0:17:39.246110\n",
      "(10, 128, 128, 3)\n",
      "0.9391691\n",
      "[Epoch 1/10] [Batch 1070/1081] [D loss: 0.504127] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.668425] time: 0:17:39.655584\n",
      "(10, 128, 128, 3)\n",
      "0.8843117\n",
      "[Epoch 1/10] [Batch 1071/1081] [D loss: 0.503401] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.720093] time: 0:17:40.117578\n",
      "(10, 128, 128, 3)\n",
      "0.8240578\n",
      "[Epoch 1/10] [Batch 1072/1081] [D loss: 0.507596] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.370771] time: 0:17:40.566173\n",
      "(10, 128, 128, 3)\n",
      "0.94141674\n",
      "[Epoch 1/10] [Batch 1073/1081] [D loss: 0.505769] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.323719] time: 0:17:40.967799\n",
      "(10, 128, 128, 3)\n",
      "0.86825275\n",
      "[Epoch 1/10] [Batch 1074/1081] [D loss: 0.504097] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.858540] time: 0:17:41.350395\n",
      "(10, 128, 128, 3)\n",
      "0.8820234\n",
      "[Epoch 1/10] [Batch 1075/1081] [D loss: 0.503563] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.654804] time: 0:17:41.762862\n",
      "(10, 128, 128, 3)\n",
      "0.90850013\n",
      "[Epoch 1/10] [Batch 1076/1081] [D loss: 0.500845] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.796198] time: 0:17:42.174480\n",
      "(10, 128, 128, 3)\n",
      "0.9303689\n",
      "[Epoch 1/10] [Batch 1077/1081] [D loss: 0.500191] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.018435] time: 0:17:42.580254\n",
      "(10, 128, 128, 3)\n",
      "0.89394885\n",
      "[Epoch 1/10] [Batch 1078/1081] [D loss: 0.500008] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.533871] time: 0:17:42.976630\n",
      "(10, 128, 128, 3)\n",
      "0.9016604\n",
      "[Epoch 1/10] [Batch 1079/1081] [D loss: 0.502234] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.331873] time: 0:17:43.401097\n",
      "(10, 128, 128, 3)\n",
      "0.9230814\n",
      "[Epoch 1/10] [Batch 1080/1081] [D loss: 0.530991] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.843498] time: 0:17:43.814985\n",
      "############ VALIDATION OF EPOCH 1 ############\n",
      "############ TRAINING OF EPOCH 2 ############\n",
      "(10, 128, 128, 3)\n",
      "0.90209174\n",
      "[Epoch 2/10] [Batch 1/1081] [D loss: 0.503577] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.392838] time: 0:18:26.303005\n",
      "(10, 128, 128, 3)\n",
      "0.905756\n",
      "[Epoch 2/10] [Batch 2/1081] [D loss: 0.502238] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.326363] time: 0:18:26.724403\n",
      "(10, 128, 128, 3)\n",
      "0.90335625\n",
      "[Epoch 2/10] [Batch 3/1081] [D loss: 0.504302] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.830009] time: 0:18:27.125474\n",
      "(10, 128, 128, 3)\n",
      "0.8673385\n",
      "[Epoch 2/10] [Batch 4/1081] [D loss: 0.497227] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.085539] time: 0:18:27.534893\n",
      "(10, 128, 128, 3)\n",
      "0.9326668\n",
      "[Epoch 2/10] [Batch 5/1081] [D loss: 0.497166] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.126432] time: 0:18:27.948034\n",
      "(10, 128, 128, 3)\n",
      "0.90439653\n",
      "[Epoch 2/10] [Batch 6/1081] [D loss: 0.495356] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.926773] time: 0:18:28.347647\n",
      "(10, 128, 128, 3)\n",
      "0.9602864\n",
      "[Epoch 2/10] [Batch 7/1081] [D loss: 0.495483] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.153290] time: 0:18:28.738342\n",
      "(10, 128, 128, 3)\n",
      "0.93495315\n",
      "[Epoch 2/10] [Batch 8/1081] [D loss: 0.496567] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.512993] time: 0:18:29.135195\n",
      "(10, 128, 128, 3)\n",
      "0.92892194\n",
      "[Epoch 2/10] [Batch 9/1081] [D loss: 0.494640] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.828030] time: 0:18:29.548230\n",
      "(10, 128, 128, 3)\n",
      "0.9231575\n",
      "[Epoch 2/10] [Batch 10/1081] [D loss: 0.493874] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.325289] time: 0:18:29.946363\n",
      "(10, 128, 128, 3)\n",
      "0.8353148\n",
      "[Epoch 2/10] [Batch 11/1081] [D loss: 0.493081] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.705414] time: 0:18:30.352725\n",
      "(10, 128, 128, 3)\n",
      "0.9155719\n",
      "[Epoch 2/10] [Batch 12/1081] [D loss: 0.493356] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.299330] time: 0:18:30.744146\n",
      "(10, 128, 128, 3)\n",
      "0.89659935\n",
      "[Epoch 2/10] [Batch 13/1081] [D loss: 0.493437] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.281202] time: 0:18:31.169733\n",
      "(10, 128, 128, 3)\n",
      "0.91072196\n",
      "[Epoch 2/10] [Batch 14/1081] [D loss: 0.491909] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.205732] time: 0:18:31.583436\n",
      "(10, 128, 128, 3)\n",
      "0.9316721\n",
      "[Epoch 2/10] [Batch 15/1081] [D loss: 0.491351] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.052658] time: 0:18:32.017655\n",
      "(10, 128, 128, 3)\n",
      "0.9577091\n",
      "[Epoch 2/10] [Batch 16/1081] [D loss: 0.490994] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.217978] time: 0:18:32.424747\n",
      "(10, 128, 128, 3)\n",
      "0.890657\n",
      "[Epoch 2/10] [Batch 17/1081] [D loss: 0.489137] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.513559] time: 0:18:32.844602\n",
      "(10, 128, 128, 3)\n",
      "0.96670085\n",
      "[Epoch 2/10] [Batch 18/1081] [D loss: 0.489209] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.106319] time: 0:18:33.284775\n",
      "(10, 128, 128, 3)\n",
      "0.92095584\n",
      "[Epoch 2/10] [Batch 19/1081] [D loss: 0.492117] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.900452] time: 0:18:33.693712\n",
      "(10, 128, 128, 3)\n",
      "0.8692417\n",
      "[Epoch 2/10] [Batch 20/1081] [D loss: 0.487676] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.442266] time: 0:18:34.111244\n",
      "(10, 128, 128, 3)\n",
      "0.90477985\n",
      "[Epoch 2/10] [Batch 21/1081] [D loss: 0.486918] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.842592] time: 0:18:34.515347\n",
      "(10, 128, 128, 3)\n",
      "0.9294608\n",
      "[Epoch 2/10] [Batch 22/1081] [D loss: 0.487071] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.642963] time: 0:18:34.924842\n",
      "(10, 128, 128, 3)\n",
      "0.9525103\n",
      "[Epoch 2/10] [Batch 23/1081] [D loss: 0.486389] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.013582] time: 0:18:35.344637\n",
      "(10, 128, 128, 3)\n",
      "0.9225945\n",
      "[Epoch 2/10] [Batch 24/1081] [D loss: 0.487430] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.079727] time: 0:18:35.781047\n",
      "(10, 128, 128, 3)\n",
      "0.94391537\n",
      "[Epoch 2/10] [Batch 25/1081] [D loss: 0.484800] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.556061] time: 0:18:36.182385\n",
      "(10, 128, 128, 3)\n",
      "0.9086394\n",
      "[Epoch 2/10] [Batch 26/1081] [D loss: 0.486708] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.510733] time: 0:18:36.587523\n",
      "(10, 128, 128, 3)\n",
      "0.8958852\n",
      "[Epoch 2/10] [Batch 27/1081] [D loss: 0.484747] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.545197] time: 0:18:37.006741\n",
      "(10, 128, 128, 3)\n",
      "0.8877737\n",
      "[Epoch 2/10] [Batch 28/1081] [D loss: 0.483338] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.526884] time: 0:18:37.426350\n",
      "(10, 128, 128, 3)\n",
      "0.92390376\n",
      "[Epoch 2/10] [Batch 29/1081] [D loss: 0.482251] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.637110] time: 0:18:37.870457\n",
      "(10, 128, 128, 3)\n",
      "0.90409046\n",
      "[Epoch 2/10] [Batch 30/1081] [D loss: 0.481782] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.098057] time: 0:18:38.324489\n",
      "(10, 128, 128, 3)\n",
      "0.91075706\n",
      "[Epoch 2/10] [Batch 31/1081] [D loss: 0.481183] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.657400] time: 0:18:38.709397\n",
      "(10, 128, 128, 3)\n",
      "0.94053215\n",
      "[Epoch 2/10] [Batch 32/1081] [D loss: 0.480669] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.346735] time: 0:18:39.142617\n",
      "(10, 128, 128, 3)\n",
      "0.907787\n",
      "[Epoch 2/10] [Batch 33/1081] [D loss: 0.480116] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.144819] time: 0:18:39.562130\n",
      "(10, 128, 128, 3)\n",
      "0.90002674\n",
      "[Epoch 2/10] [Batch 34/1081] [D loss: 0.479424] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.555454] time: 0:18:40.002877\n",
      "(10, 128, 128, 3)\n",
      "0.964307\n",
      "[Epoch 2/10] [Batch 35/1081] [D loss: 0.479704] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.481836] time: 0:18:40.426942\n",
      "(10, 128, 128, 3)\n",
      "0.96561676\n",
      "[Epoch 2/10] [Batch 36/1081] [D loss: 0.478402] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.498430] time: 0:18:40.839539\n",
      "(10, 128, 128, 3)\n",
      "0.8947408\n",
      "[Epoch 2/10] [Batch 37/1081] [D loss: 0.478015] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.484894] time: 0:18:41.250050\n",
      "(10, 128, 128, 3)\n",
      "0.8561093\n",
      "[Epoch 2/10] [Batch 38/1081] [D loss: 0.478681] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.008684] time: 0:18:41.687767\n",
      "(10, 128, 128, 3)\n",
      "0.8617275\n",
      "[Epoch 2/10] [Batch 39/1081] [D loss: 0.477366] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.090302] time: 0:18:42.098032\n",
      "(10, 128, 128, 3)\n",
      "0.8953522\n",
      "[Epoch 2/10] [Batch 40/1081] [D loss: 0.476794] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.183592] time: 0:18:42.536413\n",
      "(10, 128, 128, 3)\n",
      "0.8889696\n",
      "[Epoch 2/10] [Batch 41/1081] [D loss: 0.475822] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.164129] time: 0:18:42.941829\n",
      "(10, 128, 128, 3)\n",
      "0.93654865\n",
      "[Epoch 2/10] [Batch 42/1081] [D loss: 0.475926] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.433567] time: 0:18:43.350470\n",
      "(10, 128, 128, 3)\n",
      "0.88846254\n",
      "[Epoch 2/10] [Batch 43/1081] [D loss: 0.475502] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.366898] time: 0:18:43.747150\n",
      "(10, 128, 128, 3)\n",
      "0.9016995\n",
      "[Epoch 2/10] [Batch 44/1081] [D loss: 0.476175] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.863697] time: 0:18:44.159650\n",
      "(10, 128, 128, 3)\n",
      "0.91804975\n",
      "[Epoch 2/10] [Batch 45/1081] [D loss: 0.474097] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.228354] time: 0:18:44.556356\n",
      "(10, 128, 128, 3)\n",
      "0.900503\n",
      "[Epoch 2/10] [Batch 46/1081] [D loss: 0.473784] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.758638] time: 0:18:44.951015\n",
      "(10, 128, 128, 3)\n",
      "0.925344\n",
      "[Epoch 2/10] [Batch 47/1081] [D loss: 0.473199] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.127113] time: 0:18:45.356466\n",
      "(10, 128, 128, 3)\n",
      "0.94456226\n",
      "[Epoch 2/10] [Batch 48/1081] [D loss: 0.471733] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.038963] time: 0:18:45.763169\n",
      "(10, 128, 128, 3)\n",
      "0.9457447\n",
      "[Epoch 2/10] [Batch 49/1081] [D loss: 0.471679] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 19.152176] time: 0:18:46.183273\n",
      "(10, 128, 128, 3)\n",
      "0.9046645\n",
      "[Epoch 2/10] [Batch 50/1081] [D loss: 0.471283] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.056093] time: 0:18:46.568148\n",
      "(10, 128, 128, 3)\n",
      "0.88751656\n",
      "[Epoch 2/10] [Batch 51/1081] [D loss: 0.470615] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.658834] time: 0:18:46.996931\n",
      "(10, 128, 128, 3)\n",
      "0.93176013\n",
      "[Epoch 2/10] [Batch 52/1081] [D loss: 0.469721] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.747568] time: 0:18:47.429850\n",
      "(10, 128, 128, 3)\n",
      "0.87044114\n",
      "[Epoch 2/10] [Batch 53/1081] [D loss: 0.469440] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.606724] time: 0:18:47.858395\n",
      "(10, 128, 128, 3)\n",
      "0.87027746\n",
      "[Epoch 2/10] [Batch 54/1081] [D loss: 0.468923] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.419775] time: 0:18:48.250550\n",
      "(10, 128, 128, 3)\n",
      "0.9026286\n",
      "[Epoch 2/10] [Batch 55/1081] [D loss: 0.468163] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.962284] time: 0:18:48.669357\n",
      "(10, 128, 128, 3)\n",
      "0.87875175\n",
      "[Epoch 2/10] [Batch 56/1081] [D loss: 0.468210] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.367172] time: 0:18:49.090368\n",
      "(10, 128, 128, 3)\n",
      "0.9402065\n",
      "[Epoch 2/10] [Batch 57/1081] [D loss: 0.469131] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.850824] time: 0:18:49.485701\n",
      "(10, 128, 128, 3)\n",
      "0.8922166\n",
      "[Epoch 2/10] [Batch 58/1081] [D loss: 0.466684] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.876013] time: 0:18:49.931197\n",
      "(10, 128, 128, 3)\n",
      "0.9332226\n",
      "[Epoch 2/10] [Batch 59/1081] [D loss: 0.466161] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.768553] time: 0:18:50.330461\n",
      "(10, 128, 128, 3)\n",
      "0.9209852\n",
      "[Epoch 2/10] [Batch 60/1081] [D loss: 0.465842] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.375841] time: 0:18:50.735271\n",
      "(10, 128, 128, 3)\n",
      "0.8986909\n",
      "[Epoch 2/10] [Batch 61/1081] [D loss: 0.466314] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.412539] time: 0:18:51.148372\n",
      "(10, 128, 128, 3)\n",
      "0.8715245\n",
      "[Epoch 2/10] [Batch 62/1081] [D loss: 0.464924] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.345034] time: 0:18:51.616570\n",
      "(10, 128, 128, 3)\n",
      "0.9048627\n",
      "[Epoch 2/10] [Batch 63/1081] [D loss: 0.465308] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.454863] time: 0:18:52.042297\n",
      "(10, 128, 128, 3)\n",
      "0.93276024\n",
      "[Epoch 2/10] [Batch 64/1081] [D loss: 0.463552] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.505802] time: 0:18:52.451545\n",
      "(10, 128, 128, 3)\n",
      "0.9418091\n",
      "[Epoch 2/10] [Batch 65/1081] [D loss: 0.462858] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.330702] time: 0:18:52.865061\n",
      "(10, 128, 128, 3)\n",
      "0.959563\n",
      "[Epoch 2/10] [Batch 66/1081] [D loss: 0.462898] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.457485] time: 0:18:53.295553\n",
      "(10, 128, 128, 3)\n",
      "0.9056279\n",
      "[Epoch 2/10] [Batch 67/1081] [D loss: 0.461721] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.498339] time: 0:18:53.730759\n",
      "(10, 128, 128, 3)\n",
      "0.8970273\n",
      "[Epoch 2/10] [Batch 68/1081] [D loss: 0.461327] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.784346] time: 0:18:54.141100\n",
      "(10, 128, 128, 3)\n",
      "0.92555374\n",
      "[Epoch 2/10] [Batch 69/1081] [D loss: 0.461840] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.111509] time: 0:18:54.580448\n",
      "(10, 128, 128, 3)\n",
      "0.91212296\n",
      "[Epoch 2/10] [Batch 70/1081] [D loss: 0.460357] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.698982] time: 0:18:54.965155\n",
      "(10, 128, 128, 3)\n",
      "0.8872667\n",
      "[Epoch 2/10] [Batch 71/1081] [D loss: 0.459605] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.474443] time: 0:18:55.375682\n",
      "(10, 128, 128, 3)\n",
      "0.8982415\n",
      "[Epoch 2/10] [Batch 72/1081] [D loss: 0.458925] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.276749] time: 0:18:55.813363\n",
      "(10, 128, 128, 3)\n",
      "0.95189285\n",
      "[Epoch 2/10] [Batch 73/1081] [D loss: 0.459347] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.414165] time: 0:18:56.266981\n",
      "(10, 128, 128, 3)\n",
      "0.8794593\n",
      "[Epoch 2/10] [Batch 74/1081] [D loss: 0.457866] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.692190] time: 0:18:56.668341\n",
      "(10, 128, 128, 3)\n",
      "0.87389535\n",
      "[Epoch 2/10] [Batch 75/1081] [D loss: 0.459431] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.272593] time: 0:18:57.078493\n",
      "(10, 128, 128, 3)\n",
      "0.93624973\n",
      "[Epoch 2/10] [Batch 76/1081] [D loss: 0.457322] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.635563] time: 0:18:57.558177\n",
      "(10, 128, 128, 3)\n",
      "0.9284613\n",
      "[Epoch 2/10] [Batch 77/1081] [D loss: 0.456816] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.339291] time: 0:18:57.964624\n",
      "(10, 128, 128, 3)\n",
      "0.94274276\n",
      "[Epoch 2/10] [Batch 78/1081] [D loss: 1.094121] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 16.600735] time: 0:18:58.388197\n",
      "(10, 128, 128, 3)\n",
      "0.8970768\n",
      "[Epoch 2/10] [Batch 79/1081] [D loss: 0.488350] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.998426] time: 0:18:58.818924\n",
      "(10, 128, 128, 3)\n",
      "0.89669305\n",
      "[Epoch 2/10] [Batch 80/1081] [D loss: 0.516932] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.655186] time: 0:18:59.252269\n",
      "(10, 128, 128, 3)\n",
      "0.9630082\n",
      "[Epoch 2/10] [Batch 81/1081] [D loss: 0.466340] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.009769] time: 0:18:59.660305\n",
      "(10, 128, 128, 3)\n",
      "0.95388\n",
      "[Epoch 2/10] [Batch 82/1081] [D loss: 0.481551] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.543819] time: 0:19:00.072458\n",
      "(10, 128, 128, 3)\n",
      "0.83194095\n",
      "[Epoch 2/10] [Batch 83/1081] [D loss: 0.474630] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.648033] time: 0:19:00.461323\n",
      "(10, 128, 128, 3)\n",
      "0.8883938\n",
      "[Epoch 2/10] [Batch 84/1081] [D loss: 0.498079] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.786068] time: 0:19:00.873652\n",
      "(10, 128, 128, 3)\n",
      "0.9352496\n",
      "[Epoch 2/10] [Batch 85/1081] [D loss: 0.458512] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.289709] time: 0:19:01.313991\n",
      "(10, 128, 128, 3)\n",
      "0.87808084\n",
      "[Epoch 2/10] [Batch 86/1081] [D loss: 0.474511] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.537615] time: 0:19:01.720205\n",
      "(10, 128, 128, 3)\n",
      "0.95722824\n",
      "[Epoch 2/10] [Batch 87/1081] [D loss: 0.463095] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.801411] time: 0:19:02.156351\n",
      "(10, 128, 128, 3)\n",
      "0.9005138\n",
      "[Epoch 2/10] [Batch 88/1081] [D loss: 0.456787] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.929653] time: 0:19:02.578334\n",
      "(10, 128, 128, 3)\n",
      "0.8633676\n",
      "[Epoch 2/10] [Batch 89/1081] [D loss: 0.457244] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.661100] time: 0:19:02.988381\n",
      "(10, 128, 128, 3)\n",
      "0.8837158\n",
      "[Epoch 2/10] [Batch 90/1081] [D loss: 0.471885] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.818081] time: 0:19:03.432926\n",
      "(10, 128, 128, 3)\n",
      "0.9456122\n",
      "[Epoch 2/10] [Batch 91/1081] [D loss: 0.458469] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.309153] time: 0:19:03.827447\n",
      "(10, 128, 128, 3)\n",
      "0.9596009\n",
      "[Epoch 2/10] [Batch 92/1081] [D loss: 0.458282] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.226561] time: 0:19:04.236757\n",
      "(10, 128, 128, 3)\n",
      "0.90000916\n",
      "[Epoch 2/10] [Batch 93/1081] [D loss: 0.456354] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.541979] time: 0:19:04.644198\n",
      "(10, 128, 128, 3)\n",
      "0.9334166\n",
      "[Epoch 2/10] [Batch 94/1081] [D loss: 0.454592] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.663792] time: 0:19:05.096095\n",
      "(10, 128, 128, 3)\n",
      "0.8559952\n",
      "[Epoch 2/10] [Batch 95/1081] [D loss: 0.452290] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.653618] time: 0:19:05.517528\n",
      "(10, 128, 128, 3)\n",
      "0.91208625\n",
      "[Epoch 2/10] [Batch 96/1081] [D loss: 0.455786] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.947577] time: 0:19:05.932316\n",
      "(10, 128, 128, 3)\n",
      "0.94789076\n",
      "[Epoch 2/10] [Batch 97/1081] [D loss: 0.453935] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.208748] time: 0:19:06.349075\n",
      "(10, 128, 128, 3)\n",
      "0.89658165\n",
      "[Epoch 2/10] [Batch 98/1081] [D loss: 0.455351] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.120556] time: 0:19:06.773728\n",
      "(10, 128, 128, 3)\n",
      "0.9380649\n",
      "[Epoch 2/10] [Batch 99/1081] [D loss: 0.451726] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.430374] time: 0:19:07.197197\n",
      "(10, 128, 128, 3)\n",
      "0.9376766\n",
      "[Epoch 2/10] [Batch 100/1081] [D loss: 0.453986] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.208904] time: 0:19:07.621874\n",
      "(10, 128, 128, 3)\n",
      "0.84060526\n",
      "[Epoch 2/10] [Batch 101/1081] [D loss: 0.449890] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.486431] time: 0:19:08.016575\n",
      "(10, 128, 128, 3)\n",
      "0.9271758\n",
      "[Epoch 2/10] [Batch 102/1081] [D loss: 0.455007] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.015736] time: 0:19:08.430096\n",
      "(10, 128, 128, 3)\n",
      "0.9185047\n",
      "[Epoch 2/10] [Batch 103/1081] [D loss: 0.452749] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.127317] time: 0:19:08.818108\n",
      "(10, 128, 128, 3)\n",
      "0.92204756\n",
      "[Epoch 2/10] [Batch 104/1081] [D loss: 0.445817] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.767464] time: 0:19:09.232085\n",
      "(10, 128, 128, 3)\n",
      "0.8864108\n",
      "[Epoch 2/10] [Batch 105/1081] [D loss: 0.454849] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.998362] time: 0:19:09.650474\n",
      "(10, 128, 128, 3)\n",
      "0.8883961\n",
      "[Epoch 2/10] [Batch 106/1081] [D loss: 0.449596] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.581385] time: 0:19:10.062597\n",
      "(10, 128, 128, 3)\n",
      "0.9127367\n",
      "[Epoch 2/10] [Batch 107/1081] [D loss: 0.446579] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.273245] time: 0:19:10.460452\n",
      "(10, 128, 128, 3)\n",
      "0.90636367\n",
      "[Epoch 2/10] [Batch 108/1081] [D loss: 0.444933] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.459997] time: 0:19:10.881397\n",
      "(10, 128, 128, 3)\n",
      "0.94094497\n",
      "[Epoch 2/10] [Batch 109/1081] [D loss: 0.444157] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.210243] time: 0:19:11.303716\n",
      "(10, 128, 128, 3)\n",
      "0.9628292\n",
      "[Epoch 2/10] [Batch 110/1081] [D loss: 0.444129] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.639137] time: 0:19:11.701478\n",
      "(10, 128, 128, 3)\n",
      "0.9156708\n",
      "[Epoch 2/10] [Batch 111/1081] [D loss: 0.444267] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.085285] time: 0:19:12.108766\n",
      "(10, 128, 128, 3)\n",
      "0.896784\n",
      "[Epoch 2/10] [Batch 112/1081] [D loss: 0.445206] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.949400] time: 0:19:12.523071\n",
      "(10, 128, 128, 3)\n",
      "0.95235723\n",
      "[Epoch 2/10] [Batch 113/1081] [D loss: 0.445764] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.747271] time: 0:19:12.946106\n",
      "(10, 128, 128, 3)\n",
      "0.93454665\n",
      "[Epoch 2/10] [Batch 114/1081] [D loss: 0.444313] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.301399] time: 0:19:13.336508\n",
      "(10, 128, 128, 3)\n",
      "0.90621376\n",
      "[Epoch 2/10] [Batch 115/1081] [D loss: 0.442208] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.493284] time: 0:19:13.767673\n",
      "(10, 128, 128, 3)\n",
      "0.8370242\n",
      "[Epoch 2/10] [Batch 116/1081] [D loss: 0.440528] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.622511] time: 0:19:14.146899\n",
      "(10, 128, 128, 3)\n",
      "0.93979716\n",
      "[Epoch 2/10] [Batch 117/1081] [D loss: 0.439740] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.144398] time: 0:19:14.559338\n",
      "(10, 128, 128, 3)\n",
      "0.9170349\n",
      "[Epoch 2/10] [Batch 118/1081] [D loss: 0.440973] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.786346] time: 0:19:14.995800\n",
      "(10, 128, 128, 3)\n",
      "0.91620207\n",
      "[Epoch 2/10] [Batch 119/1081] [D loss: 0.443431] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.940771] time: 0:19:15.412533\n",
      "(10, 128, 128, 3)\n",
      "0.9294254\n",
      "[Epoch 2/10] [Batch 120/1081] [D loss: 0.444287] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.228966] time: 0:19:15.845101\n",
      "(10, 128, 128, 3)\n",
      "0.8724437\n",
      "[Epoch 2/10] [Batch 121/1081] [D loss: 0.437673] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.033146] time: 0:19:16.259998\n",
      "(10, 128, 128, 3)\n",
      "0.8929649\n",
      "[Epoch 2/10] [Batch 122/1081] [D loss: 0.441321] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.759174] time: 0:19:16.663018\n",
      "(10, 128, 128, 3)\n",
      "0.91575766\n",
      "[Epoch 2/10] [Batch 123/1081] [D loss: 0.436999] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.320766] time: 0:19:17.101391\n",
      "(10, 128, 128, 3)\n",
      "0.9053929\n",
      "[Epoch 2/10] [Batch 124/1081] [D loss: 0.439972] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.988344] time: 0:19:17.502678\n",
      "(10, 128, 128, 3)\n",
      "0.88173753\n",
      "[Epoch 2/10] [Batch 125/1081] [D loss: 0.436565] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.577259] time: 0:19:17.928537\n",
      "(10, 128, 128, 3)\n",
      "0.8881817\n",
      "[Epoch 2/10] [Batch 126/1081] [D loss: 0.435712] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.079214] time: 0:19:18.335378\n",
      "(10, 128, 128, 3)\n",
      "0.8944456\n",
      "[Epoch 2/10] [Batch 127/1081] [D loss: 0.434898] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.400148] time: 0:19:18.755973\n",
      "(10, 128, 128, 3)\n",
      "0.9012634\n",
      "[Epoch 2/10] [Batch 128/1081] [D loss: 0.436377] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.410433] time: 0:19:19.155666\n",
      "(10, 128, 128, 3)\n",
      "0.93767095\n",
      "[Epoch 2/10] [Batch 129/1081] [D loss: 0.435940] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.818724] time: 0:19:19.573274\n",
      "(10, 128, 128, 3)\n",
      "0.89481264\n",
      "[Epoch 2/10] [Batch 130/1081] [D loss: 0.434215] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.772106] time: 0:19:20.010425\n",
      "(10, 128, 128, 3)\n",
      "0.9416385\n",
      "[Epoch 2/10] [Batch 131/1081] [D loss: 0.434790] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.481268] time: 0:19:20.436497\n",
      "(10, 128, 128, 3)\n",
      "0.94688845\n",
      "[Epoch 2/10] [Batch 132/1081] [D loss: 0.433728] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.447392] time: 0:19:20.836032\n",
      "(10, 128, 128, 3)\n",
      "0.928585\n",
      "[Epoch 2/10] [Batch 133/1081] [D loss: 0.433088] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.788647] time: 0:19:21.239306\n",
      "(10, 128, 128, 3)\n",
      "0.9269499\n",
      "[Epoch 2/10] [Batch 134/1081] [D loss: 0.430772] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.696476] time: 0:19:21.690542\n",
      "(10, 128, 128, 3)\n",
      "0.85769135\n",
      "[Epoch 2/10] [Batch 135/1081] [D loss: 0.430063] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.238791] time: 0:19:22.084013\n",
      "(10, 128, 128, 3)\n",
      "0.93909544\n",
      "[Epoch 2/10] [Batch 136/1081] [D loss: 0.477061] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.728914] time: 0:19:22.487963\n",
      "(10, 128, 128, 3)\n",
      "0.89643496\n",
      "[Epoch 2/10] [Batch 137/1081] [D loss: 0.430576] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.181364] time: 0:19:22.927881\n",
      "(10, 128, 128, 3)\n",
      "0.9343891\n",
      "[Epoch 2/10] [Batch 138/1081] [D loss: 0.430919] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.716276] time: 0:19:23.365850\n",
      "(10, 128, 128, 3)\n",
      "0.8814578\n",
      "[Epoch 2/10] [Batch 139/1081] [D loss: 0.431667] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.455217] time: 0:19:23.779373\n",
      "(10, 128, 128, 3)\n",
      "0.9687728\n",
      "[Epoch 2/10] [Batch 140/1081] [D loss: 0.428243] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.720131] time: 0:19:24.176745\n",
      "(10, 128, 128, 3)\n",
      "0.9164087\n",
      "[Epoch 2/10] [Batch 141/1081] [D loss: 0.433867] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.520895] time: 0:19:24.627497\n",
      "(10, 128, 128, 3)\n",
      "0.8628538\n",
      "[Epoch 2/10] [Batch 142/1081] [D loss: 0.427966] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.233322] time: 0:19:25.042462\n",
      "(10, 128, 128, 3)\n",
      "0.9019785\n",
      "[Epoch 2/10] [Batch 143/1081] [D loss: 0.428828] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.862635] time: 0:19:25.436384\n",
      "(10, 128, 128, 3)\n",
      "0.9444067\n",
      "[Epoch 2/10] [Batch 144/1081] [D loss: 0.448416] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.260086] time: 0:19:25.865643\n",
      "(10, 128, 128, 3)\n",
      "0.8804874\n",
      "[Epoch 2/10] [Batch 145/1081] [D loss: 0.431215] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.920591] time: 0:19:26.258199\n",
      "(10, 128, 128, 3)\n",
      "0.90796787\n",
      "[Epoch 2/10] [Batch 146/1081] [D loss: 0.424982] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.211617] time: 0:19:26.688101\n",
      "(10, 128, 128, 3)\n",
      "0.8617212\n",
      "[Epoch 2/10] [Batch 147/1081] [D loss: 0.428737] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.065010] time: 0:19:27.106632\n",
      "(10, 128, 128, 3)\n",
      "0.92536616\n",
      "[Epoch 2/10] [Batch 148/1081] [D loss: 0.424408] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.169979] time: 0:19:27.550482\n",
      "(10, 128, 128, 3)\n",
      "0.9022158\n",
      "[Epoch 2/10] [Batch 149/1081] [D loss: 0.424425] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.195990] time: 0:19:27.973328\n",
      "(10, 128, 128, 3)\n",
      "0.9430284\n",
      "[Epoch 2/10] [Batch 150/1081] [D loss: 0.423357] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.553307] time: 0:19:28.426111\n",
      "(10, 128, 128, 3)\n",
      "0.92809135\n",
      "[Epoch 2/10] [Batch 151/1081] [D loss: 0.422648] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.991386] time: 0:19:28.830480\n",
      "(10, 128, 128, 3)\n",
      "0.87617546\n",
      "[Epoch 2/10] [Batch 152/1081] [D loss: 0.428177] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.540051] time: 0:19:29.230616\n",
      "(10, 128, 128, 3)\n",
      "0.90084934\n",
      "[Epoch 2/10] [Batch 153/1081] [D loss: 0.423204] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.992012] time: 0:19:29.647986\n",
      "(10, 128, 128, 3)\n",
      "0.90243983\n",
      "[Epoch 2/10] [Batch 154/1081] [D loss: 0.422964] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.437656] time: 0:19:30.065095\n",
      "(10, 128, 128, 3)\n",
      "0.8928106\n",
      "[Epoch 2/10] [Batch 155/1081] [D loss: 0.420930] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.866636] time: 0:19:30.479157\n",
      "(10, 128, 128, 3)\n",
      "0.877654\n",
      "[Epoch 2/10] [Batch 156/1081] [D loss: 0.420404] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.048824] time: 0:19:30.906562\n",
      "(10, 128, 128, 3)\n",
      "0.91198856\n",
      "[Epoch 2/10] [Batch 157/1081] [D loss: 0.420484] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.019304] time: 0:19:31.359099\n",
      "(10, 128, 128, 3)\n",
      "0.89152426\n",
      "[Epoch 2/10] [Batch 158/1081] [D loss: 0.419485] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.447132] time: 0:19:31.785506\n",
      "(10, 128, 128, 3)\n",
      "0.93026704\n",
      "[Epoch 2/10] [Batch 159/1081] [D loss: 0.420218] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.518726] time: 0:19:32.216573\n",
      "(10, 128, 128, 3)\n",
      "0.92654306\n",
      "[Epoch 2/10] [Batch 160/1081] [D loss: 0.418364] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.035528] time: 0:19:32.613555\n",
      "(10, 128, 128, 3)\n",
      "0.89051604\n",
      "[Epoch 2/10] [Batch 161/1081] [D loss: 0.418605] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.784706] time: 0:19:33.053958\n",
      "(10, 128, 128, 3)\n",
      "0.96193725\n",
      "[Epoch 2/10] [Batch 162/1081] [D loss: 0.418837] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.831907] time: 0:19:33.492419\n",
      "(10, 128, 128, 3)\n",
      "0.8979185\n",
      "[Epoch 2/10] [Batch 163/1081] [D loss: 0.417154] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.202932] time: 0:19:33.908485\n",
      "(10, 128, 128, 3)\n",
      "0.9095109\n",
      "[Epoch 2/10] [Batch 164/1081] [D loss: 0.416526] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.324207] time: 0:19:34.343719\n",
      "(10, 128, 128, 3)\n",
      "0.9140988\n",
      "[Epoch 2/10] [Batch 165/1081] [D loss: 0.416086] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.473871] time: 0:19:34.759031\n",
      "(10, 128, 128, 3)\n",
      "0.9805057\n",
      "[Epoch 2/10] [Batch 166/1081] [D loss: 0.415221] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.720846] time: 0:19:35.211865\n",
      "(10, 128, 128, 3)\n",
      "0.9348817\n",
      "[Epoch 2/10] [Batch 167/1081] [D loss: 0.443687] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.563965] time: 0:19:35.646914\n",
      "(10, 128, 128, 3)\n",
      "0.97978777\n",
      "[Epoch 2/10] [Batch 168/1081] [D loss: 0.433849] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.690983] time: 0:19:36.046346\n",
      "(10, 128, 128, 3)\n",
      "0.88487244\n",
      "[Epoch 2/10] [Batch 169/1081] [D loss: 0.415159] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.675329] time: 0:19:36.449390\n",
      "(10, 128, 128, 3)\n",
      "0.86364317\n",
      "[Epoch 2/10] [Batch 170/1081] [D loss: 0.414396] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.074631] time: 0:19:36.854708\n",
      "(10, 128, 128, 3)\n",
      "0.8658419\n",
      "[Epoch 2/10] [Batch 171/1081] [D loss: 0.413813] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.885897] time: 0:19:37.264759\n",
      "(10, 128, 128, 3)\n",
      "0.934995\n",
      "[Epoch 2/10] [Batch 172/1081] [D loss: 0.413585] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.769451] time: 0:19:37.676590\n",
      "(10, 128, 128, 3)\n",
      "0.9383445\n",
      "[Epoch 2/10] [Batch 173/1081] [D loss: 0.413999] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.653139] time: 0:19:38.110558\n",
      "(10, 128, 128, 3)\n",
      "0.8704938\n",
      "[Epoch 2/10] [Batch 174/1081] [D loss: 0.411476] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.276005] time: 0:19:38.527853\n",
      "(10, 128, 128, 3)\n",
      "0.9348655\n",
      "[Epoch 2/10] [Batch 175/1081] [D loss: 0.411183] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.898865] time: 0:19:38.923931\n",
      "(10, 128, 128, 3)\n",
      "0.91185373\n",
      "[Epoch 2/10] [Batch 176/1081] [D loss: 0.410765] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.138147] time: 0:19:39.306378\n",
      "(10, 128, 128, 3)\n",
      "0.94911855\n",
      "[Epoch 2/10] [Batch 177/1081] [D loss: 0.410033] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.124559] time: 0:19:39.740656\n",
      "(10, 128, 128, 3)\n",
      "0.858157\n",
      "[Epoch 2/10] [Batch 178/1081] [D loss: 0.409259] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.217354] time: 0:19:40.139892\n",
      "(10, 128, 128, 3)\n",
      "0.89694554\n",
      "[Epoch 2/10] [Batch 179/1081] [D loss: 0.409522] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.933775] time: 0:19:40.528093\n",
      "(10, 128, 128, 3)\n",
      "0.87914544\n",
      "[Epoch 2/10] [Batch 180/1081] [D loss: 0.410689] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.821211] time: 0:19:40.958173\n",
      "(10, 128, 128, 3)\n",
      "0.83998656\n",
      "[Epoch 2/10] [Batch 181/1081] [D loss: 0.407898] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.595383] time: 0:19:41.380021\n",
      "(10, 128, 128, 3)\n",
      "0.9046378\n",
      "[Epoch 2/10] [Batch 182/1081] [D loss: 0.408036] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.544737] time: 0:19:41.771571\n",
      "(10, 128, 128, 3)\n",
      "0.9142909\n",
      "[Epoch 2/10] [Batch 183/1081] [D loss: 0.407030] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.831059] time: 0:19:42.203417\n",
      "(10, 128, 128, 3)\n",
      "0.93038744\n",
      "[Epoch 2/10] [Batch 184/1081] [D loss: 0.407967] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.670494] time: 0:19:42.615372\n",
      "(10, 128, 128, 3)\n",
      "0.9280978\n",
      "[Epoch 2/10] [Batch 185/1081] [D loss: 0.406556] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.644499] time: 0:19:43.055357\n",
      "(10, 128, 128, 3)\n",
      "0.92973447\n",
      "[Epoch 2/10] [Batch 186/1081] [D loss: 0.405869] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.647755] time: 0:19:43.456636\n",
      "(10, 128, 128, 3)\n",
      "0.8907632\n",
      "[Epoch 2/10] [Batch 187/1081] [D loss: 0.819666] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 17.626465] time: 0:19:43.858805\n",
      "(10, 128, 128, 3)\n",
      "0.924361\n",
      "[Epoch 2/10] [Batch 188/1081] [D loss: 0.473329] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.745754] time: 0:19:44.267797\n",
      "(10, 128, 128, 3)\n",
      "0.96784496\n",
      "[Epoch 2/10] [Batch 189/1081] [D loss: 0.464801] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.190578] time: 0:19:44.684034\n",
      "(10, 128, 128, 3)\n",
      "0.8616369\n",
      "[Epoch 2/10] [Batch 190/1081] [D loss: 0.440605] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.554264] time: 0:19:45.120306\n",
      "(10, 128, 128, 3)\n",
      "0.92103213\n",
      "[Epoch 2/10] [Batch 191/1081] [D loss: 0.417112] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.730320] time: 0:19:45.547656\n",
      "(10, 128, 128, 3)\n",
      "0.93234617\n",
      "[Epoch 2/10] [Batch 192/1081] [D loss: 0.657472] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 16.594130] time: 0:19:45.975319\n",
      "(10, 128, 128, 3)\n",
      "0.96285796\n",
      "[Epoch 2/10] [Batch 193/1081] [D loss: 0.630108] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 17.588467] time: 0:19:46.379132\n",
      "(10, 128, 128, 3)\n",
      "0.88624114\n",
      "[Epoch 2/10] [Batch 194/1081] [D loss: 0.831311] [D acc: 0.05 (0.00 real, 0.10 fake)] [G loss: 16.714766] time: 0:19:46.807433\n",
      "(10, 128, 128, 3)\n",
      "0.9110961\n",
      "[Epoch 2/10] [Batch 195/1081] [D loss: 0.607107] [D acc: 0.60 (0.40 real, 0.80 fake)] [G loss: 16.234934] time: 0:19:47.199225\n",
      "(10, 128, 128, 3)\n",
      "0.8776482\n",
      "[Epoch 2/10] [Batch 196/1081] [D loss: 0.660926] [D acc: 0.60 (0.20 real, 1.00 fake)] [G loss: 16.786980] time: 0:19:47.608826\n",
      "(10, 128, 128, 3)\n",
      "0.90068746\n",
      "[Epoch 2/10] [Batch 197/1081] [D loss: 0.491975] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.577288] time: 0:19:48.030873\n",
      "(10, 128, 128, 3)\n",
      "0.93277746\n",
      "[Epoch 2/10] [Batch 198/1081] [D loss: 0.457293] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.637873] time: 0:19:48.500163\n",
      "(10, 128, 128, 3)\n",
      "0.931554\n",
      "[Epoch 2/10] [Batch 199/1081] [D loss: 0.484994] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 17.085794] time: 0:19:48.944365\n",
      "(10, 128, 128, 3)\n",
      "0.84223795\n",
      "[Epoch 2/10] [Batch 200/1081] [D loss: 0.427577] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.509806] time: 0:19:49.379529\n",
      "(10, 128, 128, 3)\n",
      "0.9126385\n",
      "[Epoch 2/10] [Batch 201/1081] [D loss: 0.413977] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.537510] time: 0:19:49.795681\n",
      "(10, 128, 128, 3)\n",
      "0.8692507\n",
      "[Epoch 2/10] [Batch 202/1081] [D loss: 0.405097] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.347019] time: 0:19:50.196507\n",
      "(10, 128, 128, 3)\n",
      "0.95860523\n",
      "[Epoch 2/10] [Batch 203/1081] [D loss: 0.400627] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.704052] time: 0:19:50.620213\n",
      "(10, 128, 128, 3)\n",
      "0.8523228\n",
      "[Epoch 2/10] [Batch 204/1081] [D loss: 0.406709] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.504560] time: 0:19:51.044697\n",
      "(10, 128, 128, 3)\n",
      "0.9387331\n",
      "[Epoch 2/10] [Batch 205/1081] [D loss: 0.405706] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.402279] time: 0:19:51.464804\n",
      "(10, 128, 128, 3)\n",
      "0.95907396\n",
      "[Epoch 2/10] [Batch 206/1081] [D loss: 0.401910] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.028112] time: 0:19:51.862649\n",
      "(10, 128, 128, 3)\n",
      "0.9540747\n",
      "[Epoch 2/10] [Batch 207/1081] [D loss: 0.405811] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.759743] time: 0:19:52.250805\n",
      "(10, 128, 128, 3)\n",
      "0.935548\n",
      "[Epoch 2/10] [Batch 208/1081] [D loss: 0.399858] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.085766] time: 0:19:52.642054\n",
      "(10, 128, 128, 3)\n",
      "0.9019316\n",
      "[Epoch 2/10] [Batch 209/1081] [D loss: 0.398378] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.152164] time: 0:19:53.059816\n",
      "(10, 128, 128, 3)\n",
      "0.91525364\n",
      "[Epoch 2/10] [Batch 210/1081] [D loss: 0.739945] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 16.244770] time: 0:19:53.477276\n",
      "(10, 128, 128, 3)\n",
      "0.9063689\n",
      "[Epoch 2/10] [Batch 211/1081] [D loss: 0.473609] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 18.466251] time: 0:19:53.886025\n",
      "(10, 128, 128, 3)\n",
      "0.927613\n",
      "[Epoch 2/10] [Batch 212/1081] [D loss: 0.458168] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.732300] time: 0:19:54.279983\n",
      "(10, 128, 128, 3)\n",
      "0.9103413\n",
      "[Epoch 2/10] [Batch 213/1081] [D loss: 0.437899] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.556736] time: 0:19:54.733353\n",
      "(10, 128, 128, 3)\n",
      "0.90643173\n",
      "[Epoch 2/10] [Batch 214/1081] [D loss: 0.434242] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.542385] time: 0:19:55.153062\n",
      "(10, 128, 128, 3)\n",
      "0.8857412\n",
      "[Epoch 2/10] [Batch 215/1081] [D loss: 0.400643] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.796062] time: 0:19:55.591905\n",
      "(10, 128, 128, 3)\n",
      "0.95238686\n",
      "[Epoch 2/10] [Batch 216/1081] [D loss: 0.397441] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.408100] time: 0:19:56.016801\n",
      "(10, 128, 128, 3)\n",
      "0.912231\n",
      "[Epoch 2/10] [Batch 217/1081] [D loss: 0.397168] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.464951] time: 0:19:56.430112\n",
      "(10, 128, 128, 3)\n",
      "0.87503767\n",
      "[Epoch 2/10] [Batch 218/1081] [D loss: 0.396426] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.554058] time: 0:19:56.861148\n",
      "(10, 128, 128, 3)\n",
      "0.9043192\n",
      "[Epoch 2/10] [Batch 219/1081] [D loss: 0.401141] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.446640] time: 0:19:57.282706\n",
      "(10, 128, 128, 3)\n",
      "0.88569397\n",
      "[Epoch 2/10] [Batch 220/1081] [D loss: 0.396454] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.645960] time: 0:19:57.711186\n",
      "(10, 128, 128, 3)\n",
      "0.8371356\n",
      "[Epoch 2/10] [Batch 221/1081] [D loss: 0.399557] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.282898] time: 0:19:58.160813\n",
      "(10, 128, 128, 3)\n",
      "0.935957\n",
      "[Epoch 2/10] [Batch 222/1081] [D loss: 0.393772] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.592552] time: 0:19:58.563747\n",
      "(10, 128, 128, 3)\n",
      "0.8225255\n",
      "[Epoch 2/10] [Batch 223/1081] [D loss: 0.392627] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.213625] time: 0:19:58.962023\n",
      "(10, 128, 128, 3)\n",
      "0.9247296\n",
      "[Epoch 2/10] [Batch 224/1081] [D loss: 0.393587] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.242060] time: 0:19:59.371393\n",
      "(10, 128, 128, 3)\n",
      "0.932538\n",
      "[Epoch 2/10] [Batch 225/1081] [D loss: 0.408892] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.673167] time: 0:19:59.796829\n",
      "(10, 128, 128, 3)\n",
      "0.92908436\n",
      "[Epoch 2/10] [Batch 226/1081] [D loss: 0.391363] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.469021] time: 0:20:00.229757\n",
      "(10, 128, 128, 3)\n",
      "0.9302462\n",
      "[Epoch 2/10] [Batch 227/1081] [D loss: 0.390621] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.415522] time: 0:20:00.629254\n",
      "(10, 128, 128, 3)\n",
      "0.926318\n",
      "[Epoch 2/10] [Batch 228/1081] [D loss: 0.390338] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.028162] time: 0:20:01.036650\n",
      "(10, 128, 128, 3)\n",
      "0.9245841\n",
      "[Epoch 2/10] [Batch 229/1081] [D loss: 0.389519] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.912922] time: 0:20:01.436505\n",
      "(10, 128, 128, 3)\n",
      "0.88623816\n",
      "[Epoch 2/10] [Batch 230/1081] [D loss: 0.393995] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.964882] time: 0:20:01.891058\n",
      "(10, 128, 128, 3)\n",
      "0.9038555\n",
      "[Epoch 2/10] [Batch 231/1081] [D loss: 0.387948] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.828684] time: 0:20:02.283870\n",
      "(10, 128, 128, 3)\n",
      "0.8880953\n",
      "[Epoch 2/10] [Batch 232/1081] [D loss: 0.451626] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.730305] time: 0:20:02.687331\n",
      "(10, 128, 128, 3)\n",
      "0.905953\n",
      "[Epoch 2/10] [Batch 233/1081] [D loss: 0.390915] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.616800] time: 0:20:03.075348\n",
      "(10, 128, 128, 3)\n",
      "0.908288\n",
      "[Epoch 2/10] [Batch 234/1081] [D loss: 0.390616] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.778011] time: 0:20:03.502607\n",
      "(10, 128, 128, 3)\n",
      "0.9165325\n",
      "[Epoch 2/10] [Batch 235/1081] [D loss: 0.388951] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.358414] time: 0:20:03.891341\n",
      "(10, 128, 128, 3)\n",
      "0.8783893\n",
      "[Epoch 2/10] [Batch 236/1081] [D loss: 0.398688] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.738686] time: 0:20:04.295320\n",
      "(10, 128, 128, 3)\n",
      "0.87855583\n",
      "[Epoch 2/10] [Batch 237/1081] [D loss: 0.401261] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.423134] time: 0:20:04.692730\n",
      "(10, 128, 128, 3)\n",
      "0.89974755\n",
      "[Epoch 2/10] [Batch 238/1081] [D loss: 0.389184] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.417175] time: 0:20:05.087084\n",
      "(10, 128, 128, 3)\n",
      "0.8952859\n",
      "[Epoch 2/10] [Batch 239/1081] [D loss: 0.388097] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.457691] time: 0:20:05.505854\n",
      "(10, 128, 128, 3)\n",
      "0.89254093\n",
      "[Epoch 2/10] [Batch 240/1081] [D loss: 0.384971] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.715747] time: 0:20:05.918536\n",
      "(10, 128, 128, 3)\n",
      "0.9299304\n",
      "[Epoch 2/10] [Batch 241/1081] [D loss: 0.385011] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.135803] time: 0:20:06.346723\n",
      "(10, 128, 128, 3)\n",
      "0.9192517\n",
      "[Epoch 2/10] [Batch 242/1081] [D loss: 0.383382] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.600779] time: 0:20:06.750544\n",
      "(10, 128, 128, 3)\n",
      "0.9269907\n",
      "[Epoch 2/10] [Batch 243/1081] [D loss: 0.385224] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.707993] time: 0:20:07.166402\n",
      "(10, 128, 128, 3)\n",
      "0.8887407\n",
      "[Epoch 2/10] [Batch 244/1081] [D loss: 0.382389] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.591631] time: 0:20:07.553546\n",
      "(10, 128, 128, 3)\n",
      "0.8939387\n",
      "[Epoch 2/10] [Batch 245/1081] [D loss: 0.383308] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.180609] time: 0:20:08.014540\n",
      "(10, 128, 128, 3)\n",
      "0.92866737\n",
      "[Epoch 2/10] [Batch 246/1081] [D loss: 0.382247] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.011148] time: 0:20:08.419487\n",
      "(10, 128, 128, 3)\n",
      "0.9453824\n",
      "[Epoch 2/10] [Batch 247/1081] [D loss: 0.383334] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.094721] time: 0:20:08.830535\n",
      "(10, 128, 128, 3)\n",
      "0.92799616\n",
      "[Epoch 2/10] [Batch 248/1081] [D loss: 0.382803] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.825218] time: 0:20:09.218617\n",
      "(10, 128, 128, 3)\n",
      "0.8910756\n",
      "[Epoch 2/10] [Batch 249/1081] [D loss: 0.380711] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.527966] time: 0:20:09.610462\n",
      "(10, 128, 128, 3)\n",
      "0.9313392\n",
      "[Epoch 2/10] [Batch 250/1081] [D loss: 0.379609] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.335365] time: 0:20:10.032488\n",
      "(10, 128, 128, 3)\n",
      "0.92640996\n",
      "[Epoch 2/10] [Batch 251/1081] [D loss: 0.380510] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.800954] time: 0:20:10.439976\n",
      "(10, 128, 128, 3)\n",
      "0.8607869\n",
      "[Epoch 2/10] [Batch 252/1081] [D loss: 0.385163] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.770748] time: 0:20:10.824923\n",
      "(10, 128, 128, 3)\n",
      "0.9061181\n",
      "[Epoch 2/10] [Batch 253/1081] [D loss: 0.380857] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.476553] time: 0:20:11.243819\n",
      "(10, 128, 128, 3)\n",
      "0.91753125\n",
      "[Epoch 2/10] [Batch 254/1081] [D loss: 0.378202] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.484671] time: 0:20:11.626025\n",
      "(10, 128, 128, 3)\n",
      "0.91918254\n",
      "[Epoch 2/10] [Batch 255/1081] [D loss: 0.383452] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.832232] time: 0:20:12.002188\n",
      "(10, 128, 128, 3)\n",
      "0.91587424\n",
      "[Epoch 2/10] [Batch 256/1081] [D loss: 0.376804] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.422525] time: 0:20:12.388325\n",
      "(10, 128, 128, 3)\n",
      "0.9290092\n",
      "[Epoch 2/10] [Batch 257/1081] [D loss: 0.377112] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.306030] time: 0:20:12.848139\n",
      "(10, 128, 128, 3)\n",
      "0.96267205\n",
      "[Epoch 2/10] [Batch 258/1081] [D loss: 0.375954] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.066679] time: 0:20:13.274217\n",
      "(10, 128, 128, 3)\n",
      "0.9246648\n",
      "[Epoch 2/10] [Batch 259/1081] [D loss: 0.377959] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.981189] time: 0:20:13.679715\n",
      "(10, 128, 128, 3)\n",
      "0.89584947\n",
      "[Epoch 2/10] [Batch 260/1081] [D loss: 0.375927] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.204901] time: 0:20:14.120069\n",
      "(10, 128, 128, 3)\n",
      "0.9185338\n",
      "[Epoch 2/10] [Batch 261/1081] [D loss: 0.375610] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.488640] time: 0:20:14.541180\n",
      "(10, 128, 128, 3)\n",
      "0.92877007\n",
      "[Epoch 2/10] [Batch 262/1081] [D loss: 0.374569] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.987600] time: 0:20:14.940873\n",
      "(10, 128, 128, 3)\n",
      "0.9302307\n",
      "[Epoch 2/10] [Batch 263/1081] [D loss: 0.375509] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.029449] time: 0:20:15.361662\n",
      "(10, 128, 128, 3)\n",
      "0.9180558\n",
      "[Epoch 2/10] [Batch 264/1081] [D loss: 0.375872] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.433029] time: 0:20:15.783419\n",
      "(10, 128, 128, 3)\n",
      "0.922899\n",
      "[Epoch 2/10] [Batch 265/1081] [D loss: 0.373569] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.787447] time: 0:20:16.173471\n",
      "(10, 128, 128, 3)\n",
      "0.9236792\n",
      "[Epoch 2/10] [Batch 266/1081] [D loss: 0.379531] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.659529] time: 0:20:16.586375\n",
      "(10, 128, 128, 3)\n",
      "0.9210174\n",
      "[Epoch 2/10] [Batch 267/1081] [D loss: 0.376117] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.588470] time: 0:20:17.012228\n",
      "(10, 128, 128, 3)\n",
      "0.9161046\n",
      "[Epoch 2/10] [Batch 268/1081] [D loss: 0.373921] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.566516] time: 0:20:17.421333\n",
      "(10, 128, 128, 3)\n",
      "0.94297343\n",
      "[Epoch 2/10] [Batch 269/1081] [D loss: 0.377467] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.418159] time: 0:20:17.812261\n",
      "(10, 128, 128, 3)\n",
      "0.9087023\n",
      "[Epoch 2/10] [Batch 270/1081] [D loss: 0.370972] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.934149] time: 0:20:18.233190\n",
      "(10, 128, 128, 3)\n",
      "0.9544291\n",
      "[Epoch 2/10] [Batch 271/1081] [D loss: 0.375963] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.643814] time: 0:20:18.628592\n",
      "(10, 128, 128, 3)\n",
      "0.92563504\n",
      "[Epoch 2/10] [Batch 272/1081] [D loss: 0.370604] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.024738] time: 0:20:19.064859\n",
      "(10, 128, 128, 3)\n",
      "0.91456604\n",
      "[Epoch 2/10] [Batch 273/1081] [D loss: 0.371263] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.767942] time: 0:20:19.485367\n",
      "(10, 128, 128, 3)\n",
      "0.9399844\n",
      "[Epoch 2/10] [Batch 274/1081] [D loss: 0.371507] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 18.201130] time: 0:20:19.895882\n",
      "(10, 128, 128, 3)\n",
      "0.90938354\n",
      "[Epoch 2/10] [Batch 275/1081] [D loss: 0.375716] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.239456] time: 0:20:20.309988\n",
      "(10, 128, 128, 3)\n",
      "0.9038367\n",
      "[Epoch 2/10] [Batch 276/1081] [D loss: 0.368963] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.190550] time: 0:20:20.703733\n",
      "(10, 128, 128, 3)\n",
      "0.9382596\n",
      "[Epoch 2/10] [Batch 277/1081] [D loss: 0.368561] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.479162] time: 0:20:21.123141\n",
      "(10, 128, 128, 3)\n",
      "0.94832426\n",
      "[Epoch 2/10] [Batch 278/1081] [D loss: 0.367744] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.369276] time: 0:20:21.523817\n",
      "(10, 128, 128, 3)\n",
      "0.9321732\n",
      "[Epoch 2/10] [Batch 279/1081] [D loss: 0.367978] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.623846] time: 0:20:21.937592\n",
      "(10, 128, 128, 3)\n",
      "0.9281079\n",
      "[Epoch 2/10] [Batch 280/1081] [D loss: 0.373095] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.697649] time: 0:20:22.352028\n",
      "(10, 128, 128, 3)\n",
      "0.9202123\n",
      "[Epoch 2/10] [Batch 281/1081] [D loss: 0.366908] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.059778] time: 0:20:22.796699\n",
      "(10, 128, 128, 3)\n",
      "0.9022403\n",
      "[Epoch 2/10] [Batch 282/1081] [D loss: 0.366083] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.379253] time: 0:20:23.239958\n",
      "(10, 128, 128, 3)\n",
      "0.92464596\n",
      "[Epoch 2/10] [Batch 283/1081] [D loss: 0.365715] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.351147] time: 0:20:23.654810\n",
      "(10, 128, 128, 3)\n",
      "0.8906682\n",
      "[Epoch 2/10] [Batch 284/1081] [D loss: 0.365909] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.406256] time: 0:20:24.072841\n",
      "(10, 128, 128, 3)\n",
      "0.9307971\n",
      "[Epoch 2/10] [Batch 285/1081] [D loss: 0.370518] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.766644] time: 0:20:24.473293\n",
      "(10, 128, 128, 3)\n",
      "0.95758706\n",
      "[Epoch 2/10] [Batch 286/1081] [D loss: 0.364391] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.994959] time: 0:20:24.892582\n",
      "(10, 128, 128, 3)\n",
      "0.92426443\n",
      "[Epoch 2/10] [Batch 287/1081] [D loss: 0.364778] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.110861] time: 0:20:25.284187\n",
      "(10, 128, 128, 3)\n",
      "0.9076374\n",
      "[Epoch 2/10] [Batch 288/1081] [D loss: 0.363949] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.864180] time: 0:20:25.683723\n",
      "(10, 128, 128, 3)\n",
      "0.88337517\n",
      "[Epoch 2/10] [Batch 289/1081] [D loss: 0.363479] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.588152] time: 0:20:26.113530\n",
      "(10, 128, 128, 3)\n",
      "0.95738095\n",
      "[Epoch 2/10] [Batch 290/1081] [D loss: 0.363695] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.701185] time: 0:20:26.566828\n",
      "(10, 128, 128, 3)\n",
      "0.9415285\n",
      "[Epoch 2/10] [Batch 291/1081] [D loss: 0.363019] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.431280] time: 0:20:27.003395\n",
      "(10, 128, 128, 3)\n",
      "0.90596277\n",
      "[Epoch 2/10] [Batch 292/1081] [D loss: 0.362190] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.154099] time: 0:20:27.388911\n",
      "(10, 128, 128, 3)\n",
      "0.9655819\n",
      "[Epoch 2/10] [Batch 293/1081] [D loss: 0.361566] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.791492] time: 0:20:27.786260\n",
      "(10, 128, 128, 3)\n",
      "0.9172034\n",
      "[Epoch 2/10] [Batch 294/1081] [D loss: 0.361313] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.736174] time: 0:20:28.212000\n",
      "(10, 128, 128, 3)\n",
      "0.87839293\n",
      "[Epoch 2/10] [Batch 295/1081] [D loss: 0.360718] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.144056] time: 0:20:28.616242\n",
      "(10, 128, 128, 3)\n",
      "0.93994236\n",
      "[Epoch 2/10] [Batch 296/1081] [D loss: 0.360254] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.601382] time: 0:20:29.022796\n",
      "(10, 128, 128, 3)\n",
      "0.9151554\n",
      "[Epoch 2/10] [Batch 297/1081] [D loss: 0.359983] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.910225] time: 0:20:29.407429\n",
      "(10, 128, 128, 3)\n",
      "0.9423012\n",
      "[Epoch 2/10] [Batch 298/1081] [D loss: 0.360075] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.326265] time: 0:20:29.851505\n",
      "(10, 128, 128, 3)\n",
      "0.9350392\n",
      "[Epoch 2/10] [Batch 299/1081] [D loss: 0.359325] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.538890] time: 0:20:30.245405\n",
      "(10, 128, 128, 3)\n",
      "0.91193825\n",
      "[Epoch 2/10] [Batch 300/1081] [D loss: 0.358543] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.600421] time: 0:20:30.629989\n",
      "(10, 128, 128, 3)\n",
      "0.8807488\n",
      "[Epoch 2/10] [Batch 301/1081] [D loss: 0.358148] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.735272] time: 0:20:31.044280\n",
      "(10, 128, 128, 3)\n",
      "0.89190245\n",
      "[Epoch 2/10] [Batch 302/1081] [D loss: 0.357813] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.149487] time: 0:20:31.454879\n",
      "(10, 128, 128, 3)\n",
      "0.88036853\n",
      "[Epoch 2/10] [Batch 303/1081] [D loss: 0.357795] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.442123] time: 0:20:31.871383\n",
      "(10, 128, 128, 3)\n",
      "0.8995459\n",
      "[Epoch 2/10] [Batch 304/1081] [D loss: 0.357987] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.489414] time: 0:20:32.260749\n",
      "(10, 128, 128, 3)\n",
      "0.9042229\n",
      "[Epoch 2/10] [Batch 305/1081] [D loss: 0.356675] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.527044] time: 0:20:32.672887\n",
      "(10, 128, 128, 3)\n",
      "0.9100709\n",
      "[Epoch 2/10] [Batch 306/1081] [D loss: 0.356446] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.095924] time: 0:20:33.058050\n",
      "(10, 128, 128, 3)\n",
      "0.9449194\n",
      "[Epoch 2/10] [Batch 307/1081] [D loss: 0.355686] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.907608] time: 0:20:33.446398\n",
      "(10, 128, 128, 3)\n",
      "0.88338166\n",
      "[Epoch 2/10] [Batch 308/1081] [D loss: 0.355338] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.227709] time: 0:20:33.853985\n",
      "(10, 128, 128, 3)\n",
      "0.88956547\n",
      "[Epoch 2/10] [Batch 309/1081] [D loss: 0.357026] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.618086] time: 0:20:34.248211\n",
      "(10, 128, 128, 3)\n",
      "0.91554755\n",
      "[Epoch 2/10] [Batch 310/1081] [D loss: 0.354656] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.352739] time: 0:20:34.655086\n",
      "(10, 128, 128, 3)\n",
      "0.90264434\n",
      "[Epoch 2/10] [Batch 311/1081] [D loss: 0.354271] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.724958] time: 0:20:35.064358\n",
      "(10, 128, 128, 3)\n",
      "0.92256504\n",
      "[Epoch 2/10] [Batch 312/1081] [D loss: 0.357794] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.212570] time: 0:20:35.465331\n",
      "(10, 128, 128, 3)\n",
      "0.91590613\n",
      "[Epoch 2/10] [Batch 313/1081] [D loss: 0.353713] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.851628] time: 0:20:35.873139\n",
      "(10, 128, 128, 3)\n",
      "0.92985326\n",
      "[Epoch 2/10] [Batch 314/1081] [D loss: 0.353206] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.588120] time: 0:20:36.287690\n",
      "(10, 128, 128, 3)\n",
      "0.9159384\n",
      "[Epoch 2/10] [Batch 315/1081] [D loss: 0.352553] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.518336] time: 0:20:36.676154\n",
      "(10, 128, 128, 3)\n",
      "0.9607219\n",
      "[Epoch 2/10] [Batch 316/1081] [D loss: 0.352283] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.885080] time: 0:20:37.124261\n",
      "(10, 128, 128, 3)\n",
      "0.9128514\n",
      "[Epoch 2/10] [Batch 317/1081] [D loss: 0.352333] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.954114] time: 0:20:37.545344\n",
      "(10, 128, 128, 3)\n",
      "0.89502376\n",
      "[Epoch 2/10] [Batch 318/1081] [D loss: 0.351513] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.693697] time: 0:20:37.980395\n",
      "(10, 128, 128, 3)\n",
      "0.88581705\n",
      "[Epoch 2/10] [Batch 319/1081] [D loss: 0.351174] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.651993] time: 0:20:38.404407\n",
      "(10, 128, 128, 3)\n",
      "0.93528265\n",
      "[Epoch 2/10] [Batch 320/1081] [D loss: 0.350734] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.773348] time: 0:20:38.816965\n",
      "(10, 128, 128, 3)\n",
      "0.9570829\n",
      "[Epoch 2/10] [Batch 321/1081] [D loss: 0.350172] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.852968] time: 0:20:39.237773\n",
      "(10, 128, 128, 3)\n",
      "0.94030523\n",
      "[Epoch 2/10] [Batch 322/1081] [D loss: 0.350033] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.548889] time: 0:20:39.637188\n",
      "(10, 128, 128, 3)\n",
      "0.90468144\n",
      "[Epoch 2/10] [Batch 323/1081] [D loss: 0.350547] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.787908] time: 0:20:40.034704\n",
      "(10, 128, 128, 3)\n",
      "0.9488204\n",
      "[Epoch 2/10] [Batch 324/1081] [D loss: 0.349143] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.832268] time: 0:20:40.414052\n",
      "(10, 128, 128, 3)\n",
      "0.8951126\n",
      "[Epoch 2/10] [Batch 325/1081] [D loss: 0.349682] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.896837] time: 0:20:40.821582\n",
      "(10, 128, 128, 3)\n",
      "0.9406481\n",
      "[Epoch 2/10] [Batch 326/1081] [D loss: 0.348805] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.846601] time: 0:20:41.239967\n",
      "(10, 128, 128, 3)\n",
      "0.9338743\n",
      "[Epoch 2/10] [Batch 327/1081] [D loss: 0.348473] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.459195] time: 0:20:41.647666\n",
      "(10, 128, 128, 3)\n",
      "0.8870554\n",
      "[Epoch 2/10] [Batch 328/1081] [D loss: 0.349103] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.571611] time: 0:20:42.075879\n",
      "(10, 128, 128, 3)\n",
      "0.9404497\n",
      "[Epoch 2/10] [Batch 329/1081] [D loss: 0.346947] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.462296] time: 0:20:42.471673\n",
      "(10, 128, 128, 3)\n",
      "0.9056863\n",
      "[Epoch 2/10] [Batch 330/1081] [D loss: 0.347487] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.070920] time: 0:20:42.890451\n",
      "(10, 128, 128, 3)\n",
      "0.89170283\n",
      "[Epoch 2/10] [Batch 331/1081] [D loss: 0.346667] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.828493] time: 0:20:43.281064\n",
      "(10, 128, 128, 3)\n",
      "0.9053013\n",
      "[Epoch 2/10] [Batch 332/1081] [D loss: 0.347261] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.657782] time: 0:20:43.720956\n",
      "(10, 128, 128, 3)\n",
      "0.9107883\n",
      "[Epoch 2/10] [Batch 333/1081] [D loss: 0.345551] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.225933] time: 0:20:44.149520\n",
      "(10, 128, 128, 3)\n",
      "0.91899294\n",
      "[Epoch 2/10] [Batch 334/1081] [D loss: 0.345277] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.298002] time: 0:20:44.532463\n",
      "(10, 128, 128, 3)\n",
      "0.8867123\n",
      "[Epoch 2/10] [Batch 335/1081] [D loss: 0.353149] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.791966] time: 0:20:44.936775\n",
      "(10, 128, 128, 3)\n",
      "0.91194296\n",
      "[Epoch 2/10] [Batch 336/1081] [D loss: 0.346238] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.433743] time: 0:20:45.326556\n",
      "(10, 128, 128, 3)\n",
      "0.9112049\n",
      "[Epoch 2/10] [Batch 337/1081] [D loss: 0.345129] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.063463] time: 0:20:45.756721\n",
      "(10, 128, 128, 3)\n",
      "0.9537166\n",
      "[Epoch 2/10] [Batch 338/1081] [D loss: 0.346451] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.491247] time: 0:20:46.207296\n",
      "(10, 128, 128, 3)\n",
      "0.91603106\n",
      "[Epoch 2/10] [Batch 339/1081] [D loss: 0.346663] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.294482] time: 0:20:46.596625\n",
      "(10, 128, 128, 3)\n",
      "0.9289713\n",
      "[Epoch 2/10] [Batch 340/1081] [D loss: 0.344687] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.267839] time: 0:20:47.023935\n",
      "(10, 128, 128, 3)\n",
      "0.87192535\n",
      "[Epoch 2/10] [Batch 341/1081] [D loss: 0.343525] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.778929] time: 0:20:47.452305\n",
      "(10, 128, 128, 3)\n",
      "0.92000157\n",
      "[Epoch 2/10] [Batch 342/1081] [D loss: 0.342031] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.839256] time: 0:20:47.872970\n",
      "(10, 128, 128, 3)\n",
      "0.89389926\n",
      "[Epoch 2/10] [Batch 343/1081] [D loss: 0.342685] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.222370] time: 0:20:48.286188\n",
      "(10, 128, 128, 3)\n",
      "0.8931199\n",
      "[Epoch 2/10] [Batch 344/1081] [D loss: 0.341125] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.709421] time: 0:20:48.710607\n",
      "(10, 128, 128, 3)\n",
      "0.9520034\n",
      "[Epoch 2/10] [Batch 345/1081] [D loss: 0.340711] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.927768] time: 0:20:49.182311\n",
      "(10, 128, 128, 3)\n",
      "0.89224195\n",
      "[Epoch 2/10] [Batch 346/1081] [D loss: 0.341830] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.249165] time: 0:20:49.626452\n",
      "(10, 128, 128, 3)\n",
      "0.8821695\n",
      "[Epoch 2/10] [Batch 347/1081] [D loss: 0.340317] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.824387] time: 0:20:50.076095\n",
      "(10, 128, 128, 3)\n",
      "0.90854436\n",
      "[Epoch 2/10] [Batch 348/1081] [D loss: 0.340466] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.532085] time: 0:20:50.475204\n",
      "(10, 128, 128, 3)\n",
      "0.9222238\n",
      "[Epoch 2/10] [Batch 349/1081] [D loss: 0.339164] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.012995] time: 0:20:50.896558\n",
      "(10, 128, 128, 3)\n",
      "0.9452277\n",
      "[Epoch 2/10] [Batch 350/1081] [D loss: 0.339564] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.273853] time: 0:20:51.289792\n",
      "(10, 128, 128, 3)\n",
      "0.86238354\n",
      "[Epoch 2/10] [Batch 351/1081] [D loss: 0.338774] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.581923] time: 0:20:51.706158\n",
      "(10, 128, 128, 3)\n",
      "0.93174744\n",
      "[Epoch 2/10] [Batch 352/1081] [D loss: 0.340725] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.904985] time: 0:20:52.142440\n",
      "(10, 128, 128, 3)\n",
      "0.92049533\n",
      "[Epoch 2/10] [Batch 353/1081] [D loss: 0.338033] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.240421] time: 0:20:52.559281\n",
      "(10, 128, 128, 3)\n",
      "0.9509134\n",
      "[Epoch 2/10] [Batch 354/1081] [D loss: 0.338704] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.806925] time: 0:20:52.971147\n",
      "(10, 128, 128, 3)\n",
      "0.9768699\n",
      "[Epoch 2/10] [Batch 355/1081] [D loss: 0.340901] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.974916] time: 0:20:53.379070\n",
      "(10, 128, 128, 3)\n",
      "0.9288338\n",
      "[Epoch 2/10] [Batch 356/1081] [D loss: 0.338100] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.101826] time: 0:20:53.776167\n",
      "(10, 128, 128, 3)\n",
      "0.8898211\n",
      "[Epoch 2/10] [Batch 357/1081] [D loss: 0.336319] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.514328] time: 0:20:54.192724\n",
      "(10, 128, 128, 3)\n",
      "0.89298934\n",
      "[Epoch 2/10] [Batch 358/1081] [D loss: 0.336235] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.327866] time: 0:20:54.618533\n",
      "(10, 128, 128, 3)\n",
      "0.8902224\n",
      "[Epoch 2/10] [Batch 359/1081] [D loss: 0.335510] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.208673] time: 0:20:55.050981\n",
      "(10, 128, 128, 3)\n",
      "0.94302034\n",
      "[Epoch 2/10] [Batch 360/1081] [D loss: 0.335517] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.314226] time: 0:20:55.447148\n",
      "(10, 128, 128, 3)\n",
      "0.94014376\n",
      "[Epoch 2/10] [Batch 361/1081] [D loss: 0.335014] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.620424] time: 0:20:55.829986\n",
      "(10, 128, 128, 3)\n",
      "0.8894739\n",
      "[Epoch 2/10] [Batch 362/1081] [D loss: 0.334336] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.686497] time: 0:20:56.243060\n",
      "(10, 128, 128, 3)\n",
      "0.94742733\n",
      "[Epoch 2/10] [Batch 363/1081] [D loss: 0.333943] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.530400] time: 0:20:56.642758\n",
      "(10, 128, 128, 3)\n",
      "0.9419169\n",
      "[Epoch 2/10] [Batch 364/1081] [D loss: 0.335600] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.625822] time: 0:20:57.042794\n",
      "(10, 128, 128, 3)\n",
      "0.89625365\n",
      "[Epoch 2/10] [Batch 365/1081] [D loss: 0.333648] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.088684] time: 0:20:57.459841\n",
      "(10, 128, 128, 3)\n",
      "0.92703104\n",
      "[Epoch 2/10] [Batch 366/1081] [D loss: 0.333741] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.847067] time: 0:20:57.876529\n",
      "(10, 128, 128, 3)\n",
      "0.9220962\n",
      "[Epoch 2/10] [Batch 367/1081] [D loss: 0.332656] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.996203] time: 0:20:58.253088\n",
      "(10, 128, 128, 3)\n",
      "0.8821054\n",
      "[Epoch 2/10] [Batch 368/1081] [D loss: 0.332217] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.692268] time: 0:20:58.640705\n",
      "(10, 128, 128, 3)\n",
      "0.88683033\n",
      "[Epoch 2/10] [Batch 369/1081] [D loss: 0.331580] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.406237] time: 0:20:59.106459\n",
      "(10, 128, 128, 3)\n",
      "0.8548414\n",
      "[Epoch 2/10] [Batch 370/1081] [D loss: 0.331308] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.041586] time: 0:20:59.529533\n",
      "(10, 128, 128, 3)\n",
      "0.92267567\n",
      "[Epoch 2/10] [Batch 371/1081] [D loss: 0.331577] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.423586] time: 0:20:59.938519\n",
      "(10, 128, 128, 3)\n",
      "0.8794761\n",
      "[Epoch 2/10] [Batch 372/1081] [D loss: 0.330907] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.560445] time: 0:21:00.342745\n",
      "(10, 128, 128, 3)\n",
      "0.87778765\n",
      "[Epoch 2/10] [Batch 373/1081] [D loss: 0.330303] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.157608] time: 0:21:00.757549\n",
      "(10, 128, 128, 3)\n",
      "0.96537733\n",
      "[Epoch 2/10] [Batch 374/1081] [D loss: 0.329995] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.548635] time: 0:21:01.178401\n",
      "(10, 128, 128, 3)\n",
      "0.8529094\n",
      "[Epoch 2/10] [Batch 375/1081] [D loss: 0.329408] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.929068] time: 0:21:01.611760\n",
      "(10, 128, 128, 3)\n",
      "0.90907604\n",
      "[Epoch 2/10] [Batch 376/1081] [D loss: 0.329225] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.070105] time: 0:21:02.025111\n",
      "(10, 128, 128, 3)\n",
      "0.8911748\n",
      "[Epoch 2/10] [Batch 377/1081] [D loss: 0.333878] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.120142] time: 0:21:02.444802\n",
      "(10, 128, 128, 3)\n",
      "0.8974722\n",
      "[Epoch 2/10] [Batch 378/1081] [D loss: 0.329018] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.230815] time: 0:21:02.867576\n",
      "(10, 128, 128, 3)\n",
      "0.93909734\n",
      "[Epoch 2/10] [Batch 379/1081] [D loss: 0.329534] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.739146] time: 0:21:03.336850\n",
      "(10, 128, 128, 3)\n",
      "0.90646744\n",
      "[Epoch 2/10] [Batch 380/1081] [D loss: 0.329019] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.222151] time: 0:21:03.775461\n",
      "(10, 128, 128, 3)\n",
      "0.9143242\n",
      "[Epoch 2/10] [Batch 381/1081] [D loss: 0.327412] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.157896] time: 0:21:04.194233\n",
      "(10, 128, 128, 3)\n",
      "0.93461055\n",
      "[Epoch 2/10] [Batch 382/1081] [D loss: 0.326830] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.633654] time: 0:21:04.623140\n",
      "(10, 128, 128, 3)\n",
      "0.9336669\n",
      "[Epoch 2/10] [Batch 383/1081] [D loss: 0.326270] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.860983] time: 0:21:05.043128\n",
      "(10, 128, 128, 3)\n",
      "0.8935826\n",
      "[Epoch 2/10] [Batch 384/1081] [D loss: 0.326095] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.647151] time: 0:21:05.488050\n",
      "(10, 128, 128, 3)\n",
      "0.86613345\n",
      "[Epoch 2/10] [Batch 385/1081] [D loss: 0.325550] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.191042] time: 0:21:05.927569\n",
      "(10, 128, 128, 3)\n",
      "0.9303739\n",
      "[Epoch 2/10] [Batch 386/1081] [D loss: 0.325785] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.509315] time: 0:21:06.350902\n",
      "(10, 128, 128, 3)\n",
      "0.91764075\n",
      "[Epoch 2/10] [Batch 387/1081] [D loss: 0.326154] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.484665] time: 0:21:06.757296\n",
      "(10, 128, 128, 3)\n",
      "0.8416191\n",
      "[Epoch 2/10] [Batch 388/1081] [D loss: 0.324815] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.884956] time: 0:21:07.195369\n",
      "(10, 128, 128, 3)\n",
      "0.8499163\n",
      "[Epoch 2/10] [Batch 389/1081] [D loss: 0.324404] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.302282] time: 0:21:07.599894\n",
      "(10, 128, 128, 3)\n",
      "0.9802608\n",
      "[Epoch 2/10] [Batch 390/1081] [D loss: 0.324369] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.231684] time: 0:21:08.032343\n",
      "(10, 128, 128, 3)\n",
      "0.894394\n",
      "[Epoch 2/10] [Batch 391/1081] [D loss: 0.323482] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.612775] time: 0:21:08.484434\n",
      "(10, 128, 128, 3)\n",
      "0.93622255\n",
      "[Epoch 2/10] [Batch 392/1081] [D loss: 0.323270] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.128023] time: 0:21:08.910308\n",
      "(10, 128, 128, 3)\n",
      "0.92751974\n",
      "[Epoch 2/10] [Batch 393/1081] [D loss: 0.327244] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.858724] time: 0:21:09.315201\n",
      "(10, 128, 128, 3)\n",
      "0.91066676\n",
      "[Epoch 2/10] [Batch 394/1081] [D loss: 0.322802] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.029915] time: 0:21:09.745648\n",
      "(10, 128, 128, 3)\n",
      "0.90467876\n",
      "[Epoch 2/10] [Batch 395/1081] [D loss: 0.323019] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.976697] time: 0:21:10.138654\n",
      "(10, 128, 128, 3)\n",
      "0.880011\n",
      "[Epoch 2/10] [Batch 396/1081] [D loss: 0.321753] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.091162] time: 0:21:10.582419\n",
      "(10, 128, 128, 3)\n",
      "0.87672895\n",
      "[Epoch 2/10] [Batch 397/1081] [D loss: 0.321364] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.524823] time: 0:21:11.001458\n",
      "(10, 128, 128, 3)\n",
      "0.9000657\n",
      "[Epoch 2/10] [Batch 398/1081] [D loss: 0.321475] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.009850] time: 0:21:11.437130\n",
      "(10, 128, 128, 3)\n",
      "0.91665244\n",
      "[Epoch 2/10] [Batch 399/1081] [D loss: 0.321126] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.679186] time: 0:21:11.835212\n",
      "(10, 128, 128, 3)\n",
      "0.9206645\n",
      "[Epoch 2/10] [Batch 400/1081] [D loss: 0.320748] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.832983] time: 0:21:12.219789\n",
      "(10, 128, 128, 3)\n",
      "0.9173531\n",
      "[Epoch 2/10] [Batch 401/1081] [D loss: 0.319903] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.348569] time: 0:21:12.656378\n",
      "(10, 128, 128, 3)\n",
      "0.9209879\n",
      "[Epoch 2/10] [Batch 402/1081] [D loss: 0.319989] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.306564] time: 0:21:13.039919\n",
      "(10, 128, 128, 3)\n",
      "0.9137776\n",
      "[Epoch 2/10] [Batch 403/1081] [D loss: 0.319079] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.441984] time: 0:21:13.482168\n",
      "(10, 128, 128, 3)\n",
      "0.91111106\n",
      "[Epoch 2/10] [Batch 404/1081] [D loss: 0.320139] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.361231] time: 0:21:13.880319\n",
      "(10, 128, 128, 3)\n",
      "0.9154411\n",
      "[Epoch 2/10] [Batch 405/1081] [D loss: 0.318238] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.225603] time: 0:21:14.266723\n",
      "(10, 128, 128, 3)\n",
      "0.87703305\n",
      "[Epoch 2/10] [Batch 406/1081] [D loss: 0.318708] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.045820] time: 0:21:14.641855\n",
      "(10, 128, 128, 3)\n",
      "0.8751004\n",
      "[Epoch 2/10] [Batch 407/1081] [D loss: 0.318132] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.087896] time: 0:21:15.028313\n",
      "(10, 128, 128, 3)\n",
      "0.9405667\n",
      "[Epoch 2/10] [Batch 408/1081] [D loss: 0.318971] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.868967] time: 0:21:15.455898\n",
      "(10, 128, 128, 3)\n",
      "0.9409158\n",
      "[Epoch 2/10] [Batch 409/1081] [D loss: 0.317155] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.984357] time: 0:21:15.878695\n",
      "(10, 128, 128, 3)\n",
      "0.8518396\n",
      "[Epoch 2/10] [Batch 410/1081] [D loss: 0.316586] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.172810] time: 0:21:16.251508\n",
      "(10, 128, 128, 3)\n",
      "0.948317\n",
      "[Epoch 2/10] [Batch 411/1081] [D loss: 0.317215] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.920523] time: 0:21:16.670731\n",
      "(10, 128, 128, 3)\n",
      "0.8731515\n",
      "[Epoch 2/10] [Batch 412/1081] [D loss: 0.316168] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.754641] time: 0:21:17.044966\n",
      "(10, 128, 128, 3)\n",
      "0.92618966\n",
      "[Epoch 2/10] [Batch 413/1081] [D loss: 0.315449] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.554736] time: 0:21:17.433604\n",
      "(10, 128, 128, 3)\n",
      "0.9146647\n",
      "[Epoch 2/10] [Batch 414/1081] [D loss: 0.315506] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.065573] time: 0:21:17.860074\n",
      "(10, 128, 128, 3)\n",
      "0.94161916\n",
      "[Epoch 2/10] [Batch 415/1081] [D loss: 0.314777] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.881198] time: 0:21:18.240319\n",
      "(10, 128, 128, 3)\n",
      "0.9153435\n",
      "[Epoch 2/10] [Batch 416/1081] [D loss: 0.314904] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.867144] time: 0:21:18.649666\n",
      "(10, 128, 128, 3)\n",
      "0.9274864\n",
      "[Epoch 2/10] [Batch 417/1081] [D loss: 0.314108] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.918741] time: 0:21:19.052047\n",
      "(10, 128, 128, 3)\n",
      "0.92369\n",
      "[Epoch 2/10] [Batch 418/1081] [D loss: 0.313589] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.033243] time: 0:21:19.464345\n",
      "(10, 128, 128, 3)\n",
      "0.9328187\n",
      "[Epoch 2/10] [Batch 419/1081] [D loss: 0.313465] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.621600] time: 0:21:19.876469\n",
      "(10, 128, 128, 3)\n",
      "0.9430049\n",
      "[Epoch 2/10] [Batch 420/1081] [D loss: 0.313422] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.160347] time: 0:21:20.279492\n",
      "(10, 128, 128, 3)\n",
      "0.94366765\n",
      "[Epoch 2/10] [Batch 421/1081] [D loss: 0.312747] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.592160] time: 0:21:20.667653\n",
      "(10, 128, 128, 3)\n",
      "0.88304037\n",
      "[Epoch 2/10] [Batch 422/1081] [D loss: 0.312214] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.065104] time: 0:21:21.058430\n",
      "(10, 128, 128, 3)\n",
      "0.8788786\n",
      "[Epoch 2/10] [Batch 423/1081] [D loss: 0.311879] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.688040] time: 0:21:21.464270\n",
      "(10, 128, 128, 3)\n",
      "0.89712787\n",
      "[Epoch 2/10] [Batch 424/1081] [D loss: 0.311878] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.054331] time: 0:21:21.875673\n",
      "(10, 128, 128, 3)\n",
      "0.9105025\n",
      "[Epoch 2/10] [Batch 425/1081] [D loss: 0.311800] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.216887] time: 0:21:22.295125\n",
      "(10, 128, 128, 3)\n",
      "0.90086436\n",
      "[Epoch 2/10] [Batch 426/1081] [D loss: 0.311206] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.631230] time: 0:21:22.700645\n",
      "(10, 128, 128, 3)\n",
      "0.90276855\n",
      "[Epoch 2/10] [Batch 427/1081] [D loss: 0.310470] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.244608] time: 0:21:23.078927\n",
      "(10, 128, 128, 3)\n",
      "0.9566495\n",
      "[Epoch 2/10] [Batch 428/1081] [D loss: 0.310247] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.065115] time: 0:21:23.467685\n",
      "(10, 128, 128, 3)\n",
      "0.9156496\n",
      "[Epoch 2/10] [Batch 429/1081] [D loss: 0.309971] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.695416] time: 0:21:23.906161\n",
      "(10, 128, 128, 3)\n",
      "0.9216865\n",
      "[Epoch 2/10] [Batch 430/1081] [D loss: 0.309530] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.862085] time: 0:21:24.338092\n",
      "(10, 128, 128, 3)\n",
      "0.9710118\n",
      "[Epoch 2/10] [Batch 431/1081] [D loss: 0.309179] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.272123] time: 0:21:24.736367\n",
      "(10, 128, 128, 3)\n",
      "0.94721794\n",
      "[Epoch 2/10] [Batch 432/1081] [D loss: 0.308974] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.516626] time: 0:21:25.139106\n",
      "(10, 128, 128, 3)\n",
      "0.92926955\n",
      "[Epoch 2/10] [Batch 433/1081] [D loss: 0.308610] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.603952] time: 0:21:25.564025\n",
      "(10, 128, 128, 3)\n",
      "0.89430493\n",
      "[Epoch 2/10] [Batch 434/1081] [D loss: 0.308868] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.301565] time: 0:21:25.963668\n",
      "(10, 128, 128, 3)\n",
      "0.90139526\n",
      "[Epoch 2/10] [Batch 435/1081] [D loss: 0.307739] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.846799] time: 0:21:26.355742\n",
      "(10, 128, 128, 3)\n",
      "0.93422884\n",
      "[Epoch 2/10] [Batch 436/1081] [D loss: 0.308040] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.290684] time: 0:21:26.759030\n",
      "(10, 128, 128, 3)\n",
      "0.873467\n",
      "[Epoch 2/10] [Batch 437/1081] [D loss: 0.309122] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.180040] time: 0:21:27.155695\n",
      "(10, 128, 128, 3)\n",
      "0.8970298\n",
      "[Epoch 2/10] [Batch 438/1081] [D loss: 0.308323] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.272095] time: 0:21:27.586939\n",
      "(10, 128, 128, 3)\n",
      "0.8740521\n",
      "[Epoch 2/10] [Batch 439/1081] [D loss: 0.306832] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.748308] time: 0:21:27.978078\n",
      "(10, 128, 128, 3)\n",
      "0.8894517\n",
      "[Epoch 2/10] [Batch 440/1081] [D loss: 0.306669] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.095505] time: 0:21:28.378798\n",
      "(10, 128, 128, 3)\n",
      "0.8981245\n",
      "[Epoch 2/10] [Batch 441/1081] [D loss: 0.306056] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.935575] time: 0:21:28.778338\n",
      "(10, 128, 128, 3)\n",
      "0.8776729\n",
      "[Epoch 2/10] [Batch 442/1081] [D loss: 0.305257] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.736067] time: 0:21:29.186977\n",
      "(10, 128, 128, 3)\n",
      "0.88571626\n",
      "[Epoch 2/10] [Batch 443/1081] [D loss: 0.305064] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.371515] time: 0:21:29.567740\n",
      "(10, 128, 128, 3)\n",
      "0.8878243\n",
      "[Epoch 2/10] [Batch 444/1081] [D loss: 0.306165] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.319837] time: 0:21:29.958881\n",
      "(10, 128, 128, 3)\n",
      "0.9226982\n",
      "[Epoch 2/10] [Batch 445/1081] [D loss: 0.304302] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.834265] time: 0:21:30.384905\n",
      "(10, 128, 128, 3)\n",
      "0.9408694\n",
      "[Epoch 2/10] [Batch 446/1081] [D loss: 0.304972] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.437447] time: 0:21:30.786424\n",
      "(10, 128, 128, 3)\n",
      "0.938242\n",
      "[Epoch 2/10] [Batch 447/1081] [D loss: 0.305270] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.037297] time: 0:21:31.202821\n",
      "(10, 128, 128, 3)\n",
      "0.8871796\n",
      "[Epoch 2/10] [Batch 448/1081] [D loss: 0.303969] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.245026] time: 0:21:31.613351\n",
      "(10, 128, 128, 3)\n",
      "0.9586043\n",
      "[Epoch 2/10] [Batch 449/1081] [D loss: 0.303115] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.392560] time: 0:21:31.997086\n",
      "(10, 128, 128, 3)\n",
      "0.8364299\n",
      "[Epoch 2/10] [Batch 450/1081] [D loss: 0.302780] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.765991] time: 0:21:32.388110\n",
      "(10, 128, 128, 3)\n",
      "0.8770721\n",
      "[Epoch 2/10] [Batch 451/1081] [D loss: 0.302623] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.258997] time: 0:21:32.795647\n",
      "(10, 128, 128, 3)\n",
      "0.93587995\n",
      "[Epoch 2/10] [Batch 452/1081] [D loss: 0.302046] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.737833] time: 0:21:33.197387\n",
      "(10, 128, 128, 3)\n",
      "0.93556166\n",
      "[Epoch 2/10] [Batch 453/1081] [D loss: 0.301650] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.500961] time: 0:21:33.592191\n",
      "(10, 128, 128, 3)\n",
      "0.8841178\n",
      "[Epoch 2/10] [Batch 454/1081] [D loss: 0.301609] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.392244] time: 0:21:33.999315\n",
      "(10, 128, 128, 3)\n",
      "0.84582883\n",
      "[Epoch 2/10] [Batch 455/1081] [D loss: 0.301355] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.901014] time: 0:21:34.387542\n",
      "(10, 128, 128, 3)\n",
      "0.9182561\n",
      "[Epoch 2/10] [Batch 456/1081] [D loss: 0.300903] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.536903] time: 0:21:34.770200\n",
      "(10, 128, 128, 3)\n",
      "0.91364956\n",
      "[Epoch 2/10] [Batch 457/1081] [D loss: 0.300695] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.204892] time: 0:21:35.211219\n",
      "(10, 128, 128, 3)\n",
      "0.89734787\n",
      "[Epoch 2/10] [Batch 458/1081] [D loss: 0.300335] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.025891] time: 0:21:35.606773\n",
      "(10, 128, 128, 3)\n",
      "0.91888314\n",
      "[Epoch 2/10] [Batch 459/1081] [D loss: 0.300345] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.050922] time: 0:21:36.052858\n",
      "(10, 128, 128, 3)\n",
      "0.90446573\n",
      "[Epoch 2/10] [Batch 460/1081] [D loss: 0.299485] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.451445] time: 0:21:36.454853\n",
      "(10, 128, 128, 3)\n",
      "0.9366307\n",
      "[Epoch 2/10] [Batch 461/1081] [D loss: 0.298969] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.850103] time: 0:21:36.846592\n",
      "(10, 128, 128, 3)\n",
      "0.89433175\n",
      "[Epoch 2/10] [Batch 462/1081] [D loss: 0.298650] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.326620] time: 0:21:37.235824\n",
      "(10, 128, 128, 3)\n",
      "0.94945484\n",
      "[Epoch 2/10] [Batch 463/1081] [D loss: 0.299247] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.681262] time: 0:21:37.669845\n",
      "(10, 128, 128, 3)\n",
      "0.86866903\n",
      "[Epoch 2/10] [Batch 464/1081] [D loss: 0.297902] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.146748] time: 0:21:38.059986\n",
      "(10, 128, 128, 3)\n",
      "0.91351074\n",
      "[Epoch 2/10] [Batch 465/1081] [D loss: 0.298345] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.637085] time: 0:21:38.503115\n",
      "(10, 128, 128, 3)\n",
      "0.8717771\n",
      "[Epoch 2/10] [Batch 466/1081] [D loss: 0.297414] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.513819] time: 0:21:38.890530\n",
      "(10, 128, 128, 3)\n",
      "0.9151514\n",
      "[Epoch 2/10] [Batch 467/1081] [D loss: 0.297871] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.618538] time: 0:21:39.284191\n",
      "(10, 128, 128, 3)\n",
      "0.90030074\n",
      "[Epoch 2/10] [Batch 468/1081] [D loss: 0.296447] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.755877] time: 0:21:39.702128\n",
      "(10, 128, 128, 3)\n",
      "0.934493\n",
      "[Epoch 2/10] [Batch 469/1081] [D loss: 0.297190] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.927725] time: 0:21:40.090698\n",
      "(10, 128, 128, 3)\n",
      "0.8604352\n",
      "[Epoch 2/10] [Batch 470/1081] [D loss: 0.295764] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.199382] time: 0:21:40.501152\n",
      "(10, 128, 128, 3)\n",
      "0.86909825\n",
      "[Epoch 2/10] [Batch 471/1081] [D loss: 0.296380] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.077122] time: 0:21:40.901692\n",
      "(10, 128, 128, 3)\n",
      "0.89665866\n",
      "[Epoch 2/10] [Batch 472/1081] [D loss: 0.295241] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.438296] time: 0:21:41.327554\n",
      "(10, 128, 128, 3)\n",
      "0.9529534\n",
      "[Epoch 2/10] [Batch 473/1081] [D loss: 0.294681] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.341113] time: 0:21:41.745768\n",
      "(10, 128, 128, 3)\n",
      "0.95072013\n",
      "[Epoch 2/10] [Batch 474/1081] [D loss: 0.295721] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.452670] time: 0:21:42.135821\n",
      "(10, 128, 128, 3)\n",
      "0.8435207\n",
      "[Epoch 2/10] [Batch 475/1081] [D loss: 0.293991] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.148134] time: 0:21:42.563743\n",
      "(10, 128, 128, 3)\n",
      "0.95371383\n",
      "[Epoch 2/10] [Batch 476/1081] [D loss: 0.293965] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.381579] time: 0:21:42.999999\n",
      "(10, 128, 128, 3)\n",
      "0.93357426\n",
      "[Epoch 2/10] [Batch 477/1081] [D loss: 0.293537] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.697881] time: 0:21:43.424540\n",
      "(10, 128, 128, 3)\n",
      "0.8884816\n",
      "[Epoch 2/10] [Batch 478/1081] [D loss: 0.293149] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.085686] time: 0:21:43.851479\n",
      "(10, 128, 128, 3)\n",
      "0.93519324\n",
      "[Epoch 2/10] [Batch 479/1081] [D loss: 0.292899] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.352292] time: 0:21:44.282164\n",
      "(10, 128, 128, 3)\n",
      "0.93181294\n",
      "[Epoch 2/10] [Batch 480/1081] [D loss: 0.292387] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.698453] time: 0:21:44.724190\n",
      "(10, 128, 128, 3)\n",
      "0.83721334\n",
      "[Epoch 2/10] [Batch 481/1081] [D loss: 0.292208] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.059242] time: 0:21:45.141386\n",
      "(10, 128, 128, 3)\n",
      "0.90716344\n",
      "[Epoch 2/10] [Batch 482/1081] [D loss: 0.291909] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.854769] time: 0:21:45.551381\n",
      "(10, 128, 128, 3)\n",
      "0.8691077\n",
      "[Epoch 2/10] [Batch 483/1081] [D loss: 0.291553] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.130201] time: 0:21:45.979217\n",
      "(10, 128, 128, 3)\n",
      "0.91183424\n",
      "[Epoch 2/10] [Batch 484/1081] [D loss: 0.291065] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.438509] time: 0:21:46.355987\n",
      "(10, 128, 128, 3)\n",
      "0.9442217\n",
      "[Epoch 2/10] [Batch 485/1081] [D loss: 0.291410] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.319229] time: 0:21:46.772648\n",
      "(10, 128, 128, 3)\n",
      "0.94279194\n",
      "[Epoch 2/10] [Batch 486/1081] [D loss: 0.290396] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.657637] time: 0:21:47.155036\n",
      "(10, 128, 128, 3)\n",
      "0.872184\n",
      "[Epoch 2/10] [Batch 487/1081] [D loss: 0.290304] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.528242] time: 0:21:47.548822\n",
      "(10, 128, 128, 3)\n",
      "0.88901\n",
      "[Epoch 2/10] [Batch 488/1081] [D loss: 0.289750] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.159546] time: 0:21:47.931263\n",
      "(10, 128, 128, 3)\n",
      "0.88340473\n",
      "[Epoch 2/10] [Batch 489/1081] [D loss: 0.289821] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.831568] time: 0:21:48.316212\n",
      "(10, 128, 128, 3)\n",
      "0.9496124\n",
      "[Epoch 2/10] [Batch 490/1081] [D loss: 0.289450] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.445620] time: 0:21:48.702769\n",
      "(10, 128, 128, 3)\n",
      "0.9444308\n",
      "[Epoch 2/10] [Batch 491/1081] [D loss: 0.289112] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.559206] time: 0:21:49.088841\n",
      "(10, 128, 128, 3)\n",
      "0.9145562\n",
      "[Epoch 2/10] [Batch 492/1081] [D loss: 0.288562] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.443403] time: 0:21:49.502023\n",
      "(10, 128, 128, 3)\n",
      "0.9124674\n",
      "[Epoch 2/10] [Batch 493/1081] [D loss: 0.288357] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.257968] time: 0:21:49.924500\n",
      "(10, 128, 128, 3)\n",
      "0.9168481\n",
      "[Epoch 2/10] [Batch 494/1081] [D loss: 0.289016] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.084093] time: 0:21:50.312779\n",
      "(10, 128, 128, 3)\n",
      "0.9536484\n",
      "[Epoch 2/10] [Batch 495/1081] [D loss: 0.288453] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.874331] time: 0:21:50.705239\n",
      "(10, 128, 128, 3)\n",
      "0.9130556\n",
      "[Epoch 2/10] [Batch 496/1081] [D loss: 0.287461] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.501068] time: 0:21:51.083800\n",
      "(10, 128, 128, 3)\n",
      "0.91714907\n",
      "[Epoch 2/10] [Batch 497/1081] [D loss: 0.287122] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.339033] time: 0:21:51.487029\n",
      "(10, 128, 128, 3)\n",
      "0.9044613\n",
      "[Epoch 2/10] [Batch 498/1081] [D loss: 0.286951] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.153059] time: 0:21:51.866587\n",
      "(10, 128, 128, 3)\n",
      "0.9125325\n",
      "[Epoch 2/10] [Batch 499/1081] [D loss: 0.286911] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.030848] time: 0:21:52.270507\n",
      "(10, 128, 128, 3)\n",
      "0.93348813\n",
      "[Epoch 2/10] [Batch 500/1081] [D loss: 0.286026] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.941409] time: 0:21:52.684190\n",
      "(10, 128, 128, 3)\n",
      "0.94722134\n",
      "[Epoch 2/10] [Batch 501/1081] [D loss: 0.285922] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.924974] time: 0:21:53.087585\n",
      "(10, 128, 128, 3)\n",
      "0.9240818\n",
      "[Epoch 2/10] [Batch 502/1081] [D loss: 0.286860] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.734276] time: 0:21:53.511736\n",
      "(10, 128, 128, 3)\n",
      "0.9046108\n",
      "[Epoch 2/10] [Batch 503/1081] [D loss: 0.285478] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.945265] time: 0:21:53.912643\n",
      "(10, 128, 128, 3)\n",
      "0.9437552\n",
      "[Epoch 2/10] [Batch 504/1081] [D loss: 0.284753] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.241877] time: 0:21:54.330095\n",
      "(10, 128, 128, 3)\n",
      "0.9215191\n",
      "[Epoch 2/10] [Batch 505/1081] [D loss: 0.285980] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.383286] time: 0:21:54.783565\n",
      "(10, 128, 128, 3)\n",
      "0.85869366\n",
      "[Epoch 2/10] [Batch 506/1081] [D loss: 0.285595] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.622648] time: 0:21:55.172501\n",
      "(10, 128, 128, 3)\n",
      "0.89522433\n",
      "[Epoch 2/10] [Batch 507/1081] [D loss: 0.283950] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.839632] time: 0:21:55.564835\n",
      "(10, 128, 128, 3)\n",
      "0.87509483\n",
      "[Epoch 2/10] [Batch 508/1081] [D loss: 0.283633] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.003710] time: 0:21:55.963385\n",
      "(10, 128, 128, 3)\n",
      "0.8910276\n",
      "[Epoch 2/10] [Batch 509/1081] [D loss: 0.283571] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.078206] time: 0:21:56.340775\n",
      "(10, 128, 128, 3)\n",
      "0.90411466\n",
      "[Epoch 2/10] [Batch 510/1081] [D loss: 0.282877] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.441226] time: 0:21:56.768626\n",
      "(10, 128, 128, 3)\n",
      "0.87124854\n",
      "[Epoch 2/10] [Batch 511/1081] [D loss: 0.282344] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.099648] time: 0:21:57.168462\n",
      "(10, 128, 128, 3)\n",
      "0.8788161\n",
      "[Epoch 2/10] [Batch 512/1081] [D loss: 0.282800] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.094441] time: 0:21:57.588263\n",
      "(10, 128, 128, 3)\n",
      "0.91380674\n",
      "[Epoch 2/10] [Batch 513/1081] [D loss: 0.282062] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.271402] time: 0:21:57.995969\n",
      "(10, 128, 128, 3)\n",
      "0.89776784\n",
      "[Epoch 2/10] [Batch 514/1081] [D loss: 0.281372] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.010859] time: 0:21:58.399155\n",
      "(10, 128, 128, 3)\n",
      "0.8735997\n",
      "[Epoch 2/10] [Batch 515/1081] [D loss: 0.281132] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.260570] time: 0:21:58.778764\n",
      "(10, 128, 128, 3)\n",
      "0.89375144\n",
      "[Epoch 2/10] [Batch 516/1081] [D loss: 0.280798] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.108955] time: 0:21:59.175541\n",
      "(10, 128, 128, 3)\n",
      "0.89046115\n",
      "[Epoch 2/10] [Batch 517/1081] [D loss: 0.280483] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.523703] time: 0:21:59.563637\n",
      "(10, 128, 128, 3)\n",
      "0.91915923\n",
      "[Epoch 2/10] [Batch 518/1081] [D loss: 0.281297] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.556009] time: 0:21:59.981308\n",
      "(10, 128, 128, 3)\n",
      "0.88672304\n",
      "[Epoch 2/10] [Batch 519/1081] [D loss: 0.279941] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.802099] time: 0:22:00.387387\n",
      "(10, 128, 128, 3)\n",
      "0.9044451\n",
      "[Epoch 2/10] [Batch 520/1081] [D loss: 0.279650] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.030141] time: 0:22:00.817009\n",
      "(10, 128, 128, 3)\n",
      "0.8815803\n",
      "[Epoch 2/10] [Batch 521/1081] [D loss: 0.279814] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.916368] time: 0:22:01.233984\n",
      "(10, 128, 128, 3)\n",
      "0.9361703\n",
      "[Epoch 2/10] [Batch 522/1081] [D loss: 0.280278] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.866336] time: 0:22:01.633120\n",
      "(10, 128, 128, 3)\n",
      "0.8673304\n",
      "[Epoch 2/10] [Batch 523/1081] [D loss: 0.279816] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.110415] time: 0:22:02.064706\n",
      "(10, 128, 128, 3)\n",
      "0.9168907\n",
      "[Epoch 2/10] [Batch 524/1081] [D loss: 0.278715] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.831114] time: 0:22:02.489411\n",
      "(10, 128, 128, 3)\n",
      "0.8685074\n",
      "[Epoch 2/10] [Batch 525/1081] [D loss: 0.277990] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.146390] time: 0:22:02.902103\n",
      "(10, 128, 128, 3)\n",
      "0.9337978\n",
      "[Epoch 2/10] [Batch 526/1081] [D loss: 0.277703] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.257068] time: 0:22:03.335753\n",
      "(10, 128, 128, 3)\n",
      "0.96166915\n",
      "[Epoch 2/10] [Batch 527/1081] [D loss: 0.277668] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.000275] time: 0:22:03.766956\n",
      "(10, 128, 128, 3)\n",
      "0.891309\n",
      "[Epoch 2/10] [Batch 528/1081] [D loss: 0.277186] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.736201] time: 0:22:04.166776\n",
      "(10, 128, 128, 3)\n",
      "0.90387464\n",
      "[Epoch 2/10] [Batch 529/1081] [D loss: 0.276603] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.080435] time: 0:22:04.552473\n",
      "(10, 128, 128, 3)\n",
      "0.90382606\n",
      "[Epoch 2/10] [Batch 530/1081] [D loss: 0.276590] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.799288] time: 0:22:04.945015\n",
      "(10, 128, 128, 3)\n",
      "0.92722464\n",
      "[Epoch 2/10] [Batch 531/1081] [D loss: 0.276121] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.356371] time: 0:22:05.337583\n",
      "(10, 128, 128, 3)\n",
      "0.8923168\n",
      "[Epoch 2/10] [Batch 532/1081] [D loss: 0.275889] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.184397] time: 0:22:05.731420\n",
      "(10, 128, 128, 3)\n",
      "0.86799616\n",
      "[Epoch 2/10] [Batch 533/1081] [D loss: 0.277203] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.342420] time: 0:22:06.121961\n",
      "(10, 128, 128, 3)\n",
      "0.93273383\n",
      "[Epoch 2/10] [Batch 534/1081] [D loss: 0.275881] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.071897] time: 0:22:06.532830\n",
      "(10, 128, 128, 3)\n",
      "0.9263182\n",
      "[Epoch 2/10] [Batch 535/1081] [D loss: 0.274896] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.574079] time: 0:22:06.921620\n",
      "(10, 128, 128, 3)\n",
      "0.90958166\n",
      "[Epoch 2/10] [Batch 536/1081] [D loss: 0.274667] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.150248] time: 0:22:07.305623\n",
      "(10, 128, 128, 3)\n",
      "0.8895371\n",
      "[Epoch 2/10] [Batch 537/1081] [D loss: 0.274247] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.665545] time: 0:22:07.687211\n",
      "(10, 128, 128, 3)\n",
      "0.87467927\n",
      "[Epoch 2/10] [Batch 538/1081] [D loss: 0.275784] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.555681] time: 0:22:08.064334\n",
      "(10, 128, 128, 3)\n",
      "0.8486259\n",
      "[Epoch 2/10] [Batch 539/1081] [D loss: 0.274995] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.746754] time: 0:22:08.440742\n",
      "(10, 128, 128, 3)\n",
      "0.9140833\n",
      "[Epoch 2/10] [Batch 540/1081] [D loss: 0.273832] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.563774] time: 0:22:08.845620\n",
      "(10, 128, 128, 3)\n",
      "0.9134705\n",
      "[Epoch 2/10] [Batch 541/1081] [D loss: 0.272999] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.062414] time: 0:22:09.286405\n",
      "(10, 128, 128, 3)\n",
      "0.92520666\n",
      "[Epoch 2/10] [Batch 542/1081] [D loss: 0.272840] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.997165] time: 0:22:09.699580\n",
      "(10, 128, 128, 3)\n",
      "0.8451374\n",
      "[Epoch 2/10] [Batch 543/1081] [D loss: 0.272571] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.962664] time: 0:22:10.109017\n",
      "(10, 128, 128, 3)\n",
      "0.90563893\n",
      "[Epoch 2/10] [Batch 544/1081] [D loss: 0.272024] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.739992] time: 0:22:10.511270\n",
      "(10, 128, 128, 3)\n",
      "0.8927837\n",
      "[Epoch 2/10] [Batch 545/1081] [D loss: 0.271865] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.207746] time: 0:22:10.911594\n",
      "(10, 128, 128, 3)\n",
      "0.90859294\n",
      "[Epoch 2/10] [Batch 546/1081] [D loss: 0.271403] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.515117] time: 0:22:11.339845\n",
      "(10, 128, 128, 3)\n",
      "0.94957644\n",
      "[Epoch 2/10] [Batch 547/1081] [D loss: 0.271947] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.739929] time: 0:22:11.753312\n",
      "(10, 128, 128, 3)\n",
      "0.94723946\n",
      "[Epoch 2/10] [Batch 548/1081] [D loss: 0.271328] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.040314] time: 0:22:12.136119\n",
      "(10, 128, 128, 3)\n",
      "0.95956755\n",
      "[Epoch 2/10] [Batch 549/1081] [D loss: 0.270529] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.830411] time: 0:22:12.566947\n",
      "(10, 128, 128, 3)\n",
      "0.91210365\n",
      "[Epoch 2/10] [Batch 550/1081] [D loss: 0.270259] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.832872] time: 0:22:12.975886\n",
      "(10, 128, 128, 3)\n",
      "0.92660326\n",
      "[Epoch 2/10] [Batch 551/1081] [D loss: 0.270144] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.737543] time: 0:22:13.422866\n",
      "(10, 128, 128, 3)\n",
      "0.9019248\n",
      "[Epoch 2/10] [Batch 552/1081] [D loss: 0.269648] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.352318] time: 0:22:13.809703\n",
      "(10, 128, 128, 3)\n",
      "0.91576296\n",
      "[Epoch 2/10] [Batch 553/1081] [D loss: 0.269710] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.344638] time: 0:22:14.220167\n",
      "(10, 128, 128, 3)\n",
      "0.88042146\n",
      "[Epoch 2/10] [Batch 554/1081] [D loss: 0.269379] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.841263] time: 0:22:14.626901\n",
      "(10, 128, 128, 3)\n",
      "0.90258193\n",
      "[Epoch 2/10] [Batch 555/1081] [D loss: 0.271304] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.598018] time: 0:22:15.033871\n",
      "(10, 128, 128, 3)\n",
      "0.91549635\n",
      "[Epoch 2/10] [Batch 556/1081] [D loss: 0.269383] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.328989] time: 0:22:15.442564\n",
      "(10, 128, 128, 3)\n",
      "0.9790759\n",
      "[Epoch 2/10] [Batch 557/1081] [D loss: 0.274426] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.286966] time: 0:22:15.861861\n",
      "(10, 128, 128, 3)\n",
      "0.92195225\n",
      "[Epoch 2/10] [Batch 558/1081] [D loss: 0.270592] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.747169] time: 0:22:16.274763\n",
      "(10, 128, 128, 3)\n",
      "0.8975656\n",
      "[Epoch 2/10] [Batch 559/1081] [D loss: 0.268012] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.655939] time: 0:22:16.654164\n",
      "(10, 128, 128, 3)\n",
      "0.9181781\n",
      "[Epoch 2/10] [Batch 560/1081] [D loss: 0.267801] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.359865] time: 0:22:17.027291\n",
      "(10, 128, 128, 3)\n",
      "0.9665508\n",
      "[Epoch 2/10] [Batch 561/1081] [D loss: 0.267994] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.578173] time: 0:22:17.764190\n",
      "(10, 128, 128, 3)\n",
      "0.91752046\n",
      "[Epoch 2/10] [Batch 562/1081] [D loss: 0.267162] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.685072] time: 0:22:18.172631\n",
      "(10, 128, 128, 3)\n",
      "0.92683125\n",
      "[Epoch 2/10] [Batch 563/1081] [D loss: 0.266503] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.171756] time: 0:22:18.615531\n",
      "(10, 128, 128, 3)\n",
      "0.90152425\n",
      "[Epoch 2/10] [Batch 564/1081] [D loss: 0.268171] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.677248] time: 0:22:19.000780\n",
      "(10, 128, 128, 3)\n",
      "0.89905715\n",
      "[Epoch 2/10] [Batch 565/1081] [D loss: 0.268584] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.102949] time: 0:22:19.412191\n",
      "(10, 128, 128, 3)\n",
      "0.93006235\n",
      "[Epoch 2/10] [Batch 566/1081] [D loss: 0.266053] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.519711] time: 0:22:19.818918\n",
      "(10, 128, 128, 3)\n",
      "0.8638356\n",
      "[Epoch 2/10] [Batch 567/1081] [D loss: 0.265248] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.929614] time: 0:22:20.204064\n",
      "(10, 128, 128, 3)\n",
      "0.8948751\n",
      "[Epoch 2/10] [Batch 568/1081] [D loss: 0.265079] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.070775] time: 0:22:20.623095\n",
      "(10, 128, 128, 3)\n",
      "0.94025487\n",
      "[Epoch 2/10] [Batch 569/1081] [D loss: 0.264636] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.705439] time: 0:22:21.025518\n",
      "(10, 128, 128, 3)\n",
      "0.9111378\n",
      "[Epoch 2/10] [Batch 570/1081] [D loss: 0.264809] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.158098] time: 0:22:21.407701\n",
      "(10, 128, 128, 3)\n",
      "0.8582427\n",
      "[Epoch 2/10] [Batch 571/1081] [D loss: 0.264294] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.963877] time: 0:22:21.799429\n",
      "(10, 128, 128, 3)\n",
      "0.91554403\n",
      "[Epoch 2/10] [Batch 572/1081] [D loss: 0.263753] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.165068] time: 0:22:22.195336\n",
      "(10, 128, 128, 3)\n",
      "0.87623835\n",
      "[Epoch 2/10] [Batch 573/1081] [D loss: 0.263565] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.083417] time: 0:22:22.647051\n",
      "(10, 128, 128, 3)\n",
      "0.91540664\n",
      "[Epoch 2/10] [Batch 574/1081] [D loss: 0.263287] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.778935] time: 0:22:23.057663\n",
      "(10, 128, 128, 3)\n",
      "0.8826094\n",
      "[Epoch 2/10] [Batch 575/1081] [D loss: 0.262678] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.224179] time: 0:22:23.442455\n",
      "(10, 128, 128, 3)\n",
      "0.92934686\n",
      "[Epoch 2/10] [Batch 576/1081] [D loss: 0.262405] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.397783] time: 0:22:23.858951\n",
      "(10, 128, 128, 3)\n",
      "0.8853822\n",
      "[Epoch 2/10] [Batch 577/1081] [D loss: 0.262413] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.373537] time: 0:22:24.310045\n",
      "(10, 128, 128, 3)\n",
      "0.9387078\n",
      "[Epoch 2/10] [Batch 578/1081] [D loss: 0.261807] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.885132] time: 0:22:24.736360\n",
      "(10, 128, 128, 3)\n",
      "0.9258928\n",
      "[Epoch 2/10] [Batch 579/1081] [D loss: 0.261501] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.576129] time: 0:22:25.134620\n",
      "(10, 128, 128, 3)\n",
      "0.8988972\n",
      "[Epoch 2/10] [Batch 580/1081] [D loss: 0.261228] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.127398] time: 0:22:25.553213\n",
      "(10, 128, 128, 3)\n",
      "0.94671005\n",
      "[Epoch 2/10] [Batch 581/1081] [D loss: 0.261079] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.167114] time: 0:22:25.957651\n",
      "(10, 128, 128, 3)\n",
      "0.88269097\n",
      "[Epoch 2/10] [Batch 582/1081] [D loss: 0.261103] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.587109] time: 0:22:26.362798\n",
      "(10, 128, 128, 3)\n",
      "0.9549002\n",
      "[Epoch 2/10] [Batch 583/1081] [D loss: 0.260899] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.735344] time: 0:22:26.796823\n",
      "(10, 128, 128, 3)\n",
      "0.89965963\n",
      "[Epoch 2/10] [Batch 584/1081] [D loss: 0.260251] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.996414] time: 0:22:27.202412\n",
      "(10, 128, 128, 3)\n",
      "0.92152977\n",
      "[Epoch 2/10] [Batch 585/1081] [D loss: 0.259942] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.280706] time: 0:22:27.608081\n",
      "(10, 128, 128, 3)\n",
      "0.8816473\n",
      "[Epoch 2/10] [Batch 586/1081] [D loss: 0.260033] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.270952] time: 0:22:28.011512\n",
      "(10, 128, 128, 3)\n",
      "0.94659656\n",
      "[Epoch 2/10] [Batch 587/1081] [D loss: 0.259526] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.234415] time: 0:22:28.424690\n",
      "(10, 128, 128, 3)\n",
      "0.9073987\n",
      "[Epoch 2/10] [Batch 588/1081] [D loss: 0.259180] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.957823] time: 0:22:28.852086\n",
      "(10, 128, 128, 3)\n",
      "0.879859\n",
      "[Epoch 2/10] [Batch 589/1081] [D loss: 0.258980] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.528893] time: 0:22:29.256127\n",
      "(10, 128, 128, 3)\n",
      "0.901789\n",
      "[Epoch 2/10] [Batch 590/1081] [D loss: 0.258771] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.235202] time: 0:22:29.652277\n",
      "(10, 128, 128, 3)\n",
      "0.906884\n",
      "[Epoch 2/10] [Batch 591/1081] [D loss: 0.258052] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.752810] time: 0:22:30.028134\n",
      "(10, 128, 128, 3)\n",
      "0.9050701\n",
      "[Epoch 2/10] [Batch 592/1081] [D loss: 0.257918] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.201566] time: 0:22:30.407050\n",
      "(10, 128, 128, 3)\n",
      "0.87256414\n",
      "[Epoch 2/10] [Batch 593/1081] [D loss: 0.257990] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.160131] time: 0:22:30.834638\n",
      "(10, 128, 128, 3)\n",
      "0.90728074\n",
      "[Epoch 2/10] [Batch 594/1081] [D loss: 0.257920] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.813846] time: 0:22:31.236382\n",
      "(10, 128, 128, 3)\n",
      "0.9413047\n",
      "[Epoch 2/10] [Batch 595/1081] [D loss: 0.257148] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.458918] time: 0:22:31.654486\n",
      "(10, 128, 128, 3)\n",
      "0.87108016\n",
      "[Epoch 2/10] [Batch 596/1081] [D loss: 0.256928] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.110819] time: 0:22:32.076660\n",
      "(10, 128, 128, 3)\n",
      "0.9171147\n",
      "[Epoch 2/10] [Batch 597/1081] [D loss: 0.257008] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.444288] time: 0:22:32.472134\n",
      "(10, 128, 128, 3)\n",
      "0.95855904\n",
      "[Epoch 2/10] [Batch 598/1081] [D loss: 0.256053] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.374643] time: 0:22:32.867177\n",
      "(10, 128, 128, 3)\n",
      "0.88761526\n",
      "[Epoch 2/10] [Batch 599/1081] [D loss: 0.256159] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.636133] time: 0:22:33.246332\n",
      "(10, 128, 128, 3)\n",
      "0.8710787\n",
      "[Epoch 2/10] [Batch 600/1081] [D loss: 0.255541] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.902578] time: 0:22:33.677770\n",
      "(10, 128, 128, 3)\n",
      "0.9164259\n",
      "[Epoch 2/10] [Batch 601/1081] [D loss: 0.255360] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.443296] time: 0:22:34.102197\n",
      "(10, 128, 128, 3)\n",
      "0.96062374\n",
      "[Epoch 2/10] [Batch 602/1081] [D loss: 0.255400] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.404819] time: 0:22:34.500541\n",
      "(10, 128, 128, 3)\n",
      "0.92029065\n",
      "[Epoch 2/10] [Batch 603/1081] [D loss: 0.255153] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.534857] time: 0:22:34.911224\n",
      "(10, 128, 128, 3)\n",
      "0.8923122\n",
      "[Epoch 2/10] [Batch 604/1081] [D loss: 0.255103] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.293549] time: 0:22:35.308155\n",
      "(10, 128, 128, 3)\n",
      "0.89011526\n",
      "[Epoch 2/10] [Batch 605/1081] [D loss: 0.254070] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.769091] time: 0:22:35.706676\n",
      "(10, 128, 128, 3)\n",
      "0.88936025\n",
      "[Epoch 2/10] [Batch 606/1081] [D loss: 0.253821] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.528090] time: 0:22:36.093806\n",
      "(10, 128, 128, 3)\n",
      "0.9335887\n",
      "[Epoch 2/10] [Batch 607/1081] [D loss: 0.254112] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.720201] time: 0:22:36.510532\n",
      "(10, 128, 128, 3)\n",
      "0.91820836\n",
      "[Epoch 2/10] [Batch 608/1081] [D loss: 0.253486] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.912234] time: 0:22:36.899047\n",
      "(10, 128, 128, 3)\n",
      "0.92638344\n",
      "[Epoch 2/10] [Batch 609/1081] [D loss: 0.253459] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.929502] time: 0:22:37.292738\n",
      "(10, 128, 128, 3)\n",
      "0.9065192\n",
      "[Epoch 2/10] [Batch 610/1081] [D loss: 0.253279] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.137753] time: 0:22:37.708152\n",
      "(10, 128, 128, 3)\n",
      "0.9430539\n",
      "[Epoch 2/10] [Batch 611/1081] [D loss: 0.252486] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.434573] time: 0:22:38.094662\n",
      "(10, 128, 128, 3)\n",
      "0.8887372\n",
      "[Epoch 2/10] [Batch 612/1081] [D loss: 0.252159] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.282741] time: 0:22:38.520142\n",
      "(10, 128, 128, 3)\n",
      "0.8965583\n",
      "[Epoch 2/10] [Batch 613/1081] [D loss: 0.251867] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.376810] time: 0:22:38.916110\n",
      "(10, 128, 128, 3)\n",
      "0.8627923\n",
      "[Epoch 2/10] [Batch 614/1081] [D loss: 0.251831] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.787335] time: 0:22:39.312411\n",
      "(10, 128, 128, 3)\n",
      "0.88053733\n",
      "[Epoch 2/10] [Batch 615/1081] [D loss: 0.251535] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.515187] time: 0:22:39.750099\n",
      "(10, 128, 128, 3)\n",
      "0.90204257\n",
      "[Epoch 2/10] [Batch 616/1081] [D loss: 0.250917] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.454920] time: 0:22:40.180530\n",
      "(10, 128, 128, 3)\n",
      "0.879649\n",
      "[Epoch 2/10] [Batch 617/1081] [D loss: 0.250613] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.224440] time: 0:22:40.623560\n",
      "(10, 128, 128, 3)\n",
      "0.91903955\n",
      "[Epoch 2/10] [Batch 618/1081] [D loss: 0.253392] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.308805] time: 0:22:41.006727\n",
      "(10, 128, 128, 3)\n",
      "0.8969987\n",
      "[Epoch 2/10] [Batch 619/1081] [D loss: 0.252551] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.460640] time: 0:22:41.433787\n",
      "(10, 128, 128, 3)\n",
      "0.950572\n",
      "[Epoch 2/10] [Batch 620/1081] [D loss: 0.251335] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.565332] time: 0:22:41.823685\n",
      "(10, 128, 128, 3)\n",
      "0.96357495\n",
      "[Epoch 2/10] [Batch 621/1081] [D loss: 0.249720] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.402353] time: 0:22:42.246267\n",
      "(10, 128, 128, 3)\n",
      "0.91472656\n",
      "[Epoch 2/10] [Batch 622/1081] [D loss: 0.250877] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.485802] time: 0:22:42.646013\n",
      "(10, 128, 128, 3)\n",
      "0.94383067\n",
      "[Epoch 2/10] [Batch 623/1081] [D loss: 0.249257] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.006662] time: 0:22:43.055592\n",
      "(10, 128, 128, 3)\n",
      "0.93108886\n",
      "[Epoch 2/10] [Batch 624/1081] [D loss: 0.248901] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.578133] time: 0:22:43.466468\n",
      "(10, 128, 128, 3)\n",
      "0.9127903\n",
      "[Epoch 2/10] [Batch 625/1081] [D loss: 0.248996] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.095469] time: 0:22:43.871040\n",
      "(10, 128, 128, 3)\n",
      "0.9000392\n",
      "[Epoch 2/10] [Batch 626/1081] [D loss: 0.248203] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.103060] time: 0:22:44.279868\n",
      "(10, 128, 128, 3)\n",
      "0.92889816\n",
      "[Epoch 2/10] [Batch 627/1081] [D loss: 0.248108] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.903857] time: 0:22:44.670110\n",
      "(10, 128, 128, 3)\n",
      "0.9091361\n",
      "[Epoch 2/10] [Batch 628/1081] [D loss: 0.247855] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.659056] time: 0:22:45.069197\n",
      "(10, 128, 128, 3)\n",
      "0.9296046\n",
      "[Epoch 2/10] [Batch 629/1081] [D loss: 0.247526] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.989214] time: 0:22:45.454640\n",
      "(10, 128, 128, 3)\n",
      "0.9114526\n",
      "[Epoch 2/10] [Batch 630/1081] [D loss: 0.247540] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.225832] time: 0:22:45.849818\n",
      "(10, 128, 128, 3)\n",
      "0.90246105\n",
      "[Epoch 2/10] [Batch 631/1081] [D loss: 0.247523] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.786268] time: 0:22:46.263035\n",
      "(10, 128, 128, 3)\n",
      "0.91047984\n",
      "[Epoch 2/10] [Batch 632/1081] [D loss: 0.246711] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.180944] time: 0:22:46.668077\n",
      "(10, 128, 128, 3)\n",
      "0.9492876\n",
      "[Epoch 2/10] [Batch 633/1081] [D loss: 0.247166] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.149635] time: 0:22:47.073643\n",
      "(10, 128, 128, 3)\n",
      "0.93893987\n",
      "[Epoch 2/10] [Batch 634/1081] [D loss: 0.247002] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.001436] time: 0:22:47.476706\n",
      "(10, 128, 128, 3)\n",
      "0.9396517\n",
      "[Epoch 2/10] [Batch 635/1081] [D loss: 0.246883] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.454565] time: 0:22:47.915792\n",
      "(10, 128, 128, 3)\n",
      "0.87445766\n",
      "[Epoch 2/10] [Batch 636/1081] [D loss: 0.245564] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.968249] time: 0:22:48.332995\n",
      "(10, 128, 128, 3)\n",
      "0.9309249\n",
      "[Epoch 2/10] [Batch 637/1081] [D loss: 0.245164] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.108492] time: 0:22:48.721620\n",
      "(10, 128, 128, 3)\n",
      "0.8763215\n",
      "[Epoch 2/10] [Batch 638/1081] [D loss: 0.245145] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.390338] time: 0:22:49.157431\n",
      "(10, 128, 128, 3)\n",
      "0.9076686\n",
      "[Epoch 2/10] [Batch 639/1081] [D loss: 0.244723] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.181524] time: 0:22:49.576263\n",
      "(10, 128, 128, 3)\n",
      "0.9246898\n",
      "[Epoch 2/10] [Batch 640/1081] [D loss: 0.244447] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.912412] time: 0:22:49.986051\n",
      "(10, 128, 128, 3)\n",
      "0.92379254\n",
      "[Epoch 2/10] [Batch 641/1081] [D loss: 0.244104] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.324213] time: 0:22:50.393274\n",
      "(10, 128, 128, 3)\n",
      "0.9308813\n",
      "[Epoch 2/10] [Batch 642/1081] [D loss: 0.244230] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.981659] time: 0:22:50.816774\n",
      "(10, 128, 128, 3)\n",
      "0.9659861\n",
      "[Epoch 2/10] [Batch 643/1081] [D loss: 0.243993] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.315241] time: 0:22:51.208537\n",
      "(10, 128, 128, 3)\n",
      "0.9132042\n",
      "[Epoch 2/10] [Batch 644/1081] [D loss: 0.243271] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.975240] time: 0:22:51.601649\n",
      "(10, 128, 128, 3)\n",
      "0.933675\n",
      "[Epoch 2/10] [Batch 645/1081] [D loss: 0.243470] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.459166] time: 0:22:51.986227\n",
      "(10, 128, 128, 3)\n",
      "0.9325581\n",
      "[Epoch 2/10] [Batch 646/1081] [D loss: 0.242789] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.879118] time: 0:22:52.376233\n",
      "(10, 128, 128, 3)\n",
      "0.9283581\n",
      "[Epoch 2/10] [Batch 647/1081] [D loss: 0.244677] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.159694] time: 0:22:52.764766\n",
      "(10, 128, 128, 3)\n",
      "0.9144768\n",
      "[Epoch 2/10] [Batch 648/1081] [D loss: 0.244647] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.355192] time: 0:22:53.175851\n",
      "(10, 128, 128, 3)\n",
      "0.81546146\n",
      "[Epoch 2/10] [Batch 649/1081] [D loss: 0.242574] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.138614] time: 0:22:53.582843\n",
      "(10, 128, 128, 3)\n",
      "0.90247536\n",
      "[Epoch 2/10] [Batch 650/1081] [D loss: 0.241696] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.712084] time: 0:22:53.972391\n",
      "(10, 128, 128, 3)\n",
      "0.882308\n",
      "[Epoch 2/10] [Batch 651/1081] [D loss: 0.241635] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.001337] time: 0:22:54.400396\n",
      "(10, 128, 128, 3)\n",
      "0.94440144\n",
      "[Epoch 2/10] [Batch 652/1081] [D loss: 0.241193] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.219238] time: 0:22:54.829253\n",
      "(10, 128, 128, 3)\n",
      "0.896619\n",
      "[Epoch 2/10] [Batch 653/1081] [D loss: 0.240826] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.987213] time: 0:22:55.252660\n",
      "(10, 128, 128, 3)\n",
      "0.9301844\n",
      "[Epoch 2/10] [Batch 654/1081] [D loss: 0.240524] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.135683] time: 0:22:55.662710\n",
      "(10, 128, 128, 3)\n",
      "0.8908079\n",
      "[Epoch 2/10] [Batch 655/1081] [D loss: 0.240552] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.533262] time: 0:22:56.049270\n",
      "(10, 128, 128, 3)\n",
      "0.8969833\n",
      "[Epoch 2/10] [Batch 656/1081] [D loss: 0.240609] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.019666] time: 0:22:56.461666\n",
      "(10, 128, 128, 3)\n",
      "0.87992555\n",
      "[Epoch 2/10] [Batch 657/1081] [D loss: 0.240097] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.683615] time: 0:22:56.876797\n",
      "(10, 128, 128, 3)\n",
      "0.9312921\n",
      "[Epoch 2/10] [Batch 658/1081] [D loss: 0.239950] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.777542] time: 0:22:57.257683\n",
      "(10, 128, 128, 3)\n",
      "0.87298155\n",
      "[Epoch 2/10] [Batch 659/1081] [D loss: 0.239204] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.543966] time: 0:22:57.650747\n",
      "(10, 128, 128, 3)\n",
      "0.87497264\n",
      "[Epoch 2/10] [Batch 660/1081] [D loss: 0.239458] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.943705] time: 0:22:58.070227\n",
      "(10, 128, 128, 3)\n",
      "0.9429145\n",
      "[Epoch 2/10] [Batch 661/1081] [D loss: 0.238975] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.633665] time: 0:22:58.474459\n",
      "(10, 128, 128, 3)\n",
      "0.8508711\n",
      "[Epoch 2/10] [Batch 662/1081] [D loss: 0.238548] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.276979] time: 0:22:58.890325\n",
      "(10, 128, 128, 3)\n",
      "0.97107965\n",
      "[Epoch 2/10] [Batch 663/1081] [D loss: 0.238361] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.330679] time: 0:22:59.304560\n",
      "(10, 128, 128, 3)\n",
      "0.9026022\n",
      "[Epoch 2/10] [Batch 664/1081] [D loss: 0.237839] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.169962] time: 0:22:59.707347\n",
      "(10, 128, 128, 3)\n",
      "0.908762\n",
      "[Epoch 2/10] [Batch 665/1081] [D loss: 0.237634] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.009096] time: 0:23:00.166436\n",
      "(10, 128, 128, 3)\n",
      "0.9355548\n",
      "[Epoch 2/10] [Batch 666/1081] [D loss: 0.237647] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.289427] time: 0:23:00.562656\n",
      "(10, 128, 128, 3)\n",
      "0.9037159\n",
      "[Epoch 2/10] [Batch 667/1081] [D loss: 0.237086] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 16.592785] time: 0:23:00.944732\n",
      "(10, 128, 128, 3)\n",
      "0.9154156\n",
      "[Epoch 2/10] [Batch 668/1081] [D loss: 0.236846] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.881941] time: 0:23:01.355529\n",
      "(10, 128, 128, 3)\n",
      "0.9080544\n",
      "[Epoch 2/10] [Batch 669/1081] [D loss: 0.236505] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.606569] time: 0:23:01.776770\n",
      "(10, 128, 128, 3)\n",
      "0.86536986\n",
      "[Epoch 2/10] [Batch 670/1081] [D loss: 0.236386] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.839348] time: 0:23:02.175835\n",
      "(10, 128, 128, 3)\n",
      "0.8878258\n",
      "[Epoch 2/10] [Batch 671/1081] [D loss: 0.236150] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.725360] time: 0:23:02.600806\n",
      "(10, 128, 128, 3)\n",
      "0.9432718\n",
      "[Epoch 2/10] [Batch 672/1081] [D loss: 0.235950] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.888863] time: 0:23:03.049378\n",
      "(10, 128, 128, 3)\n",
      "0.88730556\n",
      "[Epoch 2/10] [Batch 673/1081] [D loss: 0.236588] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.995100] time: 0:23:03.456098\n",
      "(10, 128, 128, 3)\n",
      "0.89595366\n",
      "[Epoch 2/10] [Batch 674/1081] [D loss: 0.235311] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.485994] time: 0:23:03.852526\n",
      "(10, 128, 128, 3)\n",
      "0.87956136\n",
      "[Epoch 2/10] [Batch 675/1081] [D loss: 0.235319] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.887042] time: 0:23:04.278780\n",
      "(10, 128, 128, 3)\n",
      "0.8894742\n",
      "[Epoch 2/10] [Batch 676/1081] [D loss: 0.235163] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.661474] time: 0:23:04.686609\n",
      "(10, 128, 128, 3)\n",
      "0.9174493\n",
      "[Epoch 2/10] [Batch 677/1081] [D loss: 0.234668] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.079145] time: 0:23:05.099257\n",
      "(10, 128, 128, 3)\n",
      "0.9127323\n",
      "[Epoch 2/10] [Batch 678/1081] [D loss: 0.234440] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.591963] time: 0:23:05.495608\n",
      "(10, 128, 128, 3)\n",
      "0.9297045\n",
      "[Epoch 2/10] [Batch 679/1081] [D loss: 0.234283] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.797567] time: 0:23:05.909912\n",
      "(10, 128, 128, 3)\n",
      "0.9331294\n",
      "[Epoch 2/10] [Batch 680/1081] [D loss: 0.233744] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.266748] time: 0:23:06.363087\n",
      "(10, 128, 128, 3)\n",
      "0.9293204\n",
      "[Epoch 2/10] [Batch 681/1081] [D loss: 0.234106] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.037977] time: 0:23:06.772152\n",
      "(10, 128, 128, 3)\n",
      "0.8875049\n",
      "[Epoch 2/10] [Batch 682/1081] [D loss: 0.233787] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.196314] time: 0:23:07.191563\n",
      "(10, 128, 128, 3)\n",
      "0.83923435\n",
      "[Epoch 2/10] [Batch 683/1081] [D loss: 0.233067] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.628265] time: 0:23:07.577885\n",
      "(10, 128, 128, 3)\n",
      "0.8935189\n",
      "[Epoch 2/10] [Batch 684/1081] [D loss: 0.232829] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.057048] time: 0:23:07.977661\n",
      "(10, 128, 128, 3)\n",
      "0.86832\n",
      "[Epoch 2/10] [Batch 685/1081] [D loss: 0.232322] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.135562] time: 0:23:08.400890\n",
      "(10, 128, 128, 3)\n",
      "0.9233988\n",
      "[Epoch 2/10] [Batch 686/1081] [D loss: 0.232570] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.240024] time: 0:23:08.813493\n",
      "(10, 128, 128, 3)\n",
      "0.91137415\n",
      "[Epoch 2/10] [Batch 687/1081] [D loss: 0.232128] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.916969] time: 0:23:09.211296\n",
      "(10, 128, 128, 3)\n",
      "0.881396\n",
      "[Epoch 2/10] [Batch 688/1081] [D loss: 0.231731] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.303740] time: 0:23:09.606125\n",
      "(10, 128, 128, 3)\n",
      "0.94609374\n",
      "[Epoch 2/10] [Batch 689/1081] [D loss: 0.231602] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.646777] time: 0:23:10.000932\n",
      "(10, 128, 128, 3)\n",
      "0.910814\n",
      "[Epoch 2/10] [Batch 690/1081] [D loss: 0.231719] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.120084] time: 0:23:10.408486\n",
      "(10, 128, 128, 3)\n",
      "0.9409725\n",
      "[Epoch 2/10] [Batch 691/1081] [D loss: 0.231309] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.819582] time: 0:23:10.820434\n",
      "(10, 128, 128, 3)\n",
      "0.89296484\n",
      "[Epoch 2/10] [Batch 692/1081] [D loss: 0.231354] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.725955] time: 0:23:11.231841\n",
      "(10, 128, 128, 3)\n",
      "0.8806986\n",
      "[Epoch 2/10] [Batch 693/1081] [D loss: 0.230610] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.579443] time: 0:23:11.652377\n",
      "(10, 128, 128, 3)\n",
      "0.9161375\n",
      "[Epoch 2/10] [Batch 694/1081] [D loss: 0.230172] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.399607] time: 0:23:12.072890\n",
      "(10, 128, 128, 3)\n",
      "0.8910203\n",
      "[Epoch 2/10] [Batch 695/1081] [D loss: 0.229885] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.969007] time: 0:23:12.499984\n",
      "(10, 128, 128, 3)\n",
      "0.8078685\n",
      "[Epoch 2/10] [Batch 696/1081] [D loss: 0.229618] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.509001] time: 0:23:12.872016\n",
      "(10, 128, 128, 3)\n",
      "0.9045178\n",
      "[Epoch 2/10] [Batch 697/1081] [D loss: 0.230451] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.354399] time: 0:23:13.319459\n",
      "(10, 128, 128, 3)\n",
      "0.852909\n",
      "[Epoch 2/10] [Batch 698/1081] [D loss: 0.229426] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.070976] time: 0:23:13.716692\n",
      "(10, 128, 128, 3)\n",
      "0.9403277\n",
      "[Epoch 2/10] [Batch 699/1081] [D loss: 0.228899] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.788315] time: 0:23:14.151388\n",
      "(10, 128, 128, 3)\n",
      "0.9417841\n",
      "[Epoch 2/10] [Batch 700/1081] [D loss: 0.229007] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.090118] time: 0:23:14.552780\n",
      "(10, 128, 128, 3)\n",
      "0.8796706\n",
      "[Epoch 2/10] [Batch 701/1081] [D loss: 0.228901] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.514371] time: 0:23:14.982246\n",
      "(10, 128, 128, 3)\n",
      "0.96594137\n",
      "[Epoch 2/10] [Batch 702/1081] [D loss: 0.229635] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.849454] time: 0:23:15.369887\n",
      "(10, 128, 128, 3)\n",
      "0.86897945\n",
      "[Epoch 2/10] [Batch 703/1081] [D loss: 0.229170] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.371671] time: 0:23:15.800049\n",
      "(10, 128, 128, 3)\n",
      "0.9269359\n",
      "[Epoch 2/10] [Batch 704/1081] [D loss: 0.229179] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.823351] time: 0:23:16.203310\n",
      "(10, 128, 128, 3)\n",
      "0.8777861\n",
      "[Epoch 2/10] [Batch 705/1081] [D loss: 0.230089] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.229953] time: 0:23:16.638399\n",
      "(10, 128, 128, 3)\n",
      "0.94661254\n",
      "[Epoch 2/10] [Batch 706/1081] [D loss: 0.227778] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.536972] time: 0:23:17.031210\n",
      "(10, 128, 128, 3)\n",
      "0.9224818\n",
      "[Epoch 2/10] [Batch 707/1081] [D loss: 0.227164] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.398264] time: 0:23:17.438428\n",
      "(10, 128, 128, 3)\n",
      "0.91192275\n",
      "[Epoch 2/10] [Batch 708/1081] [D loss: 0.226645] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.475958] time: 0:23:17.835133\n",
      "(10, 128, 128, 3)\n",
      "0.94564456\n",
      "[Epoch 2/10] [Batch 709/1081] [D loss: 0.226717] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.263670] time: 0:23:18.260988\n",
      "(10, 128, 128, 3)\n",
      "0.92743224\n",
      "[Epoch 2/10] [Batch 710/1081] [D loss: 0.226271] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.228552] time: 0:23:18.636391\n",
      "(10, 128, 128, 3)\n",
      "0.9125777\n",
      "[Epoch 2/10] [Batch 711/1081] [D loss: 0.226425] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.768244] time: 0:23:19.042897\n",
      "(10, 128, 128, 3)\n",
      "0.94724816\n",
      "[Epoch 2/10] [Batch 712/1081] [D loss: 0.225859] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.986227] time: 0:23:19.428793\n",
      "(10, 128, 128, 3)\n",
      "0.91823727\n",
      "[Epoch 2/10] [Batch 713/1081] [D loss: 0.225353] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.048651] time: 0:23:19.825900\n",
      "(10, 128, 128, 3)\n",
      "0.89718384\n",
      "[Epoch 2/10] [Batch 714/1081] [D loss: 0.225227] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.813947] time: 0:23:20.226480\n",
      "(10, 128, 128, 3)\n",
      "0.9415024\n",
      "[Epoch 2/10] [Batch 715/1081] [D loss: 0.225069] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.894102] time: 0:23:20.641766\n",
      "(10, 128, 128, 3)\n",
      "0.92605925\n",
      "[Epoch 2/10] [Batch 716/1081] [D loss: 0.224828] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.063472] time: 0:23:21.022228\n",
      "(10, 128, 128, 3)\n",
      "0.8655655\n",
      "[Epoch 2/10] [Batch 717/1081] [D loss: 0.224471] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.640532] time: 0:23:21.442321\n",
      "(10, 128, 128, 3)\n",
      "0.96016675\n",
      "[Epoch 2/10] [Batch 718/1081] [D loss: 0.224138] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.820074] time: 0:23:21.868218\n",
      "(10, 128, 128, 3)\n",
      "0.8381255\n",
      "[Epoch 2/10] [Batch 719/1081] [D loss: 0.223794] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.113254] time: 0:23:22.292379\n",
      "(10, 128, 128, 3)\n",
      "0.93566704\n",
      "[Epoch 2/10] [Batch 720/1081] [D loss: 0.223823] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.781534] time: 0:23:22.670099\n",
      "(10, 128, 128, 3)\n",
      "0.93482184\n",
      "[Epoch 2/10] [Batch 721/1081] [D loss: 0.223960] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.231997] time: 0:23:23.064985\n",
      "(10, 128, 128, 3)\n",
      "0.9255063\n",
      "[Epoch 2/10] [Batch 722/1081] [D loss: 0.223307] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.586069] time: 0:23:23.443502\n",
      "(10, 128, 128, 3)\n",
      "0.89792323\n",
      "[Epoch 2/10] [Batch 723/1081] [D loss: 0.223176] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.167150] time: 0:23:23.876409\n",
      "(10, 128, 128, 3)\n",
      "0.91499406\n",
      "[Epoch 2/10] [Batch 724/1081] [D loss: 0.222880] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.280815] time: 0:23:24.261229\n",
      "(10, 128, 128, 3)\n",
      "0.8668147\n",
      "[Epoch 2/10] [Batch 725/1081] [D loss: 0.222403] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.801204] time: 0:23:24.660526\n",
      "(10, 128, 128, 3)\n",
      "0.91748506\n",
      "[Epoch 2/10] [Batch 726/1081] [D loss: 0.222576] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.660823] time: 0:23:25.072128\n",
      "(10, 128, 128, 3)\n",
      "0.874749\n",
      "[Epoch 2/10] [Batch 727/1081] [D loss: 0.221906] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.447652] time: 0:23:25.515649\n",
      "(10, 128, 128, 3)\n",
      "0.8383717\n",
      "[Epoch 2/10] [Batch 728/1081] [D loss: 0.221924] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.887978] time: 0:23:25.930908\n",
      "(10, 128, 128, 3)\n",
      "0.9538276\n",
      "[Epoch 2/10] [Batch 729/1081] [D loss: 0.221700] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.239764] time: 0:23:26.338465\n",
      "(10, 128, 128, 3)\n",
      "0.94346744\n",
      "[Epoch 2/10] [Batch 730/1081] [D loss: 0.222343] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.642099] time: 0:23:26.717997\n",
      "(10, 128, 128, 3)\n",
      "0.870806\n",
      "[Epoch 2/10] [Batch 731/1081] [D loss: 0.222300] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.959460] time: 0:23:27.133250\n",
      "(10, 128, 128, 3)\n",
      "0.88825446\n",
      "[Epoch 2/10] [Batch 732/1081] [D loss: 0.221849] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.310445] time: 0:23:27.550403\n",
      "(10, 128, 128, 3)\n",
      "0.88401675\n",
      "[Epoch 2/10] [Batch 733/1081] [D loss: 0.220961] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.303749] time: 0:23:27.966796\n",
      "(10, 128, 128, 3)\n",
      "0.87618417\n",
      "[Epoch 2/10] [Batch 734/1081] [D loss: 0.220192] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.628448] time: 0:23:28.370347\n",
      "(10, 128, 128, 3)\n",
      "0.96827555\n",
      "[Epoch 2/10] [Batch 735/1081] [D loss: 0.220076] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.384375] time: 0:23:28.765042\n",
      "(10, 128, 128, 3)\n",
      "0.9122212\n",
      "[Epoch 2/10] [Batch 736/1081] [D loss: 0.219961] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.402483] time: 0:23:29.153205\n",
      "(10, 128, 128, 3)\n",
      "0.93607306\n",
      "[Epoch 2/10] [Batch 737/1081] [D loss: 0.219342] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.011076] time: 0:23:29.582749\n",
      "(10, 128, 128, 3)\n",
      "0.86421937\n",
      "[Epoch 2/10] [Batch 738/1081] [D loss: 0.219505] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.724690] time: 0:23:30.000082\n",
      "(10, 128, 128, 3)\n",
      "0.905618\n",
      "[Epoch 2/10] [Batch 739/1081] [D loss: 0.218883] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.085411] time: 0:23:30.396778\n",
      "(10, 128, 128, 3)\n",
      "0.90053445\n",
      "[Epoch 2/10] [Batch 740/1081] [D loss: 0.218608] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.359388] time: 0:23:30.787363\n",
      "(10, 128, 128, 3)\n",
      "0.9736739\n",
      "[Epoch 2/10] [Batch 741/1081] [D loss: 0.218516] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.457026] time: 0:23:31.212800\n",
      "(10, 128, 128, 3)\n",
      "0.91569257\n",
      "[Epoch 2/10] [Batch 742/1081] [D loss: 0.218160] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.570249] time: 0:23:31.588926\n",
      "(10, 128, 128, 3)\n",
      "0.8644714\n",
      "[Epoch 2/10] [Batch 743/1081] [D loss: 0.218049] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.202734] time: 0:23:31.988425\n",
      "(10, 128, 128, 3)\n",
      "0.8601746\n",
      "[Epoch 2/10] [Batch 744/1081] [D loss: 0.218280] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.144397] time: 0:23:32.380624\n",
      "(10, 128, 128, 3)\n",
      "0.9471548\n",
      "[Epoch 2/10] [Batch 745/1081] [D loss: 0.218703] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.169284] time: 0:23:32.784947\n",
      "(10, 128, 128, 3)\n",
      "0.9241361\n",
      "[Epoch 2/10] [Batch 746/1081] [D loss: 0.217529] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.157629] time: 0:23:33.198520\n",
      "(10, 128, 128, 3)\n",
      "0.87096184\n",
      "[Epoch 2/10] [Batch 747/1081] [D loss: 0.217089] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.777807] time: 0:23:33.613255\n",
      "(10, 128, 128, 3)\n",
      "0.93942755\n",
      "[Epoch 2/10] [Batch 748/1081] [D loss: 0.217786] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.743185] time: 0:23:34.026205\n",
      "(10, 128, 128, 3)\n",
      "0.9113211\n",
      "[Epoch 2/10] [Batch 749/1081] [D loss: 0.216891] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.451284] time: 0:23:34.430153\n",
      "(10, 128, 128, 3)\n",
      "0.85194993\n",
      "[Epoch 2/10] [Batch 750/1081] [D loss: 0.216889] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.458471] time: 0:23:34.849546\n",
      "(10, 128, 128, 3)\n",
      "0.95532256\n",
      "[Epoch 2/10] [Batch 751/1081] [D loss: 0.216703] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.819246] time: 0:23:35.248273\n",
      "(10, 128, 128, 3)\n",
      "0.9759738\n",
      "[Epoch 2/10] [Batch 752/1081] [D loss: 0.215837] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.613329] time: 0:23:35.626128\n",
      "(10, 128, 128, 3)\n",
      "0.9056535\n",
      "[Epoch 2/10] [Batch 753/1081] [D loss: 0.215741] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.017285] time: 0:23:36.036420\n",
      "(10, 128, 128, 3)\n",
      "0.8990879\n",
      "[Epoch 2/10] [Batch 754/1081] [D loss: 0.215719] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.278499] time: 0:23:36.427342\n",
      "(10, 128, 128, 3)\n",
      "0.9048872\n",
      "[Epoch 2/10] [Batch 755/1081] [D loss: 0.215589] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.360746] time: 0:23:36.866241\n",
      "(10, 128, 128, 3)\n",
      "0.86062384\n",
      "[Epoch 2/10] [Batch 756/1081] [D loss: 0.215196] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.748278] time: 0:23:37.264452\n",
      "(10, 128, 128, 3)\n",
      "0.91171837\n",
      "[Epoch 2/10] [Batch 757/1081] [D loss: 0.214608] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.459081] time: 0:23:37.672305\n",
      "(10, 128, 128, 3)\n",
      "0.92954993\n",
      "[Epoch 2/10] [Batch 758/1081] [D loss: 0.214398] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.580011] time: 0:23:38.087583\n",
      "(10, 128, 128, 3)\n",
      "0.97009736\n",
      "[Epoch 2/10] [Batch 759/1081] [D loss: 0.214213] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.354892] time: 0:23:38.517045\n",
      "(10, 128, 128, 3)\n",
      "0.9104097\n",
      "[Epoch 2/10] [Batch 760/1081] [D loss: 0.214313] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.238556] time: 0:23:38.904142\n",
      "(10, 128, 128, 3)\n",
      "0.91950655\n",
      "[Epoch 2/10] [Batch 761/1081] [D loss: 0.213872] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.118479] time: 0:23:39.294947\n",
      "(10, 128, 128, 3)\n",
      "0.91503555\n",
      "[Epoch 2/10] [Batch 762/1081] [D loss: 0.213859] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.092990] time: 0:23:39.721895\n",
      "(10, 128, 128, 3)\n",
      "0.91529065\n",
      "[Epoch 2/10] [Batch 763/1081] [D loss: 0.213777] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.278708] time: 0:23:40.144629\n",
      "(10, 128, 128, 3)\n",
      "0.90572596\n",
      "[Epoch 2/10] [Batch 764/1081] [D loss: 0.214025] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.990568] time: 0:23:40.561593\n",
      "(10, 128, 128, 3)\n",
      "0.9125679\n",
      "[Epoch 2/10] [Batch 765/1081] [D loss: 0.212789] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.357267] time: 0:23:40.971978\n",
      "(10, 128, 128, 3)\n",
      "0.8414076\n",
      "[Epoch 2/10] [Batch 766/1081] [D loss: 0.212965] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.578207] time: 0:23:41.422837\n",
      "(10, 128, 128, 3)\n",
      "0.9219927\n",
      "[Epoch 2/10] [Batch 767/1081] [D loss: 0.212658] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.987577] time: 0:23:41.835200\n",
      "(10, 128, 128, 3)\n",
      "0.9337297\n",
      "[Epoch 2/10] [Batch 768/1081] [D loss: 0.212694] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.102473] time: 0:23:42.226935\n",
      "(10, 128, 128, 3)\n",
      "0.89075106\n",
      "[Epoch 2/10] [Batch 769/1081] [D loss: 0.211798] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.641115] time: 0:23:42.640011\n",
      "(10, 128, 128, 3)\n",
      "0.8743408\n",
      "[Epoch 2/10] [Batch 770/1081] [D loss: 0.212534] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.888998] time: 0:23:43.046013\n",
      "(10, 128, 128, 3)\n",
      "0.90415883\n",
      "[Epoch 2/10] [Batch 771/1081] [D loss: 0.211607] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.318300] time: 0:23:43.452693\n",
      "(10, 128, 128, 3)\n",
      "0.9520127\n",
      "[Epoch 2/10] [Batch 772/1081] [D loss: 0.211014] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.217326] time: 0:23:43.844971\n",
      "(10, 128, 128, 3)\n",
      "0.90765494\n",
      "[Epoch 2/10] [Batch 773/1081] [D loss: 0.210780] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.703911] time: 0:23:44.239616\n",
      "(10, 128, 128, 3)\n",
      "0.9287215\n",
      "[Epoch 2/10] [Batch 774/1081] [D loss: 0.210680] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.566470] time: 0:23:44.645193\n",
      "(10, 128, 128, 3)\n",
      "0.9319851\n",
      "[Epoch 2/10] [Batch 775/1081] [D loss: 0.210673] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.109647] time: 0:23:45.030367\n",
      "(10, 128, 128, 3)\n",
      "0.9259446\n",
      "[Epoch 2/10] [Batch 776/1081] [D loss: 0.210533] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.165649] time: 0:23:45.465107\n",
      "(10, 128, 128, 3)\n",
      "0.93325925\n",
      "[Epoch 2/10] [Batch 777/1081] [D loss: 0.209903] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.930799] time: 0:23:45.882199\n",
      "(10, 128, 128, 3)\n",
      "0.8886642\n",
      "[Epoch 2/10] [Batch 778/1081] [D loss: 0.209743] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.034183] time: 0:23:46.276670\n",
      "(10, 128, 128, 3)\n",
      "0.94618124\n",
      "[Epoch 2/10] [Batch 779/1081] [D loss: 0.209535] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.099710] time: 0:23:46.701456\n",
      "(10, 128, 128, 3)\n",
      "0.87223357\n",
      "[Epoch 2/10] [Batch 780/1081] [D loss: 0.209739] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.496735] time: 0:23:47.103327\n",
      "(10, 128, 128, 3)\n",
      "0.9080928\n",
      "[Epoch 2/10] [Batch 781/1081] [D loss: 0.209230] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.033556] time: 0:23:47.508722\n",
      "(10, 128, 128, 3)\n",
      "0.91428596\n",
      "[Epoch 2/10] [Batch 782/1081] [D loss: 0.209064] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.274976] time: 0:23:47.889126\n",
      "(10, 128, 128, 3)\n",
      "0.9367923\n",
      "[Epoch 2/10] [Batch 783/1081] [D loss: 0.208797] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.772134] time: 0:23:48.288259\n",
      "(10, 128, 128, 3)\n",
      "0.93777204\n",
      "[Epoch 2/10] [Batch 784/1081] [D loss: 0.208354] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.931366] time: 0:23:48.722792\n",
      "(10, 128, 128, 3)\n",
      "0.90154123\n",
      "[Epoch 2/10] [Batch 785/1081] [D loss: 0.208542] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.281339] time: 0:23:49.132921\n",
      "(10, 128, 128, 3)\n",
      "0.915602\n",
      "[Epoch 2/10] [Batch 786/1081] [D loss: 0.208474] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.231519] time: 0:23:49.528797\n",
      "(10, 128, 128, 3)\n",
      "0.91524583\n",
      "[Epoch 2/10] [Batch 787/1081] [D loss: 0.210587] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.763161] time: 0:23:49.953100\n",
      "(10, 128, 128, 3)\n",
      "0.88389105\n",
      "[Epoch 2/10] [Batch 788/1081] [D loss: 0.212679] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.060331] time: 0:23:50.384677\n",
      "(10, 128, 128, 3)\n",
      "0.8461577\n",
      "[Epoch 2/10] [Batch 789/1081] [D loss: 0.211712] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.255081] time: 0:23:50.808813\n",
      "(10, 128, 128, 3)\n",
      "0.8623505\n",
      "[Epoch 2/10] [Batch 790/1081] [D loss: 0.212225] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.928350] time: 0:23:51.200647\n",
      "(10, 128, 128, 3)\n",
      "0.94185764\n",
      "[Epoch 2/10] [Batch 791/1081] [D loss: 0.208369] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.342482] time: 0:23:51.595573\n",
      "(10, 128, 128, 3)\n",
      "0.9290468\n",
      "[Epoch 2/10] [Batch 792/1081] [D loss: 0.207083] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.501200] time: 0:23:51.995994\n",
      "(10, 128, 128, 3)\n",
      "0.8820513\n",
      "[Epoch 2/10] [Batch 793/1081] [D loss: 0.206676] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.484159] time: 0:23:52.440251\n",
      "(10, 128, 128, 3)\n",
      "0.8852827\n",
      "[Epoch 2/10] [Batch 794/1081] [D loss: 0.208074] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.736208] time: 0:23:52.855320\n",
      "(10, 128, 128, 3)\n",
      "0.9220269\n",
      "[Epoch 2/10] [Batch 795/1081] [D loss: 0.209299] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.194443] time: 0:23:53.245347\n",
      "(10, 128, 128, 3)\n",
      "0.9195266\n",
      "[Epoch 2/10] [Batch 796/1081] [D loss: 0.208463] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.609052] time: 0:23:53.667580\n",
      "(10, 128, 128, 3)\n",
      "0.9071989\n",
      "[Epoch 2/10] [Batch 797/1081] [D loss: 0.207221] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.230856] time: 0:23:54.079212\n",
      "(10, 128, 128, 3)\n",
      "0.9435823\n",
      "[Epoch 2/10] [Batch 798/1081] [D loss: 0.206869] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.283030] time: 0:23:54.491062\n",
      "(10, 128, 128, 3)\n",
      "0.9356311\n",
      "[Epoch 2/10] [Batch 799/1081] [D loss: 0.210434] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.941577] time: 0:23:54.912839\n",
      "(10, 128, 128, 3)\n",
      "0.93509907\n",
      "[Epoch 2/10] [Batch 800/1081] [D loss: 0.206788] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.321838] time: 0:23:55.302950\n",
      "(10, 128, 128, 3)\n",
      "0.93120295\n",
      "[Epoch 2/10] [Batch 801/1081] [D loss: 0.214013] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.783831] time: 0:23:55.687301\n",
      "(10, 128, 128, 3)\n",
      "0.92372054\n",
      "[Epoch 2/10] [Batch 802/1081] [D loss: 0.210385] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.885981] time: 0:23:56.115965\n",
      "(10, 128, 128, 3)\n",
      "0.91507286\n",
      "[Epoch 2/10] [Batch 803/1081] [D loss: 0.205096] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.512491] time: 0:23:56.522587\n",
      "(10, 128, 128, 3)\n",
      "0.9072993\n",
      "[Epoch 2/10] [Batch 804/1081] [D loss: 0.204582] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.371976] time: 0:23:56.900990\n",
      "(10, 128, 128, 3)\n",
      "0.8920571\n",
      "[Epoch 2/10] [Batch 805/1081] [D loss: 0.205911] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.289751] time: 0:23:57.307961\n",
      "(10, 128, 128, 3)\n",
      "0.9655948\n",
      "[Epoch 2/10] [Batch 806/1081] [D loss: 0.204305] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.595146] time: 0:23:57.712811\n",
      "(10, 128, 128, 3)\n",
      "0.8813383\n",
      "[Epoch 2/10] [Batch 807/1081] [D loss: 0.207113] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.673297] time: 0:23:58.104539\n",
      "(10, 128, 128, 3)\n",
      "0.8877489\n",
      "[Epoch 2/10] [Batch 808/1081] [D loss: 0.203476] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.653625] time: 0:23:58.533675\n",
      "(10, 128, 128, 3)\n",
      "0.89950895\n",
      "[Epoch 2/10] [Batch 809/1081] [D loss: 0.203184] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.380510] time: 0:23:58.940781\n",
      "(10, 128, 128, 3)\n",
      "0.84616375\n",
      "[Epoch 2/10] [Batch 810/1081] [D loss: 0.203771] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.671270] time: 0:23:59.323880\n",
      "(10, 128, 128, 3)\n",
      "0.9745299\n",
      "[Epoch 2/10] [Batch 811/1081] [D loss: 0.202823] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.544588] time: 0:23:59.713538\n",
      "(10, 128, 128, 3)\n",
      "0.8994829\n",
      "[Epoch 2/10] [Batch 812/1081] [D loss: 0.202677] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.493677] time: 0:24:00.115035\n",
      "(10, 128, 128, 3)\n",
      "0.9290095\n",
      "[Epoch 2/10] [Batch 813/1081] [D loss: 0.202593] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.255926] time: 0:24:00.527499\n",
      "(10, 128, 128, 3)\n",
      "0.8984051\n",
      "[Epoch 2/10] [Batch 814/1081] [D loss: 0.202476] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.103437] time: 0:24:00.927042\n",
      "(10, 128, 128, 3)\n",
      "0.91105366\n",
      "[Epoch 2/10] [Batch 815/1081] [D loss: 0.202869] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.216112] time: 0:24:01.315151\n",
      "(10, 128, 128, 3)\n",
      "0.88102126\n",
      "[Epoch 2/10] [Batch 816/1081] [D loss: 0.202204] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.897215] time: 0:24:01.708761\n",
      "(10, 128, 128, 3)\n",
      "0.9163375\n",
      "[Epoch 2/10] [Batch 817/1081] [D loss: 0.201743] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.510889] time: 0:24:02.116723\n",
      "(10, 128, 128, 3)\n",
      "0.9405775\n",
      "[Epoch 2/10] [Batch 818/1081] [D loss: 0.201310] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.887785] time: 0:24:02.515489\n",
      "(10, 128, 128, 3)\n",
      "0.8867795\n",
      "[Epoch 2/10] [Batch 819/1081] [D loss: 0.201132] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.792448] time: 0:24:02.937283\n",
      "(10, 128, 128, 3)\n",
      "0.9296387\n",
      "[Epoch 2/10] [Batch 820/1081] [D loss: 0.200684] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.637441] time: 0:24:03.330188\n",
      "(10, 128, 128, 3)\n",
      "0.8946679\n",
      "[Epoch 2/10] [Batch 821/1081] [D loss: 0.200438] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.715935] time: 0:24:03.711955\n",
      "(10, 128, 128, 3)\n",
      "0.8550946\n",
      "[Epoch 2/10] [Batch 822/1081] [D loss: 0.200824] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.544378] time: 0:24:04.130976\n",
      "(10, 128, 128, 3)\n",
      "0.91583395\n",
      "[Epoch 2/10] [Batch 823/1081] [D loss: 0.202817] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.689399] time: 0:24:04.520195\n",
      "(10, 128, 128, 3)\n",
      "0.956999\n",
      "[Epoch 2/10] [Batch 824/1081] [D loss: 0.200683] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.957041] time: 0:24:04.908964\n",
      "(10, 128, 128, 3)\n",
      "0.89218885\n",
      "[Epoch 2/10] [Batch 825/1081] [D loss: 0.201106] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.663916] time: 0:24:05.352412\n",
      "(10, 128, 128, 3)\n",
      "0.88897634\n",
      "[Epoch 2/10] [Batch 826/1081] [D loss: 0.203914] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.007713] time: 0:24:05.763577\n",
      "(10, 128, 128, 3)\n",
      "0.9267605\n",
      "[Epoch 2/10] [Batch 827/1081] [D loss: 0.202203] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.536366] time: 0:24:06.196770\n",
      "(10, 128, 128, 3)\n",
      "0.922983\n",
      "[Epoch 2/10] [Batch 828/1081] [D loss: 0.199519] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.034955] time: 0:24:06.576825\n",
      "(10, 128, 128, 3)\n",
      "0.9012943\n",
      "[Epoch 2/10] [Batch 829/1081] [D loss: 0.199608] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.086409] time: 0:24:06.974404\n",
      "(10, 128, 128, 3)\n",
      "0.8545654\n",
      "[Epoch 2/10] [Batch 830/1081] [D loss: 0.199207] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.964587] time: 0:24:07.375620\n",
      "(10, 128, 128, 3)\n",
      "0.92540264\n",
      "[Epoch 2/10] [Batch 831/1081] [D loss: 0.198844] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.226561] time: 0:24:07.778568\n",
      "(10, 128, 128, 3)\n",
      "0.8383269\n",
      "[Epoch 2/10] [Batch 832/1081] [D loss: 0.199082] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.586429] time: 0:24:08.173342\n",
      "(10, 128, 128, 3)\n",
      "0.90778446\n",
      "[Epoch 2/10] [Batch 833/1081] [D loss: 0.199674] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.571465] time: 0:24:08.558162\n",
      "(10, 128, 128, 3)\n",
      "0.86687535\n",
      "[Epoch 2/10] [Batch 834/1081] [D loss: 0.200176] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.913443] time: 0:24:08.966022\n",
      "(10, 128, 128, 3)\n",
      "0.90837544\n",
      "[Epoch 2/10] [Batch 835/1081] [D loss: 0.201093] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.274121] time: 0:24:09.387805\n",
      "(10, 128, 128, 3)\n",
      "0.94564843\n",
      "[Epoch 2/10] [Batch 836/1081] [D loss: 0.200105] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.445622] time: 0:24:09.792056\n",
      "(10, 128, 128, 3)\n",
      "0.93233985\n",
      "[Epoch 2/10] [Batch 837/1081] [D loss: 0.200576] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.506869] time: 0:24:10.189697\n",
      "(10, 128, 128, 3)\n",
      "0.9574044\n",
      "[Epoch 2/10] [Batch 838/1081] [D loss: 0.197465] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.515475] time: 0:24:10.613140\n",
      "(10, 128, 128, 3)\n",
      "0.9422553\n",
      "[Epoch 2/10] [Batch 839/1081] [D loss: 0.197549] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.855060] time: 0:24:10.991586\n",
      "(10, 128, 128, 3)\n",
      "0.9810252\n",
      "[Epoch 2/10] [Batch 840/1081] [D loss: 0.197122] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.457338] time: 0:24:11.387824\n",
      "(10, 128, 128, 3)\n",
      "0.8793252\n",
      "[Epoch 2/10] [Batch 841/1081] [D loss: 0.196646] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.078547] time: 0:24:11.765397\n",
      "(10, 128, 128, 3)\n",
      "0.92126113\n",
      "[Epoch 2/10] [Batch 842/1081] [D loss: 0.197074] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.835398] time: 0:24:12.185765\n",
      "(10, 128, 128, 3)\n",
      "0.9452519\n",
      "[Epoch 2/10] [Batch 843/1081] [D loss: 0.196504] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.619034] time: 0:24:12.601379\n",
      "(10, 128, 128, 3)\n",
      "0.8992719\n",
      "[Epoch 2/10] [Batch 844/1081] [D loss: 0.195622] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.085680] time: 0:24:13.014147\n",
      "(10, 128, 128, 3)\n",
      "0.8845236\n",
      "[Epoch 2/10] [Batch 845/1081] [D loss: 0.196099] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.394430] time: 0:24:13.439334\n",
      "(10, 128, 128, 3)\n",
      "0.90687007\n",
      "[Epoch 2/10] [Batch 846/1081] [D loss: 0.196025] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.510458] time: 0:24:13.834086\n",
      "(10, 128, 128, 3)\n",
      "0.8757949\n",
      "[Epoch 2/10] [Batch 847/1081] [D loss: 0.195948] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.562610] time: 0:24:14.225443\n",
      "(10, 128, 128, 3)\n",
      "0.9283933\n",
      "[Epoch 2/10] [Batch 848/1081] [D loss: 0.196073] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.227823] time: 0:24:14.613853\n",
      "(10, 128, 128, 3)\n",
      "0.9001636\n",
      "[Epoch 2/10] [Batch 849/1081] [D loss: 0.196370] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.352046] time: 0:24:15.035915\n",
      "(10, 128, 128, 3)\n",
      "0.9119176\n",
      "[Epoch 2/10] [Batch 850/1081] [D loss: 0.195365] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.936525] time: 0:24:15.469408\n",
      "(10, 128, 128, 3)\n",
      "0.9148812\n",
      "[Epoch 2/10] [Batch 851/1081] [D loss: 0.195542] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.836334] time: 0:24:15.865878\n",
      "(10, 128, 128, 3)\n",
      "0.91678077\n",
      "[Epoch 2/10] [Batch 852/1081] [D loss: 0.195212] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.037554] time: 0:24:16.260193\n",
      "(10, 128, 128, 3)\n",
      "0.9287548\n",
      "[Epoch 2/10] [Batch 853/1081] [D loss: 0.194258] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.109265] time: 0:24:16.672268\n",
      "(10, 128, 128, 3)\n",
      "0.9510937\n",
      "[Epoch 2/10] [Batch 854/1081] [D loss: 0.194286] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.932653] time: 0:24:17.062470\n",
      "(10, 128, 128, 3)\n",
      "0.9279542\n",
      "[Epoch 2/10] [Batch 855/1081] [D loss: 0.193193] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.555435] time: 0:24:17.471851\n",
      "(10, 128, 128, 3)\n",
      "0.910628\n",
      "[Epoch 2/10] [Batch 856/1081] [D loss: 0.193907] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.567731] time: 0:24:17.889456\n",
      "(10, 128, 128, 3)\n",
      "0.92769927\n",
      "[Epoch 2/10] [Batch 857/1081] [D loss: 0.193036] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.824597] time: 0:24:18.316070\n",
      "(10, 128, 128, 3)\n",
      "0.8942904\n",
      "[Epoch 2/10] [Batch 858/1081] [D loss: 0.193137] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.108751] time: 0:24:18.716151\n",
      "(10, 128, 128, 3)\n",
      "0.8957742\n",
      "[Epoch 2/10] [Batch 859/1081] [D loss: 0.193000] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.490469] time: 0:24:19.137774\n",
      "(10, 128, 128, 3)\n",
      "0.9138525\n",
      "[Epoch 2/10] [Batch 860/1081] [D loss: 0.192284] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.796661] time: 0:24:19.519095\n",
      "(10, 128, 128, 3)\n",
      "0.9591983\n",
      "[Epoch 2/10] [Batch 861/1081] [D loss: 0.775503] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 32.911003] time: 0:24:19.942327\n",
      "(10, 128, 128, 3)\n",
      "0.9475846\n",
      "[Epoch 2/10] [Batch 862/1081] [D loss: 0.507400] [D acc: 0.50 (0.80 real, 0.20 fake)] [G loss: 71.757088] time: 0:24:20.356288\n",
      "(10, 128, 128, 3)\n",
      "0.5072065\n",
      "[Epoch 2/10] [Batch 863/1081] [D loss: 0.587693] [D acc: 0.30 (0.00 real, 0.60 fake)] [G loss: 19.966663] time: 0:24:20.756007\n",
      "(10, 128, 128, 3)\n",
      "0.35891664\n",
      "[Epoch 2/10] [Batch 864/1081] [D loss: 0.668616] [D acc: 0.15 (0.00 real, 0.30 fake)] [G loss: 20.774128] time: 0:24:21.175291\n",
      "(10, 128, 128, 3)\n",
      "0.23034197\n",
      "[Epoch 2/10] [Batch 865/1081] [D loss: 0.406068] [D acc: 0.55 (0.10 real, 1.00 fake)] [G loss: 17.147480] time: 0:24:21.586565\n",
      "(10, 128, 128, 3)\n",
      "0.34260204\n",
      "[Epoch 2/10] [Batch 866/1081] [D loss: 0.490944] [D acc: 0.40 (0.30 real, 0.50 fake)] [G loss: 14.333156] time: 0:24:21.996470\n",
      "(10, 128, 128, 3)\n",
      "0.4454019\n",
      "[Epoch 2/10] [Batch 867/1081] [D loss: 0.744713] [D acc: 0.10 (0.00 real, 0.20 fake)] [G loss: 16.975487] time: 0:24:22.378734\n",
      "(10, 128, 128, 3)\n",
      "0.38079736\n",
      "[Epoch 2/10] [Batch 868/1081] [D loss: 0.707329] [D acc: 0.20 (0.00 real, 0.40 fake)] [G loss: 15.637571] time: 0:24:22.783541\n",
      "(10, 128, 128, 3)\n",
      "0.57005256\n",
      "[Epoch 2/10] [Batch 869/1081] [D loss: 0.393766] [D acc: 0.80 (0.90 real, 0.70 fake)] [G loss: 14.970548] time: 0:24:23.182912\n",
      "(10, 128, 128, 3)\n",
      "0.82693523\n",
      "[Epoch 2/10] [Batch 870/1081] [D loss: 0.551848] [D acc: 0.30 (0.10 real, 0.50 fake)] [G loss: 13.640058] time: 0:24:23.617820\n",
      "(10, 128, 128, 3)\n",
      "0.890187\n",
      "[Epoch 2/10] [Batch 871/1081] [D loss: 0.302576] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 14.142367] time: 0:24:24.003413\n",
      "(10, 128, 128, 3)\n",
      "0.887552\n",
      "[Epoch 2/10] [Batch 872/1081] [D loss: 0.432022] [D acc: 0.65 (0.30 real, 1.00 fake)] [G loss: 15.238035] time: 0:24:24.408983\n",
      "(10, 128, 128, 3)\n",
      "0.89630914\n",
      "[Epoch 2/10] [Batch 873/1081] [D loss: 0.525152] [D acc: 0.55 (1.00 real, 0.10 fake)] [G loss: 14.403180] time: 0:24:24.803711\n",
      "(10, 128, 128, 3)\n",
      "0.845113\n",
      "[Epoch 2/10] [Batch 874/1081] [D loss: 0.391784] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 14.550615] time: 0:24:25.221120\n",
      "(10, 128, 128, 3)\n",
      "0.90858203\n",
      "[Epoch 2/10] [Batch 875/1081] [D loss: 0.239231] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.254625] time: 0:24:25.638632\n",
      "(10, 128, 128, 3)\n",
      "0.96782964\n",
      "[Epoch 2/10] [Batch 876/1081] [D loss: 0.286452] [D acc: 0.90 (0.90 real, 0.90 fake)] [G loss: 13.249776] time: 0:24:26.047579\n",
      "(10, 128, 128, 3)\n",
      "0.9027038\n",
      "[Epoch 2/10] [Batch 877/1081] [D loss: 0.248754] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.954306] time: 0:24:26.431859\n",
      "(10, 128, 128, 3)\n",
      "0.915658\n",
      "[Epoch 2/10] [Batch 878/1081] [D loss: 0.737064] [D acc: 0.30 (0.60 real, 0.00 fake)] [G loss: 12.862024] time: 0:24:26.852444\n",
      "(10, 128, 128, 3)\n",
      "0.93591756\n",
      "[Epoch 2/10] [Batch 879/1081] [D loss: 0.474952] [D acc: 0.55 (0.20 real, 0.90 fake)] [G loss: 13.641741] time: 0:24:27.276225\n",
      "(10, 128, 128, 3)\n",
      "0.8810795\n",
      "[Epoch 2/10] [Batch 880/1081] [D loss: 0.281359] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.426404] time: 0:24:27.682381\n",
      "(10, 128, 128, 3)\n",
      "0.9057992\n",
      "[Epoch 2/10] [Batch 881/1081] [D loss: 0.248233] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.932979] time: 0:24:28.098487\n",
      "(10, 128, 128, 3)\n",
      "0.9165632\n",
      "[Epoch 2/10] [Batch 882/1081] [D loss: 0.265573] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.522751] time: 0:24:28.514041\n",
      "(10, 128, 128, 3)\n",
      "0.8871015\n",
      "[Epoch 2/10] [Batch 883/1081] [D loss: 0.246876] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.799765] time: 0:24:28.921478\n",
      "(10, 128, 128, 3)\n",
      "0.90723366\n",
      "[Epoch 2/10] [Batch 884/1081] [D loss: 0.219994] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.408043] time: 0:24:29.330708\n",
      "(10, 128, 128, 3)\n",
      "0.91248745\n",
      "[Epoch 2/10] [Batch 885/1081] [D loss: 0.238350] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 14.719248] time: 0:24:29.723374\n",
      "(10, 128, 128, 3)\n",
      "0.9751974\n",
      "[Epoch 2/10] [Batch 886/1081] [D loss: 0.218186] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.979105] time: 0:24:30.112983\n",
      "(10, 128, 128, 3)\n",
      "0.9387993\n",
      "[Epoch 2/10] [Batch 887/1081] [D loss: 0.226192] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.891504] time: 0:24:30.535182\n",
      "(10, 128, 128, 3)\n",
      "0.8272331\n",
      "[Epoch 2/10] [Batch 888/1081] [D loss: 0.232308] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 14.762108] time: 0:24:30.940029\n",
      "(10, 128, 128, 3)\n",
      "0.92266965\n",
      "[Epoch 2/10] [Batch 889/1081] [D loss: 0.219412] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.800937] time: 0:24:31.341112\n",
      "(10, 128, 128, 3)\n",
      "0.8880863\n",
      "[Epoch 2/10] [Batch 890/1081] [D loss: 0.209484] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.114843] time: 0:24:31.769153\n",
      "(10, 128, 128, 3)\n",
      "0.9495616\n",
      "[Epoch 2/10] [Batch 891/1081] [D loss: 0.224407] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.972911] time: 0:24:32.218863\n",
      "(10, 128, 128, 3)\n",
      "0.90160245\n",
      "[Epoch 2/10] [Batch 892/1081] [D loss: 0.213619] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.966616] time: 0:24:32.625935\n",
      "(10, 128, 128, 3)\n",
      "0.94164723\n",
      "[Epoch 2/10] [Batch 893/1081] [D loss: 0.227246] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.585106] time: 0:24:33.027564\n",
      "(10, 128, 128, 3)\n",
      "0.90761805\n",
      "[Epoch 2/10] [Batch 894/1081] [D loss: 0.212421] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.613378] time: 0:24:33.424333\n",
      "(10, 128, 128, 3)\n",
      "0.85588217\n",
      "[Epoch 2/10] [Batch 895/1081] [D loss: 0.211425] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.880348] time: 0:24:33.876193\n",
      "(10, 128, 128, 3)\n",
      "0.9458247\n",
      "[Epoch 2/10] [Batch 896/1081] [D loss: 0.211509] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.195478] time: 0:24:34.298497\n",
      "(10, 128, 128, 3)\n",
      "0.871922\n",
      "[Epoch 2/10] [Batch 897/1081] [D loss: 0.218990] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.531008] time: 0:24:34.683712\n",
      "(10, 128, 128, 3)\n",
      "0.8986829\n",
      "[Epoch 2/10] [Batch 898/1081] [D loss: 0.208009] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.223058] time: 0:24:35.060884\n",
      "(10, 128, 128, 3)\n",
      "0.8950696\n",
      "[Epoch 2/10] [Batch 899/1081] [D loss: 0.220919] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.729388] time: 0:24:35.451020\n",
      "(10, 128, 128, 3)\n",
      "0.9035788\n",
      "[Epoch 2/10] [Batch 900/1081] [D loss: 0.205555] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.544115] time: 0:24:35.863289\n",
      "(10, 128, 128, 3)\n",
      "0.94836444\n",
      "[Epoch 2/10] [Batch 901/1081] [D loss: 0.207412] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.974521] time: 0:24:36.250098\n",
      "(10, 128, 128, 3)\n",
      "0.9391605\n",
      "[Epoch 2/10] [Batch 902/1081] [D loss: 0.205528] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.083239] time: 0:24:36.644099\n",
      "(10, 128, 128, 3)\n",
      "0.9710948\n",
      "[Epoch 2/10] [Batch 903/1081] [D loss: 0.205461] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.819181] time: 0:24:37.077715\n",
      "(10, 128, 128, 3)\n",
      "0.92229414\n",
      "[Epoch 2/10] [Batch 904/1081] [D loss: 0.209345] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.840254] time: 0:24:37.479821\n",
      "(10, 128, 128, 3)\n",
      "0.90996486\n",
      "[Epoch 2/10] [Batch 905/1081] [D loss: 0.208139] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.283926] time: 0:24:37.891999\n",
      "(10, 128, 128, 3)\n",
      "0.9061709\n",
      "[Epoch 2/10] [Batch 906/1081] [D loss: 0.209732] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.987534] time: 0:24:38.308297\n",
      "(10, 128, 128, 3)\n",
      "0.89968896\n",
      "[Epoch 2/10] [Batch 907/1081] [D loss: 0.204741] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.447888] time: 0:24:38.704838\n",
      "(10, 128, 128, 3)\n",
      "0.9110202\n",
      "[Epoch 2/10] [Batch 908/1081] [D loss: 0.204296] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.061897] time: 0:24:39.090985\n",
      "(10, 128, 128, 3)\n",
      "0.90214115\n",
      "[Epoch 2/10] [Batch 909/1081] [D loss: 0.211880] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.715474] time: 0:24:39.507479\n",
      "(10, 128, 128, 3)\n",
      "0.9208663\n",
      "[Epoch 2/10] [Batch 910/1081] [D loss: 0.204866] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.050224] time: 0:24:39.931722\n",
      "(10, 128, 128, 3)\n",
      "0.889751\n",
      "[Epoch 2/10] [Batch 911/1081] [D loss: 0.201547] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.301532] time: 0:24:40.329373\n",
      "(10, 128, 128, 3)\n",
      "0.8758347\n",
      "[Epoch 2/10] [Batch 912/1081] [D loss: 0.242132] [D acc: 0.90 (1.00 real, 0.80 fake)] [G loss: 15.214005] time: 0:24:40.734350\n",
      "(10, 128, 128, 3)\n",
      "0.9045779\n",
      "[Epoch 2/10] [Batch 913/1081] [D loss: 0.215898] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.963249] time: 0:24:41.161778\n",
      "(10, 128, 128, 3)\n",
      "0.9557037\n",
      "[Epoch 2/10] [Batch 914/1081] [D loss: 0.204349] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.989268] time: 0:24:41.596468\n",
      "(10, 128, 128, 3)\n",
      "0.8566219\n",
      "[Epoch 2/10] [Batch 915/1081] [D loss: 0.205248] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.694799] time: 0:24:42.002588\n",
      "(10, 128, 128, 3)\n",
      "0.9093039\n",
      "[Epoch 2/10] [Batch 916/1081] [D loss: 0.578577] [D acc: 0.50 (0.10 real, 0.90 fake)] [G loss: 13.219281] time: 0:24:42.412901\n",
      "(10, 128, 128, 3)\n",
      "0.927038\n",
      "[Epoch 2/10] [Batch 917/1081] [D loss: 0.273710] [D acc: 0.90 (1.00 real, 0.80 fake)] [G loss: 14.188902] time: 0:24:42.817698\n",
      "(10, 128, 128, 3)\n",
      "0.87352866\n",
      "[Epoch 2/10] [Batch 918/1081] [D loss: 0.211408] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.036886] time: 0:24:43.216424\n",
      "(10, 128, 128, 3)\n",
      "0.93378514\n",
      "[Epoch 2/10] [Batch 919/1081] [D loss: 0.245543] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.051783] time: 0:24:43.632579\n",
      "(10, 128, 128, 3)\n",
      "0.8916178\n",
      "[Epoch 2/10] [Batch 920/1081] [D loss: 0.217617] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.291998] time: 0:24:44.016295\n",
      "(10, 128, 128, 3)\n",
      "0.932851\n",
      "[Epoch 2/10] [Batch 921/1081] [D loss: 0.213907] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.984668] time: 0:24:44.433023\n",
      "(10, 128, 128, 3)\n",
      "0.9200206\n",
      "[Epoch 2/10] [Batch 922/1081] [D loss: 0.205579] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.771521] time: 0:24:44.844026\n",
      "(10, 128, 128, 3)\n",
      "0.87169075\n",
      "[Epoch 2/10] [Batch 923/1081] [D loss: 0.204540] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.974724] time: 0:24:45.250707\n",
      "(10, 128, 128, 3)\n",
      "0.9159746\n",
      "[Epoch 2/10] [Batch 924/1081] [D loss: 0.209113] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.585615] time: 0:24:45.654069\n",
      "(10, 128, 128, 3)\n",
      "0.90404916\n",
      "[Epoch 2/10] [Batch 925/1081] [D loss: 0.203171] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.440298] time: 0:24:46.078945\n",
      "(10, 128, 128, 3)\n",
      "0.95929426\n",
      "[Epoch 2/10] [Batch 926/1081] [D loss: 0.201898] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.226112] time: 0:24:46.471184\n",
      "(10, 128, 128, 3)\n",
      "0.91094565\n",
      "[Epoch 2/10] [Batch 927/1081] [D loss: 0.200558] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.818789] time: 0:24:46.876138\n",
      "(10, 128, 128, 3)\n",
      "0.8864481\n",
      "[Epoch 2/10] [Batch 928/1081] [D loss: 0.208260] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.384596] time: 0:24:47.296878\n",
      "(10, 128, 128, 3)\n",
      "0.9115224\n",
      "[Epoch 2/10] [Batch 929/1081] [D loss: 0.201429] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.835650] time: 0:24:47.730092\n",
      "(10, 128, 128, 3)\n",
      "0.90748596\n",
      "[Epoch 2/10] [Batch 930/1081] [D loss: 0.200461] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.610272] time: 0:24:48.148271\n",
      "(10, 128, 128, 3)\n",
      "0.91374326\n",
      "[Epoch 2/10] [Batch 931/1081] [D loss: 0.199349] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.617661] time: 0:24:48.537998\n",
      "(10, 128, 128, 3)\n",
      "0.89984775\n",
      "[Epoch 2/10] [Batch 932/1081] [D loss: 0.201479] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.606814] time: 0:24:48.935896\n",
      "(10, 128, 128, 3)\n",
      "0.91517186\n",
      "[Epoch 2/10] [Batch 933/1081] [D loss: 0.201270] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.809713] time: 0:24:49.350048\n",
      "(10, 128, 128, 3)\n",
      "0.92209727\n",
      "[Epoch 2/10] [Batch 934/1081] [D loss: 0.199048] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.988406] time: 0:24:49.755976\n",
      "(10, 128, 128, 3)\n",
      "0.909396\n",
      "[Epoch 2/10] [Batch 935/1081] [D loss: 0.202584] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.018942] time: 0:24:50.149245\n",
      "(10, 128, 128, 3)\n",
      "0.91107005\n",
      "[Epoch 2/10] [Batch 936/1081] [D loss: 0.201581] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.388147] time: 0:24:50.559724\n",
      "(10, 128, 128, 3)\n",
      "0.9662113\n",
      "[Epoch 2/10] [Batch 937/1081] [D loss: 0.198971] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.674060] time: 0:24:50.975112\n",
      "(10, 128, 128, 3)\n",
      "0.9129047\n",
      "[Epoch 2/10] [Batch 938/1081] [D loss: 0.198160] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.497447] time: 0:24:51.360872\n",
      "(10, 128, 128, 3)\n",
      "0.9272163\n",
      "[Epoch 2/10] [Batch 939/1081] [D loss: 0.199813] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.072621] time: 0:24:51.736200\n",
      "(10, 128, 128, 3)\n",
      "0.9202759\n",
      "[Epoch 2/10] [Batch 940/1081] [D loss: 0.197088] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.176428] time: 0:24:52.155670\n",
      "(10, 128, 128, 3)\n",
      "0.9143198\n",
      "[Epoch 2/10] [Batch 941/1081] [D loss: 0.202716] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.825449] time: 0:24:52.568687\n",
      "(10, 128, 128, 3)\n",
      "0.9191857\n",
      "[Epoch 2/10] [Batch 942/1081] [D loss: 0.197523] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.985758] time: 0:24:52.956699\n",
      "(10, 128, 128, 3)\n",
      "0.88717264\n",
      "[Epoch 2/10] [Batch 943/1081] [D loss: 0.199667] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.281717] time: 0:24:53.394554\n",
      "(10, 128, 128, 3)\n",
      "0.9067128\n",
      "[Epoch 2/10] [Batch 944/1081] [D loss: 0.196249] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.336283] time: 0:24:53.804430\n",
      "(10, 128, 128, 3)\n",
      "0.9179329\n",
      "[Epoch 2/10] [Batch 945/1081] [D loss: 0.196336] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.020078] time: 0:24:54.212287\n",
      "(10, 128, 128, 3)\n",
      "0.88479537\n",
      "[Epoch 2/10] [Batch 946/1081] [D loss: 0.196761] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.667930] time: 0:24:54.606002\n",
      "(10, 128, 128, 3)\n",
      "0.8353646\n",
      "[Epoch 2/10] [Batch 947/1081] [D loss: 0.198093] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.882190] time: 0:24:55.007634\n",
      "(10, 128, 128, 3)\n",
      "0.90190166\n",
      "[Epoch 2/10] [Batch 948/1081] [D loss: 0.195741] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.013193] time: 0:24:55.421598\n",
      "(10, 128, 128, 3)\n",
      "0.7953024\n",
      "[Epoch 2/10] [Batch 949/1081] [D loss: 0.198185] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.959368] time: 0:24:55.837599\n",
      "(10, 128, 128, 3)\n",
      "0.8749461\n",
      "[Epoch 2/10] [Batch 950/1081] [D loss: 0.196584] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.206245] time: 0:24:56.261287\n",
      "(10, 128, 128, 3)\n",
      "0.91211754\n",
      "[Epoch 2/10] [Batch 951/1081] [D loss: 0.194996] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.381640] time: 0:24:56.697614\n",
      "(10, 128, 128, 3)\n",
      "0.9116599\n",
      "[Epoch 2/10] [Batch 952/1081] [D loss: 0.195341] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.247714] time: 0:24:57.079870\n",
      "(10, 128, 128, 3)\n",
      "0.90989286\n",
      "[Epoch 2/10] [Batch 953/1081] [D loss: 0.198280] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.631514] time: 0:24:57.465843\n",
      "(10, 128, 128, 3)\n",
      "0.9362571\n",
      "[Epoch 2/10] [Batch 954/1081] [D loss: 0.197421] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.791386] time: 0:24:57.894400\n",
      "(10, 128, 128, 3)\n",
      "0.88711333\n",
      "[Epoch 2/10] [Batch 955/1081] [D loss: 0.196494] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.657086] time: 0:24:58.295761\n",
      "(10, 128, 128, 3)\n",
      "0.9166274\n",
      "[Epoch 2/10] [Batch 956/1081] [D loss: 0.194620] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.461615] time: 0:24:58.699401\n",
      "(10, 128, 128, 3)\n",
      "0.86237144\n",
      "[Epoch 2/10] [Batch 957/1081] [D loss: 0.197108] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.159001] time: 0:24:59.081348\n",
      "(10, 128, 128, 3)\n",
      "0.9030366\n",
      "[Epoch 2/10] [Batch 958/1081] [D loss: 0.199938] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.478063] time: 0:24:59.501844\n",
      "(10, 128, 128, 3)\n",
      "0.875029\n",
      "[Epoch 2/10] [Batch 959/1081] [D loss: 0.194291] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.483160] time: 0:24:59.894936\n",
      "(10, 128, 128, 3)\n",
      "0.92015857\n",
      "[Epoch 2/10] [Batch 960/1081] [D loss: 0.198308] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.098226] time: 0:25:00.281698\n",
      "(10, 128, 128, 3)\n",
      "0.92542773\n",
      "[Epoch 2/10] [Batch 961/1081] [D loss: 0.193233] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.573003] time: 0:25:00.692078\n",
      "(10, 128, 128, 3)\n",
      "0.9478511\n",
      "[Epoch 2/10] [Batch 962/1081] [D loss: 0.192822] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.850828] time: 0:25:01.133808\n",
      "(10, 128, 128, 3)\n",
      "0.87852985\n",
      "[Epoch 2/10] [Batch 963/1081] [D loss: 0.192729] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.020775] time: 0:25:01.524312\n",
      "(10, 128, 128, 3)\n",
      "0.8598812\n",
      "[Epoch 2/10] [Batch 964/1081] [D loss: 0.193981] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.603861] time: 0:25:01.938977\n",
      "(10, 128, 128, 3)\n",
      "0.92465276\n",
      "[Epoch 2/10] [Batch 965/1081] [D loss: 0.194576] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.918251] time: 0:25:02.342807\n",
      "(10, 128, 128, 3)\n",
      "0.86873436\n",
      "[Epoch 2/10] [Batch 966/1081] [D loss: 0.191338] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.652220] time: 0:25:02.756232\n",
      "(10, 128, 128, 3)\n",
      "0.9174545\n",
      "[Epoch 2/10] [Batch 967/1081] [D loss: 0.190539] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.412094] time: 0:25:03.143862\n",
      "(10, 128, 128, 3)\n",
      "0.94642013\n",
      "[Epoch 2/10] [Batch 968/1081] [D loss: 0.191032] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.776231] time: 0:25:03.546238\n",
      "(10, 128, 128, 3)\n",
      "0.8217183\n",
      "[Epoch 2/10] [Batch 969/1081] [D loss: 0.198603] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.549021] time: 0:25:03.949819\n",
      "(10, 128, 128, 3)\n",
      "0.9288253\n",
      "[Epoch 2/10] [Batch 970/1081] [D loss: 0.190050] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.992467] time: 0:25:04.347020\n",
      "(10, 128, 128, 3)\n",
      "0.90514755\n",
      "[Epoch 2/10] [Batch 971/1081] [D loss: 0.190081] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.244364] time: 0:25:04.766764\n",
      "(10, 128, 128, 3)\n",
      "0.8962698\n",
      "[Epoch 2/10] [Batch 972/1081] [D loss: 0.190214] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.679649] time: 0:25:05.156446\n",
      "(10, 128, 128, 3)\n",
      "0.9108673\n",
      "[Epoch 2/10] [Batch 973/1081] [D loss: 0.190924] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.019786] time: 0:25:05.541909\n",
      "(10, 128, 128, 3)\n",
      "0.9072962\n",
      "[Epoch 2/10] [Batch 974/1081] [D loss: 0.193481] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.655805] time: 0:25:05.954076\n",
      "(10, 128, 128, 3)\n",
      "0.85125035\n",
      "[Epoch 2/10] [Batch 975/1081] [D loss: 0.190536] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.957779] time: 0:25:06.330801\n",
      "(10, 128, 128, 3)\n",
      "0.94547963\n",
      "[Epoch 2/10] [Batch 976/1081] [D loss: 0.189485] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.014104] time: 0:25:06.719561\n",
      "(10, 128, 128, 3)\n",
      "0.90634847\n",
      "[Epoch 2/10] [Batch 977/1081] [D loss: 0.191826] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.012411] time: 0:25:07.148742\n",
      "(10, 128, 128, 3)\n",
      "0.8908987\n",
      "[Epoch 2/10] [Batch 978/1081] [D loss: 0.189293] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.163446] time: 0:25:07.542071\n",
      "(10, 128, 128, 3)\n",
      "0.9084959\n",
      "[Epoch 2/10] [Batch 979/1081] [D loss: 0.188557] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.388124] time: 0:25:07.944165\n",
      "(10, 128, 128, 3)\n",
      "0.94253975\n",
      "[Epoch 2/10] [Batch 980/1081] [D loss: 0.187914] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.911532] time: 0:25:08.349145\n",
      "(10, 128, 128, 3)\n",
      "0.9096846\n",
      "[Epoch 2/10] [Batch 981/1081] [D loss: 0.189347] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.703534] time: 0:25:08.739864\n",
      "(10, 128, 128, 3)\n",
      "0.91650254\n",
      "[Epoch 2/10] [Batch 982/1081] [D loss: 0.188825] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.688955] time: 0:25:09.106496\n",
      "(10, 128, 128, 3)\n",
      "0.9182431\n",
      "[Epoch 2/10] [Batch 983/1081] [D loss: 0.188600] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.439975] time: 0:25:09.503194\n",
      "(10, 128, 128, 3)\n",
      "0.9062478\n",
      "[Epoch 2/10] [Batch 984/1081] [D loss: 0.187557] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.355624] time: 0:25:09.896801\n",
      "(10, 128, 128, 3)\n",
      "0.89605886\n",
      "[Epoch 2/10] [Batch 985/1081] [D loss: 0.188483] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.660666] time: 0:25:10.324950\n",
      "(10, 128, 128, 3)\n",
      "0.95405644\n",
      "[Epoch 2/10] [Batch 986/1081] [D loss: 0.186870] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.421206] time: 0:25:10.722343\n",
      "(10, 128, 128, 3)\n",
      "0.8551982\n",
      "[Epoch 2/10] [Batch 987/1081] [D loss: 0.186857] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.861647] time: 0:25:11.131179\n",
      "(10, 128, 128, 3)\n",
      "0.8820905\n",
      "[Epoch 2/10] [Batch 988/1081] [D loss: 0.189616] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.688372] time: 0:25:11.559487\n",
      "(10, 128, 128, 3)\n",
      "0.94467765\n",
      "[Epoch 2/10] [Batch 989/1081] [D loss: 0.187421] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.071886] time: 0:25:11.969854\n",
      "(10, 128, 128, 3)\n",
      "0.9478958\n",
      "[Epoch 2/10] [Batch 990/1081] [D loss: 0.186091] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.593637] time: 0:25:12.351438\n",
      "(10, 128, 128, 3)\n",
      "0.8796477\n",
      "[Epoch 2/10] [Batch 991/1081] [D loss: 0.186624] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.718184] time: 0:25:12.745193\n",
      "(10, 128, 128, 3)\n",
      "0.8497315\n",
      "[Epoch 2/10] [Batch 992/1081] [D loss: 0.186440] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.575064] time: 0:25:13.152168\n",
      "(10, 128, 128, 3)\n",
      "0.9501063\n",
      "[Epoch 2/10] [Batch 993/1081] [D loss: 0.188710] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.432933] time: 0:25:13.568369\n",
      "(10, 128, 128, 3)\n",
      "0.94718355\n",
      "[Epoch 2/10] [Batch 994/1081] [D loss: 0.194535] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.922177] time: 0:25:13.996028\n",
      "(10, 128, 128, 3)\n",
      "0.8698895\n",
      "[Epoch 2/10] [Batch 995/1081] [D loss: 0.185763] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.869482] time: 0:25:14.396289\n",
      "(10, 128, 128, 3)\n",
      "0.9390576\n",
      "[Epoch 2/10] [Batch 996/1081] [D loss: 0.184653] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.749804] time: 0:25:14.787678\n",
      "(10, 128, 128, 3)\n",
      "0.9118354\n",
      "[Epoch 2/10] [Batch 997/1081] [D loss: 0.185354] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.118883] time: 0:25:15.194770\n",
      "(10, 128, 128, 3)\n",
      "0.96739084\n",
      "[Epoch 2/10] [Batch 998/1081] [D loss: 0.185783] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.414827] time: 0:25:15.601043\n",
      "(10, 128, 128, 3)\n",
      "0.9421861\n",
      "[Epoch 2/10] [Batch 999/1081] [D loss: 0.184487] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.486542] time: 0:25:16.012502\n",
      "(10, 128, 128, 3)\n",
      "0.94578743\n",
      "[Epoch 2/10] [Batch 1000/1081] [D loss: 0.183859] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.090742] time: 0:25:16.430444\n",
      "(10, 128, 128, 3)\n",
      "0.9302053\n",
      "[Epoch 2/10] [Batch 1001/1081] [D loss: 0.186412] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.819201] time: 0:25:16.843426\n",
      "(10, 128, 128, 3)\n",
      "0.905354\n",
      "[Epoch 2/10] [Batch 1002/1081] [D loss: 0.187904] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.606601] time: 0:25:17.225151\n",
      "(10, 128, 128, 3)\n",
      "0.8754516\n",
      "[Epoch 2/10] [Batch 1003/1081] [D loss: 0.623994] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 14.283991] time: 0:25:17.620111\n",
      "(10, 128, 128, 3)\n",
      "0.8612483\n",
      "[Epoch 2/10] [Batch 1004/1081] [D loss: 0.241946] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.873616] time: 0:25:18.038920\n",
      "(10, 128, 128, 3)\n",
      "0.9073661\n",
      "[Epoch 2/10] [Batch 1005/1081] [D loss: 0.378768] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 12.208771] time: 0:25:18.446066\n",
      "(10, 128, 128, 3)\n",
      "0.9608248\n",
      "[Epoch 2/10] [Batch 1006/1081] [D loss: 0.210371] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.289114] time: 0:25:18.830565\n",
      "(10, 128, 128, 3)\n",
      "0.9112837\n",
      "[Epoch 2/10] [Batch 1007/1081] [D loss: 0.228839] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.590517] time: 0:25:19.246163\n",
      "(10, 128, 128, 3)\n",
      "0.9406217\n",
      "[Epoch 2/10] [Batch 1008/1081] [D loss: 0.196371] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.526625] time: 0:25:19.656414\n",
      "(10, 128, 128, 3)\n",
      "0.919579\n",
      "[Epoch 2/10] [Batch 1009/1081] [D loss: 0.187644] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.456772] time: 0:25:20.042154\n",
      "(10, 128, 128, 3)\n",
      "0.9488891\n",
      "[Epoch 2/10] [Batch 1010/1081] [D loss: 0.186173] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.393429] time: 0:25:20.409255\n",
      "(10, 128, 128, 3)\n",
      "0.8918789\n",
      "[Epoch 2/10] [Batch 1011/1081] [D loss: 0.192044] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.253603] time: 0:25:20.830517\n",
      "(10, 128, 128, 3)\n",
      "0.905587\n",
      "[Epoch 2/10] [Batch 1012/1081] [D loss: 0.191871] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.929911] time: 0:25:21.240240\n",
      "(10, 128, 128, 3)\n",
      "0.9088176\n",
      "[Epoch 2/10] [Batch 1013/1081] [D loss: 0.184285] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.121884] time: 0:25:21.639987\n",
      "(10, 128, 128, 3)\n",
      "0.9027183\n",
      "[Epoch 2/10] [Batch 1014/1081] [D loss: 0.183012] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.944272] time: 0:25:22.047822\n",
      "(10, 128, 128, 3)\n",
      "0.89996696\n",
      "[Epoch 2/10] [Batch 1015/1081] [D loss: 0.183763] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.431364] time: 0:25:22.451175\n",
      "(10, 128, 128, 3)\n",
      "0.9369135\n",
      "[Epoch 2/10] [Batch 1016/1081] [D loss: 0.183102] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.623446] time: 0:25:22.886510\n",
      "(10, 128, 128, 3)\n",
      "0.9265719\n",
      "[Epoch 2/10] [Batch 1017/1081] [D loss: 0.182846] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.283795] time: 0:25:23.332934\n",
      "(10, 128, 128, 3)\n",
      "0.9246536\n",
      "[Epoch 2/10] [Batch 1018/1081] [D loss: 0.182240] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.750812] time: 0:25:23.743079\n",
      "(10, 128, 128, 3)\n",
      "0.87738246\n",
      "[Epoch 2/10] [Batch 1019/1081] [D loss: 0.184330] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.842989] time: 0:25:24.162056\n",
      "(10, 128, 128, 3)\n",
      "0.9010455\n",
      "[Epoch 2/10] [Batch 1020/1081] [D loss: 0.188867] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.921049] time: 0:25:24.541752\n",
      "(10, 128, 128, 3)\n",
      "0.9400253\n",
      "[Epoch 2/10] [Batch 1021/1081] [D loss: 0.183124] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.510681] time: 0:25:24.945069\n",
      "(10, 128, 128, 3)\n",
      "0.9131678\n",
      "[Epoch 2/10] [Batch 1022/1081] [D loss: 0.183416] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.544087] time: 0:25:25.358472\n",
      "(10, 128, 128, 3)\n",
      "0.90670466\n",
      "[Epoch 2/10] [Batch 1023/1081] [D loss: 0.181014] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.738833] time: 0:25:25.741833\n",
      "(10, 128, 128, 3)\n",
      "0.9290013\n",
      "[Epoch 2/10] [Batch 1024/1081] [D loss: 0.181481] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.644310] time: 0:25:26.180107\n",
      "(10, 128, 128, 3)\n",
      "0.9191877\n",
      "[Epoch 2/10] [Batch 1025/1081] [D loss: 0.180506] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.536135] time: 0:25:26.595620\n",
      "(10, 128, 128, 3)\n",
      "0.92560434\n",
      "[Epoch 2/10] [Batch 1026/1081] [D loss: 0.179873] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.520719] time: 0:25:26.988640\n",
      "(10, 128, 128, 3)\n",
      "0.8908079\n",
      "[Epoch 2/10] [Batch 1027/1081] [D loss: 0.179730] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.750720] time: 0:25:27.391849\n",
      "(10, 128, 128, 3)\n",
      "0.9305782\n",
      "[Epoch 2/10] [Batch 1028/1081] [D loss: 0.180162] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.784329] time: 0:25:27.799762\n",
      "(10, 128, 128, 3)\n",
      "0.92767113\n",
      "[Epoch 2/10] [Batch 1029/1081] [D loss: 0.189385] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.916365] time: 0:25:28.219719\n",
      "(10, 128, 128, 3)\n",
      "0.9266169\n",
      "[Epoch 2/10] [Batch 1030/1081] [D loss: 0.180055] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.812323] time: 0:25:28.598817\n",
      "(10, 128, 128, 3)\n",
      "0.8772934\n",
      "[Epoch 2/10] [Batch 1031/1081] [D loss: 0.180207] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.680682] time: 0:25:28.993128\n",
      "(10, 128, 128, 3)\n",
      "0.8461833\n",
      "[Epoch 2/10] [Batch 1032/1081] [D loss: 0.180506] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.550221] time: 0:25:29.378356\n",
      "(10, 128, 128, 3)\n",
      "0.8691644\n",
      "[Epoch 2/10] [Batch 1033/1081] [D loss: 0.184591] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.134071] time: 0:25:29.792945\n",
      "(10, 128, 128, 3)\n",
      "0.88305324\n",
      "[Epoch 2/10] [Batch 1034/1081] [D loss: 0.179957] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.516207] time: 0:25:30.207322\n",
      "(10, 128, 128, 3)\n",
      "0.9038418\n",
      "[Epoch 2/10] [Batch 1035/1081] [D loss: 0.180846] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.887800] time: 0:25:30.589606\n",
      "(10, 128, 128, 3)\n",
      "0.94329506\n",
      "[Epoch 2/10] [Batch 1036/1081] [D loss: 0.177958] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.849855] time: 0:25:31.006026\n",
      "(10, 128, 128, 3)\n",
      "0.88638395\n",
      "[Epoch 2/10] [Batch 1037/1081] [D loss: 0.178632] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.914488] time: 0:25:31.440238\n",
      "(10, 128, 128, 3)\n",
      "0.95228153\n",
      "[Epoch 2/10] [Batch 1038/1081] [D loss: 0.178623] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.331889] time: 0:25:31.872685\n",
      "(10, 128, 128, 3)\n",
      "0.9461073\n",
      "[Epoch 2/10] [Batch 1039/1081] [D loss: 0.180649] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.828150] time: 0:25:32.307836\n",
      "(10, 128, 128, 3)\n",
      "0.84341663\n",
      "[Epoch 2/10] [Batch 1040/1081] [D loss: 0.177576] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.658278] time: 0:25:32.743288\n",
      "(10, 128, 128, 3)\n",
      "0.9002591\n",
      "[Epoch 2/10] [Batch 1041/1081] [D loss: 0.177060] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.125974] time: 0:25:33.132073\n",
      "(10, 128, 128, 3)\n",
      "0.94205683\n",
      "[Epoch 2/10] [Batch 1042/1081] [D loss: 0.177415] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.048422] time: 0:25:33.553059\n",
      "(10, 128, 128, 3)\n",
      "0.9029183\n",
      "[Epoch 2/10] [Batch 1043/1081] [D loss: 0.176868] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.562542] time: 0:25:33.953336\n",
      "(10, 128, 128, 3)\n",
      "0.9504195\n",
      "[Epoch 2/10] [Batch 1044/1081] [D loss: 0.177103] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 15.347860] time: 0:25:34.358810\n",
      "(10, 128, 128, 3)\n",
      "0.9364324\n",
      "[Epoch 2/10] [Batch 1045/1081] [D loss: 0.176107] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.223248] time: 0:25:34.757241\n",
      "(10, 128, 128, 3)\n",
      "0.8781484\n",
      "[Epoch 2/10] [Batch 1046/1081] [D loss: 0.177146] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.166609] time: 0:25:35.135778\n",
      "(10, 128, 128, 3)\n",
      "0.90914804\n",
      "[Epoch 2/10] [Batch 1047/1081] [D loss: 0.175797] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.697899] time: 0:25:35.532993\n",
      "(10, 128, 128, 3)\n",
      "0.9036789\n",
      "[Epoch 2/10] [Batch 1048/1081] [D loss: 0.176319] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.509351] time: 0:25:35.941783\n",
      "(10, 128, 128, 3)\n",
      "0.88594335\n",
      "[Epoch 2/10] [Batch 1049/1081] [D loss: 0.179860] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.808841] time: 0:25:36.355594\n",
      "(10, 128, 128, 3)\n",
      "0.91034436\n",
      "[Epoch 2/10] [Batch 1050/1081] [D loss: 0.175237] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.853015] time: 0:25:36.758123\n",
      "(10, 128, 128, 3)\n",
      "0.91900283\n",
      "[Epoch 2/10] [Batch 1051/1081] [D loss: 0.175346] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.725863] time: 0:25:37.155394\n",
      "(10, 128, 128, 3)\n",
      "0.9151256\n",
      "[Epoch 2/10] [Batch 1052/1081] [D loss: 0.177186] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.042974] time: 0:25:37.573951\n",
      "(10, 128, 128, 3)\n",
      "0.8717513\n",
      "[Epoch 2/10] [Batch 1053/1081] [D loss: 0.175731] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.536807] time: 0:25:37.992345\n",
      "(10, 128, 128, 3)\n",
      "0.9445255\n",
      "[Epoch 2/10] [Batch 1054/1081] [D loss: 0.175057] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.716596] time: 0:25:38.421030\n",
      "(10, 128, 128, 3)\n",
      "0.88533026\n",
      "[Epoch 2/10] [Batch 1055/1081] [D loss: 0.175440] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.548666] time: 0:25:38.812048\n",
      "(10, 128, 128, 3)\n",
      "0.93702817\n",
      "[Epoch 2/10] [Batch 1056/1081] [D loss: 0.174112] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.095743] time: 0:25:39.191243\n",
      "(10, 128, 128, 3)\n",
      "0.9401788\n",
      "[Epoch 2/10] [Batch 1057/1081] [D loss: 0.173778] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.953176] time: 0:25:39.587529\n",
      "(10, 128, 128, 3)\n",
      "0.93866795\n",
      "[Epoch 2/10] [Batch 1058/1081] [D loss: 0.179181] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.288097] time: 0:25:39.989282\n",
      "(10, 128, 128, 3)\n",
      "0.92133445\n",
      "[Epoch 2/10] [Batch 1059/1081] [D loss: 0.174773] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.795345] time: 0:25:40.396880\n",
      "(10, 128, 128, 3)\n",
      "0.9029291\n",
      "[Epoch 2/10] [Batch 1060/1081] [D loss: 0.172894] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.283415] time: 0:25:40.791699\n",
      "(10, 128, 128, 3)\n",
      "0.9269407\n",
      "[Epoch 2/10] [Batch 1061/1081] [D loss: 0.173306] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.495949] time: 0:25:41.208959\n",
      "(10, 128, 128, 3)\n",
      "0.950885\n",
      "[Epoch 2/10] [Batch 1062/1081] [D loss: 0.172849] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.936563] time: 0:25:41.616149\n",
      "(10, 128, 128, 3)\n",
      "0.86645776\n",
      "[Epoch 2/10] [Batch 1063/1081] [D loss: 0.172848] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.816881] time: 0:25:42.040039\n",
      "(10, 128, 128, 3)\n",
      "0.9118306\n",
      "[Epoch 2/10] [Batch 1064/1081] [D loss: 0.172923] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.073378] time: 0:25:42.456474\n",
      "(10, 128, 128, 3)\n",
      "0.90913516\n",
      "[Epoch 2/10] [Batch 1065/1081] [D loss: 0.172027] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.013372] time: 0:25:42.862020\n",
      "(10, 128, 128, 3)\n",
      "0.90521425\n",
      "[Epoch 2/10] [Batch 1066/1081] [D loss: 0.171843] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.189796] time: 0:25:43.274965\n",
      "(10, 128, 128, 3)\n",
      "0.94697696\n",
      "[Epoch 2/10] [Batch 1067/1081] [D loss: 0.173513] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.355955] time: 0:25:43.680425\n",
      "(10, 128, 128, 3)\n",
      "0.9089474\n",
      "[Epoch 2/10] [Batch 1068/1081] [D loss: 0.172894] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.606440] time: 0:25:44.087204\n",
      "(10, 128, 128, 3)\n",
      "0.9750865\n",
      "[Epoch 2/10] [Batch 1069/1081] [D loss: 0.172312] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.613251] time: 0:25:44.465521\n",
      "(10, 128, 128, 3)\n",
      "0.8767929\n",
      "[Epoch 2/10] [Batch 1070/1081] [D loss: 0.171773] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.610069] time: 0:25:44.879206\n",
      "(10, 128, 128, 3)\n",
      "0.92908186\n",
      "[Epoch 2/10] [Batch 1071/1081] [D loss: 0.171258] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.163712] time: 0:25:45.305047\n",
      "(10, 128, 128, 3)\n",
      "0.8594833\n",
      "[Epoch 2/10] [Batch 1072/1081] [D loss: 0.170743] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.824918] time: 0:25:45.715129\n",
      "(10, 128, 128, 3)\n",
      "0.94412726\n",
      "[Epoch 2/10] [Batch 1073/1081] [D loss: 0.171396] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.499935] time: 0:25:46.108616\n",
      "(10, 128, 128, 3)\n",
      "0.9469008\n",
      "[Epoch 2/10] [Batch 1074/1081] [D loss: 0.170511] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.571049] time: 0:25:46.517719\n",
      "(10, 128, 128, 3)\n",
      "0.9543136\n",
      "[Epoch 2/10] [Batch 1075/1081] [D loss: 0.170636] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.376192] time: 0:25:46.917606\n",
      "(10, 128, 128, 3)\n",
      "0.87764186\n",
      "[Epoch 2/10] [Batch 1076/1081] [D loss: 0.170545] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.875992] time: 0:25:47.297042\n",
      "(10, 128, 128, 3)\n",
      "0.9010107\n",
      "[Epoch 2/10] [Batch 1077/1081] [D loss: 0.169784] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.050943] time: 0:25:47.733622\n",
      "(10, 128, 128, 3)\n",
      "0.88880867\n",
      "[Epoch 2/10] [Batch 1078/1081] [D loss: 0.171010] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.725435] time: 0:25:48.132106\n",
      "(10, 128, 128, 3)\n",
      "0.920304\n",
      "[Epoch 2/10] [Batch 1079/1081] [D loss: 0.169649] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.888514] time: 0:25:48.540698\n",
      "(10, 128, 128, 3)\n",
      "0.911053\n",
      "[Epoch 2/10] [Batch 1080/1081] [D loss: 0.169533] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.204615] time: 0:25:48.937170\n",
      "############ VALIDATION OF EPOCH 2 ############\n",
      "############ TRAINING OF EPOCH 3 ############\n",
      "(10, 128, 128, 3)\n",
      "0.9358413\n",
      "[Epoch 3/10] [Batch 0/1081] [D loss: 0.169966] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.394189] time: 0:26:30.790705\n",
      "(10, 128, 128, 3)\n",
      "0.8985408\n",
      "[Epoch 3/10] [Batch 2/1081] [D loss: 0.169036] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.054144] time: 0:26:31.209817\n",
      "(10, 128, 128, 3)\n",
      "0.8948922\n",
      "[Epoch 3/10] [Batch 3/1081] [D loss: 0.170987] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.544846] time: 0:26:31.638393\n",
      "(10, 128, 128, 3)\n",
      "0.88362455\n",
      "[Epoch 3/10] [Batch 4/1081] [D loss: 0.170194] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.030754] time: 0:26:32.055121\n",
      "(10, 128, 128, 3)\n",
      "0.92189676\n",
      "[Epoch 3/10] [Batch 5/1081] [D loss: 0.168986] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.343025] time: 0:26:32.455604\n",
      "(10, 128, 128, 3)\n",
      "0.8079138\n",
      "[Epoch 3/10] [Batch 6/1081] [D loss: 0.169840] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.616344] time: 0:26:32.850642\n",
      "(10, 128, 128, 3)\n",
      "0.8929644\n",
      "[Epoch 3/10] [Batch 7/1081] [D loss: 0.168799] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.507301] time: 0:26:33.261766\n",
      "(10, 128, 128, 3)\n",
      "0.85059935\n",
      "[Epoch 3/10] [Batch 8/1081] [D loss: 0.168254] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.588858] time: 0:26:33.672524\n",
      "(10, 128, 128, 3)\n",
      "0.9795074\n",
      "[Epoch 3/10] [Batch 9/1081] [D loss: 0.167977] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.442730] time: 0:26:34.068705\n",
      "(10, 128, 128, 3)\n",
      "0.93470794\n",
      "[Epoch 3/10] [Batch 10/1081] [D loss: 0.167531] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.269139] time: 0:26:34.514633\n",
      "(10, 128, 128, 3)\n",
      "0.92354345\n",
      "[Epoch 3/10] [Batch 11/1081] [D loss: 0.167692] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.112393] time: 0:26:34.942957\n",
      "(10, 128, 128, 3)\n",
      "0.88553876\n",
      "[Epoch 3/10] [Batch 12/1081] [D loss: 0.167693] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.870565] time: 0:26:35.342399\n",
      "(10, 128, 128, 3)\n",
      "0.9015456\n",
      "[Epoch 3/10] [Batch 13/1081] [D loss: 0.167028] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.910675] time: 0:26:35.767281\n",
      "(10, 128, 128, 3)\n",
      "0.8934874\n",
      "[Epoch 3/10] [Batch 14/1081] [D loss: 0.167310] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.471440] time: 0:26:36.148531\n",
      "(10, 128, 128, 3)\n",
      "0.96296257\n",
      "[Epoch 3/10] [Batch 15/1081] [D loss: 0.169120] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.339207] time: 0:26:36.543127\n",
      "(10, 128, 128, 3)\n",
      "0.93028903\n",
      "[Epoch 3/10] [Batch 16/1081] [D loss: 0.168527] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.401114] time: 0:26:36.930230\n",
      "(10, 128, 128, 3)\n",
      "0.8740969\n",
      "[Epoch 3/10] [Batch 17/1081] [D loss: 0.166799] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.386765] time: 0:26:37.360745\n",
      "(10, 128, 128, 3)\n",
      "0.86324924\n",
      "[Epoch 3/10] [Batch 18/1081] [D loss: 0.166233] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.188670] time: 0:26:37.746257\n",
      "(10, 128, 128, 3)\n",
      "0.9183045\n",
      "[Epoch 3/10] [Batch 19/1081] [D loss: 0.166079] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.659114] time: 0:26:38.144098\n",
      "(10, 128, 128, 3)\n",
      "0.8601777\n",
      "[Epoch 3/10] [Batch 20/1081] [D loss: 0.166045] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.769279] time: 0:26:38.545537\n",
      "(10, 128, 128, 3)\n",
      "0.9630402\n",
      "[Epoch 3/10] [Batch 21/1081] [D loss: 0.166607] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.412199] time: 0:26:38.948137\n",
      "(10, 128, 128, 3)\n",
      "0.8602852\n",
      "[Epoch 3/10] [Batch 22/1081] [D loss: 0.165621] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.907529] time: 0:26:39.352555\n",
      "(10, 128, 128, 3)\n",
      "0.8804149\n",
      "[Epoch 3/10] [Batch 23/1081] [D loss: 0.165652] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.140902] time: 0:26:39.743969\n",
      "(10, 128, 128, 3)\n",
      "0.8698005\n",
      "[Epoch 3/10] [Batch 24/1081] [D loss: 0.166634] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.372918] time: 0:26:40.169336\n",
      "(10, 128, 128, 3)\n",
      "0.91009325\n",
      "[Epoch 3/10] [Batch 25/1081] [D loss: 0.166911] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.886374] time: 0:26:40.586042\n",
      "(10, 128, 128, 3)\n",
      "0.9111023\n",
      "[Epoch 3/10] [Batch 26/1081] [D loss: 0.165499] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.408084] time: 0:26:40.979138\n",
      "(10, 128, 128, 3)\n",
      "0.9503605\n",
      "[Epoch 3/10] [Batch 27/1081] [D loss: 0.164604] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.377501] time: 0:26:41.365352\n",
      "(10, 128, 128, 3)\n",
      "0.86885434\n",
      "[Epoch 3/10] [Batch 28/1081] [D loss: 0.164362] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.596667] time: 0:26:41.744289\n",
      "(10, 128, 128, 3)\n",
      "0.8593866\n",
      "[Epoch 3/10] [Batch 29/1081] [D loss: 0.164404] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.125803] time: 0:26:42.182955\n",
      "(10, 128, 128, 3)\n",
      "0.9336123\n",
      "[Epoch 3/10] [Batch 30/1081] [D loss: 0.164296] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.418635] time: 0:26:42.608654\n",
      "(10, 128, 128, 3)\n",
      "0.94191617\n",
      "[Epoch 3/10] [Batch 31/1081] [D loss: 0.442885] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 11.756872] time: 0:26:43.016930\n",
      "(10, 128, 128, 3)\n",
      "0.9698457\n",
      "[Epoch 3/10] [Batch 32/1081] [D loss: 0.400960] [D acc: 0.60 (0.40 real, 0.80 fake)] [G loss: 48.035637] time: 0:26:43.408272\n",
      "(10, 128, 128, 3)\n",
      "0.9743622\n",
      "[Epoch 3/10] [Batch 33/1081] [D loss: 0.396933] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 14.878041] time: 0:26:43.812278\n",
      "(10, 128, 128, 3)\n",
      "0.9450961\n",
      "[Epoch 3/10] [Batch 34/1081] [D loss: 0.416246] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 13.616107] time: 0:26:44.218511\n",
      "(10, 128, 128, 3)\n",
      "0.91629964\n",
      "[Epoch 3/10] [Batch 35/1081] [D loss: 0.764120] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 12.758608] time: 0:26:44.608380\n",
      "(10, 128, 128, 3)\n",
      "0.8697395\n",
      "[Epoch 3/10] [Batch 36/1081] [D loss: 0.256131] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.507805] time: 0:26:45.006611\n",
      "(10, 128, 128, 3)\n",
      "0.9386943\n",
      "[Epoch 3/10] [Batch 37/1081] [D loss: 0.215089] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.326714] time: 0:26:45.449709\n",
      "(10, 128, 128, 3)\n",
      "0.90311664\n",
      "[Epoch 3/10] [Batch 38/1081] [D loss: 0.259459] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.893984] time: 0:26:45.827356\n",
      "(10, 128, 128, 3)\n",
      "0.92811817\n",
      "[Epoch 3/10] [Batch 39/1081] [D loss: 0.231336] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 17.310837] time: 0:26:46.284326\n",
      "(10, 128, 128, 3)\n",
      "0.92835665\n",
      "[Epoch 3/10] [Batch 40/1081] [D loss: 0.955862] [D acc: 0.30 (0.60 real, 0.00 fake)] [G loss: 22.169027] time: 0:26:46.671754\n",
      "(10, 128, 128, 3)\n",
      "0.9499257\n",
      "[Epoch 3/10] [Batch 41/1081] [D loss: 0.337766] [D acc: 0.80 (1.00 real, 0.60 fake)] [G loss: 12.808052] time: 0:26:47.074798\n",
      "(10, 128, 128, 3)\n",
      "0.9582243\n",
      "[Epoch 3/10] [Batch 42/1081] [D loss: 0.300538] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 12.363760] time: 0:26:47.467182\n",
      "(10, 128, 128, 3)\n",
      "0.951778\n",
      "[Epoch 3/10] [Batch 43/1081] [D loss: 0.314697] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 12.611245] time: 0:26:47.859739\n",
      "(10, 128, 128, 3)\n",
      "0.92429084\n",
      "[Epoch 3/10] [Batch 44/1081] [D loss: 0.244122] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.266251] time: 0:26:48.267317\n",
      "(10, 128, 128, 3)\n",
      "0.9154318\n",
      "[Epoch 3/10] [Batch 45/1081] [D loss: 0.202077] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.617346] time: 0:26:48.683039\n",
      "(10, 128, 128, 3)\n",
      "0.92398065\n",
      "[Epoch 3/10] [Batch 46/1081] [D loss: 0.206465] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.041227] time: 0:26:49.104786\n",
      "(10, 128, 128, 3)\n",
      "0.9292047\n",
      "[Epoch 3/10] [Batch 47/1081] [D loss: 0.207754] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.293544] time: 0:26:49.490510\n",
      "(10, 128, 128, 3)\n",
      "0.88157827\n",
      "[Epoch 3/10] [Batch 48/1081] [D loss: 0.186976] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.015549] time: 0:26:49.883733\n",
      "(10, 128, 128, 3)\n",
      "0.95290774\n",
      "[Epoch 3/10] [Batch 49/1081] [D loss: 0.270171] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.164831] time: 0:26:50.281203\n",
      "(10, 128, 128, 3)\n",
      "0.89774376\n",
      "[Epoch 3/10] [Batch 50/1081] [D loss: 0.187770] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.732327] time: 0:26:50.720163\n",
      "(10, 128, 128, 3)\n",
      "0.9015109\n",
      "[Epoch 3/10] [Batch 51/1081] [D loss: 0.189551] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.116338] time: 0:26:51.138746\n",
      "(10, 128, 128, 3)\n",
      "0.9097828\n",
      "[Epoch 3/10] [Batch 52/1081] [D loss: 0.193137] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.863085] time: 0:26:51.558897\n",
      "(10, 128, 128, 3)\n",
      "0.89537174\n",
      "[Epoch 3/10] [Batch 53/1081] [D loss: 0.188494] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.470278] time: 0:26:51.997962\n",
      "(10, 128, 128, 3)\n",
      "0.90591997\n",
      "[Epoch 3/10] [Batch 54/1081] [D loss: 0.353526] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 13.732298] time: 0:26:52.396701\n",
      "(10, 128, 128, 3)\n",
      "0.9312387\n",
      "[Epoch 3/10] [Batch 55/1081] [D loss: 0.219311] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.482104] time: 0:26:52.802883\n",
      "(10, 128, 128, 3)\n",
      "0.857574\n",
      "[Epoch 3/10] [Batch 56/1081] [D loss: 0.197221] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.049273] time: 0:26:53.199267\n",
      "(10, 128, 128, 3)\n",
      "0.94288677\n",
      "[Epoch 3/10] [Batch 57/1081] [D loss: 0.186632] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.525185] time: 0:26:53.618662\n",
      "(10, 128, 128, 3)\n",
      "0.9081705\n",
      "[Epoch 3/10] [Batch 58/1081] [D loss: 0.181460] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.587934] time: 0:26:54.404630\n",
      "(10, 128, 128, 3)\n",
      "0.9418154\n",
      "[Epoch 3/10] [Batch 59/1081] [D loss: 0.184010] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.717463] time: 0:26:54.794467\n",
      "(10, 128, 128, 3)\n",
      "0.8672202\n",
      "[Epoch 3/10] [Batch 60/1081] [D loss: 0.197967] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.470022] time: 0:26:55.196834\n",
      "(10, 128, 128, 3)\n",
      "0.9081969\n",
      "[Epoch 3/10] [Batch 61/1081] [D loss: 0.195824] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.148699] time: 0:26:55.611012\n",
      "(10, 128, 128, 3)\n",
      "0.9114222\n",
      "[Epoch 3/10] [Batch 62/1081] [D loss: 0.189773] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.030512] time: 0:26:56.014245\n",
      "(10, 128, 128, 3)\n",
      "0.9233074\n",
      "[Epoch 3/10] [Batch 63/1081] [D loss: 0.183846] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.855127] time: 0:26:56.412242\n",
      "(10, 128, 128, 3)\n",
      "0.9357148\n",
      "[Epoch 3/10] [Batch 64/1081] [D loss: 0.183631] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.099953] time: 0:26:56.799329\n",
      "(10, 128, 128, 3)\n",
      "0.87518877\n",
      "[Epoch 3/10] [Batch 65/1081] [D loss: 0.179622] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.527468] time: 0:26:57.230070\n",
      "(10, 128, 128, 3)\n",
      "0.91599655\n",
      "[Epoch 3/10] [Batch 66/1081] [D loss: 0.180868] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.280527] time: 0:26:57.626430\n",
      "(10, 128, 128, 3)\n",
      "0.8841646\n",
      "[Epoch 3/10] [Batch 67/1081] [D loss: 0.180166] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.093943] time: 0:26:58.012100\n",
      "(10, 128, 128, 3)\n",
      "0.92910403\n",
      "[Epoch 3/10] [Batch 68/1081] [D loss: 0.182947] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.772698] time: 0:26:58.464698\n",
      "(10, 128, 128, 3)\n",
      "0.9119139\n",
      "[Epoch 3/10] [Batch 69/1081] [D loss: 0.178304] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.760686] time: 0:26:58.861998\n",
      "(10, 128, 128, 3)\n",
      "0.93912524\n",
      "[Epoch 3/10] [Batch 70/1081] [D loss: 0.179619] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.701039] time: 0:26:59.305912\n",
      "(10, 128, 128, 3)\n",
      "0.9558952\n",
      "[Epoch 3/10] [Batch 71/1081] [D loss: 0.183980] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.816856] time: 0:26:59.701899\n",
      "(10, 128, 128, 3)\n",
      "0.9217207\n",
      "[Epoch 3/10] [Batch 72/1081] [D loss: 0.181818] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.726046] time: 0:27:00.079168\n",
      "(10, 128, 128, 3)\n",
      "0.9217611\n",
      "[Epoch 3/10] [Batch 73/1081] [D loss: 0.222806] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.931993] time: 0:27:00.481073\n",
      "(10, 128, 128, 3)\n",
      "0.88765115\n",
      "[Epoch 3/10] [Batch 74/1081] [D loss: 0.200475] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.770188] time: 0:27:00.880564\n",
      "(10, 128, 128, 3)\n",
      "0.8893575\n",
      "[Epoch 3/10] [Batch 75/1081] [D loss: 0.180653] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.847483] time: 0:27:01.274289\n",
      "(10, 128, 128, 3)\n",
      "0.9343334\n",
      "[Epoch 3/10] [Batch 76/1081] [D loss: 0.181892] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.905452] time: 0:27:01.673653\n",
      "(10, 128, 128, 3)\n",
      "0.95607305\n",
      "[Epoch 3/10] [Batch 77/1081] [D loss: 0.208978] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.263170] time: 0:27:02.053688\n",
      "(10, 128, 128, 3)\n",
      "0.90832883\n",
      "[Epoch 3/10] [Batch 78/1081] [D loss: 0.178104] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.867240] time: 0:27:02.435180\n",
      "(10, 128, 128, 3)\n",
      "0.9356432\n",
      "[Epoch 3/10] [Batch 79/1081] [D loss: 0.181292] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.009614] time: 0:27:02.847353\n",
      "(10, 128, 128, 3)\n",
      "0.885159\n",
      "[Epoch 3/10] [Batch 80/1081] [D loss: 0.176727] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.407103] time: 0:27:03.237154\n",
      "(10, 128, 128, 3)\n",
      "0.98018247\n",
      "[Epoch 3/10] [Batch 81/1081] [D loss: 0.179900] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.961443] time: 0:27:03.627322\n",
      "(10, 128, 128, 3)\n",
      "0.8876965\n",
      "[Epoch 3/10] [Batch 82/1081] [D loss: 0.174754] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.772727] time: 0:27:04.033483\n",
      "(10, 128, 128, 3)\n",
      "0.88194793\n",
      "[Epoch 3/10] [Batch 83/1081] [D loss: 0.177188] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.837294] time: 0:27:04.439154\n",
      "(10, 128, 128, 3)\n",
      "0.93910795\n",
      "[Epoch 3/10] [Batch 84/1081] [D loss: 0.179388] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.588757] time: 0:27:04.853485\n",
      "(10, 128, 128, 3)\n",
      "0.91563016\n",
      "[Epoch 3/10] [Batch 85/1081] [D loss: 0.175290] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.038229] time: 0:27:05.276885\n",
      "(10, 128, 128, 3)\n",
      "0.94309944\n",
      "[Epoch 3/10] [Batch 86/1081] [D loss: 0.173587] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.862965] time: 0:27:05.700276\n",
      "(10, 128, 128, 3)\n",
      "0.8648071\n",
      "[Epoch 3/10] [Batch 87/1081] [D loss: 0.173963] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.100345] time: 0:27:06.075281\n",
      "(10, 128, 128, 3)\n",
      "0.9806984\n",
      "[Epoch 3/10] [Batch 88/1081] [D loss: 0.176889] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.808070] time: 0:27:06.530804\n",
      "(10, 128, 128, 3)\n",
      "0.9146417\n",
      "[Epoch 3/10] [Batch 89/1081] [D loss: 0.176407] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.702678] time: 0:27:06.935049\n",
      "(10, 128, 128, 3)\n",
      "0.85725445\n",
      "[Epoch 3/10] [Batch 90/1081] [D loss: 0.174339] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.916141] time: 0:27:07.343846\n",
      "(10, 128, 128, 3)\n",
      "0.92087096\n",
      "[Epoch 3/10] [Batch 91/1081] [D loss: 0.175810] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.547931] time: 0:27:07.759546\n",
      "(10, 128, 128, 3)\n",
      "0.9027434\n",
      "[Epoch 3/10] [Batch 92/1081] [D loss: 0.178944] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.137239] time: 0:27:08.150591\n",
      "(10, 128, 128, 3)\n",
      "0.92686653\n",
      "[Epoch 3/10] [Batch 93/1081] [D loss: 0.172882] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.191622] time: 0:27:08.581277\n",
      "(10, 128, 128, 3)\n",
      "0.8925902\n",
      "[Epoch 3/10] [Batch 94/1081] [D loss: 0.174436] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.995526] time: 0:27:08.971665\n",
      "(10, 128, 128, 3)\n",
      "0.89934736\n",
      "[Epoch 3/10] [Batch 95/1081] [D loss: 0.174372] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.797174] time: 0:27:09.377212\n",
      "(10, 128, 128, 3)\n",
      "0.92775416\n",
      "[Epoch 3/10] [Batch 96/1081] [D loss: 0.180241] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.174578] time: 0:27:09.790166\n",
      "(10, 128, 128, 3)\n",
      "0.9158601\n",
      "[Epoch 3/10] [Batch 97/1081] [D loss: 0.172503] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.951637] time: 0:27:10.175304\n",
      "(10, 128, 128, 3)\n",
      "0.87727696\n",
      "[Epoch 3/10] [Batch 98/1081] [D loss: 0.171105] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.451105] time: 0:27:10.578046\n",
      "(10, 128, 128, 3)\n",
      "0.9364669\n",
      "[Epoch 3/10] [Batch 99/1081] [D loss: 0.171708] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.308016] time: 0:27:10.970624\n",
      "(10, 128, 128, 3)\n",
      "0.96654195\n",
      "[Epoch 3/10] [Batch 100/1081] [D loss: 0.178805] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.048030] time: 0:27:11.385548\n",
      "(10, 128, 128, 3)\n",
      "0.922602\n",
      "[Epoch 3/10] [Batch 101/1081] [D loss: 0.172284] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.402288] time: 0:27:11.771404\n",
      "(10, 128, 128, 3)\n",
      "0.969872\n",
      "[Epoch 3/10] [Batch 102/1081] [D loss: 0.171235] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.862276] time: 0:27:12.166908\n",
      "(10, 128, 128, 3)\n",
      "0.8905366\n",
      "[Epoch 3/10] [Batch 103/1081] [D loss: 0.171267] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.825851] time: 0:27:12.553830\n",
      "(10, 128, 128, 3)\n",
      "0.9743268\n",
      "[Epoch 3/10] [Batch 104/1081] [D loss: 0.170333] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.060142] time: 0:27:12.940931\n",
      "(10, 128, 128, 3)\n",
      "0.8619948\n",
      "[Epoch 3/10] [Batch 105/1081] [D loss: 0.170232] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.330765] time: 0:27:13.324578\n",
      "(10, 128, 128, 3)\n",
      "0.94156605\n",
      "[Epoch 3/10] [Batch 106/1081] [D loss: 0.169860] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.746690] time: 0:27:13.734192\n",
      "(10, 128, 128, 3)\n",
      "0.9000993\n",
      "[Epoch 3/10] [Batch 107/1081] [D loss: 0.172643] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.817259] time: 0:27:14.124124\n",
      "(10, 128, 128, 3)\n",
      "0.92473024\n",
      "[Epoch 3/10] [Batch 108/1081] [D loss: 0.172893] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.322210] time: 0:27:14.528972\n",
      "(10, 128, 128, 3)\n",
      "0.9114399\n",
      "[Epoch 3/10] [Batch 109/1081] [D loss: 0.168732] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.794729] time: 0:27:14.908198\n",
      "(10, 128, 128, 3)\n",
      "0.8760845\n",
      "[Epoch 3/10] [Batch 110/1081] [D loss: 0.168305] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.877039] time: 0:27:15.307113\n",
      "(10, 128, 128, 3)\n",
      "0.93087786\n",
      "[Epoch 3/10] [Batch 111/1081] [D loss: 0.168569] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.224395] time: 0:27:15.693861\n",
      "(10, 128, 128, 3)\n",
      "0.8884929\n",
      "[Epoch 3/10] [Batch 112/1081] [D loss: 0.170779] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.868765] time: 0:27:16.110418\n",
      "(10, 128, 128, 3)\n",
      "0.8877435\n",
      "[Epoch 3/10] [Batch 113/1081] [D loss: 0.168900] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.923725] time: 0:27:16.486792\n",
      "(10, 128, 128, 3)\n",
      "0.92384976\n",
      "[Epoch 3/10] [Batch 114/1081] [D loss: 0.167798] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.828631] time: 0:27:16.883737\n",
      "(10, 128, 128, 3)\n",
      "0.9063854\n",
      "[Epoch 3/10] [Batch 115/1081] [D loss: 0.167344] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.163141] time: 0:27:17.297009\n",
      "(10, 128, 128, 3)\n",
      "0.9248929\n",
      "[Epoch 3/10] [Batch 116/1081] [D loss: 0.167105] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.972169] time: 0:27:17.690763\n",
      "(10, 128, 128, 3)\n",
      "0.95466685\n",
      "[Epoch 3/10] [Batch 117/1081] [D loss: 0.166921] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.029160] time: 0:27:18.079236\n",
      "(10, 128, 128, 3)\n",
      "0.93647027\n",
      "[Epoch 3/10] [Batch 118/1081] [D loss: 0.201522] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.127360] time: 0:27:18.468729\n",
      "(10, 128, 128, 3)\n",
      "0.9075194\n",
      "[Epoch 3/10] [Batch 119/1081] [D loss: 0.191169] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.930188] time: 0:27:18.860076\n",
      "(10, 128, 128, 3)\n",
      "0.9219069\n",
      "[Epoch 3/10] [Batch 120/1081] [D loss: 0.170216] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.387808] time: 0:27:19.254461\n",
      "(10, 128, 128, 3)\n",
      "0.90303296\n",
      "[Epoch 3/10] [Batch 121/1081] [D loss: 0.170697] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.259039] time: 0:27:19.652853\n",
      "(10, 128, 128, 3)\n",
      "0.91471654\n",
      "[Epoch 3/10] [Batch 122/1081] [D loss: 0.174110] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.493375] time: 0:27:20.046501\n",
      "(10, 128, 128, 3)\n",
      "0.93833876\n",
      "[Epoch 3/10] [Batch 123/1081] [D loss: 0.173458] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.839475] time: 0:27:20.427901\n",
      "(10, 128, 128, 3)\n",
      "0.9318952\n",
      "[Epoch 3/10] [Batch 124/1081] [D loss: 0.167432] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.045212] time: 0:27:20.821917\n",
      "(10, 128, 128, 3)\n",
      "0.8678381\n",
      "[Epoch 3/10] [Batch 125/1081] [D loss: 0.166454] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.322536] time: 0:27:21.214616\n",
      "(10, 128, 128, 3)\n",
      "0.92614627\n",
      "[Epoch 3/10] [Batch 126/1081] [D loss: 0.367449] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 11.963217] time: 0:27:21.632855\n",
      "(10, 128, 128, 3)\n",
      "0.8849931\n",
      "[Epoch 3/10] [Batch 127/1081] [D loss: 0.192684] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.581944] time: 0:27:22.041859\n",
      "(10, 128, 128, 3)\n",
      "0.8636032\n",
      "[Epoch 3/10] [Batch 128/1081] [D loss: 0.173759] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.012523] time: 0:27:22.454072\n",
      "(10, 128, 128, 3)\n",
      "0.9666271\n",
      "[Epoch 3/10] [Batch 129/1081] [D loss: 0.169525] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.858470] time: 0:27:22.859317\n",
      "(10, 128, 128, 3)\n",
      "0.9458997\n",
      "[Epoch 3/10] [Batch 130/1081] [D loss: 0.174062] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.312043] time: 0:27:23.254796\n",
      "(10, 128, 128, 3)\n",
      "0.90157014\n",
      "[Epoch 3/10] [Batch 131/1081] [D loss: 0.167932] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.698844] time: 0:27:23.651820\n",
      "(10, 128, 128, 3)\n",
      "0.9101595\n",
      "[Epoch 3/10] [Batch 132/1081] [D loss: 0.168009] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.892087] time: 0:27:24.059397\n",
      "(10, 128, 128, 3)\n",
      "0.92477554\n",
      "[Epoch 3/10] [Batch 133/1081] [D loss: 0.166338] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.683486] time: 0:27:24.456021\n",
      "(10, 128, 128, 3)\n",
      "0.8908572\n",
      "[Epoch 3/10] [Batch 134/1081] [D loss: 0.168277] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.847921] time: 0:27:24.887767\n",
      "(10, 128, 128, 3)\n",
      "0.9085477\n",
      "[Epoch 3/10] [Batch 135/1081] [D loss: 0.165964] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.038730] time: 0:27:25.287613\n",
      "(10, 128, 128, 3)\n",
      "0.9206848\n",
      "[Epoch 3/10] [Batch 136/1081] [D loss: 0.167771] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.470150] time: 0:27:25.684238\n",
      "(10, 128, 128, 3)\n",
      "0.9467245\n",
      "[Epoch 3/10] [Batch 137/1081] [D loss: 0.165947] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.593266] time: 0:27:26.079046\n",
      "(10, 128, 128, 3)\n",
      "0.9355073\n",
      "[Epoch 3/10] [Batch 138/1081] [D loss: 0.168429] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.358898] time: 0:27:26.513859\n",
      "(10, 128, 128, 3)\n",
      "0.9243636\n",
      "[Epoch 3/10] [Batch 139/1081] [D loss: 0.165589] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.685061] time: 0:27:26.906798\n",
      "(10, 128, 128, 3)\n",
      "0.86866695\n",
      "[Epoch 3/10] [Batch 140/1081] [D loss: 0.168282] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.305392] time: 0:27:27.309830\n",
      "(10, 128, 128, 3)\n",
      "0.9093638\n",
      "[Epoch 3/10] [Batch 141/1081] [D loss: 0.166626] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.659263] time: 0:27:27.690644\n",
      "(10, 128, 128, 3)\n",
      "0.8912565\n",
      "[Epoch 3/10] [Batch 142/1081] [D loss: 0.168530] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.367849] time: 0:27:28.093122\n",
      "(10, 128, 128, 3)\n",
      "0.9048303\n",
      "[Epoch 3/10] [Batch 143/1081] [D loss: 0.165837] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.701859] time: 0:27:28.492781\n",
      "(10, 128, 128, 3)\n",
      "0.9337929\n",
      "[Epoch 3/10] [Batch 144/1081] [D loss: 0.164907] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.454232] time: 0:27:28.883947\n",
      "(10, 128, 128, 3)\n",
      "0.93902844\n",
      "[Epoch 3/10] [Batch 145/1081] [D loss: 0.165812] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.783909] time: 0:27:29.294434\n",
      "(10, 128, 128, 3)\n",
      "0.93913156\n",
      "[Epoch 3/10] [Batch 146/1081] [D loss: 0.163995] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.542243] time: 0:27:29.686041\n",
      "(10, 128, 128, 3)\n",
      "0.8950451\n",
      "[Epoch 3/10] [Batch 147/1081] [D loss: 0.164179] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.122017] time: 0:27:30.066821\n",
      "(10, 128, 128, 3)\n",
      "0.9301982\n",
      "[Epoch 3/10] [Batch 148/1081] [D loss: 0.163551] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.580257] time: 0:27:30.486445\n",
      "(10, 128, 128, 3)\n",
      "0.94134265\n",
      "[Epoch 3/10] [Batch 149/1081] [D loss: 0.163297] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.285619] time: 0:27:30.901353\n",
      "(10, 128, 128, 3)\n",
      "0.92249775\n",
      "[Epoch 3/10] [Batch 150/1081] [D loss: 0.163680] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.311768] time: 0:27:31.339980\n",
      "(10, 128, 128, 3)\n",
      "0.8811315\n",
      "[Epoch 3/10] [Batch 151/1081] [D loss: 0.163573] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.478054] time: 0:27:31.739127\n",
      "(10, 128, 128, 3)\n",
      "0.91395545\n",
      "[Epoch 3/10] [Batch 152/1081] [D loss: 0.163880] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.707733] time: 0:27:32.132678\n",
      "(10, 128, 128, 3)\n",
      "0.92419547\n",
      "[Epoch 3/10] [Batch 153/1081] [D loss: 0.164288] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.800206] time: 0:27:32.536905\n",
      "(10, 128, 128, 3)\n",
      "0.96680623\n",
      "[Epoch 3/10] [Batch 154/1081] [D loss: 0.167740] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.058943] time: 0:27:32.946995\n",
      "(10, 128, 128, 3)\n",
      "0.9362791\n",
      "[Epoch 3/10] [Batch 155/1081] [D loss: 0.163488] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.434364] time: 0:27:33.338479\n",
      "(10, 128, 128, 3)\n",
      "0.9071427\n",
      "[Epoch 3/10] [Batch 156/1081] [D loss: 0.163885] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.634657] time: 0:27:33.721627\n",
      "(10, 128, 128, 3)\n",
      "0.86272746\n",
      "[Epoch 3/10] [Batch 157/1081] [D loss: 0.162210] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.196108] time: 0:27:34.101002\n",
      "(10, 128, 128, 3)\n",
      "0.9036486\n",
      "[Epoch 3/10] [Batch 158/1081] [D loss: 0.162631] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.626358] time: 0:27:34.507193\n",
      "(10, 128, 128, 3)\n",
      "0.91651815\n",
      "[Epoch 3/10] [Batch 159/1081] [D loss: 0.162075] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.726470] time: 0:27:34.892214\n",
      "(10, 128, 128, 3)\n",
      "0.91514343\n",
      "[Epoch 3/10] [Batch 160/1081] [D loss: 0.162313] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.007645] time: 0:27:35.280633\n",
      "(10, 128, 128, 3)\n",
      "0.931904\n",
      "[Epoch 3/10] [Batch 161/1081] [D loss: 0.162413] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.304271] time: 0:27:35.668099\n",
      "(10, 128, 128, 3)\n",
      "0.9569716\n",
      "[Epoch 3/10] [Batch 162/1081] [D loss: 0.166518] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.268367] time: 0:27:36.079700\n",
      "(10, 128, 128, 3)\n",
      "0.8672542\n",
      "[Epoch 3/10] [Batch 163/1081] [D loss: 0.161609] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.559912] time: 0:27:36.480756\n",
      "(10, 128, 128, 3)\n",
      "0.9339377\n",
      "[Epoch 3/10] [Batch 164/1081] [D loss: 0.161350] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.454706] time: 0:27:36.906305\n",
      "(10, 128, 128, 3)\n",
      "0.9329452\n",
      "[Epoch 3/10] [Batch 165/1081] [D loss: 0.161486] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.261000] time: 0:27:37.312019\n",
      "(10, 128, 128, 3)\n",
      "0.89150196\n",
      "[Epoch 3/10] [Batch 166/1081] [D loss: 0.160952] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.995684] time: 0:27:37.726553\n",
      "(10, 128, 128, 3)\n",
      "0.92397326\n",
      "[Epoch 3/10] [Batch 167/1081] [D loss: 0.160354] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.851730] time: 0:27:38.120942\n",
      "(10, 128, 128, 3)\n",
      "0.91427207\n",
      "[Epoch 3/10] [Batch 168/1081] [D loss: 0.160722] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.336723] time: 0:27:38.537931\n",
      "(10, 128, 128, 3)\n",
      "0.87878925\n",
      "[Epoch 3/10] [Batch 169/1081] [D loss: 0.161420] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.910033] time: 0:27:38.927410\n",
      "(10, 128, 128, 3)\n",
      "0.8958157\n",
      "[Epoch 3/10] [Batch 170/1081] [D loss: 0.162403] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.889318] time: 0:27:39.343290\n",
      "(10, 128, 128, 3)\n",
      "0.8631439\n",
      "[Epoch 3/10] [Batch 171/1081] [D loss: 0.159807] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.174471] time: 0:27:39.788185\n",
      "(10, 128, 128, 3)\n",
      "0.9264676\n",
      "[Epoch 3/10] [Batch 172/1081] [D loss: 0.160002] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.739124] time: 0:27:40.217320\n",
      "(10, 128, 128, 3)\n",
      "0.9219993\n",
      "[Epoch 3/10] [Batch 173/1081] [D loss: 0.160810] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.261913] time: 0:27:40.599389\n",
      "(10, 128, 128, 3)\n",
      "0.91077447\n",
      "[Epoch 3/10] [Batch 174/1081] [D loss: 0.161978] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.434522] time: 0:27:41.005664\n",
      "(10, 128, 128, 3)\n",
      "0.900517\n",
      "[Epoch 3/10] [Batch 175/1081] [D loss: 0.185125] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.490897] time: 0:27:41.413877\n",
      "(10, 128, 128, 3)\n",
      "0.9068072\n",
      "[Epoch 3/10] [Batch 176/1081] [D loss: 0.163575] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.542089] time: 0:27:41.796872\n",
      "(10, 128, 128, 3)\n",
      "0.927052\n",
      "[Epoch 3/10] [Batch 177/1081] [D loss: 0.161715] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.812940] time: 0:27:42.202574\n",
      "(10, 128, 128, 3)\n",
      "0.88090444\n",
      "[Epoch 3/10] [Batch 178/1081] [D loss: 0.161839] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.056957] time: 0:27:42.615359\n",
      "(10, 128, 128, 3)\n",
      "0.9444499\n",
      "[Epoch 3/10] [Batch 179/1081] [D loss: 0.655657] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 13.120392] time: 0:27:43.019579\n",
      "(10, 128, 128, 3)\n",
      "0.9709735\n",
      "[Epoch 3/10] [Batch 180/1081] [D loss: 0.337675] [D acc: 0.80 (0.90 real, 0.70 fake)] [G loss: 11.232244] time: 0:27:43.413220\n",
      "(10, 128, 128, 3)\n",
      "0.93336016\n",
      "[Epoch 3/10] [Batch 181/1081] [D loss: 0.234932] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.596886] time: 0:27:43.825970\n",
      "(10, 128, 128, 3)\n",
      "0.8783768\n",
      "[Epoch 3/10] [Batch 182/1081] [D loss: 0.202865] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.127522] time: 0:27:44.226409\n",
      "(10, 128, 128, 3)\n",
      "0.9564596\n",
      "[Epoch 3/10] [Batch 183/1081] [D loss: 0.243056] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.664181] time: 0:27:44.627422\n",
      "(10, 128, 128, 3)\n",
      "0.9456449\n",
      "[Epoch 3/10] [Batch 184/1081] [D loss: 0.162297] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.060799] time: 0:27:45.052064\n",
      "(10, 128, 128, 3)\n",
      "0.97901326\n",
      "[Epoch 3/10] [Batch 185/1081] [D loss: 0.164155] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.698222] time: 0:27:45.446029\n",
      "(10, 128, 128, 3)\n",
      "0.912602\n",
      "[Epoch 3/10] [Batch 186/1081] [D loss: 0.163988] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.625936] time: 0:27:45.837759\n",
      "(10, 128, 128, 3)\n",
      "0.94148684\n",
      "[Epoch 3/10] [Batch 187/1081] [D loss: 0.162251] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.894550] time: 0:27:46.247548\n",
      "(10, 128, 128, 3)\n",
      "0.91444445\n",
      "[Epoch 3/10] [Batch 188/1081] [D loss: 0.161654] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.928288] time: 0:27:46.656473\n",
      "(10, 128, 128, 3)\n",
      "0.9683539\n",
      "[Epoch 3/10] [Batch 189/1081] [D loss: 0.164329] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.978477] time: 0:27:47.053071\n",
      "(10, 128, 128, 3)\n",
      "0.90801305\n",
      "[Epoch 3/10] [Batch 190/1081] [D loss: 0.160271] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.776273] time: 0:27:47.483367\n",
      "(10, 128, 128, 3)\n",
      "0.9410228\n",
      "[Epoch 3/10] [Batch 191/1081] [D loss: 0.160543] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.107115] time: 0:27:47.867566\n",
      "(10, 128, 128, 3)\n",
      "0.867151\n",
      "[Epoch 3/10] [Batch 192/1081] [D loss: 0.167458] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.626436] time: 0:27:48.264959\n",
      "(10, 128, 128, 3)\n",
      "0.91304016\n",
      "[Epoch 3/10] [Batch 193/1081] [D loss: 0.159755] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.213351] time: 0:27:48.654166\n",
      "(10, 128, 128, 3)\n",
      "0.8997113\n",
      "[Epoch 3/10] [Batch 194/1081] [D loss: 0.159421] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.551804] time: 0:27:49.036952\n",
      "(10, 128, 128, 3)\n",
      "0.93171483\n",
      "[Epoch 3/10] [Batch 195/1081] [D loss: 0.823918] [D acc: 0.05 (0.00 real, 0.10 fake)] [G loss: 10.863514] time: 0:27:49.430821\n",
      "(10, 128, 128, 3)\n",
      "0.9282076\n",
      "[Epoch 3/10] [Batch 196/1081] [D loss: 0.242172] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.280329] time: 0:27:49.854677\n",
      "(10, 128, 128, 3)\n",
      "0.9452662\n",
      "[Epoch 3/10] [Batch 197/1081] [D loss: 0.170237] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.923371] time: 0:27:50.226366\n",
      "(10, 128, 128, 3)\n",
      "0.92036504\n",
      "[Epoch 3/10] [Batch 198/1081] [D loss: 0.171853] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.366152] time: 0:27:50.641193\n",
      "(10, 128, 128, 3)\n",
      "0.910934\n",
      "[Epoch 3/10] [Batch 199/1081] [D loss: 0.479414] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 11.497031] time: 0:27:51.057770\n",
      "(10, 128, 128, 3)\n",
      "0.9344242\n",
      "[Epoch 3/10] [Batch 200/1081] [D loss: 0.293288] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.942785] time: 0:27:51.469589\n",
      "(10, 128, 128, 3)\n",
      "0.9113486\n",
      "[Epoch 3/10] [Batch 201/1081] [D loss: 0.169972] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.859459] time: 0:27:51.891648\n",
      "(10, 128, 128, 3)\n",
      "0.9059162\n",
      "[Epoch 3/10] [Batch 202/1081] [D loss: 0.164254] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.936788] time: 0:27:52.304553\n",
      "(10, 128, 128, 3)\n",
      "0.87328404\n",
      "[Epoch 3/10] [Batch 203/1081] [D loss: 0.160774] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.660220] time: 0:27:52.734801\n",
      "(10, 128, 128, 3)\n",
      "0.9180016\n",
      "[Epoch 3/10] [Batch 204/1081] [D loss: 0.204525] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.136312] time: 0:27:53.115851\n",
      "(10, 128, 128, 3)\n",
      "0.9000697\n",
      "[Epoch 3/10] [Batch 205/1081] [D loss: 0.162429] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.060612] time: 0:27:53.523233\n",
      "(10, 128, 128, 3)\n",
      "0.91101235\n",
      "[Epoch 3/10] [Batch 206/1081] [D loss: 0.164846] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.985798] time: 0:27:53.950242\n",
      "(10, 128, 128, 3)\n",
      "0.9169567\n",
      "[Epoch 3/10] [Batch 207/1081] [D loss: 0.159941] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.587351] time: 0:27:54.349882\n",
      "(10, 128, 128, 3)\n",
      "0.87170273\n",
      "[Epoch 3/10] [Batch 208/1081] [D loss: 0.164810] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.762289] time: 0:27:54.735823\n",
      "(10, 128, 128, 3)\n",
      "0.8682284\n",
      "[Epoch 3/10] [Batch 209/1081] [D loss: 0.169154] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.550805] time: 0:27:55.152150\n",
      "(10, 128, 128, 3)\n",
      "0.8735121\n",
      "[Epoch 3/10] [Batch 210/1081] [D loss: 0.159831] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.185451] time: 0:27:55.564832\n",
      "(10, 128, 128, 3)\n",
      "0.9163042\n",
      "[Epoch 3/10] [Batch 211/1081] [D loss: 0.166949] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.221972] time: 0:27:55.961235\n",
      "(10, 128, 128, 3)\n",
      "0.888364\n",
      "[Epoch 3/10] [Batch 212/1081] [D loss: 0.158887] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.760453] time: 0:27:56.396267\n",
      "(10, 128, 128, 3)\n",
      "0.9474156\n",
      "[Epoch 3/10] [Batch 213/1081] [D loss: 0.160196] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.944794] time: 0:27:56.796987\n",
      "(10, 128, 128, 3)\n",
      "0.9283598\n",
      "[Epoch 3/10] [Batch 214/1081] [D loss: 0.161926] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.166632] time: 0:27:57.179959\n",
      "(10, 128, 128, 3)\n",
      "0.9062217\n",
      "[Epoch 3/10] [Batch 215/1081] [D loss: 0.159420] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.697863] time: 0:27:57.580105\n",
      "(10, 128, 128, 3)\n",
      "0.9597006\n",
      "[Epoch 3/10] [Batch 216/1081] [D loss: 0.159573] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.619310] time: 0:27:57.984869\n",
      "(10, 128, 128, 3)\n",
      "0.90872556\n",
      "[Epoch 3/10] [Batch 217/1081] [D loss: 0.158161] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.186155] time: 0:27:58.396158\n",
      "(10, 128, 128, 3)\n",
      "0.902385\n",
      "[Epoch 3/10] [Batch 218/1081] [D loss: 0.160668] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.233845] time: 0:27:58.801768\n",
      "(10, 128, 128, 3)\n",
      "0.907577\n",
      "[Epoch 3/10] [Batch 219/1081] [D loss: 0.157936] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.761467] time: 0:27:59.216172\n",
      "(10, 128, 128, 3)\n",
      "0.9061592\n",
      "[Epoch 3/10] [Batch 220/1081] [D loss: 0.160038] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.512791] time: 0:27:59.652758\n",
      "(10, 128, 128, 3)\n",
      "0.90329355\n",
      "[Epoch 3/10] [Batch 221/1081] [D loss: 0.159030] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.708332] time: 0:28:00.057171\n",
      "(10, 128, 128, 3)\n",
      "0.9184758\n",
      "[Epoch 3/10] [Batch 222/1081] [D loss: 0.159751] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.861437] time: 0:28:00.440569\n",
      "(10, 128, 128, 3)\n",
      "0.90392524\n",
      "[Epoch 3/10] [Batch 223/1081] [D loss: 0.164855] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.513055] time: 0:28:00.856994\n",
      "(10, 128, 128, 3)\n",
      "0.9199247\n",
      "[Epoch 3/10] [Batch 224/1081] [D loss: 0.158385] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.775774] time: 0:28:01.281835\n",
      "(10, 128, 128, 3)\n",
      "0.94224876\n",
      "[Epoch 3/10] [Batch 225/1081] [D loss: 0.158328] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.994637] time: 0:28:01.689413\n",
      "(10, 128, 128, 3)\n",
      "0.8871909\n",
      "[Epoch 3/10] [Batch 226/1081] [D loss: 0.156489] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.223188] time: 0:28:02.099257\n",
      "(10, 128, 128, 3)\n",
      "0.92648536\n",
      "[Epoch 3/10] [Batch 227/1081] [D loss: 0.157507] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.311532] time: 0:28:02.513672\n",
      "(10, 128, 128, 3)\n",
      "0.89797837\n",
      "[Epoch 3/10] [Batch 228/1081] [D loss: 0.162519] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.656236] time: 0:28:02.907348\n",
      "(10, 128, 128, 3)\n",
      "0.93655664\n",
      "[Epoch 3/10] [Batch 229/1081] [D loss: 0.156799] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.306799] time: 0:28:03.311744\n",
      "(10, 128, 128, 3)\n",
      "0.9375399\n",
      "[Epoch 3/10] [Batch 230/1081] [D loss: 0.189722] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 11.783949] time: 0:28:03.691827\n",
      "(10, 128, 128, 3)\n",
      "0.91769034\n",
      "[Epoch 3/10] [Batch 231/1081] [D loss: 0.161817] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.574879] time: 0:28:04.097407\n",
      "(10, 128, 128, 3)\n",
      "0.9224181\n",
      "[Epoch 3/10] [Batch 232/1081] [D loss: 0.160713] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.989922] time: 0:28:04.494415\n",
      "(10, 128, 128, 3)\n",
      "0.9344966\n",
      "[Epoch 3/10] [Batch 233/1081] [D loss: 0.157130] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.230855] time: 0:28:04.881703\n",
      "(10, 128, 128, 3)\n",
      "0.89818615\n",
      "[Epoch 3/10] [Batch 234/1081] [D loss: 0.157009] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.398975] time: 0:28:05.265345\n",
      "(10, 128, 128, 3)\n",
      "0.87643594\n",
      "[Epoch 3/10] [Batch 235/1081] [D loss: 0.159800] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.464650] time: 0:28:05.673420\n",
      "(10, 128, 128, 3)\n",
      "0.92179155\n",
      "[Epoch 3/10] [Batch 236/1081] [D loss: 0.154907] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.714481] time: 0:28:06.080212\n",
      "(10, 128, 128, 3)\n",
      "0.9386181\n",
      "[Epoch 3/10] [Batch 237/1081] [D loss: 0.162038] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.421892] time: 0:28:06.507649\n",
      "(10, 128, 128, 3)\n",
      "0.9353952\n",
      "[Epoch 3/10] [Batch 238/1081] [D loss: 0.155041] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.559256] time: 0:28:06.905166\n",
      "(10, 128, 128, 3)\n",
      "0.9278204\n",
      "[Epoch 3/10] [Batch 239/1081] [D loss: 0.156312] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.623987] time: 0:28:07.317067\n",
      "(10, 128, 128, 3)\n",
      "0.9217327\n",
      "[Epoch 3/10] [Batch 240/1081] [D loss: 0.155417] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.784571] time: 0:28:07.752187\n",
      "(10, 128, 128, 3)\n",
      "0.91344404\n",
      "[Epoch 3/10] [Batch 241/1081] [D loss: 0.155675] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.604956] time: 0:28:08.142336\n",
      "(10, 128, 128, 3)\n",
      "0.9555674\n",
      "[Epoch 3/10] [Batch 242/1081] [D loss: 0.155492] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.031347] time: 0:28:08.570345\n",
      "(10, 128, 128, 3)\n",
      "0.8660955\n",
      "[Epoch 3/10] [Batch 243/1081] [D loss: 0.154033] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.546308] time: 0:28:08.974360\n",
      "(10, 128, 128, 3)\n",
      "0.92094785\n",
      "[Epoch 3/10] [Batch 244/1081] [D loss: 0.154991] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.177541] time: 0:28:09.370712\n",
      "(10, 128, 128, 3)\n",
      "0.90465117\n",
      "[Epoch 3/10] [Batch 245/1081] [D loss: 0.154670] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.355645] time: 0:28:09.770371\n",
      "(10, 128, 128, 3)\n",
      "0.93546623\n",
      "[Epoch 3/10] [Batch 246/1081] [D loss: 0.153440] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.831135] time: 0:28:10.166684\n",
      "(10, 128, 128, 3)\n",
      "0.9010132\n",
      "[Epoch 3/10] [Batch 247/1081] [D loss: 0.155749] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.299994] time: 0:28:10.565809\n",
      "(10, 128, 128, 3)\n",
      "0.95897293\n",
      "[Epoch 3/10] [Batch 248/1081] [D loss: 0.153605] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.846906] time: 0:28:10.965278\n",
      "(10, 128, 128, 3)\n",
      "0.91549915\n",
      "[Epoch 3/10] [Batch 249/1081] [D loss: 0.158755] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.318422] time: 0:28:11.379913\n",
      "(10, 128, 128, 3)\n",
      "0.9162504\n",
      "[Epoch 3/10] [Batch 250/1081] [D loss: 0.159905] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.681973] time: 0:28:11.805204\n",
      "(10, 128, 128, 3)\n",
      "0.92205215\n",
      "[Epoch 3/10] [Batch 251/1081] [D loss: 0.156156] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.572317] time: 0:28:12.235526\n",
      "(10, 128, 128, 3)\n",
      "0.89512616\n",
      "[Epoch 3/10] [Batch 252/1081] [D loss: 0.152628] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.266248] time: 0:28:12.631466\n",
      "(10, 128, 128, 3)\n",
      "0.91400456\n",
      "[Epoch 3/10] [Batch 253/1081] [D loss: 0.153228] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.071491] time: 0:28:13.056628\n",
      "(10, 128, 128, 3)\n",
      "0.8926278\n",
      "[Epoch 3/10] [Batch 254/1081] [D loss: 0.153751] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.847379] time: 0:28:13.453973\n",
      "(10, 128, 128, 3)\n",
      "0.9234028\n",
      "[Epoch 3/10] [Batch 255/1081] [D loss: 0.152122] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.845819] time: 0:28:13.837414\n",
      "(10, 128, 128, 3)\n",
      "0.92809314\n",
      "[Epoch 3/10] [Batch 256/1081] [D loss: 0.152772] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.916056] time: 0:28:14.235424\n",
      "(10, 128, 128, 3)\n",
      "0.92453545\n",
      "[Epoch 3/10] [Batch 257/1081] [D loss: 0.151938] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.490128] time: 0:28:14.662466\n",
      "(10, 128, 128, 3)\n",
      "0.91970485\n",
      "[Epoch 3/10] [Batch 258/1081] [D loss: 0.151444] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.635962] time: 0:28:15.090049\n",
      "(10, 128, 128, 3)\n",
      "0.8210893\n",
      "[Epoch 3/10] [Batch 259/1081] [D loss: 0.151690] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.869154] time: 0:28:15.493823\n",
      "(10, 128, 128, 3)\n",
      "0.91595954\n",
      "[Epoch 3/10] [Batch 260/1081] [D loss: 0.151370] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.229753] time: 0:28:15.893388\n",
      "(10, 128, 128, 3)\n",
      "0.93328935\n",
      "[Epoch 3/10] [Batch 261/1081] [D loss: 0.151394] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.161713] time: 0:28:16.277043\n",
      "(10, 128, 128, 3)\n",
      "0.91937596\n",
      "[Epoch 3/10] [Batch 262/1081] [D loss: 0.151635] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.113634] time: 0:28:16.666102\n",
      "(10, 128, 128, 3)\n",
      "0.9453311\n",
      "[Epoch 3/10] [Batch 263/1081] [D loss: 0.151368] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.988889] time: 0:28:17.049790\n",
      "(10, 128, 128, 3)\n",
      "0.93705755\n",
      "[Epoch 3/10] [Batch 264/1081] [D loss: 0.150610] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.207410] time: 0:28:17.420358\n",
      "(10, 128, 128, 3)\n",
      "0.9291788\n",
      "[Epoch 3/10] [Batch 265/1081] [D loss: 0.150998] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.647213] time: 0:28:17.832943\n",
      "(10, 128, 128, 3)\n",
      "0.9032571\n",
      "[Epoch 3/10] [Batch 266/1081] [D loss: 0.151164] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.183835] time: 0:28:18.244047\n",
      "(10, 128, 128, 3)\n",
      "0.9114061\n",
      "[Epoch 3/10] [Batch 267/1081] [D loss: 0.150839] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.807676] time: 0:28:18.620175\n",
      "(10, 128, 128, 3)\n",
      "0.8880636\n",
      "[Epoch 3/10] [Batch 268/1081] [D loss: 0.151188] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.278985] time: 0:28:19.013994\n",
      "(10, 128, 128, 3)\n",
      "0.93174356\n",
      "[Epoch 3/10] [Batch 269/1081] [D loss: 0.150228] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.633335] time: 0:28:19.417409\n",
      "(10, 128, 128, 3)\n",
      "0.92286015\n",
      "[Epoch 3/10] [Batch 270/1081] [D loss: 0.149920] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.653839] time: 0:28:19.827154\n",
      "(10, 128, 128, 3)\n",
      "0.9387242\n",
      "[Epoch 3/10] [Batch 271/1081] [D loss: 0.150168] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.039361] time: 0:28:20.223586\n",
      "(10, 128, 128, 3)\n",
      "0.8791332\n",
      "[Epoch 3/10] [Batch 272/1081] [D loss: 0.150452] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.735620] time: 0:28:20.615986\n",
      "(10, 128, 128, 3)\n",
      "0.93775415\n",
      "[Epoch 3/10] [Batch 273/1081] [D loss: 0.149805] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.160677] time: 0:28:21.004176\n",
      "(10, 128, 128, 3)\n",
      "0.9455662\n",
      "[Epoch 3/10] [Batch 274/1081] [D loss: 0.149591] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.834024] time: 0:28:21.397306\n",
      "(10, 128, 128, 3)\n",
      "0.91799545\n",
      "[Epoch 3/10] [Batch 275/1081] [D loss: 0.150820] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.878403] time: 0:28:21.789049\n",
      "(10, 128, 128, 3)\n",
      "0.91662925\n",
      "[Epoch 3/10] [Batch 276/1081] [D loss: 0.149175] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.522390] time: 0:28:22.180536\n",
      "(10, 128, 128, 3)\n",
      "0.93183035\n",
      "[Epoch 3/10] [Batch 277/1081] [D loss: 0.151322] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.806276] time: 0:28:22.569853\n",
      "(10, 128, 128, 3)\n",
      "0.88914347\n",
      "[Epoch 3/10] [Batch 278/1081] [D loss: 0.149476] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.487480] time: 0:28:22.949961\n",
      "(10, 128, 128, 3)\n",
      "0.94096535\n",
      "[Epoch 3/10] [Batch 279/1081] [D loss: 0.148929] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.219038] time: 0:28:23.338097\n",
      "(10, 128, 128, 3)\n",
      "0.85291815\n",
      "[Epoch 3/10] [Batch 280/1081] [D loss: 0.149723] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.879375] time: 0:28:23.735514\n",
      "(10, 128, 128, 3)\n",
      "0.96661854\n",
      "[Epoch 3/10] [Batch 281/1081] [D loss: 0.149345] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.126678] time: 0:28:24.118983\n",
      "(10, 128, 128, 3)\n",
      "0.92830414\n",
      "[Epoch 3/10] [Batch 282/1081] [D loss: 0.149720] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.272754] time: 0:28:24.525155\n",
      "(10, 128, 128, 3)\n",
      "0.86647373\n",
      "[Epoch 3/10] [Batch 283/1081] [D loss: 0.148831] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.229826] time: 0:28:24.921381\n",
      "(10, 128, 128, 3)\n",
      "0.90443736\n",
      "[Epoch 3/10] [Batch 284/1081] [D loss: 0.148202] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.220737] time: 0:28:25.346264\n",
      "(10, 128, 128, 3)\n",
      "0.9253557\n",
      "[Epoch 3/10] [Batch 285/1081] [D loss: 0.148251] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.514769] time: 0:28:25.764022\n",
      "(10, 128, 128, 3)\n",
      "0.9057537\n",
      "[Epoch 3/10] [Batch 286/1081] [D loss: 0.149271] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.937898] time: 0:28:26.182473\n",
      "(10, 128, 128, 3)\n",
      "0.96784705\n",
      "[Epoch 3/10] [Batch 287/1081] [D loss: 0.147543] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.854712] time: 0:28:26.585208\n",
      "(10, 128, 128, 3)\n",
      "0.9090915\n",
      "[Epoch 3/10] [Batch 288/1081] [D loss: 0.147752] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.623313] time: 0:28:26.964001\n",
      "(10, 128, 128, 3)\n",
      "0.91486055\n",
      "[Epoch 3/10] [Batch 289/1081] [D loss: 0.149134] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.262203] time: 0:28:27.359949\n",
      "(10, 128, 128, 3)\n",
      "0.93477374\n",
      "[Epoch 3/10] [Batch 290/1081] [D loss: 0.147635] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.030022] time: 0:28:27.761315\n",
      "(10, 128, 128, 3)\n",
      "0.9495451\n",
      "[Epoch 3/10] [Batch 291/1081] [D loss: 0.147246] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.560625] time: 0:28:28.151502\n",
      "(10, 128, 128, 3)\n",
      "0.8707609\n",
      "[Epoch 3/10] [Batch 292/1081] [D loss: 0.147950] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.358940] time: 0:28:28.558090\n",
      "(10, 128, 128, 3)\n",
      "0.86702126\n",
      "[Epoch 3/10] [Batch 293/1081] [D loss: 0.146845] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.474007] time: 0:28:28.982531\n",
      "(10, 128, 128, 3)\n",
      "0.9763115\n",
      "[Epoch 3/10] [Batch 294/1081] [D loss: 0.149016] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.582759] time: 0:28:29.360360\n",
      "(10, 128, 128, 3)\n",
      "0.927476\n",
      "[Epoch 3/10] [Batch 295/1081] [D loss: 0.149603] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.155089] time: 0:28:29.765044\n",
      "(10, 128, 128, 3)\n",
      "0.92473006\n",
      "[Epoch 3/10] [Batch 296/1081] [D loss: 0.147527] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.971175] time: 0:28:30.182627\n",
      "(10, 128, 128, 3)\n",
      "0.91838604\n",
      "[Epoch 3/10] [Batch 297/1081] [D loss: 0.146532] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.145441] time: 0:28:30.593054\n",
      "(10, 128, 128, 3)\n",
      "0.9305842\n",
      "[Epoch 3/10] [Batch 298/1081] [D loss: 0.146725] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.434589] time: 0:28:31.021950\n",
      "(10, 128, 128, 3)\n",
      "0.90637547\n",
      "[Epoch 3/10] [Batch 299/1081] [D loss: 0.145929] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.290396] time: 0:28:31.429390\n",
      "(10, 128, 128, 3)\n",
      "0.93488437\n",
      "[Epoch 3/10] [Batch 300/1081] [D loss: 0.146644] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.318580] time: 0:28:31.822200\n",
      "(10, 128, 128, 3)\n",
      "0.89473337\n",
      "[Epoch 3/10] [Batch 301/1081] [D loss: 0.146876] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.205969] time: 0:28:32.219872\n",
      "(10, 128, 128, 3)\n",
      "0.8989225\n",
      "[Epoch 3/10] [Batch 302/1081] [D loss: 0.148573] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.023510] time: 0:28:32.633181\n",
      "(10, 128, 128, 3)\n",
      "0.8855448\n",
      "[Epoch 3/10] [Batch 303/1081] [D loss: 0.145554] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.668556] time: 0:28:33.032147\n",
      "(10, 128, 128, 3)\n",
      "0.90060693\n",
      "[Epoch 3/10] [Batch 304/1081] [D loss: 0.146771] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.822367] time: 0:28:33.450174\n",
      "(10, 128, 128, 3)\n",
      "0.91186374\n",
      "[Epoch 3/10] [Batch 305/1081] [D loss: 0.146093] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.067078] time: 0:28:33.873030\n",
      "(10, 128, 128, 3)\n",
      "0.90595555\n",
      "[Epoch 3/10] [Batch 306/1081] [D loss: 0.145262] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.300047] time: 0:28:34.279212\n",
      "(10, 128, 128, 3)\n",
      "0.8404009\n",
      "[Epoch 3/10] [Batch 307/1081] [D loss: 0.145271] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.502993] time: 0:28:34.688915\n",
      "(10, 128, 128, 3)\n",
      "0.9202623\n",
      "[Epoch 3/10] [Batch 308/1081] [D loss: 0.145249] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.247342] time: 0:28:35.078976\n",
      "(10, 128, 128, 3)\n",
      "0.88619375\n",
      "[Epoch 3/10] [Batch 309/1081] [D loss: 0.144654] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.368833] time: 0:28:35.492863\n",
      "(10, 128, 128, 3)\n",
      "0.9195216\n",
      "[Epoch 3/10] [Batch 310/1081] [D loss: 0.144649] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.052374] time: 0:28:35.901040\n",
      "(10, 128, 128, 3)\n",
      "0.90146685\n",
      "[Epoch 3/10] [Batch 311/1081] [D loss: 0.145166] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.261930] time: 0:28:36.320178\n",
      "(10, 128, 128, 3)\n",
      "0.92772055\n",
      "[Epoch 3/10] [Batch 312/1081] [D loss: 0.144788] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.324251] time: 0:28:36.723712\n",
      "(10, 128, 128, 3)\n",
      "0.88745856\n",
      "[Epoch 3/10] [Batch 313/1081] [D loss: 0.144141] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.700172] time: 0:28:37.128854\n",
      "(10, 128, 128, 3)\n",
      "0.91486\n",
      "[Epoch 3/10] [Batch 314/1081] [D loss: 0.143930] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.595137] time: 0:28:37.584501\n",
      "(10, 128, 128, 3)\n",
      "0.8962694\n",
      "[Epoch 3/10] [Batch 315/1081] [D loss: 0.748365] [D acc: 0.45 (0.00 real, 0.90 fake)] [G loss: 10.411269] time: 0:28:38.028862\n",
      "(10, 128, 128, 3)\n",
      "0.9419401\n",
      "[Epoch 3/10] [Batch 316/1081] [D loss: 0.240397] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.014132] time: 0:28:38.418064\n",
      "(10, 128, 128, 3)\n",
      "0.96759343\n",
      "[Epoch 3/10] [Batch 317/1081] [D loss: 0.158878] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.669271] time: 0:28:38.807965\n",
      "(10, 128, 128, 3)\n",
      "0.8839361\n",
      "[Epoch 3/10] [Batch 318/1081] [D loss: 0.146301] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.253177] time: 0:28:39.216912\n",
      "(10, 128, 128, 3)\n",
      "0.87549454\n",
      "[Epoch 3/10] [Batch 319/1081] [D loss: 0.144125] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.910858] time: 0:28:39.612898\n",
      "(10, 128, 128, 3)\n",
      "0.9463994\n",
      "[Epoch 3/10] [Batch 320/1081] [D loss: 0.144835] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.118739] time: 0:28:39.991392\n",
      "(10, 128, 128, 3)\n",
      "0.8799793\n",
      "[Epoch 3/10] [Batch 321/1081] [D loss: 0.143495] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.322011] time: 0:28:40.369532\n",
      "(10, 128, 128, 3)\n",
      "0.92023444\n",
      "[Epoch 3/10] [Batch 322/1081] [D loss: 0.145166] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.004478] time: 0:28:40.768142\n",
      "(10, 128, 128, 3)\n",
      "0.94497967\n",
      "[Epoch 3/10] [Batch 323/1081] [D loss: 0.143517] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.059793] time: 0:28:41.186640\n",
      "(10, 128, 128, 3)\n",
      "0.8881261\n",
      "[Epoch 3/10] [Batch 324/1081] [D loss: 0.143760] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.733972] time: 0:28:41.612434\n",
      "(10, 128, 128, 3)\n",
      "0.8885681\n",
      "[Epoch 3/10] [Batch 325/1081] [D loss: 0.143320] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.730061] time: 0:28:42.044160\n",
      "(10, 128, 128, 3)\n",
      "0.94216514\n",
      "[Epoch 3/10] [Batch 326/1081] [D loss: 0.144691] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.660458] time: 0:28:42.440515\n",
      "(10, 128, 128, 3)\n",
      "0.9110915\n",
      "[Epoch 3/10] [Batch 327/1081] [D loss: 0.142902] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.403322] time: 0:28:42.842195\n",
      "(10, 128, 128, 3)\n",
      "0.91355294\n",
      "[Epoch 3/10] [Batch 328/1081] [D loss: 0.143036] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.644957] time: 0:28:43.300314\n",
      "(10, 128, 128, 3)\n",
      "0.9441495\n",
      "[Epoch 3/10] [Batch 329/1081] [D loss: 0.143476] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.468435] time: 0:28:43.706001\n",
      "(10, 128, 128, 3)\n",
      "0.925647\n",
      "[Epoch 3/10] [Batch 330/1081] [D loss: 0.152033] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.309617] time: 0:28:44.124080\n",
      "(10, 128, 128, 3)\n",
      "0.9417474\n",
      "[Epoch 3/10] [Batch 331/1081] [D loss: 0.142910] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.089706] time: 0:28:44.529802\n",
      "(10, 128, 128, 3)\n",
      "0.9308112\n",
      "[Epoch 3/10] [Batch 332/1081] [D loss: 0.142818] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.376019] time: 0:28:44.966575\n",
      "(10, 128, 128, 3)\n",
      "0.8415594\n",
      "[Epoch 3/10] [Batch 333/1081] [D loss: 0.150629] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.708403] time: 0:28:45.373169\n",
      "(10, 128, 128, 3)\n",
      "0.9184561\n",
      "[Epoch 3/10] [Batch 334/1081] [D loss: 0.142914] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.680638] time: 0:28:45.791476\n",
      "(10, 128, 128, 3)\n",
      "0.92516905\n",
      "[Epoch 3/10] [Batch 335/1081] [D loss: 0.143698] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.857269] time: 0:28:46.158585\n",
      "(10, 128, 128, 3)\n",
      "0.9627587\n",
      "[Epoch 3/10] [Batch 336/1081] [D loss: 0.142480] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.911977] time: 0:28:46.579049\n",
      "(10, 128, 128, 3)\n",
      "0.9251035\n",
      "[Epoch 3/10] [Batch 337/1081] [D loss: 0.142749] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.250184] time: 0:28:46.970302\n",
      "(10, 128, 128, 3)\n",
      "0.90951854\n",
      "[Epoch 3/10] [Batch 338/1081] [D loss: 0.142166] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.614724] time: 0:28:47.370865\n",
      "(10, 128, 128, 3)\n",
      "0.95450777\n",
      "[Epoch 3/10] [Batch 339/1081] [D loss: 0.143628] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.979933] time: 0:28:47.736973\n",
      "(10, 128, 128, 3)\n",
      "0.90880126\n",
      "[Epoch 3/10] [Batch 340/1081] [D loss: 0.142579] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.346557] time: 0:28:48.122822\n",
      "(10, 128, 128, 3)\n",
      "0.8991663\n",
      "[Epoch 3/10] [Batch 341/1081] [D loss: 0.141638] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.281013] time: 0:28:48.516951\n",
      "(10, 128, 128, 3)\n",
      "0.8926138\n",
      "[Epoch 3/10] [Batch 342/1081] [D loss: 0.141662] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.759503] time: 0:28:48.895372\n",
      "(10, 128, 128, 3)\n",
      "0.9318518\n",
      "[Epoch 3/10] [Batch 343/1081] [D loss: 0.142350] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.523076] time: 0:28:49.307713\n",
      "(10, 128, 128, 3)\n",
      "0.87953955\n",
      "[Epoch 3/10] [Batch 344/1081] [D loss: 0.141974] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.720181] time: 0:28:49.712279\n",
      "(10, 128, 128, 3)\n",
      "0.9197113\n",
      "[Epoch 3/10] [Batch 345/1081] [D loss: 0.141998] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.666830] time: 0:28:50.122412\n",
      "(10, 128, 128, 3)\n",
      "0.8382125\n",
      "[Epoch 3/10] [Batch 346/1081] [D loss: 0.140933] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.390848] time: 0:28:50.519956\n",
      "(10, 128, 128, 3)\n",
      "0.90436274\n",
      "[Epoch 3/10] [Batch 347/1081] [D loss: 0.147543] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.006070] time: 0:28:50.961063\n",
      "(10, 128, 128, 3)\n",
      "0.93993807\n",
      "[Epoch 3/10] [Batch 348/1081] [D loss: 0.143940] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.500813] time: 0:28:51.360790\n",
      "(10, 128, 128, 3)\n",
      "0.92770547\n",
      "[Epoch 3/10] [Batch 349/1081] [D loss: 0.141087] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.352768] time: 0:28:51.770861\n",
      "(10, 128, 128, 3)\n",
      "0.95767695\n",
      "[Epoch 3/10] [Batch 350/1081] [D loss: 0.140621] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.876989] time: 0:28:52.166075\n",
      "(10, 128, 128, 3)\n",
      "0.91383713\n",
      "[Epoch 3/10] [Batch 351/1081] [D loss: 0.140817] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.702837] time: 0:28:52.530898\n",
      "(10, 128, 128, 3)\n",
      "0.8592784\n",
      "[Epoch 3/10] [Batch 352/1081] [D loss: 0.140593] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.709281] time: 0:28:52.923643\n",
      "(10, 128, 128, 3)\n",
      "0.9074414\n",
      "[Epoch 3/10] [Batch 353/1081] [D loss: 0.141405] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.958172] time: 0:28:53.316148\n",
      "(10, 128, 128, 3)\n",
      "0.91472244\n",
      "[Epoch 3/10] [Batch 354/1081] [D loss: 0.140479] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.197393] time: 0:28:53.720250\n",
      "(10, 128, 128, 3)\n",
      "0.9760664\n",
      "[Epoch 3/10] [Batch 355/1081] [D loss: 0.140874] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.628963] time: 0:28:54.128950\n",
      "(10, 128, 128, 3)\n",
      "0.9062877\n",
      "[Epoch 3/10] [Batch 356/1081] [D loss: 0.140017] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.052000] time: 0:28:54.531564\n",
      "(10, 128, 128, 3)\n",
      "0.9274044\n",
      "[Epoch 3/10] [Batch 357/1081] [D loss: 0.140372] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.469446] time: 0:28:54.943747\n",
      "(10, 128, 128, 3)\n",
      "0.91175705\n",
      "[Epoch 3/10] [Batch 358/1081] [D loss: 0.140404] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.742050] time: 0:28:55.352672\n",
      "(10, 128, 128, 3)\n",
      "0.90678185\n",
      "[Epoch 3/10] [Batch 359/1081] [D loss: 0.140370] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.883883] time: 0:28:55.748725\n",
      "(10, 128, 128, 3)\n",
      "0.8688138\n",
      "[Epoch 3/10] [Batch 360/1081] [D loss: 0.139451] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.585751] time: 0:28:56.171444\n",
      "(10, 128, 128, 3)\n",
      "0.8895409\n",
      "[Epoch 3/10] [Batch 361/1081] [D loss: 0.139623] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.490765] time: 0:28:56.580542\n",
      "(10, 128, 128, 3)\n",
      "0.91814464\n",
      "[Epoch 3/10] [Batch 362/1081] [D loss: 0.139972] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.972708] time: 0:28:56.976061\n",
      "(10, 128, 128, 3)\n",
      "0.89646006\n",
      "[Epoch 3/10] [Batch 363/1081] [D loss: 0.139044] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.908421] time: 0:28:57.375591\n",
      "(10, 128, 128, 3)\n",
      "0.90084153\n",
      "[Epoch 3/10] [Batch 364/1081] [D loss: 0.139440] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.028790] time: 0:28:57.749678\n",
      "(10, 128, 128, 3)\n",
      "0.90456796\n",
      "[Epoch 3/10] [Batch 365/1081] [D loss: 0.139954] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.399759] time: 0:28:58.134443\n",
      "(10, 128, 128, 3)\n",
      "0.94805425\n",
      "[Epoch 3/10] [Batch 366/1081] [D loss: 0.139113] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.181331] time: 0:28:58.538969\n",
      "(10, 128, 128, 3)\n",
      "0.94491553\n",
      "[Epoch 3/10] [Batch 367/1081] [D loss: 0.138434] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.289573] time: 0:28:58.918677\n",
      "(10, 128, 128, 3)\n",
      "0.8779268\n",
      "[Epoch 3/10] [Batch 368/1081] [D loss: 0.139028] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.596329] time: 0:28:59.319273\n",
      "(10, 128, 128, 3)\n",
      "0.93093544\n",
      "[Epoch 3/10] [Batch 369/1081] [D loss: 0.165413] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.597808] time: 0:28:59.739402\n",
      "(10, 128, 128, 3)\n",
      "0.93085766\n",
      "[Epoch 3/10] [Batch 370/1081] [D loss: 0.147409] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.077010] time: 0:29:00.161325\n",
      "(10, 128, 128, 3)\n",
      "0.8749725\n",
      "[Epoch 3/10] [Batch 371/1081] [D loss: 0.141652] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.428741] time: 0:29:00.589760\n",
      "(10, 128, 128, 3)\n",
      "0.9570152\n",
      "[Epoch 3/10] [Batch 372/1081] [D loss: 0.140457] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.008636] time: 0:29:01.002313\n",
      "(10, 128, 128, 3)\n",
      "0.89872617\n",
      "[Epoch 3/10] [Batch 373/1081] [D loss: 0.139604] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.620411] time: 0:29:01.381062\n",
      "(10, 128, 128, 3)\n",
      "0.9163123\n",
      "[Epoch 3/10] [Batch 374/1081] [D loss: 0.139117] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.518340] time: 0:29:01.790797\n",
      "(10, 128, 128, 3)\n",
      "0.9021066\n",
      "[Epoch 3/10] [Batch 375/1081] [D loss: 0.138643] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.926255] time: 0:29:02.218742\n",
      "(10, 128, 128, 3)\n",
      "0.90733886\n",
      "[Epoch 3/10] [Batch 376/1081] [D loss: 0.139207] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.922380] time: 0:29:02.637665\n",
      "(10, 128, 128, 3)\n",
      "0.90919846\n",
      "[Epoch 3/10] [Batch 377/1081] [D loss: 0.138334] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.798108] time: 0:29:03.042247\n",
      "(10, 128, 128, 3)\n",
      "0.92555\n",
      "[Epoch 3/10] [Batch 378/1081] [D loss: 0.137869] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.674486] time: 0:29:03.431987\n",
      "(10, 128, 128, 3)\n",
      "0.8566286\n",
      "[Epoch 3/10] [Batch 379/1081] [D loss: 0.170769] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.312817] time: 0:29:03.811700\n",
      "(10, 128, 128, 3)\n",
      "0.862503\n",
      "[Epoch 3/10] [Batch 380/1081] [D loss: 0.142926] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.371710] time: 0:29:04.220980\n",
      "(10, 128, 128, 3)\n",
      "0.9419627\n",
      "[Epoch 3/10] [Batch 381/1081] [D loss: 0.141264] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.578424] time: 0:29:04.632705\n",
      "(10, 128, 128, 3)\n",
      "0.9181327\n",
      "[Epoch 3/10] [Batch 382/1081] [D loss: 0.140776] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.264893] time: 0:29:05.060699\n",
      "(10, 128, 128, 3)\n",
      "0.92794895\n",
      "[Epoch 3/10] [Batch 383/1081] [D loss: 0.141801] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.501975] time: 0:29:05.477836\n",
      "(10, 128, 128, 3)\n",
      "0.93117714\n",
      "[Epoch 3/10] [Batch 384/1081] [D loss: 0.138621] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.046601] time: 0:29:05.890612\n",
      "(10, 128, 128, 3)\n",
      "0.8720636\n",
      "[Epoch 3/10] [Batch 385/1081] [D loss: 0.138105] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.227110] time: 0:29:06.264996\n",
      "(10, 128, 128, 3)\n",
      "0.90526557\n",
      "[Epoch 3/10] [Batch 386/1081] [D loss: 0.137581] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.032841] time: 0:29:06.695041\n",
      "(10, 128, 128, 3)\n",
      "0.92706364\n",
      "[Epoch 3/10] [Batch 387/1081] [D loss: 0.136858] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.705907] time: 0:29:07.089923\n",
      "(10, 128, 128, 3)\n",
      "0.9132665\n",
      "[Epoch 3/10] [Batch 388/1081] [D loss: 0.137082] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.423803] time: 0:29:07.509725\n",
      "(10, 128, 128, 3)\n",
      "0.8290806\n",
      "[Epoch 3/10] [Batch 389/1081] [D loss: 0.137565] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.923161] time: 0:29:07.903200\n",
      "(10, 128, 128, 3)\n",
      "0.9318525\n",
      "[Epoch 3/10] [Batch 390/1081] [D loss: 0.136841] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.415503] time: 0:29:08.323739\n",
      "(10, 128, 128, 3)\n",
      "0.83730936\n",
      "[Epoch 3/10] [Batch 391/1081] [D loss: 0.136814] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.141694] time: 0:29:08.742026\n",
      "(10, 128, 128, 3)\n",
      "0.9093053\n",
      "[Epoch 3/10] [Batch 392/1081] [D loss: 0.136404] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.276641] time: 0:29:09.118737\n",
      "(10, 128, 128, 3)\n",
      "0.8854273\n",
      "[Epoch 3/10] [Batch 393/1081] [D loss: 0.136085] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.983692] time: 0:29:09.499172\n",
      "(10, 128, 128, 3)\n",
      "0.90464514\n",
      "[Epoch 3/10] [Batch 394/1081] [D loss: 0.137319] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.406321] time: 0:29:09.916255\n",
      "(10, 128, 128, 3)\n",
      "0.91599864\n",
      "[Epoch 3/10] [Batch 395/1081] [D loss: 0.136409] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.716927] time: 0:29:10.322237\n",
      "(10, 128, 128, 3)\n",
      "0.8806629\n",
      "[Epoch 3/10] [Batch 396/1081] [D loss: 0.136150] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.105712] time: 0:29:10.743593\n",
      "(10, 128, 128, 3)\n",
      "0.9489591\n",
      "[Epoch 3/10] [Batch 397/1081] [D loss: 0.136087] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.705280] time: 0:29:11.167034\n",
      "(10, 128, 128, 3)\n",
      "0.8595786\n",
      "[Epoch 3/10] [Batch 398/1081] [D loss: 0.136139] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.935250] time: 0:29:11.578002\n",
      "(10, 128, 128, 3)\n",
      "0.93979293\n",
      "[Epoch 3/10] [Batch 399/1081] [D loss: 0.135490] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.576634] time: 0:29:11.986286\n",
      "(10, 128, 128, 3)\n",
      "0.9146173\n",
      "[Epoch 3/10] [Batch 400/1081] [D loss: 0.138462] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.503979] time: 0:29:12.440988\n",
      "(10, 128, 128, 3)\n",
      "0.9112299\n",
      "[Epoch 3/10] [Batch 401/1081] [D loss: 0.135969] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.954941] time: 0:29:12.843764\n",
      "(10, 128, 128, 3)\n",
      "0.9342521\n",
      "[Epoch 3/10] [Batch 402/1081] [D loss: 0.135625] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.603072] time: 0:29:13.256112\n",
      "(10, 128, 128, 3)\n",
      "0.85385364\n",
      "[Epoch 3/10] [Batch 403/1081] [D loss: 0.135105] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.661242] time: 0:29:13.651454\n",
      "(10, 128, 128, 3)\n",
      "0.9415865\n",
      "[Epoch 3/10] [Batch 404/1081] [D loss: 0.135260] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.239588] time: 0:29:14.034376\n",
      "(10, 128, 128, 3)\n",
      "0.91189927\n",
      "[Epoch 3/10] [Batch 405/1081] [D loss: 0.134947] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.279054] time: 0:29:14.452386\n",
      "(10, 128, 128, 3)\n",
      "0.9060321\n",
      "[Epoch 3/10] [Batch 406/1081] [D loss: 0.134780] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.999099] time: 0:29:14.840871\n",
      "(10, 128, 128, 3)\n",
      "0.9483662\n",
      "[Epoch 3/10] [Batch 407/1081] [D loss: 0.134718] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.460184] time: 0:29:15.241981\n",
      "(10, 128, 128, 3)\n",
      "0.8686659\n",
      "[Epoch 3/10] [Batch 408/1081] [D loss: 0.136144] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.233564] time: 0:29:15.676468\n",
      "(10, 128, 128, 3)\n",
      "0.89264613\n",
      "[Epoch 3/10] [Batch 409/1081] [D loss: 0.134469] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.416430] time: 0:29:16.088768\n",
      "(10, 128, 128, 3)\n",
      "0.9217674\n",
      "[Epoch 3/10] [Batch 410/1081] [D loss: 0.135733] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.352380] time: 0:29:16.472032\n",
      "(10, 128, 128, 3)\n",
      "0.9394116\n",
      "[Epoch 3/10] [Batch 411/1081] [D loss: 0.134396] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.493992] time: 0:29:16.889563\n",
      "(10, 128, 128, 3)\n",
      "0.8856856\n",
      "[Epoch 3/10] [Batch 412/1081] [D loss: 0.133969] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.377240] time: 0:29:17.289951\n",
      "(10, 128, 128, 3)\n",
      "0.93994266\n",
      "[Epoch 3/10] [Batch 413/1081] [D loss: 0.134159] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.044180] time: 0:29:17.674600\n",
      "(10, 128, 128, 3)\n",
      "0.87584186\n",
      "[Epoch 3/10] [Batch 414/1081] [D loss: 0.134228] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.956286] time: 0:29:18.093659\n",
      "(10, 128, 128, 3)\n",
      "0.8493202\n",
      "[Epoch 3/10] [Batch 415/1081] [D loss: 0.134171] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.861745] time: 0:29:18.482746\n",
      "(10, 128, 128, 3)\n",
      "0.893198\n",
      "[Epoch 3/10] [Batch 416/1081] [D loss: 0.134454] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.269829] time: 0:29:18.897277\n",
      "(10, 128, 128, 3)\n",
      "0.89615077\n",
      "[Epoch 3/10] [Batch 417/1081] [D loss: 0.134446] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.522239] time: 0:29:19.280696\n",
      "(10, 128, 128, 3)\n",
      "0.9171838\n",
      "[Epoch 3/10] [Batch 418/1081] [D loss: 0.133596] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.805538] time: 0:29:19.692884\n",
      "(10, 128, 128, 3)\n",
      "0.96618074\n",
      "[Epoch 3/10] [Batch 419/1081] [D loss: 0.133680] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.765457] time: 0:29:20.115307\n",
      "(10, 128, 128, 3)\n",
      "0.86856395\n",
      "[Epoch 3/10] [Batch 420/1081] [D loss: 0.134499] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.533771] time: 0:29:20.516361\n",
      "(10, 128, 128, 3)\n",
      "0.9355884\n",
      "[Epoch 3/10] [Batch 421/1081] [D loss: 0.135631] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.956227] time: 0:29:20.906733\n",
      "(10, 128, 128, 3)\n",
      "0.9728078\n",
      "[Epoch 3/10] [Batch 422/1081] [D loss: 0.134466] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.434143] time: 0:29:21.307722\n",
      "(10, 128, 128, 3)\n",
      "0.9389573\n",
      "[Epoch 3/10] [Batch 423/1081] [D loss: 0.133687] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.790596] time: 0:29:21.731054\n",
      "(10, 128, 128, 3)\n",
      "0.8614308\n",
      "[Epoch 3/10] [Batch 424/1081] [D loss: 0.133223] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.277586] time: 0:29:22.172673\n",
      "(10, 128, 128, 3)\n",
      "0.8628982\n",
      "[Epoch 3/10] [Batch 425/1081] [D loss: 0.132683] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.945530] time: 0:29:22.571920\n",
      "(10, 128, 128, 3)\n",
      "0.8980644\n",
      "[Epoch 3/10] [Batch 426/1081] [D loss: 0.132940] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.867919] time: 0:29:22.976120\n",
      "(10, 128, 128, 3)\n",
      "0.8727768\n",
      "[Epoch 3/10] [Batch 427/1081] [D loss: 0.133708] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.753260] time: 0:29:23.361090\n",
      "(10, 128, 128, 3)\n",
      "0.91758776\n",
      "[Epoch 3/10] [Batch 428/1081] [D loss: 0.132255] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.590134] time: 0:29:23.754678\n",
      "(10, 128, 128, 3)\n",
      "0.90857714\n",
      "[Epoch 3/10] [Batch 429/1081] [D loss: 0.133596] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.141203] time: 0:29:24.163099\n",
      "(10, 128, 128, 3)\n",
      "0.88559705\n",
      "[Epoch 3/10] [Batch 430/1081] [D loss: 0.132223] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.129629] time: 0:29:24.584852\n",
      "(10, 128, 128, 3)\n",
      "0.92184496\n",
      "[Epoch 3/10] [Batch 431/1081] [D loss: 0.132341] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.068683] time: 0:29:25.010687\n",
      "(10, 128, 128, 3)\n",
      "0.92528707\n",
      "[Epoch 3/10] [Batch 432/1081] [D loss: 0.132845] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.617996] time: 0:29:25.416557\n",
      "(10, 128, 128, 3)\n",
      "0.8998234\n",
      "[Epoch 3/10] [Batch 433/1081] [D loss: 0.132273] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.217020] time: 0:29:25.803134\n",
      "(10, 128, 128, 3)\n",
      "0.8548751\n",
      "[Epoch 3/10] [Batch 434/1081] [D loss: 0.132051] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.758768] time: 0:29:26.193651\n",
      "(10, 128, 128, 3)\n",
      "0.90762407\n",
      "[Epoch 3/10] [Batch 435/1081] [D loss: 0.131785] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.462827] time: 0:29:26.594600\n",
      "(10, 128, 128, 3)\n",
      "0.9240923\n",
      "[Epoch 3/10] [Batch 436/1081] [D loss: 0.132511] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.012432] time: 0:29:26.968136\n",
      "(10, 128, 128, 3)\n",
      "0.8752385\n",
      "[Epoch 3/10] [Batch 437/1081] [D loss: 0.132215] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.689804] time: 0:29:27.360972\n",
      "(10, 128, 128, 3)\n",
      "0.9170306\n",
      "[Epoch 3/10] [Batch 438/1081] [D loss: 0.132946] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.001129] time: 0:29:27.749271\n",
      "(10, 128, 128, 3)\n",
      "0.8910048\n",
      "[Epoch 3/10] [Batch 439/1081] [D loss: 0.132068] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.811752] time: 0:29:28.146620\n",
      "(10, 128, 128, 3)\n",
      "0.87831956\n",
      "[Epoch 3/10] [Batch 440/1081] [D loss: 0.131688] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.714836] time: 0:29:28.530382\n",
      "(10, 128, 128, 3)\n",
      "0.97664696\n",
      "[Epoch 3/10] [Batch 441/1081] [D loss: 0.131243] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.783416] time: 0:29:28.920814\n",
      "(10, 128, 128, 3)\n",
      "0.9359216\n",
      "[Epoch 3/10] [Batch 442/1081] [D loss: 0.130916] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.987083] time: 0:29:29.310339\n",
      "(10, 128, 128, 3)\n",
      "0.9150931\n",
      "[Epoch 3/10] [Batch 443/1081] [D loss: 0.131313] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.057790] time: 0:29:29.715215\n",
      "(10, 128, 128, 3)\n",
      "0.9210076\n",
      "[Epoch 3/10] [Batch 444/1081] [D loss: 0.130952] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.252513] time: 0:29:30.135480\n",
      "(10, 128, 128, 3)\n",
      "0.92849636\n",
      "[Epoch 3/10] [Batch 445/1081] [D loss: 0.130965] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.555913] time: 0:29:30.517197\n",
      "(10, 128, 128, 3)\n",
      "0.95297694\n",
      "[Epoch 3/10] [Batch 446/1081] [D loss: 0.130732] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.918479] time: 0:29:30.900629\n",
      "(10, 128, 128, 3)\n",
      "0.90564805\n",
      "[Epoch 3/10] [Batch 447/1081] [D loss: 0.131370] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.490047] time: 0:29:31.289577\n",
      "(10, 128, 128, 3)\n",
      "0.9431389\n",
      "[Epoch 3/10] [Batch 448/1081] [D loss: 0.130458] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.498327] time: 0:29:31.726033\n",
      "(10, 128, 128, 3)\n",
      "0.95401\n",
      "[Epoch 3/10] [Batch 449/1081] [D loss: 0.130457] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.394156] time: 0:29:32.112533\n",
      "(10, 128, 128, 3)\n",
      "0.9151328\n",
      "[Epoch 3/10] [Batch 450/1081] [D loss: 0.130217] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.484756] time: 0:29:32.515907\n",
      "(10, 128, 128, 3)\n",
      "0.93443865\n",
      "[Epoch 3/10] [Batch 451/1081] [D loss: 0.130610] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.595324] time: 0:29:32.933280\n",
      "(10, 128, 128, 3)\n",
      "0.85938334\n",
      "[Epoch 3/10] [Batch 452/1081] [D loss: 0.130222] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.582685] time: 0:29:33.304694\n",
      "(10, 128, 128, 3)\n",
      "0.91211176\n",
      "[Epoch 3/10] [Batch 453/1081] [D loss: 0.129911] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.805588] time: 0:29:33.718091\n",
      "(10, 128, 128, 3)\n",
      "0.91301054\n",
      "[Epoch 3/10] [Batch 454/1081] [D loss: 0.129759] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.892913] time: 0:29:34.124645\n",
      "(10, 128, 128, 3)\n",
      "0.92751503\n",
      "[Epoch 3/10] [Batch 455/1081] [D loss: 0.129887] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.289413] time: 0:29:34.545222\n",
      "(10, 128, 128, 3)\n",
      "0.94564295\n",
      "[Epoch 3/10] [Batch 456/1081] [D loss: 0.129531] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.305331] time: 0:29:34.952462\n",
      "(10, 128, 128, 3)\n",
      "0.86549395\n",
      "[Epoch 3/10] [Batch 457/1081] [D loss: 0.129423] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.288267] time: 0:29:35.349868\n",
      "(10, 128, 128, 3)\n",
      "0.89594054\n",
      "[Epoch 3/10] [Batch 458/1081] [D loss: 0.129408] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.419781] time: 0:29:35.756936\n",
      "(10, 128, 128, 3)\n",
      "0.93445563\n",
      "[Epoch 3/10] [Batch 459/1081] [D loss: 0.129275] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.655646] time: 0:29:36.166599\n",
      "(10, 128, 128, 3)\n",
      "0.9027869\n",
      "[Epoch 3/10] [Batch 460/1081] [D loss: 0.129185] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.196980] time: 0:29:36.580369\n",
      "(10, 128, 128, 3)\n",
      "0.91074544\n",
      "[Epoch 3/10] [Batch 461/1081] [D loss: 0.129403] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.436472] time: 0:29:36.960946\n",
      "(10, 128, 128, 3)\n",
      "0.90827245\n",
      "[Epoch 3/10] [Batch 462/1081] [D loss: 0.129062] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.755742] time: 0:29:37.359393\n",
      "(10, 128, 128, 3)\n",
      "0.9199665\n",
      "[Epoch 3/10] [Batch 463/1081] [D loss: 0.128998] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.261152] time: 0:29:37.752131\n",
      "(10, 128, 128, 3)\n",
      "0.9656606\n",
      "[Epoch 3/10] [Batch 464/1081] [D loss: 0.129251] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.051971] time: 0:29:38.172071\n",
      "(10, 128, 128, 3)\n",
      "0.94340223\n",
      "[Epoch 3/10] [Batch 465/1081] [D loss: 0.129638] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.708372] time: 0:29:38.583228\n",
      "(10, 128, 128, 3)\n",
      "0.95131016\n",
      "[Epoch 3/10] [Batch 466/1081] [D loss: 0.129519] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.529018] time: 0:29:38.968239\n",
      "(10, 128, 128, 3)\n",
      "0.9378217\n",
      "[Epoch 3/10] [Batch 467/1081] [D loss: 0.129131] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.094213] time: 0:29:39.362831\n",
      "(10, 128, 128, 3)\n",
      "0.9156056\n",
      "[Epoch 3/10] [Batch 468/1081] [D loss: 0.128758] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.945908] time: 0:29:39.767996\n",
      "(10, 128, 128, 3)\n",
      "0.9339823\n",
      "[Epoch 3/10] [Batch 469/1081] [D loss: 0.128366] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.565907] time: 0:29:40.153946\n",
      "(10, 128, 128, 3)\n",
      "0.93125135\n",
      "[Epoch 3/10] [Batch 470/1081] [D loss: 0.128268] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.029535] time: 0:29:40.535383\n",
      "(10, 128, 128, 3)\n",
      "0.8811574\n",
      "[Epoch 3/10] [Batch 471/1081] [D loss: 0.128411] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.902297] time: 0:29:40.919098\n",
      "(10, 128, 128, 3)\n",
      "0.9321262\n",
      "[Epoch 3/10] [Batch 472/1081] [D loss: 0.127933] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.229495] time: 0:29:41.318595\n",
      "(10, 128, 128, 3)\n",
      "0.9114337\n",
      "[Epoch 3/10] [Batch 473/1081] [D loss: 0.127961] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.486179] time: 0:29:41.710883\n",
      "(10, 128, 128, 3)\n",
      "0.91414386\n",
      "[Epoch 3/10] [Batch 474/1081] [D loss: 0.127994] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.706038] time: 0:29:42.114622\n",
      "(10, 128, 128, 3)\n",
      "0.89558077\n",
      "[Epoch 3/10] [Batch 475/1081] [D loss: 0.127997] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.671700] time: 0:29:42.492339\n",
      "(10, 128, 128, 3)\n",
      "0.9471291\n",
      "[Epoch 3/10] [Batch 476/1081] [D loss: 0.127523] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.727317] time: 0:29:42.911497\n",
      "(10, 128, 128, 3)\n",
      "0.8996765\n",
      "[Epoch 3/10] [Batch 477/1081] [D loss: 0.127384] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.924726] time: 0:29:43.292154\n",
      "(10, 128, 128, 3)\n",
      "0.87915975\n",
      "[Epoch 3/10] [Batch 478/1081] [D loss: 0.127497] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.444823] time: 0:29:43.728518\n",
      "(10, 128, 128, 3)\n",
      "0.86050755\n",
      "[Epoch 3/10] [Batch 479/1081] [D loss: 0.127786] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.908101] time: 0:29:44.123381\n",
      "(10, 128, 128, 3)\n",
      "0.9144433\n",
      "[Epoch 3/10] [Batch 480/1081] [D loss: 0.127062] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.469531] time: 0:29:44.565803\n",
      "(10, 128, 128, 3)\n",
      "0.9301817\n",
      "[Epoch 3/10] [Batch 481/1081] [D loss: 0.127018] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.211132] time: 0:29:44.969495\n",
      "(10, 128, 128, 3)\n",
      "0.9395487\n",
      "[Epoch 3/10] [Batch 482/1081] [D loss: 0.127316] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.422366] time: 0:29:45.356636\n",
      "(10, 128, 128, 3)\n",
      "0.94916576\n",
      "[Epoch 3/10] [Batch 483/1081] [D loss: 0.127084] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.152755] time: 0:29:45.731243\n",
      "(10, 128, 128, 3)\n",
      "0.89867085\n",
      "[Epoch 3/10] [Batch 484/1081] [D loss: 0.127401] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.475765] time: 0:29:46.163898\n",
      "(10, 128, 128, 3)\n",
      "0.88066775\n",
      "[Epoch 3/10] [Batch 485/1081] [D loss: 0.126715] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.012000] time: 0:29:46.571610\n",
      "(10, 128, 128, 3)\n",
      "0.8827136\n",
      "[Epoch 3/10] [Batch 486/1081] [D loss: 0.127109] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.554620] time: 0:29:46.983542\n",
      "(10, 128, 128, 3)\n",
      "0.9234044\n",
      "[Epoch 3/10] [Batch 487/1081] [D loss: 0.126965] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.089269] time: 0:29:47.387319\n",
      "(10, 128, 128, 3)\n",
      "0.94300365\n",
      "[Epoch 3/10] [Batch 488/1081] [D loss: 0.126678] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.660069] time: 0:29:47.771549\n",
      "(10, 128, 128, 3)\n",
      "0.8799707\n",
      "[Epoch 3/10] [Batch 489/1081] [D loss: 0.126842] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.949407] time: 0:29:48.172808\n",
      "(10, 128, 128, 3)\n",
      "0.9361555\n",
      "[Epoch 3/10] [Batch 490/1081] [D loss: 0.126229] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.802629] time: 0:29:48.598935\n",
      "(10, 128, 128, 3)\n",
      "0.9509885\n",
      "[Epoch 3/10] [Batch 491/1081] [D loss: 0.127775] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.538982] time: 0:29:48.994087\n",
      "(10, 128, 128, 3)\n",
      "0.88450027\n",
      "[Epoch 3/10] [Batch 492/1081] [D loss: 0.126053] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.209760] time: 0:29:49.364095\n",
      "(10, 128, 128, 3)\n",
      "0.9484405\n",
      "[Epoch 3/10] [Batch 493/1081] [D loss: 0.125931] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.663076] time: 0:29:49.771275\n",
      "(10, 128, 128, 3)\n",
      "0.91765004\n",
      "[Epoch 3/10] [Batch 494/1081] [D loss: 0.126648] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.154119] time: 0:29:50.194720\n",
      "(10, 128, 128, 3)\n",
      "0.90772605\n",
      "[Epoch 3/10] [Batch 495/1081] [D loss: 0.126343] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.521153] time: 0:29:50.611163\n",
      "(10, 128, 128, 3)\n",
      "0.8718171\n",
      "[Epoch 3/10] [Batch 496/1081] [D loss: 0.125740] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.779049] time: 0:29:51.003216\n",
      "(10, 128, 128, 3)\n",
      "0.94002247\n",
      "[Epoch 3/10] [Batch 497/1081] [D loss: 0.125725] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.487735] time: 0:29:51.382803\n",
      "(10, 128, 128, 3)\n",
      "0.92648196\n",
      "[Epoch 3/10] [Batch 498/1081] [D loss: 0.125504] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.266659] time: 0:29:51.812688\n",
      "(10, 128, 128, 3)\n",
      "0.91153836\n",
      "[Epoch 3/10] [Batch 499/1081] [D loss: 0.125468] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.102926] time: 0:29:52.203371\n",
      "(10, 128, 128, 3)\n",
      "0.91347796\n",
      "[Epoch 3/10] [Batch 500/1081] [D loss: 0.126001] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.018579] time: 0:29:52.582784\n",
      "(10, 128, 128, 3)\n",
      "0.9453175\n",
      "[Epoch 3/10] [Batch 501/1081] [D loss: 0.125320] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.105650] time: 0:29:52.952025\n",
      "(10, 128, 128, 3)\n",
      "0.89186436\n",
      "[Epoch 3/10] [Batch 502/1081] [D loss: 0.125242] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.474908] time: 0:29:53.332539\n",
      "(10, 128, 128, 3)\n",
      "0.92432666\n",
      "[Epoch 3/10] [Batch 503/1081] [D loss: 0.125977] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.418170] time: 0:29:53.713848\n",
      "(10, 128, 128, 3)\n",
      "0.92992043\n",
      "[Epoch 3/10] [Batch 504/1081] [D loss: 0.125602] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.949648] time: 0:29:54.101038\n",
      "(10, 128, 128, 3)\n",
      "0.86355686\n",
      "[Epoch 3/10] [Batch 505/1081] [D loss: 0.125145] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.556102] time: 0:29:54.481092\n",
      "(10, 128, 128, 3)\n",
      "0.905559\n",
      "[Epoch 3/10] [Batch 506/1081] [D loss: 0.124807] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.809865] time: 0:29:54.865133\n",
      "(10, 128, 128, 3)\n",
      "0.88691515\n",
      "[Epoch 3/10] [Batch 507/1081] [D loss: 0.124838] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.006462] time: 0:29:55.257925\n",
      "(10, 128, 128, 3)\n",
      "0.9111993\n",
      "[Epoch 3/10] [Batch 508/1081] [D loss: 0.124943] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.937970] time: 0:29:55.690730\n",
      "(10, 128, 128, 3)\n",
      "0.9080424\n",
      "[Epoch 3/10] [Batch 509/1081] [D loss: 0.124532] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.839833] time: 0:29:56.087757\n",
      "(10, 128, 128, 3)\n",
      "0.8990929\n",
      "[Epoch 3/10] [Batch 510/1081] [D loss: 0.124982] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.462064] time: 0:29:56.505313\n",
      "(10, 128, 128, 3)\n",
      "0.87273383\n",
      "[Epoch 3/10] [Batch 511/1081] [D loss: 0.124944] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.834648] time: 0:29:56.918117\n",
      "(10, 128, 128, 3)\n",
      "0.9464968\n",
      "[Epoch 3/10] [Batch 512/1081] [D loss: 0.124301] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.127776] time: 0:29:57.311298\n",
      "(10, 128, 128, 3)\n",
      "0.932817\n",
      "[Epoch 3/10] [Batch 513/1081] [D loss: 0.124965] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.423037] time: 0:29:57.733838\n",
      "(10, 128, 128, 3)\n",
      "0.9333196\n",
      "[Epoch 3/10] [Batch 514/1081] [D loss: 0.124245] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.812899] time: 0:29:58.143065\n",
      "(10, 128, 128, 3)\n",
      "0.92362005\n",
      "[Epoch 3/10] [Batch 515/1081] [D loss: 0.124643] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.333477] time: 0:29:58.523890\n",
      "(10, 128, 128, 3)\n",
      "0.8945561\n",
      "[Epoch 3/10] [Batch 516/1081] [D loss: 0.124122] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.829409] time: 0:29:58.924860\n",
      "(10, 128, 128, 3)\n",
      "0.9256304\n",
      "[Epoch 3/10] [Batch 517/1081] [D loss: 0.123701] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.203621] time: 0:29:59.349075\n",
      "(10, 128, 128, 3)\n",
      "0.92416024\n",
      "[Epoch 3/10] [Batch 518/1081] [D loss: 0.123638] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.933964] time: 0:29:59.775206\n",
      "(10, 128, 128, 3)\n",
      "0.8842299\n",
      "[Epoch 3/10] [Batch 519/1081] [D loss: 0.123784] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.962776] time: 0:30:00.186386\n",
      "(10, 128, 128, 3)\n",
      "0.8895716\n",
      "[Epoch 3/10] [Batch 520/1081] [D loss: 0.123897] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.006275] time: 0:30:00.559179\n",
      "(10, 128, 128, 3)\n",
      "0.8628356\n",
      "[Epoch 3/10] [Batch 521/1081] [D loss: 0.123326] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.515054] time: 0:30:00.972564\n",
      "(10, 128, 128, 3)\n",
      "0.87376446\n",
      "[Epoch 3/10] [Batch 522/1081] [D loss: 0.123482] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.764040] time: 0:30:01.375907\n",
      "(10, 128, 128, 3)\n",
      "0.9403725\n",
      "[Epoch 3/10] [Batch 523/1081] [D loss: 0.123433] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.444802] time: 0:30:01.788419\n",
      "(10, 128, 128, 3)\n",
      "0.89749116\n",
      "[Epoch 3/10] [Batch 524/1081] [D loss: 0.123402] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.937274] time: 0:30:02.192543\n",
      "(10, 128, 128, 3)\n",
      "0.92007476\n",
      "[Epoch 3/10] [Batch 525/1081] [D loss: 0.122942] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.435953] time: 0:30:02.619752\n",
      "(10, 128, 128, 3)\n",
      "0.84470034\n",
      "[Epoch 3/10] [Batch 526/1081] [D loss: 0.123359] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.516668] time: 0:30:03.015712\n",
      "(10, 128, 128, 3)\n",
      "0.870517\n",
      "[Epoch 3/10] [Batch 527/1081] [D loss: 0.122967] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.933515] time: 0:30:03.406522\n",
      "(10, 128, 128, 3)\n",
      "0.9667122\n",
      "[Epoch 3/10] [Batch 528/1081] [D loss: 0.122807] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.610353] time: 0:30:03.806739\n",
      "(10, 128, 128, 3)\n",
      "0.868375\n",
      "[Epoch 3/10] [Batch 529/1081] [D loss: 0.122792] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 13.188868] time: 0:30:04.204288\n",
      "(10, 128, 128, 3)\n",
      "0.9288958\n",
      "[Epoch 3/10] [Batch 530/1081] [D loss: 0.122985] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.900500] time: 0:30:04.610285\n",
      "(10, 128, 128, 3)\n",
      "0.86921483\n",
      "[Epoch 3/10] [Batch 531/1081] [D loss: 0.123251] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.453105] time: 0:30:05.006796\n",
      "(10, 128, 128, 3)\n",
      "0.8740354\n",
      "[Epoch 3/10] [Batch 532/1081] [D loss: 0.122531] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.462808] time: 0:30:05.410789\n",
      "(10, 128, 128, 3)\n",
      "0.8809472\n",
      "[Epoch 3/10] [Batch 533/1081] [D loss: 0.122530] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.007491] time: 0:30:05.816119\n",
      "(10, 128, 128, 3)\n",
      "0.9640198\n",
      "[Epoch 3/10] [Batch 534/1081] [D loss: 0.122673] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.651544] time: 0:30:06.231050\n",
      "(10, 128, 128, 3)\n",
      "0.8661297\n",
      "[Epoch 3/10] [Batch 535/1081] [D loss: 0.122366] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.891352] time: 0:30:06.620374\n",
      "(10, 128, 128, 3)\n",
      "0.9323222\n",
      "[Epoch 3/10] [Batch 536/1081] [D loss: 0.122203] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.623849] time: 0:30:07.027170\n",
      "(10, 128, 128, 3)\n",
      "0.88201314\n",
      "[Epoch 3/10] [Batch 537/1081] [D loss: 0.122509] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.362379] time: 0:30:07.422007\n",
      "(10, 128, 128, 3)\n",
      "0.8987613\n",
      "[Epoch 3/10] [Batch 538/1081] [D loss: 0.122293] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.327774] time: 0:30:07.826835\n",
      "(10, 128, 128, 3)\n",
      "0.87161136\n",
      "[Epoch 3/10] [Batch 539/1081] [D loss: 0.122114] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.739008] time: 0:30:08.227885\n",
      "(10, 128, 128, 3)\n",
      "0.9554078\n",
      "[Epoch 3/10] [Batch 540/1081] [D loss: 0.122893] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.562675] time: 0:30:08.630019\n",
      "(10, 128, 128, 3)\n",
      "0.882679\n",
      "[Epoch 3/10] [Batch 541/1081] [D loss: 0.122058] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.499645] time: 0:30:09.048485\n",
      "(10, 128, 128, 3)\n",
      "0.87573004\n",
      "[Epoch 3/10] [Batch 542/1081] [D loss: 0.122375] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.754591] time: 0:30:09.467733\n",
      "(10, 128, 128, 3)\n",
      "0.9041471\n",
      "[Epoch 3/10] [Batch 543/1081] [D loss: 0.121433] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.065951] time: 0:30:09.852151\n",
      "(10, 128, 128, 3)\n",
      "0.90092015\n",
      "[Epoch 3/10] [Batch 544/1081] [D loss: 0.121480] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.775970] time: 0:30:10.282139\n",
      "(10, 128, 128, 3)\n",
      "0.8882108\n",
      "[Epoch 3/10] [Batch 545/1081] [D loss: 0.121362] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.629348] time: 0:30:10.676923\n",
      "(10, 128, 128, 3)\n",
      "0.8948188\n",
      "[Epoch 3/10] [Batch 546/1081] [D loss: 0.121404] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.072229] time: 0:30:11.101774\n",
      "(10, 128, 128, 3)\n",
      "0.8934291\n",
      "[Epoch 3/10] [Batch 547/1081] [D loss: 0.121281] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.902887] time: 0:30:11.533795\n",
      "(10, 128, 128, 3)\n",
      "0.91704386\n",
      "[Epoch 3/10] [Batch 548/1081] [D loss: 0.121139] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.089359] time: 0:30:11.943472\n",
      "(10, 128, 128, 3)\n",
      "0.9165685\n",
      "[Epoch 3/10] [Batch 549/1081] [D loss: 0.120967] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.348948] time: 0:30:12.328184\n",
      "(10, 128, 128, 3)\n",
      "0.9555661\n",
      "[Epoch 3/10] [Batch 550/1081] [D loss: 0.120956] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.601352] time: 0:30:12.736854\n",
      "(10, 128, 128, 3)\n",
      "0.90077037\n",
      "[Epoch 3/10] [Batch 551/1081] [D loss: 0.121644] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.291548] time: 0:30:13.112449\n",
      "(10, 128, 128, 3)\n",
      "0.9149634\n",
      "[Epoch 3/10] [Batch 552/1081] [D loss: 0.120547] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.551483] time: 0:30:13.503754\n",
      "(10, 128, 128, 3)\n",
      "0.90649337\n",
      "[Epoch 3/10] [Batch 553/1081] [D loss: 0.120903] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.655195] time: 0:30:13.879665\n",
      "(10, 128, 128, 3)\n",
      "0.93973416\n",
      "[Epoch 3/10] [Batch 554/1081] [D loss: 0.120883] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.467844] time: 0:30:14.316216\n",
      "(10, 128, 128, 3)\n",
      "0.8945329\n",
      "[Epoch 3/10] [Batch 555/1081] [D loss: 0.120471] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.279095] time: 0:30:14.703699\n",
      "(10, 128, 128, 3)\n",
      "0.94841886\n",
      "[Epoch 3/10] [Batch 556/1081] [D loss: 0.121137] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.730282] time: 0:30:15.138847\n",
      "(10, 128, 128, 3)\n",
      "0.9538584\n",
      "[Epoch 3/10] [Batch 557/1081] [D loss: 0.120387] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.896348] time: 0:30:15.545929\n",
      "(10, 128, 128, 3)\n",
      "0.8362708\n",
      "[Epoch 3/10] [Batch 558/1081] [D loss: 0.120504] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.049431] time: 0:30:15.951390\n",
      "(10, 128, 128, 3)\n",
      "0.93491894\n",
      "[Epoch 3/10] [Batch 559/1081] [D loss: 0.121241] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.367205] time: 0:30:16.367303\n",
      "(10, 128, 128, 3)\n",
      "0.8825535\n",
      "[Epoch 3/10] [Batch 560/1081] [D loss: 0.121041] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.806863] time: 0:30:16.800109\n",
      "(10, 128, 128, 3)\n",
      "0.845738\n",
      "[Epoch 3/10] [Batch 561/1081] [D loss: 0.120161] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.277216] time: 0:30:17.216762\n",
      "(10, 128, 128, 3)\n",
      "0.89309627\n",
      "[Epoch 3/10] [Batch 562/1081] [D loss: 0.120187] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.921607] time: 0:30:17.610455\n",
      "(10, 128, 128, 3)\n",
      "0.9534304\n",
      "[Epoch 3/10] [Batch 563/1081] [D loss: 0.120678] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.191892] time: 0:30:18.025202\n",
      "(10, 128, 128, 3)\n",
      "0.9438481\n",
      "[Epoch 3/10] [Batch 564/1081] [D loss: 0.120757] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.647571] time: 0:30:18.423296\n",
      "(10, 128, 128, 3)\n",
      "0.84859943\n",
      "[Epoch 3/10] [Batch 565/1081] [D loss: 0.119885] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.789294] time: 0:30:18.849741\n",
      "(10, 128, 128, 3)\n",
      "0.8897465\n",
      "[Epoch 3/10] [Batch 566/1081] [D loss: 0.120816] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.513393] time: 0:30:19.289274\n",
      "(10, 128, 128, 3)\n",
      "0.92015743\n",
      "[Epoch 3/10] [Batch 567/1081] [D loss: 0.119620] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.401133] time: 0:30:19.699531\n",
      "(10, 128, 128, 3)\n",
      "0.87542224\n",
      "[Epoch 3/10] [Batch 568/1081] [D loss: 0.119323] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.578055] time: 0:30:20.116260\n",
      "(10, 128, 128, 3)\n",
      "0.90657395\n",
      "[Epoch 3/10] [Batch 569/1081] [D loss: 0.119214] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.229323] time: 0:30:20.500930\n",
      "(10, 128, 128, 3)\n",
      "0.966933\n",
      "[Epoch 3/10] [Batch 570/1081] [D loss: 0.119349] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.374631] time: 0:30:20.912113\n",
      "(10, 128, 128, 3)\n",
      "0.91461545\n",
      "[Epoch 3/10] [Batch 571/1081] [D loss: 0.119008] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.130544] time: 0:30:21.311975\n",
      "(10, 128, 128, 3)\n",
      "0.881481\n",
      "[Epoch 3/10] [Batch 572/1081] [D loss: 0.121442] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.801926] time: 0:30:21.716005\n",
      "(10, 128, 128, 3)\n",
      "0.93911654\n",
      "[Epoch 3/10] [Batch 573/1081] [D loss: 0.120658] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.987567] time: 0:30:22.119452\n",
      "(10, 128, 128, 3)\n",
      "0.89667153\n",
      "[Epoch 3/10] [Batch 574/1081] [D loss: 0.119046] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.005518] time: 0:30:22.506600\n",
      "(10, 128, 128, 3)\n",
      "0.91865295\n",
      "[Epoch 3/10] [Batch 575/1081] [D loss: 0.120442] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.031961] time: 0:30:22.891232\n",
      "(10, 128, 128, 3)\n",
      "0.9063\n",
      "[Epoch 3/10] [Batch 576/1081] [D loss: 0.119769] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.297468] time: 0:30:23.276133\n",
      "(10, 128, 128, 3)\n",
      "0.8913827\n",
      "[Epoch 3/10] [Batch 577/1081] [D loss: 0.119673] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.820632] time: 0:30:23.667146\n",
      "(10, 128, 128, 3)\n",
      "0.881834\n",
      "[Epoch 3/10] [Batch 578/1081] [D loss: 0.118847] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.252207] time: 0:30:24.081906\n",
      "(10, 128, 128, 3)\n",
      "0.92111236\n",
      "[Epoch 3/10] [Batch 579/1081] [D loss: 0.118832] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.454365] time: 0:30:24.478727\n",
      "(10, 128, 128, 3)\n",
      "0.9111975\n",
      "[Epoch 3/10] [Batch 580/1081] [D loss: 0.118487] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.294895] time: 0:30:24.898483\n",
      "(10, 128, 128, 3)\n",
      "0.9108076\n",
      "[Epoch 3/10] [Batch 581/1081] [D loss: 0.118384] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.627896] time: 0:30:25.315458\n",
      "(10, 128, 128, 3)\n",
      "0.8541739\n",
      "[Epoch 3/10] [Batch 582/1081] [D loss: 0.118244] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.764909] time: 0:30:25.708950\n",
      "(10, 128, 128, 3)\n",
      "0.8983176\n",
      "[Epoch 3/10] [Batch 583/1081] [D loss: 0.118296] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.151634] time: 0:30:26.096309\n",
      "(10, 128, 128, 3)\n",
      "0.93356377\n",
      "[Epoch 3/10] [Batch 584/1081] [D loss: 0.118651] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.183653] time: 0:30:26.476565\n",
      "(10, 128, 128, 3)\n",
      "0.94581103\n",
      "[Epoch 3/10] [Batch 585/1081] [D loss: 0.118582] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.511983] time: 0:30:26.865644\n",
      "(10, 128, 128, 3)\n",
      "0.91911536\n",
      "[Epoch 3/10] [Batch 586/1081] [D loss: 0.117983] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.112655] time: 0:30:27.260685\n",
      "(10, 128, 128, 3)\n",
      "0.89743024\n",
      "[Epoch 3/10] [Batch 587/1081] [D loss: 0.118019] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.707268] time: 0:30:27.693860\n",
      "(10, 128, 128, 3)\n",
      "0.8663394\n",
      "[Epoch 3/10] [Batch 588/1081] [D loss: 0.118208] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.493067] time: 0:30:28.092073\n",
      "(10, 128, 128, 3)\n",
      "0.93115807\n",
      "[Epoch 3/10] [Batch 589/1081] [D loss: 0.118133] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.006764] time: 0:30:28.510535\n",
      "(10, 128, 128, 3)\n",
      "0.93115187\n",
      "[Epoch 3/10] [Batch 590/1081] [D loss: 0.118607] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.178696] time: 0:30:28.955258\n",
      "(10, 128, 128, 3)\n",
      "0.94053006\n",
      "[Epoch 3/10] [Batch 591/1081] [D loss: 0.118032] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.089195] time: 0:30:29.377531\n",
      "(10, 128, 128, 3)\n",
      "0.9053083\n",
      "[Epoch 3/10] [Batch 592/1081] [D loss: 0.117416] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.870366] time: 0:30:29.805744\n",
      "(10, 128, 128, 3)\n",
      "0.9625457\n",
      "[Epoch 3/10] [Batch 593/1081] [D loss: 0.117293] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.194428] time: 0:30:30.219041\n",
      "(10, 128, 128, 3)\n",
      "0.9165124\n",
      "[Epoch 3/10] [Batch 594/1081] [D loss: 0.117221] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.835999] time: 0:30:30.623918\n",
      "(10, 128, 128, 3)\n",
      "0.880284\n",
      "[Epoch 3/10] [Batch 595/1081] [D loss: 0.117188] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.451308] time: 0:30:31.021221\n",
      "(10, 128, 128, 3)\n",
      "0.9241431\n",
      "[Epoch 3/10] [Batch 596/1081] [D loss: 0.117431] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.747736] time: 0:30:31.460170\n",
      "(10, 128, 128, 3)\n",
      "0.9432478\n",
      "[Epoch 3/10] [Batch 597/1081] [D loss: 0.117870] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.756333] time: 0:30:31.864836\n",
      "(10, 128, 128, 3)\n",
      "0.9181387\n",
      "[Epoch 3/10] [Batch 598/1081] [D loss: 0.117050] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.724825] time: 0:30:32.263962\n",
      "(10, 128, 128, 3)\n",
      "0.93182343\n",
      "[Epoch 3/10] [Batch 599/1081] [D loss: 0.117065] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.363319] time: 0:30:32.656436\n",
      "(10, 128, 128, 3)\n",
      "0.86989087\n",
      "[Epoch 3/10] [Batch 600/1081] [D loss: 0.117408] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.479943] time: 0:30:33.044225\n",
      "(10, 128, 128, 3)\n",
      "0.9343286\n",
      "[Epoch 3/10] [Batch 601/1081] [D loss: 0.117209] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.329853] time: 0:30:33.463254\n",
      "(10, 128, 128, 3)\n",
      "0.925499\n",
      "[Epoch 3/10] [Batch 602/1081] [D loss: 0.117794] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.596172] time: 0:30:33.871304\n",
      "(10, 128, 128, 3)\n",
      "0.94149137\n",
      "[Epoch 3/10] [Batch 603/1081] [D loss: 0.118293] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.489468] time: 0:30:34.268774\n",
      "(10, 128, 128, 3)\n",
      "0.95143837\n",
      "[Epoch 3/10] [Batch 604/1081] [D loss: 0.118398] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.846934] time: 0:30:34.670334\n",
      "(10, 128, 128, 3)\n",
      "0.94463974\n",
      "[Epoch 3/10] [Batch 605/1081] [D loss: 0.116997] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.728969] time: 0:30:35.072064\n",
      "(10, 128, 128, 3)\n",
      "0.8854508\n",
      "[Epoch 3/10] [Batch 606/1081] [D loss: 0.116393] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.007463] time: 0:30:35.460139\n",
      "(10, 128, 128, 3)\n",
      "0.94586253\n",
      "[Epoch 3/10] [Batch 607/1081] [D loss: 0.118567] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.022038] time: 0:30:35.834728\n",
      "(10, 128, 128, 3)\n",
      "0.87242526\n",
      "[Epoch 3/10] [Batch 608/1081] [D loss: 0.213844] [D acc: 0.85 (1.00 real, 0.70 fake)] [G loss: 10.937603] time: 0:30:36.221389\n",
      "(10, 128, 128, 3)\n",
      "0.90684885\n",
      "[Epoch 3/10] [Batch 609/1081] [D loss: 0.458939] [D acc: 0.35 (0.40 real, 0.30 fake)] [G loss: 10.445335] time: 0:30:36.590033\n",
      "(10, 128, 128, 3)\n",
      "0.8784397\n",
      "[Epoch 3/10] [Batch 610/1081] [D loss: 0.255082] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 10.581933] time: 0:30:36.990996\n",
      "(10, 128, 128, 3)\n",
      "0.87742275\n",
      "[Epoch 3/10] [Batch 611/1081] [D loss: 0.175348] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.229212] time: 0:30:37.375436\n",
      "(10, 128, 128, 3)\n",
      "0.8377094\n",
      "[Epoch 3/10] [Batch 612/1081] [D loss: 0.181216] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.107775] time: 0:30:37.776552\n",
      "(10, 128, 128, 3)\n",
      "0.89493483\n",
      "[Epoch 3/10] [Batch 613/1081] [D loss: 0.176329] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.462946] time: 0:30:38.150769\n",
      "(10, 128, 128, 3)\n",
      "0.91916984\n",
      "[Epoch 3/10] [Batch 614/1081] [D loss: 0.153044] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.735331] time: 0:30:38.548737\n",
      "(10, 128, 128, 3)\n",
      "0.9064639\n",
      "[Epoch 3/10] [Batch 615/1081] [D loss: 0.175422] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.146132] time: 0:30:38.988895\n",
      "(10, 128, 128, 3)\n",
      "0.93662477\n",
      "[Epoch 3/10] [Batch 616/1081] [D loss: 0.311874] [D acc: 0.70 (0.40 real, 1.00 fake)] [G loss: 10.457108] time: 0:30:39.374463\n",
      "(10, 128, 128, 3)\n",
      "0.88694245\n",
      "[Epoch 3/10] [Batch 617/1081] [D loss: 0.162313] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.179589] time: 0:30:39.797384\n",
      "(10, 128, 128, 3)\n",
      "0.9373625\n",
      "[Epoch 3/10] [Batch 618/1081] [D loss: 0.152176] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.395098] time: 0:30:40.231892\n",
      "(10, 128, 128, 3)\n",
      "0.91000336\n",
      "[Epoch 3/10] [Batch 619/1081] [D loss: 0.176456] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.077449] time: 0:30:40.643877\n",
      "(10, 128, 128, 3)\n",
      "0.92475796\n",
      "[Epoch 3/10] [Batch 620/1081] [D loss: 0.204120] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 9.947811] time: 0:30:41.051415\n",
      "(10, 128, 128, 3)\n",
      "0.8816727\n",
      "[Epoch 3/10] [Batch 621/1081] [D loss: 0.171590] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.625305] time: 0:30:41.463448\n",
      "(10, 128, 128, 3)\n",
      "0.878153\n",
      "[Epoch 3/10] [Batch 622/1081] [D loss: 0.164445] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.151760] time: 0:30:41.842528\n",
      "(10, 128, 128, 3)\n",
      "0.9322808\n",
      "[Epoch 3/10] [Batch 623/1081] [D loss: 0.151119] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.371969] time: 0:30:42.242170\n",
      "(10, 128, 128, 3)\n",
      "0.9304454\n",
      "[Epoch 3/10] [Batch 624/1081] [D loss: 0.150156] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.199389] time: 0:30:42.619323\n",
      "(10, 128, 128, 3)\n",
      "0.96441084\n",
      "[Epoch 3/10] [Batch 625/1081] [D loss: 0.147942] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.802846] time: 0:30:43.015959\n",
      "(10, 128, 128, 3)\n",
      "0.89849883\n",
      "[Epoch 3/10] [Batch 626/1081] [D loss: 0.170512] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.670217] time: 0:30:43.426568\n",
      "(10, 128, 128, 3)\n",
      "0.9154441\n",
      "[Epoch 3/10] [Batch 627/1081] [D loss: 0.157904] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.956353] time: 0:30:43.826679\n",
      "(10, 128, 128, 3)\n",
      "0.9038083\n",
      "[Epoch 3/10] [Batch 628/1081] [D loss: 0.209782] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 10.144993] time: 0:30:44.226798\n",
      "(10, 128, 128, 3)\n",
      "0.9092886\n",
      "[Epoch 3/10] [Batch 629/1081] [D loss: 0.157866] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.812332] time: 0:30:44.593711\n",
      "(10, 128, 128, 3)\n",
      "0.9397107\n",
      "[Epoch 3/10] [Batch 630/1081] [D loss: 0.149999] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.387821] time: 0:30:45.031477\n",
      "(10, 128, 128, 3)\n",
      "0.9192799\n",
      "[Epoch 3/10] [Batch 631/1081] [D loss: 0.163152] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.757631] time: 0:30:45.431729\n",
      "(10, 128, 128, 3)\n",
      "0.8505953\n",
      "[Epoch 3/10] [Batch 632/1081] [D loss: 0.149163] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.187593] time: 0:30:45.836411\n",
      "(10, 128, 128, 3)\n",
      "0.90258664\n",
      "[Epoch 3/10] [Batch 633/1081] [D loss: 0.145523] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.932625] time: 0:30:46.258936\n",
      "(10, 128, 128, 3)\n",
      "0.8893747\n",
      "[Epoch 3/10] [Batch 634/1081] [D loss: 0.145264] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.102512] time: 0:30:46.685997\n",
      "(10, 128, 128, 3)\n",
      "0.9638013\n",
      "[Epoch 3/10] [Batch 635/1081] [D loss: 0.170950] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.951480] time: 0:30:47.079829\n",
      "(10, 128, 128, 3)\n",
      "0.9017138\n",
      "[Epoch 3/10] [Batch 636/1081] [D loss: 0.144684] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.739832] time: 0:30:47.467262\n",
      "(10, 128, 128, 3)\n",
      "0.9127138\n",
      "[Epoch 3/10] [Batch 637/1081] [D loss: 0.142974] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.902033] time: 0:30:47.844065\n",
      "(10, 128, 128, 3)\n",
      "0.90080905\n",
      "[Epoch 3/10] [Batch 638/1081] [D loss: 0.145431] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.533688] time: 0:30:48.265699\n",
      "(10, 128, 128, 3)\n",
      "0.9718954\n",
      "[Epoch 3/10] [Batch 639/1081] [D loss: 0.143987] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.619342] time: 0:30:48.671763\n",
      "(10, 128, 128, 3)\n",
      "0.86419314\n",
      "[Epoch 3/10] [Batch 640/1081] [D loss: 0.148664] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.777790] time: 0:30:49.037096\n",
      "(10, 128, 128, 3)\n",
      "0.91173834\n",
      "[Epoch 3/10] [Batch 641/1081] [D loss: 0.146038] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.019417] time: 0:30:49.429627\n",
      "(10, 128, 128, 3)\n",
      "0.918256\n",
      "[Epoch 3/10] [Batch 642/1081] [D loss: 0.148770] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.899788] time: 0:30:49.841172\n",
      "(10, 128, 128, 3)\n",
      "0.90530235\n",
      "[Epoch 3/10] [Batch 643/1081] [D loss: 0.147924] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.159344] time: 0:30:50.266131\n",
      "(10, 128, 128, 3)\n",
      "0.98266554\n",
      "[Epoch 3/10] [Batch 644/1081] [D loss: 0.145759] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.768431] time: 0:30:50.671270\n",
      "(10, 128, 128, 3)\n",
      "0.87697005\n",
      "[Epoch 3/10] [Batch 645/1081] [D loss: 0.147420] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.446142] time: 0:30:51.062511\n",
      "(10, 128, 128, 3)\n",
      "0.8979617\n",
      "[Epoch 3/10] [Batch 646/1081] [D loss: 0.145351] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.065950] time: 0:30:51.451806\n",
      "(10, 128, 128, 3)\n",
      "0.8666597\n",
      "[Epoch 3/10] [Batch 647/1081] [D loss: 0.142447] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.386807] time: 0:30:51.877990\n",
      "(10, 128, 128, 3)\n",
      "0.8922472\n",
      "[Epoch 3/10] [Batch 648/1081] [D loss: 0.142542] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.248677] time: 0:30:52.303929\n",
      "(10, 128, 128, 3)\n",
      "0.8726337\n",
      "[Epoch 3/10] [Batch 649/1081] [D loss: 0.145581] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.983815] time: 0:30:52.720783\n",
      "(10, 128, 128, 3)\n",
      "0.8710974\n",
      "[Epoch 3/10] [Batch 650/1081] [D loss: 0.142759] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.145688] time: 0:30:53.114933\n",
      "(10, 128, 128, 3)\n",
      "0.93783265\n",
      "[Epoch 3/10] [Batch 651/1081] [D loss: 0.144135] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.010697] time: 0:30:53.513664\n",
      "(10, 128, 128, 3)\n",
      "0.88855886\n",
      "[Epoch 3/10] [Batch 652/1081] [D loss: 0.140836] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.820607] time: 0:30:53.906299\n",
      "(10, 128, 128, 3)\n",
      "0.91149074\n",
      "[Epoch 3/10] [Batch 653/1081] [D loss: 0.147591] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.590311] time: 0:30:54.306938\n",
      "(10, 128, 128, 3)\n",
      "0.9038059\n",
      "[Epoch 3/10] [Batch 654/1081] [D loss: 0.144352] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.311348] time: 0:30:54.705915\n",
      "(10, 128, 128, 3)\n",
      "0.8893795\n",
      "[Epoch 3/10] [Batch 655/1081] [D loss: 0.142109] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.583045] time: 0:30:55.106468\n",
      "(10, 128, 128, 3)\n",
      "0.9420903\n",
      "[Epoch 3/10] [Batch 656/1081] [D loss: 0.141300] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.790977] time: 0:30:55.541407\n",
      "(10, 128, 128, 3)\n",
      "0.8415993\n",
      "[Epoch 3/10] [Batch 657/1081] [D loss: 0.141787] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.927830] time: 0:30:55.945932\n",
      "(10, 128, 128, 3)\n",
      "0.9588742\n",
      "[Epoch 3/10] [Batch 658/1081] [D loss: 0.142498] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.755819] time: 0:30:56.383378\n",
      "(10, 128, 128, 3)\n",
      "0.965285\n",
      "[Epoch 3/10] [Batch 659/1081] [D loss: 0.142321] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.022790] time: 0:30:56.756450\n",
      "(10, 128, 128, 3)\n",
      "0.9113805\n",
      "[Epoch 3/10] [Batch 660/1081] [D loss: 0.139332] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.069690] time: 0:30:57.155427\n",
      "(10, 128, 128, 3)\n",
      "0.9412689\n",
      "[Epoch 3/10] [Batch 661/1081] [D loss: 0.139824] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.966533] time: 0:30:57.587592\n",
      "(10, 128, 128, 3)\n",
      "0.94356364\n",
      "[Epoch 3/10] [Batch 662/1081] [D loss: 0.141181] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.863106] time: 0:30:58.010022\n",
      "(10, 128, 128, 3)\n",
      "0.92571634\n",
      "[Epoch 3/10] [Batch 663/1081] [D loss: 0.137707] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.468982] time: 0:30:58.407770\n",
      "(10, 128, 128, 3)\n",
      "0.90989107\n",
      "[Epoch 3/10] [Batch 664/1081] [D loss: 0.141198] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.795146] time: 0:30:58.791629\n",
      "(10, 128, 128, 3)\n",
      "0.92193556\n",
      "[Epoch 3/10] [Batch 665/1081] [D loss: 0.143606] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.266354] time: 0:30:59.173585\n",
      "(10, 128, 128, 3)\n",
      "0.92344636\n",
      "[Epoch 3/10] [Batch 666/1081] [D loss: 0.139671] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.075041] time: 0:30:59.583375\n",
      "(10, 128, 128, 3)\n",
      "0.8993785\n",
      "[Epoch 3/10] [Batch 667/1081] [D loss: 0.137857] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.396908] time: 0:31:00.008338\n",
      "(10, 128, 128, 3)\n",
      "0.90550107\n",
      "[Epoch 3/10] [Batch 668/1081] [D loss: 0.136797] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.100622] time: 0:31:00.418491\n",
      "(10, 128, 128, 3)\n",
      "0.89955646\n",
      "[Epoch 3/10] [Batch 669/1081] [D loss: 0.787280] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 9.234793] time: 0:31:00.791775\n",
      "(10, 128, 128, 3)\n",
      "0.87579256\n",
      "[Epoch 3/10] [Batch 670/1081] [D loss: 0.238595] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 10.527086] time: 0:31:01.176109\n",
      "(10, 128, 128, 3)\n",
      "0.870656\n",
      "[Epoch 3/10] [Batch 671/1081] [D loss: 0.234305] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 10.489823] time: 0:31:01.588556\n",
      "(10, 128, 128, 3)\n",
      "0.8963039\n",
      "[Epoch 3/10] [Batch 672/1081] [D loss: 0.179984] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.935599] time: 0:31:01.995415\n",
      "(10, 128, 128, 3)\n",
      "0.8877099\n",
      "[Epoch 3/10] [Batch 673/1081] [D loss: 0.174670] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.061421] time: 0:31:02.387171\n",
      "(10, 128, 128, 3)\n",
      "0.8821885\n",
      "[Epoch 3/10] [Batch 674/1081] [D loss: 0.149667] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.305612] time: 0:31:02.808825\n",
      "(10, 128, 128, 3)\n",
      "0.9043519\n",
      "[Epoch 3/10] [Batch 675/1081] [D loss: 0.144229] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.180835] time: 0:31:03.216503\n",
      "(10, 128, 128, 3)\n",
      "0.90659136\n",
      "[Epoch 3/10] [Batch 676/1081] [D loss: 0.147111] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.500680] time: 0:31:03.596061\n",
      "(10, 128, 128, 3)\n",
      "0.91566795\n",
      "[Epoch 3/10] [Batch 677/1081] [D loss: 0.143260] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.362438] time: 0:31:03.978538\n",
      "(10, 128, 128, 3)\n",
      "0.87975454\n",
      "[Epoch 3/10] [Batch 678/1081] [D loss: 0.141599] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.015624] time: 0:31:04.380120\n",
      "(10, 128, 128, 3)\n",
      "0.9058539\n",
      "[Epoch 3/10] [Batch 679/1081] [D loss: 0.140948] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.652826] time: 0:31:04.770648\n",
      "(10, 128, 128, 3)\n",
      "0.94283515\n",
      "[Epoch 3/10] [Batch 680/1081] [D loss: 0.139054] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.053808] time: 0:31:05.140988\n",
      "(10, 128, 128, 3)\n",
      "0.8978247\n",
      "[Epoch 3/10] [Batch 681/1081] [D loss: 0.139759] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.065113] time: 0:31:05.534020\n",
      "(10, 128, 128, 3)\n",
      "0.9237242\n",
      "[Epoch 3/10] [Batch 682/1081] [D loss: 0.151175] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.746971] time: 0:31:05.953095\n",
      "(10, 128, 128, 3)\n",
      "0.9265241\n",
      "[Epoch 3/10] [Batch 683/1081] [D loss: 0.158020] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.165592] time: 0:31:06.375209\n",
      "(10, 128, 128, 3)\n",
      "0.933724\n",
      "[Epoch 3/10] [Batch 684/1081] [D loss: 0.147288] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.201942] time: 0:31:06.785183\n",
      "(10, 128, 128, 3)\n",
      "0.9078419\n",
      "[Epoch 3/10] [Batch 685/1081] [D loss: 0.367490] [D acc: 0.55 (0.10 real, 1.00 fake)] [G loss: 9.125219] time: 0:31:07.186510\n",
      "(10, 128, 128, 3)\n",
      "0.87818176\n",
      "[Epoch 3/10] [Batch 686/1081] [D loss: 0.194394] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.388298] time: 0:31:07.583518\n",
      "(10, 128, 128, 3)\n",
      "0.9162073\n",
      "[Epoch 3/10] [Batch 687/1081] [D loss: 0.140721] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.438090] time: 0:31:08.024209\n",
      "(10, 128, 128, 3)\n",
      "0.91754407\n",
      "[Epoch 3/10] [Batch 688/1081] [D loss: 0.151574] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.583117] time: 0:31:08.414331\n",
      "(10, 128, 128, 3)\n",
      "0.9067738\n",
      "[Epoch 3/10] [Batch 689/1081] [D loss: 0.177420] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.250844] time: 0:31:08.821866\n",
      "(10, 128, 128, 3)\n",
      "0.9008744\n",
      "[Epoch 3/10] [Batch 690/1081] [D loss: 0.159759] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.310093] time: 0:31:09.225776\n",
      "(10, 128, 128, 3)\n",
      "0.87890786\n",
      "[Epoch 3/10] [Batch 691/1081] [D loss: 0.153844] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.970175] time: 0:31:09.630017\n",
      "(10, 128, 128, 3)\n",
      "0.94399554\n",
      "[Epoch 3/10] [Batch 692/1081] [D loss: 0.160127] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.838090] time: 0:31:10.022382\n",
      "(10, 128, 128, 3)\n",
      "0.9321607\n",
      "[Epoch 3/10] [Batch 693/1081] [D loss: 0.141393] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.135608] time: 0:31:10.450467\n",
      "(10, 128, 128, 3)\n",
      "0.9388604\n",
      "[Epoch 3/10] [Batch 694/1081] [D loss: 0.138587] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.416952] time: 0:31:10.885731\n",
      "(10, 128, 128, 3)\n",
      "0.90829104\n",
      "[Epoch 3/10] [Batch 695/1081] [D loss: 0.138764] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.223143] time: 0:31:11.272847\n",
      "(10, 128, 128, 3)\n",
      "0.8779628\n",
      "[Epoch 3/10] [Batch 696/1081] [D loss: 0.138120] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.943874] time: 0:31:11.691086\n",
      "(10, 128, 128, 3)\n",
      "0.954904\n",
      "[Epoch 3/10] [Batch 697/1081] [D loss: 0.136291] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.408077] time: 0:31:12.087058\n",
      "(10, 128, 128, 3)\n",
      "0.93127185\n",
      "[Epoch 3/10] [Batch 698/1081] [D loss: 0.135345] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.855434] time: 0:31:12.483890\n",
      "(10, 128, 128, 3)\n",
      "0.88076144\n",
      "[Epoch 3/10] [Batch 699/1081] [D loss: 0.140539] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.929531] time: 0:31:12.883831\n",
      "(10, 128, 128, 3)\n",
      "0.867518\n",
      "[Epoch 3/10] [Batch 700/1081] [D loss: 0.135339] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.855326] time: 0:31:13.295672\n",
      "(10, 128, 128, 3)\n",
      "0.9071401\n",
      "[Epoch 3/10] [Batch 701/1081] [D loss: 0.134761] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.693482] time: 0:31:13.693591\n",
      "(10, 128, 128, 3)\n",
      "0.94346976\n",
      "[Epoch 3/10] [Batch 702/1081] [D loss: 0.134156] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.412319] time: 0:31:14.120169\n",
      "(10, 128, 128, 3)\n",
      "0.8518835\n",
      "[Epoch 3/10] [Batch 703/1081] [D loss: 0.134335] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.803376] time: 0:31:14.550048\n",
      "(10, 128, 128, 3)\n",
      "0.8963956\n",
      "[Epoch 3/10] [Batch 704/1081] [D loss: 0.135229] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.739221] time: 0:31:14.954363\n",
      "(10, 128, 128, 3)\n",
      "0.8959687\n",
      "[Epoch 3/10] [Batch 705/1081] [D loss: 0.136034] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.772554] time: 0:31:15.391397\n",
      "(10, 128, 128, 3)\n",
      "0.9101746\n",
      "[Epoch 3/10] [Batch 706/1081] [D loss: 0.137197] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.344395] time: 0:31:15.812906\n",
      "(10, 128, 128, 3)\n",
      "0.9337554\n",
      "[Epoch 3/10] [Batch 707/1081] [D loss: 0.134409] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.594517] time: 0:31:16.212378\n",
      "(10, 128, 128, 3)\n",
      "0.88712555\n",
      "[Epoch 3/10] [Batch 708/1081] [D loss: 0.133817] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.025467] time: 0:31:16.589865\n",
      "(10, 128, 128, 3)\n",
      "0.9072657\n",
      "[Epoch 3/10] [Batch 709/1081] [D loss: 0.133473] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.407937] time: 0:31:16.999580\n",
      "(10, 128, 128, 3)\n",
      "0.90005535\n",
      "[Epoch 3/10] [Batch 710/1081] [D loss: 0.133711] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.060159] time: 0:31:17.399678\n",
      "(10, 128, 128, 3)\n",
      "0.91786116\n",
      "[Epoch 3/10] [Batch 711/1081] [D loss: 0.132999] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.032606] time: 0:31:17.813290\n",
      "(10, 128, 128, 3)\n",
      "0.92728394\n",
      "[Epoch 3/10] [Batch 712/1081] [D loss: 0.132282] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.143546] time: 0:31:18.196445\n",
      "(10, 128, 128, 3)\n",
      "0.9251531\n",
      "[Epoch 3/10] [Batch 713/1081] [D loss: 0.132431] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.025023] time: 0:31:18.582593\n",
      "(10, 128, 128, 3)\n",
      "0.8709972\n",
      "[Epoch 3/10] [Batch 714/1081] [D loss: 0.134620] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.580588] time: 0:31:18.967819\n",
      "(10, 128, 128, 3)\n",
      "0.96538526\n",
      "[Epoch 3/10] [Batch 715/1081] [D loss: 0.135775] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.731760] time: 0:31:19.351729\n",
      "(10, 128, 128, 3)\n",
      "0.86374456\n",
      "[Epoch 3/10] [Batch 716/1081] [D loss: 0.132546] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.428584] time: 0:31:19.751094\n",
      "(10, 128, 128, 3)\n",
      "0.8955342\n",
      "[Epoch 3/10] [Batch 717/1081] [D loss: 0.131643] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.331913] time: 0:31:20.159914\n",
      "(10, 128, 128, 3)\n",
      "0.9268257\n",
      "[Epoch 3/10] [Batch 718/1081] [D loss: 0.131701] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.855954] time: 0:31:20.574177\n",
      "(10, 128, 128, 3)\n",
      "0.929313\n",
      "[Epoch 3/10] [Batch 719/1081] [D loss: 0.131655] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.308466] time: 0:31:20.978982\n",
      "(10, 128, 128, 3)\n",
      "0.90672916\n",
      "[Epoch 3/10] [Batch 720/1081] [D loss: 0.131253] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.910379] time: 0:31:21.393661\n",
      "(10, 128, 128, 3)\n",
      "0.90417296\n",
      "[Epoch 3/10] [Batch 721/1081] [D loss: 0.131522] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.900832] time: 0:31:21.816361\n",
      "(10, 128, 128, 3)\n",
      "0.9263838\n",
      "[Epoch 3/10] [Batch 722/1081] [D loss: 0.134670] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.108919] time: 0:31:22.228576\n",
      "(10, 128, 128, 3)\n",
      "0.903498\n",
      "[Epoch 3/10] [Batch 723/1081] [D loss: 0.130367] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.864562] time: 0:31:22.658174\n",
      "(10, 128, 128, 3)\n",
      "0.9160165\n",
      "[Epoch 3/10] [Batch 724/1081] [D loss: 0.130619] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.595349] time: 0:31:23.051595\n",
      "(10, 128, 128, 3)\n",
      "0.95743054\n",
      "[Epoch 3/10] [Batch 725/1081] [D loss: 0.186074] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 11.172100] time: 0:31:23.464554\n",
      "(10, 128, 128, 3)\n",
      "0.9000654\n",
      "[Epoch 3/10] [Batch 726/1081] [D loss: 0.136156] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.450883] time: 0:31:23.838381\n",
      "(10, 128, 128, 3)\n",
      "0.9320802\n",
      "[Epoch 3/10] [Batch 727/1081] [D loss: 0.137124] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.888088] time: 0:31:24.221190\n",
      "(10, 128, 128, 3)\n",
      "0.90864307\n",
      "[Epoch 3/10] [Batch 728/1081] [D loss: 0.132879] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.129270] time: 0:31:24.622735\n",
      "(10, 128, 128, 3)\n",
      "0.9437394\n",
      "[Epoch 3/10] [Batch 729/1081] [D loss: 0.135429] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.748391] time: 0:31:25.020767\n",
      "(10, 128, 128, 3)\n",
      "0.9343503\n",
      "[Epoch 3/10] [Batch 730/1081] [D loss: 0.130537] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.340814] time: 0:31:25.425371\n",
      "(10, 128, 128, 3)\n",
      "0.849961\n",
      "[Epoch 3/10] [Batch 731/1081] [D loss: 0.130020] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.698203] time: 0:31:25.816228\n",
      "(10, 128, 128, 3)\n",
      "0.8739026\n",
      "[Epoch 3/10] [Batch 732/1081] [D loss: 0.130121] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.826360] time: 0:31:26.205852\n",
      "(10, 128, 128, 3)\n",
      "0.9181247\n",
      "[Epoch 3/10] [Batch 733/1081] [D loss: 0.129807] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.055304] time: 0:31:26.635721\n",
      "(10, 128, 128, 3)\n",
      "0.92275685\n",
      "[Epoch 3/10] [Batch 734/1081] [D loss: 0.128965] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.133320] time: 0:31:27.425345\n",
      "(10, 128, 128, 3)\n",
      "0.89000005\n",
      "[Epoch 3/10] [Batch 735/1081] [D loss: 0.129532] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.228299] time: 0:31:27.841101\n",
      "(10, 128, 128, 3)\n",
      "0.92382413\n",
      "[Epoch 3/10] [Batch 736/1081] [D loss: 0.129172] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.623720] time: 0:31:28.242760\n",
      "(10, 128, 128, 3)\n",
      "0.93291426\n",
      "[Epoch 3/10] [Batch 737/1081] [D loss: 0.129083] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.610161] time: 0:31:28.657074\n",
      "(10, 128, 128, 3)\n",
      "0.9548052\n",
      "[Epoch 3/10] [Batch 738/1081] [D loss: 0.129727] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.698312] time: 0:31:29.044721\n",
      "(10, 128, 128, 3)\n",
      "0.93050575\n",
      "[Epoch 3/10] [Batch 739/1081] [D loss: 0.128193] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.895236] time: 0:31:29.432639\n",
      "(10, 128, 128, 3)\n",
      "0.9047534\n",
      "[Epoch 3/10] [Batch 740/1081] [D loss: 0.128848] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.650527] time: 0:31:29.844235\n",
      "(10, 128, 128, 3)\n",
      "0.8913686\n",
      "[Epoch 3/10] [Batch 741/1081] [D loss: 0.128793] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.070309] time: 0:31:30.240147\n",
      "(10, 128, 128, 3)\n",
      "0.90926296\n",
      "[Epoch 3/10] [Batch 742/1081] [D loss: 0.127844] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.296212] time: 0:31:30.646924\n",
      "(10, 128, 128, 3)\n",
      "0.9364422\n",
      "[Epoch 3/10] [Batch 743/1081] [D loss: 0.129322] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.683962] time: 0:31:31.044403\n",
      "(10, 128, 128, 3)\n",
      "0.87837964\n",
      "[Epoch 3/10] [Batch 744/1081] [D loss: 0.127259] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.175713] time: 0:31:31.437780\n",
      "(10, 128, 128, 3)\n",
      "0.90675354\n",
      "[Epoch 3/10] [Batch 745/1081] [D loss: 0.131580] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.272082] time: 0:31:31.851439\n",
      "(10, 128, 128, 3)\n",
      "0.9308167\n",
      "[Epoch 3/10] [Batch 746/1081] [D loss: 0.127285] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.905217] time: 0:31:32.274870\n",
      "(10, 128, 128, 3)\n",
      "0.93315405\n",
      "[Epoch 3/10] [Batch 747/1081] [D loss: 0.127411] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.322559] time: 0:31:32.689205\n",
      "(10, 128, 128, 3)\n",
      "0.8897052\n",
      "[Epoch 3/10] [Batch 748/1081] [D loss: 0.127039] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.534825] time: 0:31:33.073505\n",
      "(10, 128, 128, 3)\n",
      "0.89695615\n",
      "[Epoch 3/10] [Batch 749/1081] [D loss: 0.126762] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.384073] time: 0:31:33.473182\n",
      "(10, 128, 128, 3)\n",
      "0.89593\n",
      "[Epoch 3/10] [Batch 750/1081] [D loss: 0.126944] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.968874] time: 0:31:33.860022\n",
      "(10, 128, 128, 3)\n",
      "0.9155226\n",
      "[Epoch 3/10] [Batch 751/1081] [D loss: 0.126650] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.164474] time: 0:31:34.284121\n",
      "(10, 128, 128, 3)\n",
      "0.94141346\n",
      "[Epoch 3/10] [Batch 752/1081] [D loss: 0.126514] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.643963] time: 0:31:34.688705\n",
      "(10, 128, 128, 3)\n",
      "0.9183593\n",
      "[Epoch 3/10] [Batch 753/1081] [D loss: 0.126638] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.977406] time: 0:31:35.097756\n",
      "(10, 128, 128, 3)\n",
      "0.90030164\n",
      "[Epoch 3/10] [Batch 754/1081] [D loss: 0.126825] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.930591] time: 0:31:35.505817\n",
      "(10, 128, 128, 3)\n",
      "0.9367991\n",
      "[Epoch 3/10] [Batch 755/1081] [D loss: 0.125330] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.379868] time: 0:31:35.888622\n",
      "(10, 128, 128, 3)\n",
      "0.8356493\n",
      "[Epoch 3/10] [Batch 756/1081] [D loss: 0.125021] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.642578] time: 0:31:36.336763\n",
      "(10, 128, 128, 3)\n",
      "0.9263355\n",
      "[Epoch 3/10] [Batch 757/1081] [D loss: 0.125735] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.838367] time: 0:31:36.733771\n",
      "(10, 128, 128, 3)\n",
      "0.9423438\n",
      "[Epoch 3/10] [Batch 758/1081] [D loss: 0.125896] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.499859] time: 0:31:37.157245\n",
      "(10, 128, 128, 3)\n",
      "0.8968668\n",
      "[Epoch 3/10] [Batch 759/1081] [D loss: 0.126969] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.683968] time: 0:31:37.556767\n",
      "(10, 128, 128, 3)\n",
      "0.86901695\n",
      "[Epoch 3/10] [Batch 760/1081] [D loss: 0.125068] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.865436] time: 0:31:37.981084\n",
      "(10, 128, 128, 3)\n",
      "0.9472027\n",
      "[Epoch 3/10] [Batch 761/1081] [D loss: 0.125339] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.053747] time: 0:31:38.400128\n",
      "(10, 128, 128, 3)\n",
      "0.8713209\n",
      "[Epoch 3/10] [Batch 762/1081] [D loss: 0.125726] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.360413] time: 0:31:38.820020\n",
      "(10, 128, 128, 3)\n",
      "0.9588353\n",
      "[Epoch 3/10] [Batch 763/1081] [D loss: 0.125829] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.758588] time: 0:31:39.221799\n",
      "(10, 128, 128, 3)\n",
      "0.9340053\n",
      "[Epoch 3/10] [Batch 764/1081] [D loss: 0.125071] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.495271] time: 0:31:39.631805\n",
      "(10, 128, 128, 3)\n",
      "0.9079666\n",
      "[Epoch 3/10] [Batch 765/1081] [D loss: 0.124706] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.224935] time: 0:31:40.031022\n",
      "(10, 128, 128, 3)\n",
      "0.9380191\n",
      "[Epoch 3/10] [Batch 766/1081] [D loss: 0.123611] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.107401] time: 0:31:40.443922\n",
      "(10, 128, 128, 3)\n",
      "0.94581753\n",
      "[Epoch 3/10] [Batch 767/1081] [D loss: 0.123634] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.831891] time: 0:31:40.845627\n",
      "(10, 128, 128, 3)\n",
      "0.9286038\n",
      "[Epoch 3/10] [Batch 768/1081] [D loss: 0.125465] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.280140] time: 0:31:41.267140\n",
      "(10, 128, 128, 3)\n",
      "0.9113609\n",
      "[Epoch 3/10] [Batch 769/1081] [D loss: 0.123783] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.865412] time: 0:31:41.666935\n",
      "(10, 128, 128, 3)\n",
      "0.97558814\n",
      "[Epoch 3/10] [Batch 770/1081] [D loss: 0.123373] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.957184] time: 0:31:42.052711\n",
      "(10, 128, 128, 3)\n",
      "0.9410401\n",
      "[Epoch 3/10] [Batch 771/1081] [D loss: 0.123111] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.806455] time: 0:31:42.450984\n",
      "(10, 128, 128, 3)\n",
      "0.9481349\n",
      "[Epoch 3/10] [Batch 772/1081] [D loss: 0.123535] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.799855] time: 0:31:42.859268\n",
      "(10, 128, 128, 3)\n",
      "0.8966597\n",
      "[Epoch 3/10] [Batch 773/1081] [D loss: 0.123634] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.082110] time: 0:31:43.254310\n",
      "(10, 128, 128, 3)\n",
      "0.904864\n",
      "[Epoch 3/10] [Batch 774/1081] [D loss: 0.124767] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.010805] time: 0:31:43.648468\n",
      "(10, 128, 128, 3)\n",
      "0.9211059\n",
      "[Epoch 3/10] [Batch 775/1081] [D loss: 0.122779] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.339913] time: 0:31:44.052187\n",
      "(10, 128, 128, 3)\n",
      "0.9043312\n",
      "[Epoch 3/10] [Batch 776/1081] [D loss: 0.123381] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.379983] time: 0:31:44.434940\n",
      "(10, 128, 128, 3)\n",
      "0.9343505\n",
      "[Epoch 3/10] [Batch 777/1081] [D loss: 0.123502] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.087626] time: 0:31:44.838746\n",
      "(10, 128, 128, 3)\n",
      "0.92838603\n",
      "[Epoch 3/10] [Batch 778/1081] [D loss: 0.122139] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.641874] time: 0:31:45.238490\n",
      "(10, 128, 128, 3)\n",
      "0.87411135\n",
      "[Epoch 3/10] [Batch 779/1081] [D loss: 0.121900] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.705244] time: 0:31:45.658585\n",
      "(10, 128, 128, 3)\n",
      "0.9193325\n",
      "[Epoch 3/10] [Batch 780/1081] [D loss: 0.122011] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.481348] time: 0:31:46.073109\n",
      "(10, 128, 128, 3)\n",
      "0.8993335\n",
      "[Epoch 3/10] [Batch 781/1081] [D loss: 0.121730] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.913306] time: 0:31:46.460822\n",
      "(10, 128, 128, 3)\n",
      "0.8882207\n",
      "[Epoch 3/10] [Batch 782/1081] [D loss: 0.591318] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 9.128344] time: 0:31:46.893261\n",
      "(10, 128, 128, 3)\n",
      "0.8850542\n",
      "[Epoch 3/10] [Batch 783/1081] [D loss: 0.135638] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.891828] time: 0:31:47.300216\n",
      "(10, 128, 128, 3)\n",
      "0.8615818\n",
      "[Epoch 3/10] [Batch 784/1081] [D loss: 0.153481] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.405251] time: 0:31:47.707757\n",
      "(10, 128, 128, 3)\n",
      "0.9020284\n",
      "[Epoch 3/10] [Batch 785/1081] [D loss: 0.137450] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.879288] time: 0:31:48.108660\n",
      "(10, 128, 128, 3)\n",
      "0.91567343\n",
      "[Epoch 3/10] [Batch 786/1081] [D loss: 0.124838] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.598108] time: 0:31:48.531435\n",
      "(10, 128, 128, 3)\n",
      "0.9054974\n",
      "[Epoch 3/10] [Batch 787/1081] [D loss: 0.128995] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.676393] time: 0:31:48.933027\n",
      "(10, 128, 128, 3)\n",
      "0.9333243\n",
      "[Epoch 3/10] [Batch 788/1081] [D loss: 0.125113] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.570360] time: 0:31:49.337118\n",
      "(10, 128, 128, 3)\n",
      "0.92783594\n",
      "[Epoch 3/10] [Batch 789/1081] [D loss: 0.125137] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.541449] time: 0:31:49.758928\n",
      "(10, 128, 128, 3)\n",
      "0.87764806\n",
      "[Epoch 3/10] [Batch 790/1081] [D loss: 0.123251] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.524571] time: 0:31:50.162284\n",
      "(10, 128, 128, 3)\n",
      "0.94644976\n",
      "[Epoch 3/10] [Batch 791/1081] [D loss: 0.124869] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.324266] time: 0:31:50.550647\n",
      "(10, 128, 128, 3)\n",
      "0.8911998\n",
      "[Epoch 3/10] [Batch 792/1081] [D loss: 0.123518] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.895773] time: 0:31:50.971602\n",
      "(10, 128, 128, 3)\n",
      "0.9277199\n",
      "[Epoch 3/10] [Batch 793/1081] [D loss: 0.123532] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.462009] time: 0:31:51.362518\n",
      "(10, 128, 128, 3)\n",
      "0.91109854\n",
      "[Epoch 3/10] [Batch 794/1081] [D loss: 0.131100] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.678411] time: 0:31:51.776407\n",
      "(10, 128, 128, 3)\n",
      "0.8887133\n",
      "[Epoch 3/10] [Batch 795/1081] [D loss: 0.130496] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.936974] time: 0:31:52.188980\n",
      "(10, 128, 128, 3)\n",
      "0.9353366\n",
      "[Epoch 3/10] [Batch 796/1081] [D loss: 0.126811] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.119379] time: 0:31:52.600173\n",
      "(10, 128, 128, 3)\n",
      "0.8829704\n",
      "[Epoch 3/10] [Batch 797/1081] [D loss: 0.121901] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.930257] time: 0:31:53.011026\n",
      "(10, 128, 128, 3)\n",
      "0.9197281\n",
      "[Epoch 3/10] [Batch 798/1081] [D loss: 0.122193] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.710244] time: 0:31:53.405885\n",
      "(10, 128, 128, 3)\n",
      "0.91155386\n",
      "[Epoch 3/10] [Batch 799/1081] [D loss: 0.123612] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.382858] time: 0:31:53.819724\n",
      "(10, 128, 128, 3)\n",
      "0.9572634\n",
      "[Epoch 3/10] [Batch 800/1081] [D loss: 0.124178] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.904110] time: 0:31:54.226530\n",
      "(10, 128, 128, 3)\n",
      "0.9052198\n",
      "[Epoch 3/10] [Batch 801/1081] [D loss: 0.121246] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.572575] time: 0:31:54.650645\n",
      "(10, 128, 128, 3)\n",
      "0.9511757\n",
      "[Epoch 3/10] [Batch 802/1081] [D loss: 0.123046] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.062922] time: 0:31:55.078238\n",
      "(10, 128, 128, 3)\n",
      "0.89854926\n",
      "[Epoch 3/10] [Batch 803/1081] [D loss: 0.122065] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.410524] time: 0:31:55.490347\n",
      "(10, 128, 128, 3)\n",
      "0.96692944\n",
      "[Epoch 3/10] [Batch 804/1081] [D loss: 0.125298] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.554487] time: 0:31:55.925082\n",
      "(10, 128, 128, 3)\n",
      "0.9202214\n",
      "[Epoch 3/10] [Batch 805/1081] [D loss: 0.121227] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.248812] time: 0:31:56.348132\n",
      "(10, 128, 128, 3)\n",
      "0.90547603\n",
      "[Epoch 3/10] [Batch 806/1081] [D loss: 0.121830] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.139585] time: 0:31:56.758608\n",
      "(10, 128, 128, 3)\n",
      "0.91242844\n",
      "[Epoch 3/10] [Batch 807/1081] [D loss: 0.120890] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.494204] time: 0:31:57.166188\n",
      "(10, 128, 128, 3)\n",
      "0.95610356\n",
      "[Epoch 3/10] [Batch 808/1081] [D loss: 0.123491] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.983013] time: 0:31:57.590935\n",
      "(10, 128, 128, 3)\n",
      "0.91449195\n",
      "[Epoch 3/10] [Batch 809/1081] [D loss: 0.120962] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.342506] time: 0:31:57.971549\n",
      "(10, 128, 128, 3)\n",
      "0.89987755\n",
      "[Epoch 3/10] [Batch 810/1081] [D loss: 0.123471] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.484960] time: 0:31:58.350892\n",
      "(10, 128, 128, 3)\n",
      "0.9429693\n",
      "[Epoch 3/10] [Batch 811/1081] [D loss: 0.125699] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.794565] time: 0:31:58.774164\n",
      "(10, 128, 128, 3)\n",
      "0.9098544\n",
      "[Epoch 3/10] [Batch 812/1081] [D loss: 0.120251] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.517632] time: 0:31:59.189014\n",
      "(10, 128, 128, 3)\n",
      "0.91484195\n",
      "[Epoch 3/10] [Batch 813/1081] [D loss: 0.130321] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.109612] time: 0:31:59.599609\n",
      "(10, 128, 128, 3)\n",
      "0.87907785\n",
      "[Epoch 3/10] [Batch 814/1081] [D loss: 0.122678] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.550506] time: 0:32:00.032027\n",
      "(10, 128, 128, 3)\n",
      "0.925982\n",
      "[Epoch 3/10] [Batch 815/1081] [D loss: 0.121710] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.417684] time: 0:32:00.437520\n",
      "(10, 128, 128, 3)\n",
      "0.8885644\n",
      "[Epoch 3/10] [Batch 816/1081] [D loss: 0.120022] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.642810] time: 0:32:00.846155\n",
      "(10, 128, 128, 3)\n",
      "0.91917586\n",
      "[Epoch 3/10] [Batch 817/1081] [D loss: 0.122174] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.503540] time: 0:32:01.237340\n",
      "(10, 128, 128, 3)\n",
      "0.9514099\n",
      "[Epoch 3/10] [Batch 818/1081] [D loss: 0.133970] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.631930] time: 0:32:01.660973\n",
      "(10, 128, 128, 3)\n",
      "0.93581444\n",
      "[Epoch 3/10] [Batch 819/1081] [D loss: 0.126979] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.271032] time: 0:32:02.087573\n",
      "(10, 128, 128, 3)\n",
      "0.97421664\n",
      "[Epoch 3/10] [Batch 820/1081] [D loss: 0.121278] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.687377] time: 0:32:02.487476\n",
      "(10, 128, 128, 3)\n",
      "0.88234144\n",
      "[Epoch 3/10] [Batch 821/1081] [D loss: 0.121747] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.343300] time: 0:32:02.900704\n",
      "(10, 128, 128, 3)\n",
      "0.8681013\n",
      "[Epoch 3/10] [Batch 822/1081] [D loss: 0.120269] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.835461] time: 0:32:03.308883\n",
      "(10, 128, 128, 3)\n",
      "0.93483704\n",
      "[Epoch 3/10] [Batch 823/1081] [D loss: 0.119455] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.587998] time: 0:32:03.717276\n",
      "(10, 128, 128, 3)\n",
      "0.9222484\n",
      "[Epoch 3/10] [Batch 824/1081] [D loss: 0.120950] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.288332] time: 0:32:04.117936\n",
      "(10, 128, 128, 3)\n",
      "0.9087902\n",
      "[Epoch 3/10] [Batch 825/1081] [D loss: 0.119405] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.099052] time: 0:32:04.545662\n",
      "(10, 128, 128, 3)\n",
      "0.917937\n",
      "[Epoch 3/10] [Batch 826/1081] [D loss: 0.118816] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.167173] time: 0:32:04.951999\n",
      "(10, 128, 128, 3)\n",
      "0.8681094\n",
      "[Epoch 3/10] [Batch 827/1081] [D loss: 0.124299] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.937214] time: 0:32:05.373198\n",
      "(10, 128, 128, 3)\n",
      "0.9317708\n",
      "[Epoch 3/10] [Batch 828/1081] [D loss: 0.120862] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.309381] time: 0:32:05.777281\n",
      "(10, 128, 128, 3)\n",
      "0.93126154\n",
      "[Epoch 3/10] [Batch 829/1081] [D loss: 0.119560] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.852050] time: 0:32:06.174016\n",
      "(10, 128, 128, 3)\n",
      "0.8976217\n",
      "[Epoch 3/10] [Batch 830/1081] [D loss: 0.118953] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.326910] time: 0:32:06.581482\n",
      "(10, 128, 128, 3)\n",
      "0.9167588\n",
      "[Epoch 3/10] [Batch 831/1081] [D loss: 0.118045] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.405023] time: 0:32:06.966889\n",
      "(10, 128, 128, 3)\n",
      "0.88150316\n",
      "[Epoch 3/10] [Batch 832/1081] [D loss: 0.120866] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.797692] time: 0:32:07.424291\n",
      "(10, 128, 128, 3)\n",
      "0.9150469\n",
      "[Epoch 3/10] [Batch 833/1081] [D loss: 0.122790] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.499698] time: 0:32:07.851923\n",
      "(10, 128, 128, 3)\n",
      "0.8468456\n",
      "[Epoch 3/10] [Batch 834/1081] [D loss: 0.121230] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.845343] time: 0:32:08.247511\n",
      "(10, 128, 128, 3)\n",
      "0.89964795\n",
      "[Epoch 3/10] [Batch 835/1081] [D loss: 0.117281] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.390358] time: 0:32:08.659277\n",
      "(10, 128, 128, 3)\n",
      "0.8776958\n",
      "[Epoch 3/10] [Batch 836/1081] [D loss: 0.117788] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.166712] time: 0:32:09.084957\n",
      "(10, 128, 128, 3)\n",
      "0.890505\n",
      "[Epoch 3/10] [Batch 837/1081] [D loss: 0.118085] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.871287] time: 0:32:09.513254\n",
      "(10, 128, 128, 3)\n",
      "0.9324401\n",
      "[Epoch 3/10] [Batch 838/1081] [D loss: 0.117472] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.875780] time: 0:32:09.920282\n",
      "(10, 128, 128, 3)\n",
      "0.8816273\n",
      "[Epoch 3/10] [Batch 839/1081] [D loss: 0.117425] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.484762] time: 0:32:10.335789\n",
      "(10, 128, 128, 3)\n",
      "0.9165866\n",
      "[Epoch 3/10] [Batch 840/1081] [D loss: 0.116705] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.330243] time: 0:32:10.718460\n",
      "(10, 128, 128, 3)\n",
      "0.88767594\n",
      "[Epoch 3/10] [Batch 841/1081] [D loss: 0.116611] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.933062] time: 0:32:11.109636\n",
      "(10, 128, 128, 3)\n",
      "0.93792534\n",
      "[Epoch 3/10] [Batch 842/1081] [D loss: 0.116753] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.804115] time: 0:32:11.490272\n",
      "(10, 128, 128, 3)\n",
      "0.8999517\n",
      "[Epoch 3/10] [Batch 843/1081] [D loss: 0.116598] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.342939] time: 0:32:11.872011\n",
      "(10, 128, 128, 3)\n",
      "0.9159321\n",
      "[Epoch 3/10] [Batch 844/1081] [D loss: 0.116931] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.629904] time: 0:32:12.259591\n",
      "(10, 128, 128, 3)\n",
      "0.9662228\n",
      "[Epoch 3/10] [Batch 845/1081] [D loss: 0.116705] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.637514] time: 0:32:12.648097\n",
      "(10, 128, 128, 3)\n",
      "0.91881293\n",
      "[Epoch 3/10] [Batch 846/1081] [D loss: 0.116751] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.432224] time: 0:32:13.059206\n",
      "(10, 128, 128, 3)\n",
      "0.9178292\n",
      "[Epoch 3/10] [Batch 847/1081] [D loss: 0.117374] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.249146] time: 0:32:13.492260\n",
      "(10, 128, 128, 3)\n",
      "0.84906834\n",
      "[Epoch 3/10] [Batch 848/1081] [D loss: 0.116832] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.222230] time: 0:32:13.900534\n",
      "(10, 128, 128, 3)\n",
      "0.8851047\n",
      "[Epoch 3/10] [Batch 849/1081] [D loss: 0.116328] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.208175] time: 0:32:14.334460\n",
      "(10, 128, 128, 3)\n",
      "0.9511502\n",
      "[Epoch 3/10] [Batch 850/1081] [D loss: 0.116257] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.195673] time: 0:32:14.757097\n",
      "(10, 128, 128, 3)\n",
      "0.91490173\n",
      "[Epoch 3/10] [Batch 851/1081] [D loss: 0.115812] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.521991] time: 0:32:15.172980\n",
      "(10, 128, 128, 3)\n",
      "0.9230414\n",
      "[Epoch 3/10] [Batch 852/1081] [D loss: 0.115888] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.055010] time: 0:32:15.558871\n",
      "(10, 128, 128, 3)\n",
      "0.9173155\n",
      "[Epoch 3/10] [Batch 853/1081] [D loss: 0.115975] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.115200] time: 0:32:15.967098\n",
      "(10, 128, 128, 3)\n",
      "0.8722194\n",
      "[Epoch 3/10] [Batch 854/1081] [D loss: 0.119298] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.077923] time: 0:32:16.349422\n",
      "(10, 128, 128, 3)\n",
      "0.9655524\n",
      "[Epoch 3/10] [Batch 855/1081] [D loss: 0.115453] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.718062] time: 0:32:16.734992\n",
      "(10, 128, 128, 3)\n",
      "0.87221056\n",
      "[Epoch 3/10] [Batch 856/1081] [D loss: 0.115229] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.949140] time: 0:32:17.173542\n",
      "(10, 128, 128, 3)\n",
      "0.91475755\n",
      "[Epoch 3/10] [Batch 857/1081] [D loss: 0.114843] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.540113] time: 0:32:17.587205\n",
      "(10, 128, 128, 3)\n",
      "0.9323707\n",
      "[Epoch 3/10] [Batch 858/1081] [D loss: 0.115206] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.850149] time: 0:32:17.972133\n",
      "(10, 128, 128, 3)\n",
      "0.9053715\n",
      "[Epoch 3/10] [Batch 859/1081] [D loss: 0.114509] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.719369] time: 0:32:18.356053\n",
      "(10, 128, 128, 3)\n",
      "0.9466989\n",
      "[Epoch 3/10] [Batch 860/1081] [D loss: 0.114876] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.791491] time: 0:32:18.780759\n",
      "(10, 128, 128, 3)\n",
      "0.92229635\n",
      "[Epoch 3/10] [Batch 861/1081] [D loss: 0.114348] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.092708] time: 0:32:19.160711\n",
      "(10, 128, 128, 3)\n",
      "0.91190267\n",
      "[Epoch 3/10] [Batch 862/1081] [D loss: 0.114310] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.129838] time: 0:32:19.576879\n",
      "(10, 128, 128, 3)\n",
      "0.903351\n",
      "[Epoch 3/10] [Batch 863/1081] [D loss: 0.114005] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.483788] time: 0:32:19.953129\n",
      "(10, 128, 128, 3)\n",
      "0.9414435\n",
      "[Epoch 3/10] [Batch 864/1081] [D loss: 0.114486] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.735520] time: 0:32:20.390309\n",
      "(10, 128, 128, 3)\n",
      "0.91827273\n",
      "[Epoch 3/10] [Batch 865/1081] [D loss: 0.114176] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.733724] time: 0:32:20.776433\n",
      "(10, 128, 128, 3)\n",
      "0.90359944\n",
      "[Epoch 3/10] [Batch 866/1081] [D loss: 0.116128] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.961774] time: 0:32:21.171043\n",
      "(10, 128, 128, 3)\n",
      "0.9413113\n",
      "[Epoch 3/10] [Batch 867/1081] [D loss: 0.114251] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.488671] time: 0:32:21.562857\n",
      "(10, 128, 128, 3)\n",
      "0.9415619\n",
      "[Epoch 3/10] [Batch 868/1081] [D loss: 0.121377] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.866459] time: 0:32:21.953734\n",
      "(10, 128, 128, 3)\n",
      "0.937239\n",
      "[Epoch 3/10] [Batch 869/1081] [D loss: 0.117451] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.941993] time: 0:32:22.366617\n",
      "(10, 128, 128, 3)\n",
      "0.91571665\n",
      "[Epoch 3/10] [Batch 870/1081] [D loss: 0.116272] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.963285] time: 0:32:22.759214\n",
      "(10, 128, 128, 3)\n",
      "0.9313634\n",
      "[Epoch 3/10] [Batch 871/1081] [D loss: 0.113915] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.755923] time: 0:32:23.153829\n",
      "(10, 128, 128, 3)\n",
      "0.92910475\n",
      "[Epoch 3/10] [Batch 872/1081] [D loss: 0.115883] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.800885] time: 0:32:23.577053\n",
      "(10, 128, 128, 3)\n",
      "0.88457185\n",
      "[Epoch 3/10] [Batch 873/1081] [D loss: 0.116176] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.294045] time: 0:32:23.971754\n",
      "(10, 128, 128, 3)\n",
      "0.8909797\n",
      "[Epoch 3/10] [Batch 874/1081] [D loss: 0.113634] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.969111] time: 0:32:24.369825\n",
      "(10, 128, 128, 3)\n",
      "0.92899114\n",
      "[Epoch 3/10] [Batch 875/1081] [D loss: 0.113517] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.196722] time: 0:32:24.751051\n",
      "(10, 128, 128, 3)\n",
      "0.9313097\n",
      "[Epoch 3/10] [Batch 876/1081] [D loss: 0.113231] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.623640] time: 0:32:25.174172\n",
      "(10, 128, 128, 3)\n",
      "0.920193\n",
      "[Epoch 3/10] [Batch 877/1081] [D loss: 0.114383] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.964314] time: 0:32:25.544732\n",
      "(10, 128, 128, 3)\n",
      "0.9365702\n",
      "[Epoch 3/10] [Batch 878/1081] [D loss: 0.112691] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.753073] time: 0:32:25.956165\n",
      "(10, 128, 128, 3)\n",
      "0.94700456\n",
      "[Epoch 3/10] [Batch 879/1081] [D loss: 0.114277] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.906837] time: 0:32:26.347701\n",
      "(10, 128, 128, 3)\n",
      "0.85252684\n",
      "[Epoch 3/10] [Batch 880/1081] [D loss: 0.113625] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.613853] time: 0:32:26.747886\n",
      "(10, 128, 128, 3)\n",
      "0.93844265\n",
      "[Epoch 3/10] [Batch 881/1081] [D loss: 0.113914] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.021822] time: 0:32:27.150982\n",
      "(10, 128, 128, 3)\n",
      "0.9222215\n",
      "[Epoch 3/10] [Batch 882/1081] [D loss: 0.113148] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.021397] time: 0:32:27.544485\n",
      "(10, 128, 128, 3)\n",
      "0.9006805\n",
      "[Epoch 3/10] [Batch 883/1081] [D loss: 0.112321] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.715583] time: 0:32:27.926100\n",
      "(10, 128, 128, 3)\n",
      "0.85962534\n",
      "[Epoch 3/10] [Batch 884/1081] [D loss: 0.112009] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.127942] time: 0:32:28.325128\n",
      "(10, 128, 128, 3)\n",
      "0.92479926\n",
      "[Epoch 3/10] [Batch 885/1081] [D loss: 0.112223] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.859924] time: 0:32:28.735893\n",
      "(10, 128, 128, 3)\n",
      "0.94056875\n",
      "[Epoch 3/10] [Batch 886/1081] [D loss: 0.112169] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.897635] time: 0:32:29.130898\n",
      "(10, 128, 128, 3)\n",
      "0.9486335\n",
      "[Epoch 3/10] [Batch 887/1081] [D loss: 0.112741] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.808968] time: 0:32:29.534213\n",
      "(10, 128, 128, 3)\n",
      "0.92826754\n",
      "[Epoch 3/10] [Batch 888/1081] [D loss: 0.112043] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.762618] time: 0:32:29.916960\n",
      "(10, 128, 128, 3)\n",
      "0.90740734\n",
      "[Epoch 3/10] [Batch 889/1081] [D loss: 0.112198] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.143007] time: 0:32:30.324836\n",
      "(10, 128, 128, 3)\n",
      "0.9452379\n",
      "[Epoch 3/10] [Batch 890/1081] [D loss: 0.112276] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.891346] time: 0:32:30.737647\n",
      "(10, 128, 128, 3)\n",
      "0.9224663\n",
      "[Epoch 3/10] [Batch 891/1081] [D loss: 0.111799] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.335378] time: 0:32:31.126003\n",
      "(10, 128, 128, 3)\n",
      "0.8911306\n",
      "[Epoch 3/10] [Batch 892/1081] [D loss: 0.113623] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.821750] time: 0:32:31.532268\n",
      "(10, 128, 128, 3)\n",
      "0.9391356\n",
      "[Epoch 3/10] [Batch 893/1081] [D loss: 0.111569] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.374412] time: 0:32:31.933297\n",
      "(10, 128, 128, 3)\n",
      "0.8988666\n",
      "[Epoch 3/10] [Batch 894/1081] [D loss: 0.111668] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.587921] time: 0:32:32.345673\n",
      "(10, 128, 128, 3)\n",
      "0.9169343\n",
      "[Epoch 3/10] [Batch 895/1081] [D loss: 0.111638] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.583772] time: 0:32:32.736138\n",
      "(10, 128, 128, 3)\n",
      "0.8910456\n",
      "[Epoch 3/10] [Batch 896/1081] [D loss: 0.110937] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.179990] time: 0:32:33.109250\n",
      "(10, 128, 128, 3)\n",
      "0.922363\n",
      "[Epoch 3/10] [Batch 897/1081] [D loss: 0.110963] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.015209] time: 0:32:33.485559\n",
      "(10, 128, 128, 3)\n",
      "0.9660545\n",
      "[Epoch 3/10] [Batch 898/1081] [D loss: 0.110294] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.988297] time: 0:32:33.885112\n",
      "(10, 128, 128, 3)\n",
      "0.91188556\n",
      "[Epoch 3/10] [Batch 899/1081] [D loss: 0.111326] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.093172] time: 0:32:34.307430\n",
      "(10, 128, 128, 3)\n",
      "0.874775\n",
      "[Epoch 3/10] [Batch 900/1081] [D loss: 0.112079] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.475809] time: 0:32:34.699496\n",
      "(10, 128, 128, 3)\n",
      "0.92651445\n",
      "[Epoch 3/10] [Batch 901/1081] [D loss: 0.112286] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.618206] time: 0:32:35.107380\n",
      "(10, 128, 128, 3)\n",
      "0.88833433\n",
      "[Epoch 3/10] [Batch 902/1081] [D loss: 0.110136] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.439724] time: 0:32:35.499188\n",
      "(10, 128, 128, 3)\n",
      "0.9212981\n",
      "[Epoch 3/10] [Batch 903/1081] [D loss: 0.112030] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.140133] time: 0:32:35.893629\n",
      "(10, 128, 128, 3)\n",
      "0.9179856\n",
      "[Epoch 3/10] [Batch 904/1081] [D loss: 0.110074] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.987963] time: 0:32:36.303105\n",
      "(10, 128, 128, 3)\n",
      "0.8614299\n",
      "[Epoch 3/10] [Batch 905/1081] [D loss: 0.111902] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.374341] time: 0:32:36.712492\n",
      "(10, 128, 128, 3)\n",
      "0.9321904\n",
      "[Epoch 3/10] [Batch 906/1081] [D loss: 0.110047] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.412155] time: 0:32:37.107135\n",
      "(10, 128, 128, 3)\n",
      "0.94752383\n",
      "[Epoch 3/10] [Batch 907/1081] [D loss: 0.111471] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.778263] time: 0:32:37.509148\n",
      "(10, 128, 128, 3)\n",
      "0.9382515\n",
      "[Epoch 3/10] [Batch 908/1081] [D loss: 0.110741] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.322961] time: 0:32:37.889788\n",
      "(10, 128, 128, 3)\n",
      "0.8846207\n",
      "[Epoch 3/10] [Batch 909/1081] [D loss: 0.109684] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.266163] time: 0:32:38.267553\n",
      "(10, 128, 128, 3)\n",
      "0.9347334\n",
      "[Epoch 3/10] [Batch 910/1081] [D loss: 0.110048] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.525776] time: 0:32:38.662772\n",
      "(10, 128, 128, 3)\n",
      "0.92388934\n",
      "[Epoch 3/10] [Batch 911/1081] [D loss: 0.108967] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.255058] time: 0:32:39.082002\n",
      "(10, 128, 128, 3)\n",
      "0.94067127\n",
      "[Epoch 3/10] [Batch 912/1081] [D loss: 0.109515] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.156146] time: 0:32:39.471117\n",
      "(10, 128, 128, 3)\n",
      "0.9156243\n",
      "[Epoch 3/10] [Batch 913/1081] [D loss: 0.109646] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.948421] time: 0:32:39.865078\n",
      "(10, 128, 128, 3)\n",
      "0.94306463\n",
      "[Epoch 3/10] [Batch 914/1081] [D loss: 0.109634] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.843740] time: 0:32:40.292241\n",
      "(10, 128, 128, 3)\n",
      "0.93894774\n",
      "[Epoch 3/10] [Batch 915/1081] [D loss: 0.108736] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.608500] time: 0:32:40.703000\n",
      "(10, 128, 128, 3)\n",
      "0.90543765\n",
      "[Epoch 3/10] [Batch 916/1081] [D loss: 0.108679] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.453180] time: 0:32:41.109522\n",
      "(10, 128, 128, 3)\n",
      "0.95293635\n",
      "[Epoch 3/10] [Batch 917/1081] [D loss: 0.109180] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.755688] time: 0:32:41.506013\n",
      "(10, 128, 128, 3)\n",
      "0.9155078\n",
      "[Epoch 3/10] [Batch 918/1081] [D loss: 0.109277] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.911399] time: 0:32:41.929453\n",
      "(10, 128, 128, 3)\n",
      "0.9246641\n",
      "[Epoch 3/10] [Batch 919/1081] [D loss: 0.113164] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.449247] time: 0:32:42.318411\n",
      "(10, 128, 128, 3)\n",
      "0.8298275\n",
      "[Epoch 3/10] [Batch 920/1081] [D loss: 0.109447] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.238508] time: 0:32:42.734847\n",
      "(10, 128, 128, 3)\n",
      "0.89863294\n",
      "[Epoch 3/10] [Batch 921/1081] [D loss: 0.108175] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.238137] time: 0:32:43.123257\n",
      "(10, 128, 128, 3)\n",
      "0.88048524\n",
      "[Epoch 3/10] [Batch 922/1081] [D loss: 0.111121] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.411168] time: 0:32:43.544747\n",
      "(10, 128, 128, 3)\n",
      "0.9122686\n",
      "[Epoch 3/10] [Batch 923/1081] [D loss: 0.109411] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.484434] time: 0:32:43.983450\n",
      "(10, 128, 128, 3)\n",
      "0.8876551\n",
      "[Epoch 3/10] [Batch 924/1081] [D loss: 0.108101] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.030296] time: 0:32:44.371954\n",
      "(10, 128, 128, 3)\n",
      "0.97729445\n",
      "[Epoch 3/10] [Batch 925/1081] [D loss: 0.108410] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.057468] time: 0:32:44.768530\n",
      "(10, 128, 128, 3)\n",
      "0.9068606\n",
      "[Epoch 3/10] [Batch 926/1081] [D loss: 0.108980] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.643473] time: 0:32:45.176995\n",
      "(10, 128, 128, 3)\n",
      "0.96850127\n",
      "[Epoch 3/10] [Batch 927/1081] [D loss: 0.108277] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.027052] time: 0:32:45.573101\n",
      "(10, 128, 128, 3)\n",
      "0.91396016\n",
      "[Epoch 3/10] [Batch 928/1081] [D loss: 0.108348] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.700351] time: 0:32:45.987776\n",
      "(10, 128, 128, 3)\n",
      "0.8653763\n",
      "[Epoch 3/10] [Batch 929/1081] [D loss: 0.107435] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.645679] time: 0:32:46.388525\n",
      "(10, 128, 128, 3)\n",
      "0.88878137\n",
      "[Epoch 3/10] [Batch 930/1081] [D loss: 0.108161] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.620388] time: 0:32:46.802782\n",
      "(10, 128, 128, 3)\n",
      "0.9129583\n",
      "[Epoch 3/10] [Batch 931/1081] [D loss: 0.110953] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.002198] time: 0:32:47.184431\n",
      "(10, 128, 128, 3)\n",
      "0.8989737\n",
      "[Epoch 3/10] [Batch 932/1081] [D loss: 0.107465] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.967348] time: 0:32:47.582626\n",
      "(10, 128, 128, 3)\n",
      "0.8545652\n",
      "[Epoch 3/10] [Batch 933/1081] [D loss: 0.107415] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.662707] time: 0:32:47.961751\n",
      "(10, 128, 128, 3)\n",
      "0.86511326\n",
      "[Epoch 3/10] [Batch 934/1081] [D loss: 0.107066] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.157864] time: 0:32:48.342336\n",
      "(10, 128, 128, 3)\n",
      "0.90637094\n",
      "[Epoch 3/10] [Batch 935/1081] [D loss: 0.106801] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.873757] time: 0:32:48.773142\n",
      "(10, 128, 128, 3)\n",
      "0.9303272\n",
      "[Epoch 3/10] [Batch 936/1081] [D loss: 0.107017] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.806787] time: 0:32:49.169399\n",
      "(10, 128, 128, 3)\n",
      "0.9337171\n",
      "[Epoch 3/10] [Batch 937/1081] [D loss: 0.107041] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.308954] time: 0:32:49.562112\n",
      "(10, 128, 128, 3)\n",
      "0.9443658\n",
      "[Epoch 3/10] [Batch 938/1081] [D loss: 0.106692] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.806162] time: 0:32:49.943179\n",
      "(10, 128, 128, 3)\n",
      "0.92463773\n",
      "[Epoch 3/10] [Batch 939/1081] [D loss: 0.106652] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.977564] time: 0:32:50.348429\n",
      "(10, 128, 128, 3)\n",
      "0.8770025\n",
      "[Epoch 3/10] [Batch 940/1081] [D loss: 0.107245] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.547336] time: 0:32:50.772450\n",
      "(10, 128, 128, 3)\n",
      "0.90847826\n",
      "[Epoch 3/10] [Batch 941/1081] [D loss: 0.106562] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.229340] time: 0:32:51.167343\n",
      "(10, 128, 128, 3)\n",
      "0.9537489\n",
      "[Epoch 3/10] [Batch 942/1081] [D loss: 0.494941] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 9.818476] time: 0:32:51.553109\n",
      "(10, 128, 128, 3)\n",
      "0.89106303\n",
      "[Epoch 3/10] [Batch 943/1081] [D loss: 0.442269] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 20.239239] time: 0:32:51.947845\n",
      "(10, 128, 128, 3)\n",
      "0.938785\n",
      "[Epoch 3/10] [Batch 944/1081] [D loss: 0.328581] [D acc: 0.55 (1.00 real, 0.10 fake)] [G loss: 574.659180] time: 0:32:52.347184\n",
      "(10, 128, 128, 3)\n",
      "0.69275284\n",
      "[Epoch 3/10] [Batch 945/1081] [D loss: 0.329558] [D acc: 0.55 (1.00 real, 0.10 fake)] [G loss: 34.512131] time: 0:32:52.768510\n",
      "(10, 128, 128, 3)\n",
      "0.33020833\n",
      "[Epoch 3/10] [Batch 946/1081] [D loss: 0.296334] [D acc: 0.85 (0.80 real, 0.90 fake)] [G loss: 24.491310] time: 0:32:53.165948\n",
      "(10, 128, 128, 3)\n",
      "0.6721179\n",
      "[Epoch 3/10] [Batch 947/1081] [D loss: 0.218790] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 19.031059] time: 0:32:53.605149\n",
      "(10, 128, 128, 3)\n",
      "0.6578711\n",
      "[Epoch 3/10] [Batch 948/1081] [D loss: 0.180118] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 14.703341] time: 0:32:53.999839\n",
      "(10, 128, 128, 3)\n",
      "0.9433097\n",
      "[Epoch 3/10] [Batch 949/1081] [D loss: 0.532407] [D acc: 0.05 (0.00 real, 0.10 fake)] [G loss: 12.725863] time: 0:32:54.415571\n",
      "(10, 128, 128, 3)\n",
      "0.86949366\n",
      "[Epoch 3/10] [Batch 950/1081] [D loss: 0.419386] [D acc: 0.30 (0.20 real, 0.40 fake)] [G loss: 11.689845] time: 0:32:54.820249\n",
      "(10, 128, 128, 3)\n",
      "0.7535672\n",
      "[Epoch 3/10] [Batch 951/1081] [D loss: 0.268813] [D acc: 0.80 (1.00 real, 0.60 fake)] [G loss: 11.964352] time: 0:32:55.228921\n",
      "(10, 128, 128, 3)\n",
      "0.8115036\n",
      "[Epoch 3/10] [Batch 952/1081] [D loss: 0.210333] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.020946] time: 0:32:55.627719\n",
      "(10, 128, 128, 3)\n",
      "0.97813016\n",
      "[Epoch 3/10] [Batch 953/1081] [D loss: 0.483938] [D acc: 0.40 (0.80 real, 0.00 fake)] [G loss: 12.048840] time: 0:32:56.040509\n",
      "(10, 128, 128, 3)\n",
      "0.9370275\n",
      "[Epoch 3/10] [Batch 954/1081] [D loss: 0.433560] [D acc: 0.55 (0.20 real, 0.90 fake)] [G loss: 12.001866] time: 0:32:56.445658\n",
      "(10, 128, 128, 3)\n",
      "0.947416\n",
      "[Epoch 3/10] [Batch 955/1081] [D loss: 0.345482] [D acc: 0.70 (0.40 real, 1.00 fake)] [G loss: 11.824874] time: 0:32:56.838047\n",
      "(10, 128, 128, 3)\n",
      "0.912545\n",
      "[Epoch 3/10] [Batch 956/1081] [D loss: 0.446160] [D acc: 0.55 (1.00 real, 0.10 fake)] [G loss: 13.880480] time: 0:32:57.236924\n",
      "(10, 128, 128, 3)\n",
      "0.90380365\n",
      "[Epoch 3/10] [Batch 957/1081] [D loss: 0.455097] [D acc: 0.45 (0.90 real, 0.00 fake)] [G loss: 12.676064] time: 0:32:57.637682\n",
      "(10, 128, 128, 3)\n",
      "0.9004943\n",
      "[Epoch 3/10] [Batch 958/1081] [D loss: 0.270146] [D acc: 0.70 (0.40 real, 1.00 fake)] [G loss: 12.273201] time: 0:32:58.064583\n",
      "(10, 128, 128, 3)\n",
      "0.93549293\n",
      "[Epoch 3/10] [Batch 959/1081] [D loss: 0.259894] [D acc: 0.75 (0.50 real, 1.00 fake)] [G loss: 11.831837] time: 0:32:58.449258\n",
      "(10, 128, 128, 3)\n",
      "0.8915448\n",
      "[Epoch 3/10] [Batch 960/1081] [D loss: 0.167713] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.191767] time: 0:32:58.862548\n",
      "(10, 128, 128, 3)\n",
      "0.9362025\n",
      "[Epoch 3/10] [Batch 961/1081] [D loss: 0.163870] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.981831] time: 0:32:59.267320\n",
      "(10, 128, 128, 3)\n",
      "0.95123535\n",
      "[Epoch 3/10] [Batch 962/1081] [D loss: 0.141969] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.211515] time: 0:32:59.659454\n",
      "(10, 128, 128, 3)\n",
      "0.92526484\n",
      "[Epoch 3/10] [Batch 963/1081] [D loss: 0.136255] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.582392] time: 0:33:00.082492\n",
      "(10, 128, 128, 3)\n",
      "0.95051056\n",
      "[Epoch 3/10] [Batch 964/1081] [D loss: 0.129088] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.308664] time: 0:33:00.528773\n",
      "(10, 128, 128, 3)\n",
      "0.9753545\n",
      "[Epoch 3/10] [Batch 965/1081] [D loss: 0.133290] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.620792] time: 0:33:00.961349\n",
      "(10, 128, 128, 3)\n",
      "0.943325\n",
      "[Epoch 3/10] [Batch 966/1081] [D loss: 0.130894] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.054407] time: 0:33:01.353267\n",
      "(10, 128, 128, 3)\n",
      "0.87681603\n",
      "[Epoch 3/10] [Batch 967/1081] [D loss: 0.123451] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.083276] time: 0:33:01.766911\n",
      "(10, 128, 128, 3)\n",
      "0.87121993\n",
      "[Epoch 3/10] [Batch 968/1081] [D loss: 0.132125] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.601067] time: 0:33:02.159648\n",
      "(10, 128, 128, 3)\n",
      "0.9103513\n",
      "[Epoch 3/10] [Batch 969/1081] [D loss: 0.131806] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.432538] time: 0:33:02.570297\n",
      "(10, 128, 128, 3)\n",
      "0.89344597\n",
      "[Epoch 3/10] [Batch 970/1081] [D loss: 0.130259] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.726284] time: 0:33:02.988302\n",
      "(10, 128, 128, 3)\n",
      "0.9001591\n",
      "[Epoch 3/10] [Batch 971/1081] [D loss: 0.123092] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.710944] time: 0:33:03.377053\n",
      "(10, 128, 128, 3)\n",
      "0.83407\n",
      "[Epoch 3/10] [Batch 972/1081] [D loss: 0.121290] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.639410] time: 0:33:03.799969\n",
      "(10, 128, 128, 3)\n",
      "0.8980281\n",
      "[Epoch 3/10] [Batch 973/1081] [D loss: 0.136161] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.705523] time: 0:33:04.187956\n",
      "(10, 128, 128, 3)\n",
      "0.9142186\n",
      "[Epoch 3/10] [Batch 974/1081] [D loss: 0.146583] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.194828] time: 0:33:04.597115\n",
      "(10, 128, 128, 3)\n",
      "0.9371545\n",
      "[Epoch 3/10] [Batch 975/1081] [D loss: 0.181663] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.904506] time: 0:33:04.990754\n",
      "(10, 128, 128, 3)\n",
      "0.9237488\n",
      "[Epoch 3/10] [Batch 976/1081] [D loss: 0.127118] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.959484] time: 0:33:05.397439\n",
      "(10, 128, 128, 3)\n",
      "0.91415834\n",
      "[Epoch 3/10] [Batch 977/1081] [D loss: 0.137705] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.507381] time: 0:33:05.806587\n",
      "(10, 128, 128, 3)\n",
      "0.90011925\n",
      "[Epoch 3/10] [Batch 978/1081] [D loss: 0.184352] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.193883] time: 0:33:06.199822\n",
      "(10, 128, 128, 3)\n",
      "0.92339224\n",
      "[Epoch 3/10] [Batch 979/1081] [D loss: 0.168604] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.669531] time: 0:33:06.640476\n",
      "(10, 128, 128, 3)\n",
      "0.89742655\n",
      "[Epoch 3/10] [Batch 980/1081] [D loss: 0.209837] [D acc: 0.90 (1.00 real, 0.80 fake)] [G loss: 10.827998] time: 0:33:07.042809\n",
      "(10, 128, 128, 3)\n",
      "0.8540211\n",
      "[Epoch 3/10] [Batch 981/1081] [D loss: 0.197593] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 10.296584] time: 0:33:07.454726\n",
      "(10, 128, 128, 3)\n",
      "0.9278889\n",
      "[Epoch 3/10] [Batch 982/1081] [D loss: 0.122571] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.085114] time: 0:33:07.864190\n",
      "(10, 128, 128, 3)\n",
      "0.9274568\n",
      "[Epoch 3/10] [Batch 983/1081] [D loss: 0.122948] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.168772] time: 0:33:08.264874\n",
      "(10, 128, 128, 3)\n",
      "0.95620966\n",
      "[Epoch 3/10] [Batch 984/1081] [D loss: 0.126760] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.354074] time: 0:33:08.670713\n",
      "(10, 128, 128, 3)\n",
      "0.942502\n",
      "[Epoch 3/10] [Batch 985/1081] [D loss: 0.123555] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.513584] time: 0:33:09.070266\n",
      "(10, 128, 128, 3)\n",
      "0.8838267\n",
      "[Epoch 3/10] [Batch 986/1081] [D loss: 0.126227] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.808296] time: 0:33:09.469450\n",
      "(10, 128, 128, 3)\n",
      "0.8612222\n",
      "[Epoch 3/10] [Batch 987/1081] [D loss: 0.122705] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 12.347507] time: 0:33:09.864016\n",
      "(10, 128, 128, 3)\n",
      "0.90977854\n",
      "[Epoch 3/10] [Batch 988/1081] [D loss: 0.120410] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.173374] time: 0:33:10.286859\n",
      "(10, 128, 128, 3)\n",
      "0.9140535\n",
      "[Epoch 3/10] [Batch 989/1081] [D loss: 0.142050] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.218188] time: 0:33:10.681327\n",
      "(10, 128, 128, 3)\n",
      "0.9232323\n",
      "[Epoch 3/10] [Batch 990/1081] [D loss: 0.126615] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.392635] time: 0:33:11.092559\n",
      "(10, 128, 128, 3)\n",
      "0.9327858\n",
      "[Epoch 3/10] [Batch 991/1081] [D loss: 0.123030] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.380486] time: 0:33:11.481903\n",
      "(10, 128, 128, 3)\n",
      "0.83797437\n",
      "[Epoch 3/10] [Batch 992/1081] [D loss: 0.126307] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.070708] time: 0:33:11.896316\n",
      "(10, 128, 128, 3)\n",
      "0.89952797\n",
      "[Epoch 3/10] [Batch 993/1081] [D loss: 0.128169] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.650340] time: 0:33:12.305927\n",
      "(10, 128, 128, 3)\n",
      "0.9188048\n",
      "[Epoch 3/10] [Batch 994/1081] [D loss: 0.129350] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.029223] time: 0:33:12.712596\n",
      "(10, 128, 128, 3)\n",
      "0.9311318\n",
      "[Epoch 3/10] [Batch 995/1081] [D loss: 0.118594] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.186491] time: 0:33:13.172895\n",
      "(10, 128, 128, 3)\n",
      "0.8954162\n",
      "[Epoch 3/10] [Batch 996/1081] [D loss: 0.122421] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.987278] time: 0:33:13.570154\n",
      "(10, 128, 128, 3)\n",
      "0.8901253\n",
      "[Epoch 3/10] [Batch 997/1081] [D loss: 0.119885] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.463629] time: 0:33:13.984011\n",
      "(10, 128, 128, 3)\n",
      "0.89794064\n",
      "[Epoch 3/10] [Batch 998/1081] [D loss: 0.121231] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.165078] time: 0:33:14.386404\n",
      "(10, 128, 128, 3)\n",
      "0.9207628\n",
      "[Epoch 3/10] [Batch 999/1081] [D loss: 0.119455] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.973198] time: 0:33:14.799417\n",
      "(10, 128, 128, 3)\n",
      "0.9689267\n",
      "[Epoch 3/10] [Batch 1000/1081] [D loss: 0.121295] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.853380] time: 0:33:15.195792\n",
      "(10, 128, 128, 3)\n",
      "0.96049327\n",
      "[Epoch 3/10] [Batch 1001/1081] [D loss: 0.119481] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.996094] time: 0:33:15.604528\n",
      "(10, 128, 128, 3)\n",
      "0.94667464\n",
      "[Epoch 3/10] [Batch 1002/1081] [D loss: 0.117189] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.322063] time: 0:33:16.035682\n",
      "(10, 128, 128, 3)\n",
      "0.93821126\n",
      "[Epoch 3/10] [Batch 1003/1081] [D loss: 0.118357] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.495763] time: 0:33:16.412565\n",
      "(10, 128, 128, 3)\n",
      "0.846457\n",
      "[Epoch 3/10] [Batch 1004/1081] [D loss: 0.117420] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.464062] time: 0:33:16.802539\n",
      "(10, 128, 128, 3)\n",
      "0.9166505\n",
      "[Epoch 3/10] [Batch 1005/1081] [D loss: 0.116926] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.963556] time: 0:33:17.215654\n",
      "(10, 128, 128, 3)\n",
      "0.8914988\n",
      "[Epoch 3/10] [Batch 1006/1081] [D loss: 0.119022] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.338149] time: 0:33:17.617301\n",
      "(10, 128, 128, 3)\n",
      "0.94712645\n",
      "[Epoch 3/10] [Batch 1007/1081] [D loss: 0.116995] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.217442] time: 0:33:18.015740\n",
      "(10, 128, 128, 3)\n",
      "0.917764\n",
      "[Epoch 3/10] [Batch 1008/1081] [D loss: 0.117099] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.625037] time: 0:33:18.401451\n",
      "(10, 128, 128, 3)\n",
      "0.9416159\n",
      "[Epoch 3/10] [Batch 1009/1081] [D loss: 0.115913] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.938726] time: 0:33:18.808983\n",
      "(10, 128, 128, 3)\n",
      "0.9495597\n",
      "[Epoch 3/10] [Batch 1010/1081] [D loss: 0.116295] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.579472] time: 0:33:19.238123\n",
      "(10, 128, 128, 3)\n",
      "0.9250674\n",
      "[Epoch 3/10] [Batch 1011/1081] [D loss: 0.149076] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.029944] time: 0:33:19.618343\n",
      "(10, 128, 128, 3)\n",
      "0.88218737\n",
      "[Epoch 3/10] [Batch 1012/1081] [D loss: 0.120003] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.037757] time: 0:33:20.011763\n",
      "(10, 128, 128, 3)\n",
      "0.889885\n",
      "[Epoch 3/10] [Batch 1013/1081] [D loss: 0.126060] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.651808] time: 0:33:20.415499\n",
      "(10, 128, 128, 3)\n",
      "0.8835912\n",
      "[Epoch 3/10] [Batch 1014/1081] [D loss: 0.118938] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.329880] time: 0:33:20.825393\n",
      "(10, 128, 128, 3)\n",
      "0.9409892\n",
      "[Epoch 3/10] [Batch 1015/1081] [D loss: 0.117495] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.550538] time: 0:33:21.263644\n",
      "(10, 128, 128, 3)\n",
      "0.88414884\n",
      "[Epoch 3/10] [Batch 1016/1081] [D loss: 0.117888] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.303022] time: 0:33:21.706729\n",
      "(10, 128, 128, 3)\n",
      "0.94204825\n",
      "[Epoch 3/10] [Batch 1017/1081] [D loss: 0.141528] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.923641] time: 0:33:22.088044\n",
      "(10, 128, 128, 3)\n",
      "0.93091583\n",
      "[Epoch 3/10] [Batch 1018/1081] [D loss: 0.116539] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.262835] time: 0:33:22.522447\n",
      "(10, 128, 128, 3)\n",
      "0.9249962\n",
      "[Epoch 3/10] [Batch 1019/1081] [D loss: 0.114740] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.155660] time: 0:33:22.938919\n",
      "(10, 128, 128, 3)\n",
      "0.9214204\n",
      "[Epoch 3/10] [Batch 1020/1081] [D loss: 0.116687] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.596218] time: 0:33:23.339058\n",
      "(10, 128, 128, 3)\n",
      "0.96058655\n",
      "[Epoch 3/10] [Batch 1021/1081] [D loss: 0.116345] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.509475] time: 0:33:23.720233\n",
      "(10, 128, 128, 3)\n",
      "0.92300725\n",
      "[Epoch 3/10] [Batch 1022/1081] [D loss: 0.119057] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.856680] time: 0:33:24.127835\n",
      "(10, 128, 128, 3)\n",
      "0.84280396\n",
      "[Epoch 3/10] [Batch 1023/1081] [D loss: 0.116715] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.042247] time: 0:33:24.537324\n",
      "(10, 128, 128, 3)\n",
      "0.9419811\n",
      "[Epoch 3/10] [Batch 1024/1081] [D loss: 0.117197] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.383818] time: 0:33:24.951346\n",
      "(10, 128, 128, 3)\n",
      "0.8920536\n",
      "[Epoch 3/10] [Batch 1025/1081] [D loss: 0.113871] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.149174] time: 0:33:25.329572\n",
      "(10, 128, 128, 3)\n",
      "0.86870533\n",
      "[Epoch 3/10] [Batch 1026/1081] [D loss: 0.114067] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.071655] time: 0:33:25.735296\n",
      "(10, 128, 128, 3)\n",
      "0.9730697\n",
      "[Epoch 3/10] [Batch 1027/1081] [D loss: 0.115131] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.457975] time: 0:33:26.170963\n",
      "(10, 128, 128, 3)\n",
      "0.8707762\n",
      "[Epoch 3/10] [Batch 1028/1081] [D loss: 0.113104] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.750262] time: 0:33:26.556123\n",
      "(10, 128, 128, 3)\n",
      "0.94175833\n",
      "[Epoch 3/10] [Batch 1029/1081] [D loss: 0.114052] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.370039] time: 0:33:26.949799\n",
      "(10, 128, 128, 3)\n",
      "0.9390827\n",
      "[Epoch 3/10] [Batch 1030/1081] [D loss: 0.114312] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.105599] time: 0:33:27.341716\n",
      "(10, 128, 128, 3)\n",
      "0.90257984\n",
      "[Epoch 3/10] [Batch 1031/1081] [D loss: 0.113990] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.624203] time: 0:33:27.760889\n",
      "(10, 128, 128, 3)\n",
      "0.9055498\n",
      "[Epoch 3/10] [Batch 1032/1081] [D loss: 0.113413] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.277932] time: 0:33:28.177290\n",
      "(10, 128, 128, 3)\n",
      "0.9113533\n",
      "[Epoch 3/10] [Batch 1033/1081] [D loss: 0.113435] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.641531] time: 0:33:28.574059\n",
      "(10, 128, 128, 3)\n",
      "0.8869888\n",
      "[Epoch 3/10] [Batch 1034/1081] [D loss: 0.112641] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.181944] time: 0:33:28.977170\n",
      "(10, 128, 128, 3)\n",
      "0.8734236\n",
      "[Epoch 3/10] [Batch 1035/1081] [D loss: 0.112613] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.758940] time: 0:33:29.348488\n",
      "(10, 128, 128, 3)\n",
      "0.88619953\n",
      "[Epoch 3/10] [Batch 1036/1081] [D loss: 0.113420] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.591952] time: 0:33:29.753943\n",
      "(10, 128, 128, 3)\n",
      "0.9177975\n",
      "[Epoch 3/10] [Batch 1037/1081] [D loss: 0.113374] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.047933] time: 0:33:30.128714\n",
      "(10, 128, 128, 3)\n",
      "0.93480283\n",
      "[Epoch 3/10] [Batch 1038/1081] [D loss: 0.112025] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.552166] time: 0:33:30.562480\n",
      "(10, 128, 128, 3)\n",
      "0.9233339\n",
      "[Epoch 3/10] [Batch 1039/1081] [D loss: 0.112898] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.140529] time: 0:33:30.948000\n",
      "(10, 128, 128, 3)\n",
      "0.89449733\n",
      "[Epoch 3/10] [Batch 1040/1081] [D loss: 0.111606] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.909094] time: 0:33:31.356332\n",
      "(10, 128, 128, 3)\n",
      "0.8675905\n",
      "[Epoch 3/10] [Batch 1041/1081] [D loss: 0.111995] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.108758] time: 0:33:31.756127\n",
      "(10, 128, 128, 3)\n",
      "0.8841124\n",
      "[Epoch 3/10] [Batch 1042/1081] [D loss: 0.111230] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.053876] time: 0:33:32.178822\n",
      "(10, 128, 128, 3)\n",
      "0.91132194\n",
      "[Epoch 3/10] [Batch 1043/1081] [D loss: 0.113527] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.589083] time: 0:33:32.572307\n",
      "(10, 128, 128, 3)\n",
      "0.8663099\n",
      "[Epoch 3/10] [Batch 1044/1081] [D loss: 0.118884] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.823217] time: 0:33:32.972312\n",
      "(10, 128, 128, 3)\n",
      "0.9284813\n",
      "[Epoch 3/10] [Batch 1045/1081] [D loss: 0.111716] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.960660] time: 0:33:33.368526\n",
      "(10, 128, 128, 3)\n",
      "0.89636034\n",
      "[Epoch 3/10] [Batch 1046/1081] [D loss: 0.112197] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.718439] time: 0:33:33.750072\n",
      "(10, 128, 128, 3)\n",
      "0.93135923\n",
      "[Epoch 3/10] [Batch 1047/1081] [D loss: 0.112482] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.176921] time: 0:33:34.136073\n",
      "(10, 128, 128, 3)\n",
      "0.9453924\n",
      "[Epoch 3/10] [Batch 1048/1081] [D loss: 0.110370] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.304693] time: 0:33:34.519502\n",
      "(10, 128, 128, 3)\n",
      "0.89187056\n",
      "[Epoch 3/10] [Batch 1049/1081] [D loss: 0.110792] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.022375] time: 0:33:34.914267\n",
      "(10, 128, 128, 3)\n",
      "0.93274266\n",
      "[Epoch 3/10] [Batch 1050/1081] [D loss: 0.111873] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.240233] time: 0:33:35.297739\n",
      "(10, 128, 128, 3)\n",
      "0.91438293\n",
      "[Epoch 3/10] [Batch 1051/1081] [D loss: 0.110495] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.685112] time: 0:33:35.684607\n",
      "(10, 128, 128, 3)\n",
      "0.8481496\n",
      "[Epoch 3/10] [Batch 1052/1081] [D loss: 0.111842] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.370346] time: 0:33:36.070306\n",
      "(10, 128, 128, 3)\n",
      "0.91800475\n",
      "[Epoch 3/10] [Batch 1053/1081] [D loss: 0.110088] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.307865] time: 0:33:36.460405\n",
      "(10, 128, 128, 3)\n",
      "0.9531664\n",
      "[Epoch 3/10] [Batch 1054/1081] [D loss: 0.110207] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.709553] time: 0:33:36.842708\n",
      "(10, 128, 128, 3)\n",
      "0.91203207\n",
      "[Epoch 3/10] [Batch 1055/1081] [D loss: 0.111344] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.818439] time: 0:33:37.220148\n",
      "(10, 128, 128, 3)\n",
      "0.8782055\n",
      "[Epoch 3/10] [Batch 1056/1081] [D loss: 0.112500] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.582849] time: 0:33:37.639579\n",
      "(10, 128, 128, 3)\n",
      "0.9339579\n",
      "[Epoch 3/10] [Batch 1057/1081] [D loss: 0.111128] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.048776] time: 0:33:38.037226\n",
      "(10, 128, 128, 3)\n",
      "0.90344924\n",
      "[Epoch 3/10] [Batch 1058/1081] [D loss: 0.109999] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.191541] time: 0:33:38.432028\n",
      "(10, 128, 128, 3)\n",
      "0.8870767\n",
      "[Epoch 3/10] [Batch 1059/1081] [D loss: 0.109214] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.428532] time: 0:33:38.805143\n",
      "(10, 128, 128, 3)\n",
      "0.90947145\n",
      "[Epoch 3/10] [Batch 1060/1081] [D loss: 0.109912] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.943239] time: 0:33:39.219377\n",
      "(10, 128, 128, 3)\n",
      "0.8671234\n",
      "[Epoch 3/10] [Batch 1061/1081] [D loss: 0.111749] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.483303] time: 0:33:39.624516\n",
      "(10, 128, 128, 3)\n",
      "0.8927571\n",
      "[Epoch 3/10] [Batch 1062/1081] [D loss: 0.109368] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.126416] time: 0:33:40.022911\n",
      "(10, 128, 128, 3)\n",
      "0.9394925\n",
      "[Epoch 3/10] [Batch 1063/1081] [D loss: 0.121812] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.495941] time: 0:33:40.420922\n",
      "(10, 128, 128, 3)\n",
      "0.9071255\n",
      "[Epoch 3/10] [Batch 1064/1081] [D loss: 0.111744] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.508106] time: 0:33:40.826971\n",
      "(10, 128, 128, 3)\n",
      "0.9135645\n",
      "[Epoch 3/10] [Batch 1065/1081] [D loss: 0.108518] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.100364] time: 0:33:41.220912\n",
      "(10, 128, 128, 3)\n",
      "0.8830562\n",
      "[Epoch 3/10] [Batch 1066/1081] [D loss: 0.109274] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.866943] time: 0:33:41.593807\n",
      "(10, 128, 128, 3)\n",
      "0.88819236\n",
      "[Epoch 3/10] [Batch 1067/1081] [D loss: 0.108985] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.694289] time: 0:33:42.017274\n",
      "(10, 128, 128, 3)\n",
      "0.9257441\n",
      "[Epoch 3/10] [Batch 1068/1081] [D loss: 0.109409] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.140743] time: 0:33:42.418184\n",
      "(10, 128, 128, 3)\n",
      "0.89008754\n",
      "[Epoch 3/10] [Batch 1069/1081] [D loss: 0.108154] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.631355] time: 0:33:42.802002\n",
      "(10, 128, 128, 3)\n",
      "0.9186476\n",
      "[Epoch 3/10] [Batch 1070/1081] [D loss: 0.109220] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.751457] time: 0:33:43.178324\n",
      "(10, 128, 128, 3)\n",
      "0.9045233\n",
      "[Epoch 3/10] [Batch 1071/1081] [D loss: 0.108677] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.087589] time: 0:33:43.587906\n",
      "(10, 128, 128, 3)\n",
      "0.9512579\n",
      "[Epoch 3/10] [Batch 1072/1081] [D loss: 0.114045] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.555687] time: 0:33:43.981365\n",
      "(10, 128, 128, 3)\n",
      "0.8768425\n",
      "[Epoch 3/10] [Batch 1073/1081] [D loss: 0.113106] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.122690] time: 0:33:44.381457\n",
      "(10, 128, 128, 3)\n",
      "0.9110276\n",
      "[Epoch 3/10] [Batch 1074/1081] [D loss: 0.110720] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.468212] time: 0:33:44.785254\n",
      "(10, 128, 128, 3)\n",
      "0.955146\n",
      "[Epoch 3/10] [Batch 1075/1081] [D loss: 0.107159] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.851320] time: 0:33:45.179120\n",
      "(10, 128, 128, 3)\n",
      "0.8996117\n",
      "[Epoch 3/10] [Batch 1076/1081] [D loss: 0.108589] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.024228] time: 0:33:45.558476\n",
      "(10, 128, 128, 3)\n",
      "0.8711392\n",
      "[Epoch 3/10] [Batch 1077/1081] [D loss: 0.107547] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.798664] time: 0:33:45.973857\n",
      "(10, 128, 128, 3)\n",
      "0.8365176\n",
      "[Epoch 3/10] [Batch 1078/1081] [D loss: 0.107139] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.460023] time: 0:33:46.375311\n",
      "(10, 128, 128, 3)\n",
      "0.90764266\n",
      "[Epoch 3/10] [Batch 1079/1081] [D loss: 0.110018] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.016809] time: 0:33:46.819364\n",
      "(10, 128, 128, 3)\n",
      "0.9345534\n",
      "[Epoch 3/10] [Batch 1080/1081] [D loss: 0.107314] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.887694] time: 0:33:47.225706\n",
      "############ VALIDATION OF EPOCH 3 ############\n",
      "############ TRAINING OF EPOCH 4 ############\n",
      "(10, 128, 128, 3)\n",
      "0.89973783\n",
      "[Epoch 4/10] [Batch 0/1081] [D loss: 0.106866] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.602839] time: 0:34:29.286936\n",
      "(10, 128, 128, 3)\n",
      "0.8675592\n",
      "[Epoch 4/10] [Batch 1/1081] [D loss: 0.107204] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.999523] time: 0:34:29.705369\n",
      "(10, 128, 128, 3)\n",
      "0.88346\n",
      "[Epoch 4/10] [Batch 3/1081] [D loss: 0.110528] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.669333] time: 0:34:30.111461\n",
      "(10, 128, 128, 3)\n",
      "0.9606929\n",
      "[Epoch 4/10] [Batch 4/1081] [D loss: 0.107833] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.305715] time: 0:34:30.519099\n",
      "(10, 128, 128, 3)\n",
      "0.93425035\n",
      "[Epoch 4/10] [Batch 5/1081] [D loss: 0.106412] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.685428] time: 0:34:30.926187\n",
      "(10, 128, 128, 3)\n",
      "0.9605885\n",
      "[Epoch 4/10] [Batch 6/1081] [D loss: 0.114946] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.651608] time: 0:34:31.327881\n",
      "(10, 128, 128, 3)\n",
      "0.8920073\n",
      "[Epoch 4/10] [Batch 7/1081] [D loss: 0.112576] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.801558] time: 0:34:31.727918\n",
      "(10, 128, 128, 3)\n",
      "0.9238455\n",
      "[Epoch 4/10] [Batch 8/1081] [D loss: 0.109895] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.392178] time: 0:34:32.143217\n",
      "(10, 128, 128, 3)\n",
      "0.9153557\n",
      "[Epoch 4/10] [Batch 9/1081] [D loss: 0.106268] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.659523] time: 0:34:32.562429\n",
      "(10, 128, 128, 3)\n",
      "0.90897655\n",
      "[Epoch 4/10] [Batch 10/1081] [D loss: 0.106371] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.737967] time: 0:34:32.960684\n",
      "(10, 128, 128, 3)\n",
      "0.9309836\n",
      "[Epoch 4/10] [Batch 11/1081] [D loss: 0.105613] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.951848] time: 0:34:33.348606\n",
      "(10, 128, 128, 3)\n",
      "0.8960957\n",
      "[Epoch 4/10] [Batch 12/1081] [D loss: 0.106317] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.626958] time: 0:34:33.751887\n",
      "(10, 128, 128, 3)\n",
      "0.9537583\n",
      "[Epoch 4/10] [Batch 13/1081] [D loss: 0.105647] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.475548] time: 0:34:34.158394\n",
      "(10, 128, 128, 3)\n",
      "0.9365271\n",
      "[Epoch 4/10] [Batch 14/1081] [D loss: 0.107094] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.278025] time: 0:34:34.583102\n",
      "(10, 128, 128, 3)\n",
      "0.85947937\n",
      "[Epoch 4/10] [Batch 15/1081] [D loss: 0.104862] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.544518] time: 0:34:34.999600\n",
      "(10, 128, 128, 3)\n",
      "0.8755676\n",
      "[Epoch 4/10] [Batch 16/1081] [D loss: 0.105549] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.389553] time: 0:34:35.400713\n",
      "(10, 128, 128, 3)\n",
      "0.86876917\n",
      "[Epoch 4/10] [Batch 17/1081] [D loss: 0.105774] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.484824] time: 0:34:35.815630\n",
      "(10, 128, 128, 3)\n",
      "0.94293046\n",
      "[Epoch 4/10] [Batch 18/1081] [D loss: 0.109885] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.308845] time: 0:34:36.240388\n",
      "(10, 128, 128, 3)\n",
      "0.8714845\n",
      "[Epoch 4/10] [Batch 19/1081] [D loss: 0.106799] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.091135] time: 0:34:36.626065\n",
      "(10, 128, 128, 3)\n",
      "0.8766034\n",
      "[Epoch 4/10] [Batch 20/1081] [D loss: 0.105536] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.127288] time: 0:34:37.062298\n",
      "(10, 128, 128, 3)\n",
      "0.8858664\n",
      "[Epoch 4/10] [Batch 21/1081] [D loss: 0.104780] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.193586] time: 0:34:37.447595\n",
      "(10, 128, 128, 3)\n",
      "0.9242277\n",
      "[Epoch 4/10] [Batch 22/1081] [D loss: 0.104698] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.712831] time: 0:34:37.835812\n",
      "(10, 128, 128, 3)\n",
      "0.8830607\n",
      "[Epoch 4/10] [Batch 23/1081] [D loss: 0.104724] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.136724] time: 0:34:38.220535\n",
      "(10, 128, 128, 3)\n",
      "0.859921\n",
      "[Epoch 4/10] [Batch 24/1081] [D loss: 0.106436] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.772791] time: 0:34:38.628333\n",
      "(10, 128, 128, 3)\n",
      "0.83472353\n",
      "[Epoch 4/10] [Batch 25/1081] [D loss: 0.105565] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.528734] time: 0:34:39.009642\n",
      "(10, 128, 128, 3)\n",
      "0.93270296\n",
      "[Epoch 4/10] [Batch 26/1081] [D loss: 0.105182] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.526419] time: 0:34:39.429229\n",
      "(10, 128, 128, 3)\n",
      "0.9008232\n",
      "[Epoch 4/10] [Batch 27/1081] [D loss: 0.104013] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.521584] time: 0:34:39.829101\n",
      "(10, 128, 128, 3)\n",
      "0.8969433\n",
      "[Epoch 4/10] [Batch 28/1081] [D loss: 0.104340] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.272647] time: 0:34:40.254635\n",
      "(10, 128, 128, 3)\n",
      "0.8750894\n",
      "[Epoch 4/10] [Batch 29/1081] [D loss: 0.104775] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.458351] time: 0:34:40.650660\n",
      "(10, 128, 128, 3)\n",
      "0.90108246\n",
      "[Epoch 4/10] [Batch 30/1081] [D loss: 0.103598] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.434519] time: 0:34:41.033919\n",
      "(10, 128, 128, 3)\n",
      "0.90872383\n",
      "[Epoch 4/10] [Batch 31/1081] [D loss: 0.103570] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.786777] time: 0:34:41.434178\n",
      "(10, 128, 128, 3)\n",
      "0.9058647\n",
      "[Epoch 4/10] [Batch 32/1081] [D loss: 0.103734] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.191726] time: 0:34:41.822199\n",
      "(10, 128, 128, 3)\n",
      "0.91294146\n",
      "[Epoch 4/10] [Batch 33/1081] [D loss: 0.104444] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.750132] time: 0:34:42.221845\n",
      "(10, 128, 128, 3)\n",
      "0.9741998\n",
      "[Epoch 4/10] [Batch 34/1081] [D loss: 0.103197] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.768898] time: 0:34:42.613541\n",
      "(10, 128, 128, 3)\n",
      "0.9136612\n",
      "[Epoch 4/10] [Batch 35/1081] [D loss: 0.103402] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.344370] time: 0:34:43.004351\n",
      "(10, 128, 128, 3)\n",
      "0.9504157\n",
      "[Epoch 4/10] [Batch 36/1081] [D loss: 0.103860] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.788001] time: 0:34:43.400589\n",
      "(10, 128, 128, 3)\n",
      "0.913332\n",
      "[Epoch 4/10] [Batch 37/1081] [D loss: 0.105307] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.571472] time: 0:34:43.832038\n",
      "(10, 128, 128, 3)\n",
      "0.9729562\n",
      "[Epoch 4/10] [Batch 38/1081] [D loss: 0.104515] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.629623] time: 0:34:44.256820\n",
      "(10, 128, 128, 3)\n",
      "0.90290165\n",
      "[Epoch 4/10] [Batch 39/1081] [D loss: 0.103556] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.283442] time: 0:34:44.679167\n",
      "(10, 128, 128, 3)\n",
      "0.9031565\n",
      "[Epoch 4/10] [Batch 40/1081] [D loss: 0.103443] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.034924] time: 0:34:45.079562\n",
      "(10, 128, 128, 3)\n",
      "0.9278138\n",
      "[Epoch 4/10] [Batch 41/1081] [D loss: 0.106212] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.963467] time: 0:34:45.464414\n",
      "(10, 128, 128, 3)\n",
      "0.888978\n",
      "[Epoch 4/10] [Batch 42/1081] [D loss: 0.103721] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.591908] time: 0:34:45.872652\n",
      "(10, 128, 128, 3)\n",
      "0.94162005\n",
      "[Epoch 4/10] [Batch 43/1081] [D loss: 0.102671] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.861753] time: 0:34:46.280593\n",
      "(10, 128, 128, 3)\n",
      "0.92322737\n",
      "[Epoch 4/10] [Batch 44/1081] [D loss: 0.561165] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 9.468518] time: 0:34:46.672059\n",
      "(10, 128, 128, 3)\n",
      "0.9215885\n",
      "[Epoch 4/10] [Batch 45/1081] [D loss: 0.190285] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.406025] time: 0:34:47.105668\n",
      "(10, 128, 128, 3)\n",
      "0.90155846\n",
      "[Epoch 4/10] [Batch 46/1081] [D loss: 0.502774] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 9.105659] time: 0:34:47.524120\n",
      "(10, 128, 128, 3)\n",
      "0.91963553\n",
      "[Epoch 4/10] [Batch 47/1081] [D loss: 0.136981] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.218266] time: 0:34:47.926741\n",
      "(10, 128, 128, 3)\n",
      "0.9346481\n",
      "[Epoch 4/10] [Batch 48/1081] [D loss: 0.455255] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 8.946703] time: 0:34:48.329756\n",
      "(10, 128, 128, 3)\n",
      "0.9101834\n",
      "[Epoch 4/10] [Batch 49/1081] [D loss: 0.188542] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 8.765068] time: 0:34:48.738684\n",
      "(10, 128, 128, 3)\n",
      "0.9111495\n",
      "[Epoch 4/10] [Batch 50/1081] [D loss: 0.253708] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.004665] time: 0:34:49.144297\n",
      "(10, 128, 128, 3)\n",
      "0.9525712\n",
      "[Epoch 4/10] [Batch 51/1081] [D loss: 0.166784] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.250690] time: 0:34:49.548102\n",
      "(10, 128, 128, 3)\n",
      "0.91421205\n",
      "[Epoch 4/10] [Batch 52/1081] [D loss: 0.267903] [D acc: 0.55 (1.00 real, 0.10 fake)] [G loss: 9.340667] time: 0:34:49.964501\n",
      "(10, 128, 128, 3)\n",
      "0.8736172\n",
      "[Epoch 4/10] [Batch 53/1081] [D loss: 0.120830] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.376846] time: 0:34:50.387490\n",
      "(10, 128, 128, 3)\n",
      "0.9519524\n",
      "[Epoch 4/10] [Batch 54/1081] [D loss: 0.121511] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.150501] time: 0:34:50.804781\n",
      "(10, 128, 128, 3)\n",
      "0.9195509\n",
      "[Epoch 4/10] [Batch 55/1081] [D loss: 0.122304] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.286867] time: 0:34:51.205893\n",
      "(10, 128, 128, 3)\n",
      "0.8504724\n",
      "[Epoch 4/10] [Batch 56/1081] [D loss: 0.111736] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.874146] time: 0:34:51.610303\n",
      "(10, 128, 128, 3)\n",
      "0.93691367\n",
      "[Epoch 4/10] [Batch 57/1081] [D loss: 0.108959] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.368164] time: 0:34:52.006983\n",
      "(10, 128, 128, 3)\n",
      "0.92210746\n",
      "[Epoch 4/10] [Batch 58/1081] [D loss: 0.112014] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.046108] time: 0:34:52.404543\n",
      "(10, 128, 128, 3)\n",
      "0.9283364\n",
      "[Epoch 4/10] [Batch 59/1081] [D loss: 0.178790] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 9.507305] time: 0:34:52.812806\n",
      "(10, 128, 128, 3)\n",
      "0.9520281\n",
      "[Epoch 4/10] [Batch 60/1081] [D loss: 0.125593] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.663800] time: 0:34:53.204169\n",
      "(10, 128, 128, 3)\n",
      "0.9266998\n",
      "[Epoch 4/10] [Batch 61/1081] [D loss: 0.114299] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.443234] time: 0:34:53.634403\n",
      "(10, 128, 128, 3)\n",
      "0.82134277\n",
      "[Epoch 4/10] [Batch 62/1081] [D loss: 0.118228] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.368389] time: 0:34:54.072071\n",
      "(10, 128, 128, 3)\n",
      "0.9458437\n",
      "[Epoch 4/10] [Batch 63/1081] [D loss: 0.145052] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.513309] time: 0:34:54.476578\n",
      "(10, 128, 128, 3)\n",
      "0.934381\n",
      "[Epoch 4/10] [Batch 64/1081] [D loss: 0.115760] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.606602] time: 0:34:54.868287\n",
      "(10, 128, 128, 3)\n",
      "0.89066666\n",
      "[Epoch 4/10] [Batch 65/1081] [D loss: 0.119313] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.528034] time: 0:34:55.268564\n",
      "(10, 128, 128, 3)\n",
      "0.9137206\n",
      "[Epoch 4/10] [Batch 66/1081] [D loss: 0.113384] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.632326] time: 0:34:55.671844\n",
      "(10, 128, 128, 3)\n",
      "0.9818489\n",
      "[Epoch 4/10] [Batch 67/1081] [D loss: 0.108883] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.010280] time: 0:34:56.088057\n",
      "(10, 128, 128, 3)\n",
      "0.9341188\n",
      "[Epoch 4/10] [Batch 68/1081] [D loss: 0.108530] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.894243] time: 0:34:56.507138\n",
      "(10, 128, 128, 3)\n",
      "0.9259673\n",
      "[Epoch 4/10] [Batch 69/1081] [D loss: 0.108329] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.981972] time: 0:34:56.920842\n",
      "(10, 128, 128, 3)\n",
      "0.9134459\n",
      "[Epoch 4/10] [Batch 70/1081] [D loss: 0.136578] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.257256] time: 0:34:57.330083\n",
      "(10, 128, 128, 3)\n",
      "0.8732433\n",
      "[Epoch 4/10] [Batch 71/1081] [D loss: 0.108652] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.337747] time: 0:34:57.755049\n",
      "(10, 128, 128, 3)\n",
      "0.8956628\n",
      "[Epoch 4/10] [Batch 72/1081] [D loss: 0.121590] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.834337] time: 0:34:58.146060\n",
      "(10, 128, 128, 3)\n",
      "0.82010245\n",
      "[Epoch 4/10] [Batch 73/1081] [D loss: 0.107961] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.990821] time: 0:34:58.518384\n",
      "(10, 128, 128, 3)\n",
      "0.8674621\n",
      "[Epoch 4/10] [Batch 74/1081] [D loss: 0.115846] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.015278] time: 0:34:58.927120\n",
      "(10, 128, 128, 3)\n",
      "0.8320136\n",
      "[Epoch 4/10] [Batch 75/1081] [D loss: 0.122924] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.074516] time: 0:34:59.313472\n",
      "(10, 128, 128, 3)\n",
      "0.9437926\n",
      "[Epoch 4/10] [Batch 76/1081] [D loss: 0.110556] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.093334] time: 0:34:59.711846\n",
      "(10, 128, 128, 3)\n",
      "0.89306384\n",
      "[Epoch 4/10] [Batch 77/1081] [D loss: 0.109714] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.299429] time: 0:35:00.104165\n",
      "(10, 128, 128, 3)\n",
      "0.878849\n",
      "[Epoch 4/10] [Batch 78/1081] [D loss: 0.110437] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.310968] time: 0:35:00.544285\n",
      "(10, 128, 128, 3)\n",
      "0.86074495\n",
      "[Epoch 4/10] [Batch 79/1081] [D loss: 0.107793] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.699819] time: 0:35:00.953567\n",
      "(10, 128, 128, 3)\n",
      "0.8834658\n",
      "[Epoch 4/10] [Batch 80/1081] [D loss: 0.111521] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.708632] time: 0:35:01.380977\n",
      "(10, 128, 128, 3)\n",
      "0.9316501\n",
      "[Epoch 4/10] [Batch 81/1081] [D loss: 0.108394] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.713461] time: 0:35:01.788025\n",
      "(10, 128, 128, 3)\n",
      "0.9279849\n",
      "[Epoch 4/10] [Batch 82/1081] [D loss: 0.119040] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.566358] time: 0:35:02.167291\n",
      "(10, 128, 128, 3)\n",
      "0.89001113\n",
      "[Epoch 4/10] [Batch 83/1081] [D loss: 0.110908] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.827282] time: 0:35:02.555280\n",
      "(10, 128, 128, 3)\n",
      "0.90285355\n",
      "[Epoch 4/10] [Batch 84/1081] [D loss: 0.106200] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.423540] time: 0:35:02.950888\n",
      "(10, 128, 128, 3)\n",
      "0.8718961\n",
      "[Epoch 4/10] [Batch 85/1081] [D loss: 0.112058] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.268102] time: 0:35:03.320318\n",
      "(10, 128, 128, 3)\n",
      "0.8888545\n",
      "[Epoch 4/10] [Batch 86/1081] [D loss: 0.109046] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.251636] time: 0:35:03.733422\n",
      "(10, 128, 128, 3)\n",
      "0.8583508\n",
      "[Epoch 4/10] [Batch 87/1081] [D loss: 0.104467] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.041984] time: 0:35:04.116726\n",
      "(10, 128, 128, 3)\n",
      "0.82967347\n",
      "[Epoch 4/10] [Batch 88/1081] [D loss: 0.107159] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.138857] time: 0:35:04.512579\n",
      "(10, 128, 128, 3)\n",
      "0.91246647\n",
      "[Epoch 4/10] [Batch 89/1081] [D loss: 0.111212] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.044279] time: 0:35:04.906750\n",
      "(10, 128, 128, 3)\n",
      "0.8338766\n",
      "[Epoch 4/10] [Batch 90/1081] [D loss: 0.110391] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.033955] time: 0:35:05.335204\n",
      "(10, 128, 128, 3)\n",
      "0.86747414\n",
      "[Epoch 4/10] [Batch 91/1081] [D loss: 0.109351] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.848776] time: 0:35:05.705762\n",
      "(10, 128, 128, 3)\n",
      "0.8915184\n",
      "[Epoch 4/10] [Batch 92/1081] [D loss: 0.107808] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.005819] time: 0:35:06.149662\n",
      "(10, 128, 128, 3)\n",
      "0.95096284\n",
      "[Epoch 4/10] [Batch 93/1081] [D loss: 0.106701] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.005564] time: 0:35:06.560029\n",
      "(10, 128, 128, 3)\n",
      "0.9130271\n",
      "[Epoch 4/10] [Batch 94/1081] [D loss: 0.104217] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.766232] time: 0:35:06.956266\n",
      "(10, 128, 128, 3)\n",
      "0.93860555\n",
      "[Epoch 4/10] [Batch 95/1081] [D loss: 0.107664] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.957046] time: 0:35:07.353011\n",
      "(10, 128, 128, 3)\n",
      "0.9268119\n",
      "[Epoch 4/10] [Batch 96/1081] [D loss: 0.105941] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.481926] time: 0:35:07.807339\n",
      "(10, 128, 128, 3)\n",
      "0.9133014\n",
      "[Epoch 4/10] [Batch 97/1081] [D loss: 0.112319] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.110218] time: 0:35:08.204239\n",
      "(10, 128, 128, 3)\n",
      "0.9297283\n",
      "[Epoch 4/10] [Batch 98/1081] [D loss: 0.106370] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.372526] time: 0:35:08.577254\n",
      "(10, 128, 128, 3)\n",
      "0.9159694\n",
      "[Epoch 4/10] [Batch 99/1081] [D loss: 0.103831] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.606413] time: 0:35:08.947682\n",
      "(10, 128, 128, 3)\n",
      "0.9368551\n",
      "[Epoch 4/10] [Batch 100/1081] [D loss: 0.106120] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.193236] time: 0:35:09.327267\n",
      "(10, 128, 128, 3)\n",
      "0.9509609\n",
      "[Epoch 4/10] [Batch 101/1081] [D loss: 0.103084] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.648474] time: 0:35:09.706834\n",
      "(10, 128, 128, 3)\n",
      "0.871929\n",
      "[Epoch 4/10] [Batch 102/1081] [D loss: 0.104012] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.854505] time: 0:35:10.090295\n",
      "(10, 128, 128, 3)\n",
      "0.91326874\n",
      "[Epoch 4/10] [Batch 103/1081] [D loss: 0.102719] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.285112] time: 0:35:10.473792\n",
      "(10, 128, 128, 3)\n",
      "0.8408766\n",
      "[Epoch 4/10] [Batch 104/1081] [D loss: 0.104092] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.799907] time: 0:35:10.884232\n",
      "(10, 128, 128, 3)\n",
      "0.89086336\n",
      "[Epoch 4/10] [Batch 105/1081] [D loss: 0.105085] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.486979] time: 0:35:11.289345\n",
      "(10, 128, 128, 3)\n",
      "0.8917238\n",
      "[Epoch 4/10] [Batch 106/1081] [D loss: 0.117671] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.589783] time: 0:35:11.690779\n",
      "(10, 128, 128, 3)\n",
      "0.9059801\n",
      "[Epoch 4/10] [Batch 107/1081] [D loss: 0.103624] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.639511] time: 0:35:12.087213\n",
      "(10, 128, 128, 3)\n",
      "0.9278715\n",
      "[Epoch 4/10] [Batch 108/1081] [D loss: 0.109151] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.123158] time: 0:35:12.483040\n",
      "(10, 128, 128, 3)\n",
      "0.924232\n",
      "[Epoch 4/10] [Batch 109/1081] [D loss: 0.104808] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.109202] time: 0:35:12.883649\n",
      "(10, 128, 128, 3)\n",
      "0.93165183\n",
      "[Epoch 4/10] [Batch 110/1081] [D loss: 0.102748] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.361535] time: 0:35:13.271821\n",
      "(10, 128, 128, 3)\n",
      "0.8437856\n",
      "[Epoch 4/10] [Batch 111/1081] [D loss: 0.105001] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.411115] time: 0:35:13.688581\n",
      "(10, 128, 128, 3)\n",
      "0.89662194\n",
      "[Epoch 4/10] [Batch 112/1081] [D loss: 0.103404] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.596871] time: 0:35:14.071771\n",
      "(10, 128, 128, 3)\n",
      "0.86606723\n",
      "[Epoch 4/10] [Batch 113/1081] [D loss: 0.104670] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.546902] time: 0:35:14.468246\n",
      "(10, 128, 128, 3)\n",
      "0.9043646\n",
      "[Epoch 4/10] [Batch 114/1081] [D loss: 0.104335] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.703135] time: 0:35:14.901500\n",
      "(10, 128, 128, 3)\n",
      "0.9461996\n",
      "[Epoch 4/10] [Batch 115/1081] [D loss: 0.102151] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.540905] time: 0:35:15.308159\n",
      "(10, 128, 128, 3)\n",
      "0.9324119\n",
      "[Epoch 4/10] [Batch 116/1081] [D loss: 0.128196] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.145538] time: 0:35:15.703771\n",
      "(10, 128, 128, 3)\n",
      "0.9303667\n",
      "[Epoch 4/10] [Batch 117/1081] [D loss: 0.114776] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.552679] time: 0:35:16.106277\n",
      "(10, 128, 128, 3)\n",
      "0.9342076\n",
      "[Epoch 4/10] [Batch 118/1081] [D loss: 0.104657] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.159655] time: 0:35:16.498732\n",
      "(10, 128, 128, 3)\n",
      "0.9146955\n",
      "[Epoch 4/10] [Batch 119/1081] [D loss: 0.109022] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.596331] time: 0:35:16.886164\n",
      "(10, 128, 128, 3)\n",
      "0.94810987\n",
      "[Epoch 4/10] [Batch 120/1081] [D loss: 0.103367] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.033802] time: 0:35:17.300208\n",
      "(10, 128, 128, 3)\n",
      "0.91909343\n",
      "[Epoch 4/10] [Batch 121/1081] [D loss: 0.101889] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.475116] time: 0:35:17.676012\n",
      "(10, 128, 128, 3)\n",
      "0.9321411\n",
      "[Epoch 4/10] [Batch 122/1081] [D loss: 0.101888] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.586619] time: 0:35:18.050772\n",
      "(10, 128, 128, 3)\n",
      "0.90006614\n",
      "[Epoch 4/10] [Batch 123/1081] [D loss: 0.101808] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.451982] time: 0:35:18.459866\n",
      "(10, 128, 128, 3)\n",
      "0.9342304\n",
      "[Epoch 4/10] [Batch 124/1081] [D loss: 0.100897] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.257545] time: 0:35:18.847905\n",
      "(10, 128, 128, 3)\n",
      "0.88883376\n",
      "[Epoch 4/10] [Batch 125/1081] [D loss: 0.100864] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.812616] time: 0:35:19.252888\n",
      "(10, 128, 128, 3)\n",
      "0.89715433\n",
      "[Epoch 4/10] [Batch 126/1081] [D loss: 0.100643] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.643213] time: 0:35:19.648061\n",
      "(10, 128, 128, 3)\n",
      "0.90499115\n",
      "[Epoch 4/10] [Batch 127/1081] [D loss: 0.100836] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.915607] time: 0:35:20.044606\n",
      "(10, 128, 128, 3)\n",
      "0.9421349\n",
      "[Epoch 4/10] [Batch 128/1081] [D loss: 0.100513] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.593460] time: 0:35:20.434894\n",
      "(10, 128, 128, 3)\n",
      "0.8507064\n",
      "[Epoch 4/10] [Batch 129/1081] [D loss: 0.101662] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.124980] time: 0:35:20.828184\n",
      "(10, 128, 128, 3)\n",
      "0.8735754\n",
      "[Epoch 4/10] [Batch 130/1081] [D loss: 0.102995] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.838259] time: 0:35:21.259548\n",
      "(10, 128, 128, 3)\n",
      "0.88506794\n",
      "[Epoch 4/10] [Batch 131/1081] [D loss: 0.102915] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.604671] time: 0:35:21.637946\n",
      "(10, 128, 128, 3)\n",
      "0.90211445\n",
      "[Epoch 4/10] [Batch 132/1081] [D loss: 0.100874] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.864493] time: 0:35:22.032155\n",
      "(10, 128, 128, 3)\n",
      "0.9420541\n",
      "[Epoch 4/10] [Batch 133/1081] [D loss: 0.100354] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.297635] time: 0:35:22.436338\n",
      "(10, 128, 128, 3)\n",
      "0.8925626\n",
      "[Epoch 4/10] [Batch 134/1081] [D loss: 0.099882] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.596123] time: 0:35:22.856554\n",
      "(10, 128, 128, 3)\n",
      "0.9041473\n",
      "[Epoch 4/10] [Batch 135/1081] [D loss: 0.100627] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.869205] time: 0:35:23.246444\n",
      "(10, 128, 128, 3)\n",
      "0.9400485\n",
      "[Epoch 4/10] [Batch 136/1081] [D loss: 0.100433] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.289267] time: 0:35:23.629059\n",
      "(10, 128, 128, 3)\n",
      "0.9310567\n",
      "[Epoch 4/10] [Batch 137/1081] [D loss: 0.100044] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.475855] time: 0:35:24.022021\n",
      "(10, 128, 128, 3)\n",
      "0.8812737\n",
      "[Epoch 4/10] [Batch 138/1081] [D loss: 0.102044] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.670801] time: 0:35:24.414189\n",
      "(10, 128, 128, 3)\n",
      "0.8658665\n",
      "[Epoch 4/10] [Batch 139/1081] [D loss: 0.100408] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.322038] time: 0:35:24.835559\n",
      "(10, 128, 128, 3)\n",
      "0.909708\n",
      "[Epoch 4/10] [Batch 140/1081] [D loss: 0.099366] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.479179] time: 0:35:25.244870\n",
      "(10, 128, 128, 3)\n",
      "0.928463\n",
      "[Epoch 4/10] [Batch 141/1081] [D loss: 0.099566] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.907396] time: 0:35:25.628838\n",
      "(10, 128, 128, 3)\n",
      "0.9163375\n",
      "[Epoch 4/10] [Batch 142/1081] [D loss: 0.103924] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.439379] time: 0:35:26.047774\n",
      "(10, 128, 128, 3)\n",
      "0.93013257\n",
      "[Epoch 4/10] [Batch 143/1081] [D loss: 0.099783] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.010498] time: 0:35:26.480330\n",
      "(10, 128, 128, 3)\n",
      "0.8937628\n",
      "[Epoch 4/10] [Batch 144/1081] [D loss: 0.102013] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.797809] time: 0:35:26.883552\n",
      "(10, 128, 128, 3)\n",
      "0.91094303\n",
      "[Epoch 4/10] [Batch 145/1081] [D loss: 0.100284] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.654710] time: 0:35:27.298602\n",
      "(10, 128, 128, 3)\n",
      "0.8595993\n",
      "[Epoch 4/10] [Batch 146/1081] [D loss: 0.098703] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.821432] time: 0:35:27.723218\n",
      "(10, 128, 128, 3)\n",
      "0.86974925\n",
      "[Epoch 4/10] [Batch 147/1081] [D loss: 0.098380] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.630079] time: 0:35:28.140326\n",
      "(10, 128, 128, 3)\n",
      "0.91088\n",
      "[Epoch 4/10] [Batch 148/1081] [D loss: 0.099118] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.951229] time: 0:35:28.561678\n",
      "(10, 128, 128, 3)\n",
      "0.91746837\n",
      "[Epoch 4/10] [Batch 149/1081] [D loss: 0.098449] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.469762] time: 0:35:28.974167\n",
      "(10, 128, 128, 3)\n",
      "0.9023319\n",
      "[Epoch 4/10] [Batch 150/1081] [D loss: 0.098658] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.016323] time: 0:35:29.373205\n",
      "(10, 128, 128, 3)\n",
      "0.90989417\n",
      "[Epoch 4/10] [Batch 151/1081] [D loss: 0.101704] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.274848] time: 0:35:29.794830\n",
      "(10, 128, 128, 3)\n",
      "0.9036886\n",
      "[Epoch 4/10] [Batch 152/1081] [D loss: 0.098036] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.187122] time: 0:35:30.234768\n",
      "(10, 128, 128, 3)\n",
      "0.8599918\n",
      "[Epoch 4/10] [Batch 153/1081] [D loss: 0.098904] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.181246] time: 0:35:30.622214\n",
      "(10, 128, 128, 3)\n",
      "0.8902292\n",
      "[Epoch 4/10] [Batch 154/1081] [D loss: 0.098311] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.197863] time: 0:35:31.048098\n",
      "(10, 128, 128, 3)\n",
      "0.9134087\n",
      "[Epoch 4/10] [Batch 155/1081] [D loss: 0.097931] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.333014] time: 0:35:31.439782\n",
      "(10, 128, 128, 3)\n",
      "0.9193812\n",
      "[Epoch 4/10] [Batch 156/1081] [D loss: 0.098047] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.670525] time: 0:35:31.827676\n",
      "(10, 128, 128, 3)\n",
      "0.9041832\n",
      "[Epoch 4/10] [Batch 157/1081] [D loss: 0.097915] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.283081] time: 0:35:32.205965\n",
      "(10, 128, 128, 3)\n",
      "0.9533892\n",
      "[Epoch 4/10] [Batch 158/1081] [D loss: 0.097732] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.211960] time: 0:35:32.621701\n",
      "(10, 128, 128, 3)\n",
      "0.9186782\n",
      "[Epoch 4/10] [Batch 159/1081] [D loss: 0.097267] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.501280] time: 0:35:33.022420\n",
      "(10, 128, 128, 3)\n",
      "0.9124994\n",
      "[Epoch 4/10] [Batch 160/1081] [D loss: 0.097626] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.750177] time: 0:35:33.448638\n",
      "(10, 128, 128, 3)\n",
      "0.9432005\n",
      "[Epoch 4/10] [Batch 161/1081] [D loss: 0.097541] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.680075] time: 0:35:33.873640\n",
      "(10, 128, 128, 3)\n",
      "0.94158244\n",
      "[Epoch 4/10] [Batch 162/1081] [D loss: 0.096968] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.143132] time: 0:35:34.277210\n",
      "(10, 128, 128, 3)\n",
      "0.9106048\n",
      "[Epoch 4/10] [Batch 163/1081] [D loss: 0.097769] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.374613] time: 0:35:34.693724\n",
      "(10, 128, 128, 3)\n",
      "0.8713034\n",
      "[Epoch 4/10] [Batch 164/1081] [D loss: 0.096937] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.760643] time: 0:35:35.096178\n",
      "(10, 128, 128, 3)\n",
      "0.9294386\n",
      "[Epoch 4/10] [Batch 165/1081] [D loss: 0.114708] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.346316] time: 0:35:35.506971\n",
      "(10, 128, 128, 3)\n",
      "0.93548316\n",
      "[Epoch 4/10] [Batch 166/1081] [D loss: 0.098789] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.678379] time: 0:35:35.960878\n",
      "(10, 128, 128, 3)\n",
      "0.9383168\n",
      "[Epoch 4/10] [Batch 167/1081] [D loss: 0.097351] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.555468] time: 0:35:36.344495\n",
      "(10, 128, 128, 3)\n",
      "0.95445514\n",
      "[Epoch 4/10] [Batch 168/1081] [D loss: 0.098040] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.991574] time: 0:35:36.734440\n",
      "(10, 128, 128, 3)\n",
      "0.94264334\n",
      "[Epoch 4/10] [Batch 169/1081] [D loss: 0.096758] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.938030] time: 0:35:37.111128\n",
      "(10, 128, 128, 3)\n",
      "0.928159\n",
      "[Epoch 4/10] [Batch 170/1081] [D loss: 0.098262] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.721278] time: 0:35:37.517282\n",
      "(10, 128, 128, 3)\n",
      "0.88080865\n",
      "[Epoch 4/10] [Batch 171/1081] [D loss: 0.097209] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.616009] time: 0:35:37.894367\n",
      "(10, 128, 128, 3)\n",
      "0.93889993\n",
      "[Epoch 4/10] [Batch 172/1081] [D loss: 0.096413] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.166011] time: 0:35:38.311533\n",
      "(10, 128, 128, 3)\n",
      "0.9317996\n",
      "[Epoch 4/10] [Batch 173/1081] [D loss: 0.097682] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.981079] time: 0:35:38.705914\n",
      "(10, 128, 128, 3)\n",
      "0.88026196\n",
      "[Epoch 4/10] [Batch 174/1081] [D loss: 0.098159] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.705704] time: 0:35:39.126436\n",
      "(10, 128, 128, 3)\n",
      "0.88970643\n",
      "[Epoch 4/10] [Batch 175/1081] [D loss: 0.097116] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.682260] time: 0:35:39.521655\n",
      "(10, 128, 128, 3)\n",
      "0.92971236\n",
      "[Epoch 4/10] [Batch 176/1081] [D loss: 0.096104] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.332550] time: 0:35:39.942197\n",
      "(10, 128, 128, 3)\n",
      "0.92527217\n",
      "[Epoch 4/10] [Batch 177/1081] [D loss: 0.097940] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.085070] time: 0:35:40.355374\n",
      "(10, 128, 128, 3)\n",
      "0.94215363\n",
      "[Epoch 4/10] [Batch 178/1081] [D loss: 0.096221] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.317039] time: 0:35:40.737998\n",
      "(10, 128, 128, 3)\n",
      "0.9173205\n",
      "[Epoch 4/10] [Batch 179/1081] [D loss: 0.095769] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.299899] time: 0:35:41.132424\n",
      "(10, 128, 128, 3)\n",
      "0.8900895\n",
      "[Epoch 4/10] [Batch 180/1081] [D loss: 0.096148] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.434410] time: 0:35:41.543085\n",
      "(10, 128, 128, 3)\n",
      "0.9596019\n",
      "[Epoch 4/10] [Batch 181/1081] [D loss: 0.097043] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.332607] time: 0:35:41.944020\n",
      "(10, 128, 128, 3)\n",
      "0.902494\n",
      "[Epoch 4/10] [Batch 182/1081] [D loss: 0.095547] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.641288] time: 0:35:42.354778\n",
      "(10, 128, 128, 3)\n",
      "0.94213206\n",
      "[Epoch 4/10] [Batch 183/1081] [D loss: 0.095562] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.082902] time: 0:35:42.749997\n",
      "(10, 128, 128, 3)\n",
      "0.9439344\n",
      "[Epoch 4/10] [Batch 184/1081] [D loss: 0.095507] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.195684] time: 0:35:43.165521\n",
      "(10, 128, 128, 3)\n",
      "0.83152956\n",
      "[Epoch 4/10] [Batch 185/1081] [D loss: 0.095519] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.752734] time: 0:35:43.571935\n",
      "(10, 128, 128, 3)\n",
      "0.912931\n",
      "[Epoch 4/10] [Batch 186/1081] [D loss: 0.095974] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.912923] time: 0:35:43.983472\n",
      "(10, 128, 128, 3)\n",
      "0.9316075\n",
      "[Epoch 4/10] [Batch 187/1081] [D loss: 0.095007] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.714507] time: 0:35:44.384897\n",
      "(10, 128, 128, 3)\n",
      "0.8936214\n",
      "[Epoch 4/10] [Batch 188/1081] [D loss: 0.095484] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.511517] time: 0:35:44.792168\n",
      "(10, 128, 128, 3)\n",
      "0.8884856\n",
      "[Epoch 4/10] [Batch 189/1081] [D loss: 0.094766] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.672195] time: 0:35:45.199142\n",
      "(10, 128, 128, 3)\n",
      "0.8739467\n",
      "[Epoch 4/10] [Batch 190/1081] [D loss: 0.094805] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.627141] time: 0:35:45.615296\n",
      "(10, 128, 128, 3)\n",
      "0.94763094\n",
      "[Epoch 4/10] [Batch 191/1081] [D loss: 0.095107] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.632599] time: 0:35:46.004261\n",
      "(10, 128, 128, 3)\n",
      "0.9414692\n",
      "[Epoch 4/10] [Batch 192/1081] [D loss: 0.094608] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.384413] time: 0:35:46.414230\n",
      "(10, 128, 128, 3)\n",
      "0.9647744\n",
      "[Epoch 4/10] [Batch 193/1081] [D loss: 0.094994] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.973147] time: 0:35:46.792194\n",
      "(10, 128, 128, 3)\n",
      "0.9684897\n",
      "[Epoch 4/10] [Batch 194/1081] [D loss: 0.094943] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.037698] time: 0:35:47.202120\n",
      "(10, 128, 128, 3)\n",
      "0.8500388\n",
      "[Epoch 4/10] [Batch 195/1081] [D loss: 0.095482] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.840077] time: 0:35:47.606892\n",
      "(10, 128, 128, 3)\n",
      "0.9468541\n",
      "[Epoch 4/10] [Batch 196/1081] [D loss: 0.094578] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.299647] time: 0:35:48.037275\n",
      "(10, 128, 128, 3)\n",
      "0.9016814\n",
      "[Epoch 4/10] [Batch 197/1081] [D loss: 0.094309] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.826726] time: 0:35:48.448267\n",
      "(10, 128, 128, 3)\n",
      "0.87605876\n",
      "[Epoch 4/10] [Batch 198/1081] [D loss: 0.094249] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.989837] time: 0:35:48.871164\n",
      "(10, 128, 128, 3)\n",
      "0.86577725\n",
      "[Epoch 4/10] [Batch 199/1081] [D loss: 0.094225] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.936875] time: 0:35:49.279454\n",
      "(10, 128, 128, 3)\n",
      "0.9020571\n",
      "[Epoch 4/10] [Batch 200/1081] [D loss: 0.094159] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.567266] time: 0:35:49.709491\n",
      "(10, 128, 128, 3)\n",
      "0.9529194\n",
      "[Epoch 4/10] [Batch 201/1081] [D loss: 0.094239] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.785648] time: 0:35:50.085748\n",
      "(10, 128, 128, 3)\n",
      "0.885263\n",
      "[Epoch 4/10] [Batch 202/1081] [D loss: 0.094169] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.560723] time: 0:35:50.504561\n",
      "(10, 128, 128, 3)\n",
      "0.9198528\n",
      "[Epoch 4/10] [Batch 203/1081] [D loss: 0.094460] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.837455] time: 0:35:50.912175\n",
      "(10, 128, 128, 3)\n",
      "0.94042975\n",
      "[Epoch 4/10] [Batch 204/1081] [D loss: 0.094349] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.035874] time: 0:35:51.311255\n",
      "(10, 128, 128, 3)\n",
      "0.8854804\n",
      "[Epoch 4/10] [Batch 205/1081] [D loss: 0.094000] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.854523] time: 0:35:51.727418\n",
      "(10, 128, 128, 3)\n",
      "0.9159519\n",
      "[Epoch 4/10] [Batch 206/1081] [D loss: 0.095654] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.328105] time: 0:35:52.153056\n",
      "(10, 128, 128, 3)\n",
      "0.8416624\n",
      "[Epoch 4/10] [Batch 207/1081] [D loss: 0.095649] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.250987] time: 0:35:52.544354\n",
      "(10, 128, 128, 3)\n",
      "0.9126447\n",
      "[Epoch 4/10] [Batch 208/1081] [D loss: 0.093668] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.158860] time: 0:35:52.930440\n",
      "(10, 128, 128, 3)\n",
      "0.87974906\n",
      "[Epoch 4/10] [Batch 209/1081] [D loss: 0.093715] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.651778] time: 0:35:53.364444\n",
      "(10, 128, 128, 3)\n",
      "0.89331245\n",
      "[Epoch 4/10] [Batch 210/1081] [D loss: 0.093449] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.542399] time: 0:35:53.747146\n",
      "(10, 128, 128, 3)\n",
      "0.97699434\n",
      "[Epoch 4/10] [Batch 211/1081] [D loss: 0.094219] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.801003] time: 0:35:54.137962\n",
      "(10, 128, 128, 3)\n",
      "0.93686503\n",
      "[Epoch 4/10] [Batch 212/1081] [D loss: 0.093477] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.473489] time: 0:35:54.518507\n",
      "(10, 128, 128, 3)\n",
      "0.91746455\n",
      "[Epoch 4/10] [Batch 213/1081] [D loss: 0.093423] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.968213] time: 0:35:54.902475\n",
      "(10, 128, 128, 3)\n",
      "0.91714364\n",
      "[Epoch 4/10] [Batch 214/1081] [D loss: 0.093166] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.765827] time: 0:35:55.311253\n",
      "(10, 128, 128, 3)\n",
      "0.9295891\n",
      "[Epoch 4/10] [Batch 215/1081] [D loss: 0.093123] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.827293] time: 0:35:55.696237\n",
      "(10, 128, 128, 3)\n",
      "0.9195067\n",
      "[Epoch 4/10] [Batch 216/1081] [D loss: 0.093226] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.627753] time: 0:35:56.103997\n",
      "(10, 128, 128, 3)\n",
      "0.9215749\n",
      "[Epoch 4/10] [Batch 217/1081] [D loss: 0.092857] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.406650] time: 0:35:56.513160\n",
      "(10, 128, 128, 3)\n",
      "0.94283265\n",
      "[Epoch 4/10] [Batch 218/1081] [D loss: 0.092767] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.480076] time: 0:35:56.895364\n",
      "(10, 128, 128, 3)\n",
      "0.95085067\n",
      "[Epoch 4/10] [Batch 219/1081] [D loss: 0.092787] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.764132] time: 0:35:57.292364\n",
      "(10, 128, 128, 3)\n",
      "0.88319415\n",
      "[Epoch 4/10] [Batch 220/1081] [D loss: 0.094401] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.873572] time: 0:35:57.718523\n",
      "(10, 128, 128, 3)\n",
      "0.92577153\n",
      "[Epoch 4/10] [Batch 221/1081] [D loss: 0.092715] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.386883] time: 0:35:58.114179\n",
      "(10, 128, 128, 3)\n",
      "0.913872\n",
      "[Epoch 4/10] [Batch 222/1081] [D loss: 0.092612] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.819383] time: 0:35:58.516283\n",
      "(10, 128, 128, 3)\n",
      "0.86592346\n",
      "[Epoch 4/10] [Batch 223/1081] [D loss: 0.093543] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.169407] time: 0:35:58.925390\n",
      "(10, 128, 128, 3)\n",
      "0.89004046\n",
      "[Epoch 4/10] [Batch 224/1081] [D loss: 0.094154] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.479020] time: 0:35:59.306600\n",
      "(10, 128, 128, 3)\n",
      "0.9465108\n",
      "[Epoch 4/10] [Batch 225/1081] [D loss: 0.092486] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.808472] time: 0:35:59.700718\n",
      "(10, 128, 128, 3)\n",
      "0.8785465\n",
      "[Epoch 4/10] [Batch 226/1081] [D loss: 0.093601] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.936396] time: 0:36:00.106953\n",
      "(10, 128, 128, 3)\n",
      "0.9088536\n",
      "[Epoch 4/10] [Batch 227/1081] [D loss: 0.093352] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.761223] time: 0:36:00.496443\n",
      "(10, 128, 128, 3)\n",
      "0.94132096\n",
      "[Epoch 4/10] [Batch 228/1081] [D loss: 0.092176] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.488905] time: 0:36:00.878661\n",
      "(10, 128, 128, 3)\n",
      "0.9397729\n",
      "[Epoch 4/10] [Batch 229/1081] [D loss: 0.093227] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.515502] time: 0:36:01.289568\n",
      "(10, 128, 128, 3)\n",
      "0.920892\n",
      "[Epoch 4/10] [Batch 230/1081] [D loss: 0.092593] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.815030] time: 0:36:01.682499\n",
      "(10, 128, 128, 3)\n",
      "0.9250539\n",
      "[Epoch 4/10] [Batch 231/1081] [D loss: 0.092648] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.739174] time: 0:36:02.100889\n",
      "(10, 128, 128, 3)\n",
      "0.93480486\n",
      "[Epoch 4/10] [Batch 232/1081] [D loss: 0.092167] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.096570] time: 0:36:02.520395\n",
      "(10, 128, 128, 3)\n",
      "0.87714386\n",
      "[Epoch 4/10] [Batch 233/1081] [D loss: 0.092357] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.790344] time: 0:36:02.930090\n",
      "(10, 128, 128, 3)\n",
      "0.8748391\n",
      "[Epoch 4/10] [Batch 234/1081] [D loss: 0.092149] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.955884] time: 0:36:03.313144\n",
      "(10, 128, 128, 3)\n",
      "0.94393533\n",
      "[Epoch 4/10] [Batch 235/1081] [D loss: 0.091630] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.717746] time: 0:36:03.733786\n",
      "(10, 128, 128, 3)\n",
      "0.88343495\n",
      "[Epoch 4/10] [Batch 236/1081] [D loss: 0.091457] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.821295] time: 0:36:04.112671\n",
      "(10, 128, 128, 3)\n",
      "0.90614605\n",
      "[Epoch 4/10] [Batch 237/1081] [D loss: 0.091822] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.402530] time: 0:36:04.532361\n",
      "(10, 128, 128, 3)\n",
      "0.9052718\n",
      "[Epoch 4/10] [Batch 238/1081] [D loss: 0.091954] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.918610] time: 0:36:04.940973\n",
      "(10, 128, 128, 3)\n",
      "0.9308569\n",
      "[Epoch 4/10] [Batch 239/1081] [D loss: 0.091248] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.857128] time: 0:36:05.326447\n",
      "(10, 128, 128, 3)\n",
      "0.88624555\n",
      "[Epoch 4/10] [Batch 240/1081] [D loss: 0.091355] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.239176] time: 0:36:05.707287\n",
      "(10, 128, 128, 3)\n",
      "0.93149406\n",
      "[Epoch 4/10] [Batch 241/1081] [D loss: 0.091396] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.321856] time: 0:36:06.120493\n",
      "(10, 128, 128, 3)\n",
      "0.83381337\n",
      "[Epoch 4/10] [Batch 242/1081] [D loss: 0.091269] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.962641] time: 0:36:06.507473\n",
      "(10, 128, 128, 3)\n",
      "0.88873523\n",
      "[Epoch 4/10] [Batch 243/1081] [D loss: 0.091171] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.877239] time: 0:36:06.904137\n",
      "(10, 128, 128, 3)\n",
      "0.8848841\n",
      "[Epoch 4/10] [Batch 244/1081] [D loss: 0.091446] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.636311] time: 0:36:07.303530\n",
      "(10, 128, 128, 3)\n",
      "0.87132937\n",
      "[Epoch 4/10] [Batch 245/1081] [D loss: 0.091474] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.265870] time: 0:36:07.704498\n",
      "(10, 128, 128, 3)\n",
      "0.94830704\n",
      "[Epoch 4/10] [Batch 246/1081] [D loss: 0.091128] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.986456] time: 0:36:08.098795\n",
      "(10, 128, 128, 3)\n",
      "0.8728342\n",
      "[Epoch 4/10] [Batch 247/1081] [D loss: 0.091650] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.012810] time: 0:36:08.505132\n",
      "(10, 128, 128, 3)\n",
      "0.9234276\n",
      "[Epoch 4/10] [Batch 248/1081] [D loss: 0.090774] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.535301] time: 0:36:08.907963\n",
      "(10, 128, 128, 3)\n",
      "0.9469854\n",
      "[Epoch 4/10] [Batch 249/1081] [D loss: 0.090844] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.097782] time: 0:36:09.332808\n",
      "(10, 128, 128, 3)\n",
      "0.91725665\n",
      "[Epoch 4/10] [Batch 250/1081] [D loss: 0.090714] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.490369] time: 0:36:09.748310\n",
      "(10, 128, 128, 3)\n",
      "0.9347039\n",
      "[Epoch 4/10] [Batch 251/1081] [D loss: 0.090612] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.905277] time: 0:36:10.150470\n",
      "(10, 128, 128, 3)\n",
      "0.9326854\n",
      "[Epoch 4/10] [Batch 252/1081] [D loss: 0.090573] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.472919] time: 0:36:10.527795\n",
      "(10, 128, 128, 3)\n",
      "0.9806819\n",
      "[Epoch 4/10] [Batch 253/1081] [D loss: 0.091813] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.882678] time: 0:36:10.917028\n",
      "(10, 128, 128, 3)\n",
      "0.95900154\n",
      "[Epoch 4/10] [Batch 254/1081] [D loss: 0.090462] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.543888] time: 0:36:11.324581\n",
      "(10, 128, 128, 3)\n",
      "0.9389138\n",
      "[Epoch 4/10] [Batch 255/1081] [D loss: 0.090580] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.743284] time: 0:36:11.725543\n",
      "(10, 128, 128, 3)\n",
      "0.91578776\n",
      "[Epoch 4/10] [Batch 256/1081] [D loss: 0.090403] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.462713] time: 0:36:12.123129\n",
      "(10, 128, 128, 3)\n",
      "0.9387265\n",
      "[Epoch 4/10] [Batch 257/1081] [D loss: 0.090126] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.993552] time: 0:36:12.534784\n",
      "(10, 128, 128, 3)\n",
      "0.92444587\n",
      "[Epoch 4/10] [Batch 258/1081] [D loss: 0.090189] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.743349] time: 0:36:12.938621\n",
      "(10, 128, 128, 3)\n",
      "0.9411168\n",
      "[Epoch 4/10] [Batch 259/1081] [D loss: 0.090834] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.894135] time: 0:36:13.375136\n",
      "(10, 128, 128, 3)\n",
      "0.95782477\n",
      "[Epoch 4/10] [Batch 260/1081] [D loss: 0.091192] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.217543] time: 0:36:13.755374\n",
      "(10, 128, 128, 3)\n",
      "0.9181104\n",
      "[Epoch 4/10] [Batch 261/1081] [D loss: 0.090216] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.956714] time: 0:36:14.167810\n",
      "(10, 128, 128, 3)\n",
      "0.87011045\n",
      "[Epoch 4/10] [Batch 262/1081] [D loss: 0.089905] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.728059] time: 0:36:14.570551\n",
      "(10, 128, 128, 3)\n",
      "0.95087004\n",
      "[Epoch 4/10] [Batch 263/1081] [D loss: 0.090152] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.055545] time: 0:36:14.984326\n",
      "(10, 128, 128, 3)\n",
      "0.90495366\n",
      "[Epoch 4/10] [Batch 264/1081] [D loss: 0.089719] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.568185] time: 0:36:15.377455\n",
      "(10, 128, 128, 3)\n",
      "0.94129723\n",
      "[Epoch 4/10] [Batch 265/1081] [D loss: 0.089636] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.863668] time: 0:36:15.777421\n",
      "(10, 128, 128, 3)\n",
      "0.945483\n",
      "[Epoch 4/10] [Batch 266/1081] [D loss: 0.089659] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.579264] time: 0:36:16.178895\n",
      "(10, 128, 128, 3)\n",
      "0.9027849\n",
      "[Epoch 4/10] [Batch 267/1081] [D loss: 0.090023] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.064433] time: 0:36:16.577013\n",
      "(10, 128, 128, 3)\n",
      "0.8358254\n",
      "[Epoch 4/10] [Batch 268/1081] [D loss: 0.090097] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.110247] time: 0:36:16.968449\n",
      "(10, 128, 128, 3)\n",
      "0.94383097\n",
      "[Epoch 4/10] [Batch 269/1081] [D loss: 0.089753] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.440806] time: 0:36:17.352854\n",
      "(10, 128, 128, 3)\n",
      "0.94564813\n",
      "[Epoch 4/10] [Batch 270/1081] [D loss: 0.089907] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.890031] time: 0:36:17.779881\n",
      "(10, 128, 128, 3)\n",
      "0.9285155\n",
      "[Epoch 4/10] [Batch 271/1081] [D loss: 0.089392] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.626811] time: 0:36:18.166793\n",
      "(10, 128, 128, 3)\n",
      "0.9213893\n",
      "[Epoch 4/10] [Batch 272/1081] [D loss: 0.089400] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.555780] time: 0:36:18.535229\n",
      "(10, 128, 128, 3)\n",
      "0.84761876\n",
      "[Epoch 4/10] [Batch 273/1081] [D loss: 0.089092] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.097185] time: 0:36:18.918944\n",
      "(10, 128, 128, 3)\n",
      "0.94904065\n",
      "[Epoch 4/10] [Batch 274/1081] [D loss: 0.089069] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.416877] time: 0:36:19.319282\n",
      "(10, 128, 128, 3)\n",
      "0.95904285\n",
      "[Epoch 4/10] [Batch 275/1081] [D loss: 0.089113] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.105466] time: 0:36:19.744491\n",
      "(10, 128, 128, 3)\n",
      "0.8885994\n",
      "[Epoch 4/10] [Batch 276/1081] [D loss: 0.088917] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.215219] time: 0:36:20.167583\n",
      "(10, 128, 128, 3)\n",
      "0.94846535\n",
      "[Epoch 4/10] [Batch 277/1081] [D loss: 0.093743] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.713713] time: 0:36:20.575273\n",
      "(10, 128, 128, 3)\n",
      "0.8827204\n",
      "[Epoch 4/10] [Batch 278/1081] [D loss: 0.089696] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.584574] time: 0:36:20.992516\n",
      "(10, 128, 128, 3)\n",
      "0.8846827\n",
      "[Epoch 4/10] [Batch 279/1081] [D loss: 0.089092] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.622151] time: 0:36:21.407805\n",
      "(10, 128, 128, 3)\n",
      "0.8902302\n",
      "[Epoch 4/10] [Batch 280/1081] [D loss: 0.088720] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.170026] time: 0:36:21.835739\n",
      "(10, 128, 128, 3)\n",
      "0.9662592\n",
      "[Epoch 4/10] [Batch 281/1081] [D loss: 0.088943] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.205084] time: 0:36:22.263251\n",
      "(10, 128, 128, 3)\n",
      "0.9034644\n",
      "[Epoch 4/10] [Batch 282/1081] [D loss: 0.089531] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.231249] time: 0:36:22.671808\n",
      "(10, 128, 128, 3)\n",
      "0.9361563\n",
      "[Epoch 4/10] [Batch 283/1081] [D loss: 0.088875] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.665783] time: 0:36:23.067334\n",
      "(10, 128, 128, 3)\n",
      "0.89387697\n",
      "[Epoch 4/10] [Batch 284/1081] [D loss: 0.089061] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.776056] time: 0:36:23.443668\n",
      "(10, 128, 128, 3)\n",
      "0.9080542\n",
      "[Epoch 4/10] [Batch 285/1081] [D loss: 0.090490] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.111343] time: 0:36:23.868702\n",
      "(10, 128, 128, 3)\n",
      "0.9772019\n",
      "[Epoch 4/10] [Batch 286/1081] [D loss: 0.089707] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.109896] time: 0:36:24.268926\n",
      "(10, 128, 128, 3)\n",
      "0.9424262\n",
      "[Epoch 4/10] [Batch 287/1081] [D loss: 0.088795] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.478456] time: 0:36:24.667388\n",
      "(10, 128, 128, 3)\n",
      "0.9203052\n",
      "[Epoch 4/10] [Batch 288/1081] [D loss: 0.088297] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.251242] time: 0:36:25.064939\n",
      "(10, 128, 128, 3)\n",
      "0.9266281\n",
      "[Epoch 4/10] [Batch 289/1081] [D loss: 0.088509] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.996955] time: 0:36:25.442980\n",
      "(10, 128, 128, 3)\n",
      "0.9408826\n",
      "[Epoch 4/10] [Batch 290/1081] [D loss: 0.089868] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.664269] time: 0:36:25.846972\n",
      "(10, 128, 128, 3)\n",
      "0.88257957\n",
      "[Epoch 4/10] [Batch 291/1081] [D loss: 0.089230] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.729782] time: 0:36:26.265904\n",
      "(10, 128, 128, 3)\n",
      "0.88165396\n",
      "[Epoch 4/10] [Batch 292/1081] [D loss: 0.088519] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.456394] time: 0:36:26.671152\n",
      "(10, 128, 128, 3)\n",
      "0.90081245\n",
      "[Epoch 4/10] [Batch 293/1081] [D loss: 0.087985] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.066780] time: 0:36:27.059680\n",
      "(10, 128, 128, 3)\n",
      "0.8796095\n",
      "[Epoch 4/10] [Batch 294/1081] [D loss: 0.087993] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.356936] time: 0:36:27.475568\n",
      "(10, 128, 128, 3)\n",
      "0.9142502\n",
      "[Epoch 4/10] [Batch 295/1081] [D loss: 0.088577] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.695229] time: 0:36:27.871067\n",
      "(10, 128, 128, 3)\n",
      "0.9509421\n",
      "[Epoch 4/10] [Batch 296/1081] [D loss: 0.088965] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.068848] time: 0:36:28.284415\n",
      "(10, 128, 128, 3)\n",
      "0.9293727\n",
      "[Epoch 4/10] [Batch 297/1081] [D loss: 0.087775] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.706335] time: 0:36:28.701976\n",
      "(10, 128, 128, 3)\n",
      "0.8595188\n",
      "[Epoch 4/10] [Batch 298/1081] [D loss: 0.088309] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.619595] time: 0:36:29.103441\n",
      "(10, 128, 128, 3)\n",
      "0.9059432\n",
      "[Epoch 4/10] [Batch 299/1081] [D loss: 0.087610] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.997801] time: 0:36:29.494666\n",
      "(10, 128, 128, 3)\n",
      "0.94583243\n",
      "[Epoch 4/10] [Batch 300/1081] [D loss: 0.087508] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.779316] time: 0:36:29.920200\n",
      "(10, 128, 128, 3)\n",
      "0.95101005\n",
      "[Epoch 4/10] [Batch 301/1081] [D loss: 0.088155] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.676305] time: 0:36:30.344229\n",
      "(10, 128, 128, 3)\n",
      "0.8967053\n",
      "[Epoch 4/10] [Batch 302/1081] [D loss: 0.087713] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.478415] time: 0:36:30.756608\n",
      "(10, 128, 128, 3)\n",
      "0.88572484\n",
      "[Epoch 4/10] [Batch 303/1081] [D loss: 0.088222] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.778235] time: 0:36:31.139175\n",
      "(10, 128, 128, 3)\n",
      "0.9309475\n",
      "[Epoch 4/10] [Batch 304/1081] [D loss: 0.088476] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.135676] time: 0:36:31.544788\n",
      "(10, 128, 128, 3)\n",
      "0.8549142\n",
      "[Epoch 4/10] [Batch 305/1081] [D loss: 0.087275] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.107791] time: 0:36:31.924217\n",
      "(10, 128, 128, 3)\n",
      "0.9157913\n",
      "[Epoch 4/10] [Batch 306/1081] [D loss: 0.087676] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.163630] time: 0:36:32.313129\n",
      "(10, 128, 128, 3)\n",
      "0.9249633\n",
      "[Epoch 4/10] [Batch 307/1081] [D loss: 0.087110] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.394688] time: 0:36:32.726327\n",
      "(10, 128, 128, 3)\n",
      "0.966263\n",
      "[Epoch 4/10] [Batch 308/1081] [D loss: 0.087605] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.506860] time: 0:36:33.132223\n",
      "(10, 128, 128, 3)\n",
      "0.9443519\n",
      "[Epoch 4/10] [Batch 309/1081] [D loss: 0.087061] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.217939] time: 0:36:33.535988\n",
      "(10, 128, 128, 3)\n",
      "0.90360504\n",
      "[Epoch 4/10] [Batch 310/1081] [D loss: 0.087049] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.917467] time: 0:36:33.935261\n",
      "(10, 128, 128, 3)\n",
      "0.92158324\n",
      "[Epoch 4/10] [Batch 311/1081] [D loss: 0.087094] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.054514] time: 0:36:34.310296\n",
      "(10, 128, 128, 3)\n",
      "0.93425924\n",
      "[Epoch 4/10] [Batch 312/1081] [D loss: 0.087190] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.977041] time: 0:36:34.735660\n",
      "(10, 128, 128, 3)\n",
      "0.90323234\n",
      "[Epoch 4/10] [Batch 313/1081] [D loss: 0.086853] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.391650] time: 0:36:35.145573\n",
      "(10, 128, 128, 3)\n",
      "0.9446843\n",
      "[Epoch 4/10] [Batch 314/1081] [D loss: 0.088603] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.907777] time: 0:36:35.514556\n",
      "(10, 128, 128, 3)\n",
      "0.84710604\n",
      "[Epoch 4/10] [Batch 315/1081] [D loss: 0.087388] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.387788] time: 0:36:35.918051\n",
      "(10, 128, 128, 3)\n",
      "0.946023\n",
      "[Epoch 4/10] [Batch 316/1081] [D loss: 0.088878] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.621767] time: 0:36:36.312952\n",
      "(10, 128, 128, 3)\n",
      "0.93963027\n",
      "[Epoch 4/10] [Batch 317/1081] [D loss: 0.087173] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.462819] time: 0:36:36.712458\n",
      "(10, 128, 128, 3)\n",
      "0.88729095\n",
      "[Epoch 4/10] [Batch 318/1081] [D loss: 0.089229] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.397950] time: 0:36:37.110187\n",
      "(10, 128, 128, 3)\n",
      "0.909302\n",
      "[Epoch 4/10] [Batch 319/1081] [D loss: 0.088317] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.403555] time: 0:36:37.506641\n",
      "(10, 128, 128, 3)\n",
      "0.85617566\n",
      "[Epoch 4/10] [Batch 320/1081] [D loss: 0.087086] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.987467] time: 0:36:37.883172\n",
      "(10, 128, 128, 3)\n",
      "0.94737965\n",
      "[Epoch 4/10] [Batch 321/1081] [D loss: 0.086630] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.188664] time: 0:36:38.305564\n",
      "(10, 128, 128, 3)\n",
      "0.9180737\n",
      "[Epoch 4/10] [Batch 322/1081] [D loss: 0.086838] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.859488] time: 0:36:38.723911\n",
      "(10, 128, 128, 3)\n",
      "0.94528455\n",
      "[Epoch 4/10] [Batch 323/1081] [D loss: 0.087042] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.926301] time: 0:36:39.128155\n",
      "(10, 128, 128, 3)\n",
      "0.9000449\n",
      "[Epoch 4/10] [Batch 324/1081] [D loss: 0.086267] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.629832] time: 0:36:39.524616\n",
      "(10, 128, 128, 3)\n",
      "0.9223128\n",
      "[Epoch 4/10] [Batch 325/1081] [D loss: 0.086765] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.954978] time: 0:36:39.936769\n",
      "(10, 128, 128, 3)\n",
      "0.9485689\n",
      "[Epoch 4/10] [Batch 326/1081] [D loss: 0.086118] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.044681] time: 0:36:40.324809\n",
      "(10, 128, 128, 3)\n",
      "0.936425\n",
      "[Epoch 4/10] [Batch 327/1081] [D loss: 0.086291] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.253851] time: 0:36:40.715420\n",
      "(10, 128, 128, 3)\n",
      "0.95065165\n",
      "[Epoch 4/10] [Batch 328/1081] [D loss: 0.085953] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.461525] time: 0:36:41.108853\n",
      "(10, 128, 128, 3)\n",
      "0.9586535\n",
      "[Epoch 4/10] [Batch 329/1081] [D loss: 0.086360] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.935248] time: 0:36:41.498903\n",
      "(10, 128, 128, 3)\n",
      "0.8939967\n",
      "[Epoch 4/10] [Batch 330/1081] [D loss: 0.086991] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.622679] time: 0:36:41.899651\n",
      "(10, 128, 128, 3)\n",
      "0.93573135\n",
      "[Epoch 4/10] [Batch 331/1081] [D loss: 0.087795] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.182956] time: 0:36:42.619602\n",
      "(10, 128, 128, 3)\n",
      "0.8439329\n",
      "[Epoch 4/10] [Batch 332/1081] [D loss: 0.089531] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.954412] time: 0:36:43.024512\n",
      "(10, 128, 128, 3)\n",
      "0.89939195\n",
      "[Epoch 4/10] [Batch 333/1081] [D loss: 0.088408] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.393363] time: 0:36:43.430395\n",
      "(10, 128, 128, 3)\n",
      "0.92632693\n",
      "[Epoch 4/10] [Batch 334/1081] [D loss: 0.086486] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.122189] time: 0:36:43.823569\n",
      "(10, 128, 128, 3)\n",
      "0.9053275\n",
      "[Epoch 4/10] [Batch 335/1081] [D loss: 0.085681] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.181234] time: 0:36:44.288650\n",
      "(10, 128, 128, 3)\n",
      "0.9394248\n",
      "[Epoch 4/10] [Batch 336/1081] [D loss: 0.085939] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.320886] time: 0:36:44.702862\n",
      "(10, 128, 128, 3)\n",
      "0.9752903\n",
      "[Epoch 4/10] [Batch 337/1081] [D loss: 0.085837] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.846314] time: 0:36:45.118500\n",
      "(10, 128, 128, 3)\n",
      "0.90671045\n",
      "[Epoch 4/10] [Batch 338/1081] [D loss: 0.086630] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.595354] time: 0:36:45.507611\n",
      "(10, 128, 128, 3)\n",
      "0.9536457\n",
      "[Epoch 4/10] [Batch 339/1081] [D loss: 0.085575] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.753172] time: 0:36:45.933715\n",
      "(10, 128, 128, 3)\n",
      "0.8864832\n",
      "[Epoch 4/10] [Batch 340/1081] [D loss: 0.086081] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.647473] time: 0:36:46.344373\n",
      "(10, 128, 128, 3)\n",
      "0.93958646\n",
      "[Epoch 4/10] [Batch 341/1081] [D loss: 0.085645] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.822537] time: 0:36:46.781803\n",
      "(10, 128, 128, 3)\n",
      "0.8982324\n",
      "[Epoch 4/10] [Batch 342/1081] [D loss: 0.085338] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.348757] time: 0:36:47.188052\n",
      "(10, 128, 128, 3)\n",
      "0.9072225\n",
      "[Epoch 4/10] [Batch 343/1081] [D loss: 0.088539] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.163383] time: 0:36:47.624406\n",
      "(10, 128, 128, 3)\n",
      "0.8836906\n",
      "[Epoch 4/10] [Batch 344/1081] [D loss: 0.087454] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.026931] time: 0:36:48.047308\n",
      "(10, 128, 128, 3)\n",
      "0.9459098\n",
      "[Epoch 4/10] [Batch 345/1081] [D loss: 0.085734] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.535595] time: 0:36:48.464417\n",
      "(10, 128, 128, 3)\n",
      "0.890076\n",
      "[Epoch 4/10] [Batch 346/1081] [D loss: 0.085471] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.286737] time: 0:36:48.859995\n",
      "(10, 128, 128, 3)\n",
      "0.91753095\n",
      "[Epoch 4/10] [Batch 347/1081] [D loss: 0.087235] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.297941] time: 0:36:49.264964\n",
      "(10, 128, 128, 3)\n",
      "0.9010451\n",
      "[Epoch 4/10] [Batch 348/1081] [D loss: 0.086502] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.422720] time: 0:36:49.665421\n",
      "(10, 128, 128, 3)\n",
      "0.9600766\n",
      "[Epoch 4/10] [Batch 349/1081] [D loss: 0.085323] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.532883] time: 0:36:50.058463\n",
      "(10, 128, 128, 3)\n",
      "0.9349832\n",
      "[Epoch 4/10] [Batch 350/1081] [D loss: 0.085269] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.649315] time: 0:36:50.457088\n",
      "(10, 128, 128, 3)\n",
      "0.9435193\n",
      "[Epoch 4/10] [Batch 351/1081] [D loss: 0.085486] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.865497] time: 0:36:50.841464\n",
      "(10, 128, 128, 3)\n",
      "0.92150164\n",
      "[Epoch 4/10] [Batch 352/1081] [D loss: 0.084929] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.339077] time: 0:36:51.248947\n",
      "(10, 128, 128, 3)\n",
      "0.9402197\n",
      "[Epoch 4/10] [Batch 353/1081] [D loss: 0.084737] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.751872] time: 0:36:51.651897\n",
      "(10, 128, 128, 3)\n",
      "0.94216174\n",
      "[Epoch 4/10] [Batch 354/1081] [D loss: 0.085082] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.062733] time: 0:36:52.090991\n",
      "(10, 128, 128, 3)\n",
      "0.9128166\n",
      "[Epoch 4/10] [Batch 355/1081] [D loss: 0.129760] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 8.142595] time: 0:36:52.496349\n",
      "(10, 128, 128, 3)\n",
      "0.93130517\n",
      "[Epoch 4/10] [Batch 356/1081] [D loss: 0.116465] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.063231] time: 0:36:52.908744\n",
      "(10, 128, 128, 3)\n",
      "0.8999322\n",
      "[Epoch 4/10] [Batch 357/1081] [D loss: 0.423961] [D acc: 0.55 (1.00 real, 0.10 fake)] [G loss: 28.093029] time: 0:36:53.323328\n",
      "(10, 128, 128, 3)\n",
      "0.93151665\n",
      "[Epoch 4/10] [Batch 358/1081] [D loss: 0.502263] [D acc: 0.55 (0.90 real, 0.20 fake)] [G loss: 10.525734] time: 0:36:53.728433\n",
      "(10, 128, 128, 3)\n",
      "0.93223596\n",
      "[Epoch 4/10] [Batch 359/1081] [D loss: 0.451402] [D acc: 0.45 (0.30 real, 0.60 fake)] [G loss: 10.908456] time: 0:36:54.160337\n",
      "(10, 128, 128, 3)\n",
      "0.9021087\n",
      "[Epoch 4/10] [Batch 360/1081] [D loss: 0.667265] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 9.357164] time: 0:36:54.573245\n",
      "(10, 128, 128, 3)\n",
      "0.9340131\n",
      "[Epoch 4/10] [Batch 361/1081] [D loss: 0.287223] [D acc: 0.90 (0.90 real, 0.90 fake)] [G loss: 8.847567] time: 0:36:54.982488\n",
      "(10, 128, 128, 3)\n",
      "0.8812124\n",
      "[Epoch 4/10] [Batch 362/1081] [D loss: 0.497824] [D acc: 0.35 (0.70 real, 0.00 fake)] [G loss: 9.708937] time: 0:36:55.392659\n",
      "(10, 128, 128, 3)\n",
      "0.93365794\n",
      "[Epoch 4/10] [Batch 363/1081] [D loss: 0.350704] [D acc: 0.75 (0.90 real, 0.60 fake)] [G loss: 10.336004] time: 0:36:55.818096\n",
      "(10, 128, 128, 3)\n",
      "0.99073726\n",
      "[Epoch 4/10] [Batch 364/1081] [D loss: 0.356104] [D acc: 0.50 (0.20 real, 0.80 fake)] [G loss: 9.143023] time: 0:36:56.251478\n",
      "(10, 128, 128, 3)\n",
      "0.91812974\n",
      "[Epoch 4/10] [Batch 365/1081] [D loss: 0.436070] [D acc: 0.10 (0.20 real, 0.00 fake)] [G loss: 8.025092] time: 0:36:56.658375\n",
      "(10, 128, 128, 3)\n",
      "0.89227444\n",
      "[Epoch 4/10] [Batch 366/1081] [D loss: 0.333732] [D acc: 0.75 (1.00 real, 0.50 fake)] [G loss: 9.029714] time: 0:36:57.044848\n",
      "(10, 128, 128, 3)\n",
      "0.93220466\n",
      "[Epoch 4/10] [Batch 367/1081] [D loss: 0.510100] [D acc: 0.35 (0.00 real, 0.70 fake)] [G loss: 9.117820] time: 0:36:57.442016\n",
      "(10, 128, 128, 3)\n",
      "0.848855\n",
      "[Epoch 4/10] [Batch 368/1081] [D loss: 0.430147] [D acc: 0.35 (0.00 real, 0.70 fake)] [G loss: 8.288594] time: 0:36:57.830303\n",
      "(10, 128, 128, 3)\n",
      "0.8739144\n",
      "[Epoch 4/10] [Batch 369/1081] [D loss: 0.261774] [D acc: 0.75 (0.50 real, 1.00 fake)] [G loss: 9.512846] time: 0:36:58.262031\n",
      "(10, 128, 128, 3)\n",
      "0.94163877\n",
      "[Epoch 4/10] [Batch 370/1081] [D loss: 0.248673] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 8.849459] time: 0:36:58.699290\n",
      "(10, 128, 128, 3)\n",
      "0.9043891\n",
      "[Epoch 4/10] [Batch 371/1081] [D loss: 0.178881] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.396578] time: 0:36:59.104220\n",
      "(10, 128, 128, 3)\n",
      "0.8857951\n",
      "[Epoch 4/10] [Batch 372/1081] [D loss: 0.202431] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 9.700493] time: 0:36:59.498711\n",
      "(10, 128, 128, 3)\n",
      "0.9241066\n",
      "[Epoch 4/10] [Batch 373/1081] [D loss: 0.215411] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 8.988224] time: 0:36:59.886592\n",
      "(10, 128, 128, 3)\n",
      "0.913156\n",
      "[Epoch 4/10] [Batch 374/1081] [D loss: 0.623032] [D acc: 0.10 (0.00 real, 0.20 fake)] [G loss: 7.516665] time: 0:37:00.276495\n",
      "(10, 128, 128, 3)\n",
      "0.9171483\n",
      "[Epoch 4/10] [Batch 375/1081] [D loss: 0.174724] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.845042] time: 0:37:00.710630\n",
      "(10, 128, 128, 3)\n",
      "0.8609984\n",
      "[Epoch 4/10] [Batch 376/1081] [D loss: 0.144394] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.479932] time: 0:37:01.104656\n",
      "(10, 128, 128, 3)\n",
      "0.87585306\n",
      "[Epoch 4/10] [Batch 377/1081] [D loss: 0.154096] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.074242] time: 0:37:01.548453\n",
      "(10, 128, 128, 3)\n",
      "0.9306025\n",
      "[Epoch 4/10] [Batch 378/1081] [D loss: 0.140548] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.680337] time: 0:37:01.976929\n",
      "(10, 128, 128, 3)\n",
      "0.81916565\n",
      "[Epoch 4/10] [Batch 379/1081] [D loss: 0.128836] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.844889] time: 0:37:02.364646\n",
      "(10, 128, 128, 3)\n",
      "0.92689395\n",
      "[Epoch 4/10] [Batch 380/1081] [D loss: 0.132028] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.750395] time: 0:37:02.792731\n",
      "(10, 128, 128, 3)\n",
      "0.9384842\n",
      "[Epoch 4/10] [Batch 381/1081] [D loss: 0.133254] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.013377] time: 0:37:03.182700\n",
      "(10, 128, 128, 3)\n",
      "0.9314308\n",
      "[Epoch 4/10] [Batch 382/1081] [D loss: 0.117707] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.275766] time: 0:37:03.576675\n",
      "(10, 128, 128, 3)\n",
      "0.7954667\n",
      "[Epoch 4/10] [Batch 383/1081] [D loss: 0.124799] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.273097] time: 0:37:04.008620\n",
      "(10, 128, 128, 3)\n",
      "0.9526701\n",
      "[Epoch 4/10] [Batch 384/1081] [D loss: 0.124465] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.862217] time: 0:37:04.432305\n",
      "(10, 128, 128, 3)\n",
      "0.93234944\n",
      "[Epoch 4/10] [Batch 385/1081] [D loss: 0.116293] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.316676] time: 0:37:04.834810\n",
      "(10, 128, 128, 3)\n",
      "0.8946411\n",
      "[Epoch 4/10] [Batch 386/1081] [D loss: 0.118729] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.454192] time: 0:37:05.252774\n",
      "(10, 128, 128, 3)\n",
      "0.8741655\n",
      "[Epoch 4/10] [Batch 387/1081] [D loss: 0.229094] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 8.887596] time: 0:37:05.633809\n",
      "(10, 128, 128, 3)\n",
      "0.9233292\n",
      "[Epoch 4/10] [Batch 388/1081] [D loss: 0.134881] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.300706] time: 0:37:06.031637\n",
      "(10, 128, 128, 3)\n",
      "0.8832367\n",
      "[Epoch 4/10] [Batch 389/1081] [D loss: 0.148383] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.812733] time: 0:37:06.429278\n",
      "(10, 128, 128, 3)\n",
      "0.94169444\n",
      "[Epoch 4/10] [Batch 390/1081] [D loss: 0.117992] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.237897] time: 0:37:06.827747\n",
      "(10, 128, 128, 3)\n",
      "0.9371073\n",
      "[Epoch 4/10] [Batch 391/1081] [D loss: 0.118113] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.378582] time: 0:37:07.228230\n",
      "(10, 128, 128, 3)\n",
      "0.9015958\n",
      "[Epoch 4/10] [Batch 392/1081] [D loss: 0.114838] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.319933] time: 0:37:07.616628\n",
      "(10, 128, 128, 3)\n",
      "0.90605336\n",
      "[Epoch 4/10] [Batch 393/1081] [D loss: 0.114713] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.463392] time: 0:37:08.044125\n",
      "(10, 128, 128, 3)\n",
      "0.8783156\n",
      "[Epoch 4/10] [Batch 394/1081] [D loss: 0.121994] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.365314] time: 0:37:08.446197\n",
      "(10, 128, 128, 3)\n",
      "0.89249754\n",
      "[Epoch 4/10] [Batch 395/1081] [D loss: 0.113696] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.505322] time: 0:37:08.856145\n",
      "(10, 128, 128, 3)\n",
      "0.9442787\n",
      "[Epoch 4/10] [Batch 396/1081] [D loss: 0.116227] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.050802] time: 0:37:09.262361\n",
      "(10, 128, 128, 3)\n",
      "0.89531785\n",
      "[Epoch 4/10] [Batch 397/1081] [D loss: 0.122083] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.123953] time: 0:37:09.656821\n",
      "(10, 128, 128, 3)\n",
      "0.92581135\n",
      "[Epoch 4/10] [Batch 398/1081] [D loss: 0.114966] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.824729] time: 0:37:10.056967\n",
      "(10, 128, 128, 3)\n",
      "0.92929673\n",
      "[Epoch 4/10] [Batch 399/1081] [D loss: 0.126819] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.489883] time: 0:37:10.451222\n",
      "(10, 128, 128, 3)\n",
      "0.87021583\n",
      "[Epoch 4/10] [Batch 400/1081] [D loss: 0.109533] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.778469] time: 0:37:10.842828\n",
      "(10, 128, 128, 3)\n",
      "0.9163947\n",
      "[Epoch 4/10] [Batch 401/1081] [D loss: 0.119202] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.410620] time: 0:37:11.268690\n",
      "(10, 128, 128, 3)\n",
      "0.9136943\n",
      "[Epoch 4/10] [Batch 402/1081] [D loss: 0.132431] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.724141] time: 0:37:11.676827\n",
      "(10, 128, 128, 3)\n",
      "0.9309745\n",
      "[Epoch 4/10] [Batch 403/1081] [D loss: 0.109731] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.178297] time: 0:37:12.063271\n",
      "(10, 128, 128, 3)\n",
      "0.86876774\n",
      "[Epoch 4/10] [Batch 404/1081] [D loss: 0.110119] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.126396] time: 0:37:12.499230\n",
      "(10, 128, 128, 3)\n",
      "0.87427706\n",
      "[Epoch 4/10] [Batch 405/1081] [D loss: 0.110877] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.001724] time: 0:37:12.885196\n",
      "(10, 128, 128, 3)\n",
      "0.9696917\n",
      "[Epoch 4/10] [Batch 406/1081] [D loss: 0.112152] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.064575] time: 0:37:13.277100\n",
      "(10, 128, 128, 3)\n",
      "0.8918516\n",
      "[Epoch 4/10] [Batch 407/1081] [D loss: 0.114379] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.030724] time: 0:37:13.684926\n",
      "(10, 128, 128, 3)\n",
      "0.9726434\n",
      "[Epoch 4/10] [Batch 408/1081] [D loss: 0.132625] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.646156] time: 0:37:14.077195\n",
      "(10, 128, 128, 3)\n",
      "0.9509496\n",
      "[Epoch 4/10] [Batch 409/1081] [D loss: 0.109945] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.593287] time: 0:37:14.471799\n",
      "(10, 128, 128, 3)\n",
      "0.9053176\n",
      "[Epoch 4/10] [Batch 410/1081] [D loss: 0.108328] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.388819] time: 0:37:14.895734\n",
      "(10, 128, 128, 3)\n",
      "0.93558437\n",
      "[Epoch 4/10] [Batch 411/1081] [D loss: 0.111223] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.359299] time: 0:37:15.324725\n",
      "(10, 128, 128, 3)\n",
      "0.88089305\n",
      "[Epoch 4/10] [Batch 412/1081] [D loss: 0.110314] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.975465] time: 0:37:15.730641\n",
      "(10, 128, 128, 3)\n",
      "0.9249349\n",
      "[Epoch 4/10] [Batch 413/1081] [D loss: 0.117020] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.918661] time: 0:37:16.113971\n",
      "(10, 128, 128, 3)\n",
      "0.91972023\n",
      "[Epoch 4/10] [Batch 414/1081] [D loss: 0.107476] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.387957] time: 0:37:16.514435\n",
      "(10, 128, 128, 3)\n",
      "0.9047989\n",
      "[Epoch 4/10] [Batch 415/1081] [D loss: 0.107659] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.845157] time: 0:37:16.908193\n",
      "(10, 128, 128, 3)\n",
      "0.8903741\n",
      "[Epoch 4/10] [Batch 416/1081] [D loss: 0.105466] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.312221] time: 0:37:17.301235\n",
      "(10, 128, 128, 3)\n",
      "0.9096888\n",
      "[Epoch 4/10] [Batch 417/1081] [D loss: 0.107182] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.894343] time: 0:37:17.693679\n",
      "(10, 128, 128, 3)\n",
      "0.91658646\n",
      "[Epoch 4/10] [Batch 418/1081] [D loss: 0.107283] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.643915] time: 0:37:18.114403\n",
      "(10, 128, 128, 3)\n",
      "0.8771952\n",
      "[Epoch 4/10] [Batch 419/1081] [D loss: 0.107920] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.812456] time: 0:37:18.544745\n",
      "(10, 128, 128, 3)\n",
      "0.9367371\n",
      "[Epoch 4/10] [Batch 420/1081] [D loss: 0.106133] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.905584] time: 0:37:18.938031\n",
      "(10, 128, 128, 3)\n",
      "0.9324105\n",
      "[Epoch 4/10] [Batch 421/1081] [D loss: 0.117410] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.218328] time: 0:37:19.335955\n",
      "(10, 128, 128, 3)\n",
      "0.92258614\n",
      "[Epoch 4/10] [Batch 422/1081] [D loss: 0.112380] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.496849] time: 0:37:19.713155\n",
      "(10, 128, 128, 3)\n",
      "0.88994116\n",
      "[Epoch 4/10] [Batch 423/1081] [D loss: 0.108917] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.633396] time: 0:37:20.128009\n",
      "(10, 128, 128, 3)\n",
      "0.98231524\n",
      "[Epoch 4/10] [Batch 424/1081] [D loss: 0.105492] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.863984] time: 0:37:20.556845\n",
      "(10, 128, 128, 3)\n",
      "0.8994759\n",
      "[Epoch 4/10] [Batch 425/1081] [D loss: 0.104047] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.330740] time: 0:37:21.002930\n",
      "(10, 128, 128, 3)\n",
      "0.9336641\n",
      "[Epoch 4/10] [Batch 426/1081] [D loss: 0.113160] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.694587] time: 0:37:21.400954\n",
      "(10, 128, 128, 3)\n",
      "0.9340796\n",
      "[Epoch 4/10] [Batch 427/1081] [D loss: 0.104952] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.393980] time: 0:37:21.838161\n",
      "(10, 128, 128, 3)\n",
      "0.92580765\n",
      "[Epoch 4/10] [Batch 428/1081] [D loss: 0.103303] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.763268] time: 0:37:22.267730\n",
      "(10, 128, 128, 3)\n",
      "0.9319752\n",
      "[Epoch 4/10] [Batch 429/1081] [D loss: 0.103506] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.078718] time: 0:37:22.700739\n",
      "(10, 128, 128, 3)\n",
      "0.9480278\n",
      "[Epoch 4/10] [Batch 430/1081] [D loss: 0.103640] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.998116] time: 0:37:23.090888\n",
      "(10, 128, 128, 3)\n",
      "0.87324\n",
      "[Epoch 4/10] [Batch 431/1081] [D loss: 0.105024] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.031878] time: 0:37:23.466942\n",
      "(10, 128, 128, 3)\n",
      "0.90406746\n",
      "[Epoch 4/10] [Batch 432/1081] [D loss: 0.108267] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.143812] time: 0:37:23.847825\n",
      "(10, 128, 128, 3)\n",
      "0.9078657\n",
      "[Epoch 4/10] [Batch 433/1081] [D loss: 0.104478] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.390930] time: 0:37:24.249147\n",
      "(10, 128, 128, 3)\n",
      "0.9523788\n",
      "[Epoch 4/10] [Batch 434/1081] [D loss: 0.103289] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.427173] time: 0:37:24.682412\n",
      "(10, 128, 128, 3)\n",
      "0.8649556\n",
      "[Epoch 4/10] [Batch 435/1081] [D loss: 0.102971] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.081240] time: 0:37:25.067999\n",
      "(10, 128, 128, 3)\n",
      "0.955208\n",
      "[Epoch 4/10] [Batch 436/1081] [D loss: 0.101745] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.698477] time: 0:37:25.475221\n",
      "(10, 128, 128, 3)\n",
      "0.9340709\n",
      "[Epoch 4/10] [Batch 437/1081] [D loss: 0.101098] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.230580] time: 0:37:25.886992\n",
      "(10, 128, 128, 3)\n",
      "0.8825491\n",
      "[Epoch 4/10] [Batch 438/1081] [D loss: 0.102025] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.460150] time: 0:37:26.277459\n",
      "(10, 128, 128, 3)\n",
      "0.97395736\n",
      "[Epoch 4/10] [Batch 439/1081] [D loss: 0.102005] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.795034] time: 0:37:26.681437\n",
      "(10, 128, 128, 3)\n",
      "0.9725166\n",
      "[Epoch 4/10] [Batch 440/1081] [D loss: 0.100164] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.780572] time: 0:37:27.086523\n",
      "(10, 128, 128, 3)\n",
      "0.936722\n",
      "[Epoch 4/10] [Batch 441/1081] [D loss: 0.100850] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.034454] time: 0:37:27.485289\n",
      "(10, 128, 128, 3)\n",
      "0.88767356\n",
      "[Epoch 4/10] [Batch 442/1081] [D loss: 0.104748] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.388028] time: 0:37:27.910227\n",
      "(10, 128, 128, 3)\n",
      "0.92691964\n",
      "[Epoch 4/10] [Batch 443/1081] [D loss: 0.116140] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.221261] time: 0:37:28.316569\n",
      "(10, 128, 128, 3)\n",
      "0.9711258\n",
      "[Epoch 4/10] [Batch 444/1081] [D loss: 0.101189] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.020123] time: 0:37:28.728315\n",
      "(10, 128, 128, 3)\n",
      "0.93619394\n",
      "[Epoch 4/10] [Batch 445/1081] [D loss: 0.103582] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.683951] time: 0:37:29.124660\n",
      "(10, 128, 128, 3)\n",
      "0.90697724\n",
      "[Epoch 4/10] [Batch 446/1081] [D loss: 0.102293] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.350814] time: 0:37:29.507166\n",
      "(10, 128, 128, 3)\n",
      "0.91823536\n",
      "[Epoch 4/10] [Batch 447/1081] [D loss: 0.100954] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.060444] time: 0:37:29.902996\n",
      "(10, 128, 128, 3)\n",
      "0.8858344\n",
      "[Epoch 4/10] [Batch 448/1081] [D loss: 0.242873] [D acc: 0.70 (1.00 real, 0.40 fake)] [G loss: 8.218510] time: 0:37:30.304095\n",
      "(10, 128, 128, 3)\n",
      "0.9094227\n",
      "[Epoch 4/10] [Batch 449/1081] [D loss: 0.434873] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 12.175693] time: 0:37:30.703994\n",
      "(10, 128, 128, 3)\n",
      "0.91339666\n",
      "[Epoch 4/10] [Batch 450/1081] [D loss: 0.183609] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 9.408218] time: 0:37:31.129096\n",
      "(10, 128, 128, 3)\n",
      "0.95737773\n",
      "[Epoch 4/10] [Batch 451/1081] [D loss: 0.105035] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.053578] time: 0:37:31.535712\n",
      "(10, 128, 128, 3)\n",
      "0.93026704\n",
      "[Epoch 4/10] [Batch 452/1081] [D loss: 0.106513] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.240767] time: 0:37:31.947471\n",
      "(10, 128, 128, 3)\n",
      "0.9385461\n",
      "[Epoch 4/10] [Batch 453/1081] [D loss: 0.106110] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.856233] time: 0:37:32.360206\n",
      "(10, 128, 128, 3)\n",
      "0.9016964\n",
      "[Epoch 4/10] [Batch 454/1081] [D loss: 0.106464] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.625951] time: 0:37:32.773243\n",
      "(10, 128, 128, 3)\n",
      "0.93928415\n",
      "[Epoch 4/10] [Batch 455/1081] [D loss: 0.107357] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.638897] time: 0:37:33.150713\n",
      "(10, 128, 128, 3)\n",
      "0.8983354\n",
      "[Epoch 4/10] [Batch 456/1081] [D loss: 0.104910] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.926889] time: 0:37:33.554452\n",
      "(10, 128, 128, 3)\n",
      "0.9106721\n",
      "[Epoch 4/10] [Batch 457/1081] [D loss: 0.104517] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.016031] time: 0:37:33.976869\n",
      "(10, 128, 128, 3)\n",
      "0.8912881\n",
      "[Epoch 4/10] [Batch 458/1081] [D loss: 0.102784] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.897096] time: 0:37:34.404349\n",
      "(10, 128, 128, 3)\n",
      "0.9071021\n",
      "[Epoch 4/10] [Batch 459/1081] [D loss: 0.102718] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.062536] time: 0:37:34.825240\n",
      "(10, 128, 128, 3)\n",
      "0.90864545\n",
      "[Epoch 4/10] [Batch 460/1081] [D loss: 0.108895] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.437955] time: 0:37:35.253178\n",
      "(10, 128, 128, 3)\n",
      "0.88542485\n",
      "[Epoch 4/10] [Batch 461/1081] [D loss: 0.121711] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.690407] time: 0:37:35.691119\n",
      "(10, 128, 128, 3)\n",
      "0.89237565\n",
      "[Epoch 4/10] [Batch 462/1081] [D loss: 0.116072] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.700693] time: 0:37:36.087880\n",
      "(10, 128, 128, 3)\n",
      "0.91408235\n",
      "[Epoch 4/10] [Batch 463/1081] [D loss: 0.104136] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.081306] time: 0:37:36.512637\n",
      "(10, 128, 128, 3)\n",
      "0.9501962\n",
      "[Epoch 4/10] [Batch 464/1081] [D loss: 0.102408] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.241626] time: 0:37:36.889983\n",
      "(10, 128, 128, 3)\n",
      "0.9022253\n",
      "[Epoch 4/10] [Batch 465/1081] [D loss: 0.101588] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.147747] time: 0:37:37.293422\n",
      "(10, 128, 128, 3)\n",
      "0.9209339\n",
      "[Epoch 4/10] [Batch 466/1081] [D loss: 0.102688] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.293317] time: 0:37:37.723125\n",
      "(10, 128, 128, 3)\n",
      "0.98140746\n",
      "[Epoch 4/10] [Batch 467/1081] [D loss: 0.100294] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.871622] time: 0:37:38.133688\n",
      "(10, 128, 128, 3)\n",
      "0.9458845\n",
      "[Epoch 4/10] [Batch 468/1081] [D loss: 0.100778] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.513755] time: 0:37:38.540799\n",
      "(10, 128, 128, 3)\n",
      "0.8949177\n",
      "[Epoch 4/10] [Batch 469/1081] [D loss: 0.100399] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.411394] time: 0:37:38.967919\n",
      "(10, 128, 128, 3)\n",
      "0.9155157\n",
      "[Epoch 4/10] [Batch 470/1081] [D loss: 0.099926] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.677239] time: 0:37:39.404532\n",
      "(10, 128, 128, 3)\n",
      "0.9143045\n",
      "[Epoch 4/10] [Batch 471/1081] [D loss: 0.101940] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.934123] time: 0:37:39.797290\n",
      "(10, 128, 128, 3)\n",
      "0.9431348\n",
      "[Epoch 4/10] [Batch 472/1081] [D loss: 0.100990] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.843694] time: 0:37:40.180962\n",
      "(10, 128, 128, 3)\n",
      "0.9039867\n",
      "[Epoch 4/10] [Batch 473/1081] [D loss: 0.100749] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.758644] time: 0:37:40.564578\n",
      "(10, 128, 128, 3)\n",
      "0.90829676\n",
      "[Epoch 4/10] [Batch 474/1081] [D loss: 0.102204] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.134788] time: 0:37:40.979542\n",
      "(10, 128, 128, 3)\n",
      "0.89418817\n",
      "[Epoch 4/10] [Batch 475/1081] [D loss: 0.099628] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.880924] time: 0:37:41.353893\n",
      "(10, 128, 128, 3)\n",
      "0.936776\n",
      "[Epoch 4/10] [Batch 476/1081] [D loss: 0.099032] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.142455] time: 0:37:41.750473\n",
      "(10, 128, 128, 3)\n",
      "0.90462303\n",
      "[Epoch 4/10] [Batch 477/1081] [D loss: 0.099259] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.562469] time: 0:37:42.168691\n",
      "(10, 128, 128, 3)\n",
      "0.871788\n",
      "[Epoch 4/10] [Batch 478/1081] [D loss: 0.102079] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.449037] time: 0:37:42.580148\n",
      "(10, 128, 128, 3)\n",
      "0.8916351\n",
      "[Epoch 4/10] [Batch 479/1081] [D loss: 0.101856] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.939309] time: 0:37:42.962861\n",
      "(10, 128, 128, 3)\n",
      "0.9374636\n",
      "[Epoch 4/10] [Batch 480/1081] [D loss: 0.098521] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.255771] time: 0:37:43.361155\n",
      "(10, 128, 128, 3)\n",
      "0.9088159\n",
      "[Epoch 4/10] [Batch 481/1081] [D loss: 0.103420] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.199003] time: 0:37:43.759989\n",
      "(10, 128, 128, 3)\n",
      "0.907471\n",
      "[Epoch 4/10] [Batch 482/1081] [D loss: 0.106586] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.050824] time: 0:37:44.152282\n",
      "(10, 128, 128, 3)\n",
      "0.9541188\n",
      "[Epoch 4/10] [Batch 483/1081] [D loss: 0.099034] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.559319] time: 0:37:44.563782\n",
      "(10, 128, 128, 3)\n",
      "0.9035492\n",
      "[Epoch 4/10] [Batch 484/1081] [D loss: 0.103994] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.027722] time: 0:37:44.979358\n",
      "(10, 128, 128, 3)\n",
      "0.91217136\n",
      "[Epoch 4/10] [Batch 485/1081] [D loss: 0.105248] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.534783] time: 0:37:45.414886\n",
      "(10, 128, 128, 3)\n",
      "0.9122283\n",
      "[Epoch 4/10] [Batch 486/1081] [D loss: 0.100335] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.397840] time: 0:37:45.825676\n",
      "(10, 128, 128, 3)\n",
      "0.89688057\n",
      "[Epoch 4/10] [Batch 487/1081] [D loss: 0.098385] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.378359] time: 0:37:46.258156\n",
      "(10, 128, 128, 3)\n",
      "0.8999966\n",
      "[Epoch 4/10] [Batch 488/1081] [D loss: 0.099412] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.497916] time: 0:37:46.678965\n",
      "(10, 128, 128, 3)\n",
      "0.9102729\n",
      "[Epoch 4/10] [Batch 489/1081] [D loss: 0.097125] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.003235] time: 0:37:47.062345\n",
      "(10, 128, 128, 3)\n",
      "0.9131585\n",
      "[Epoch 4/10] [Batch 490/1081] [D loss: 0.097634] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.282397] time: 0:37:47.461814\n",
      "(10, 128, 128, 3)\n",
      "0.93941927\n",
      "[Epoch 4/10] [Batch 491/1081] [D loss: 0.096886] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.774913] time: 0:37:47.863064\n",
      "(10, 128, 128, 3)\n",
      "0.924781\n",
      "[Epoch 4/10] [Batch 492/1081] [D loss: 0.096885] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.982625] time: 0:37:48.303273\n",
      "(10, 128, 128, 3)\n",
      "0.8838644\n",
      "[Epoch 4/10] [Batch 493/1081] [D loss: 0.096763] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.098901] time: 0:37:48.704812\n",
      "(10, 128, 128, 3)\n",
      "0.9109835\n",
      "[Epoch 4/10] [Batch 494/1081] [D loss: 0.096678] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.132478] time: 0:37:49.106467\n",
      "(10, 128, 128, 3)\n",
      "0.90583974\n",
      "[Epoch 4/10] [Batch 495/1081] [D loss: 0.096516] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.321520] time: 0:37:49.511684\n",
      "(10, 128, 128, 3)\n",
      "0.8459962\n",
      "[Epoch 4/10] [Batch 496/1081] [D loss: 0.097423] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.359973] time: 0:37:49.918883\n",
      "(10, 128, 128, 3)\n",
      "0.89543754\n",
      "[Epoch 4/10] [Batch 497/1081] [D loss: 0.096375] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.275361] time: 0:37:50.321160\n",
      "(10, 128, 128, 3)\n",
      "0.8692913\n",
      "[Epoch 4/10] [Batch 498/1081] [D loss: 0.095607] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.085546] time: 0:37:50.743585\n",
      "(10, 128, 128, 3)\n",
      "0.8767807\n",
      "[Epoch 4/10] [Batch 499/1081] [D loss: 0.095511] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.182018] time: 0:37:51.161635\n",
      "(10, 128, 128, 3)\n",
      "0.8079123\n",
      "[Epoch 4/10] [Batch 500/1081] [D loss: 0.130311] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.261873] time: 0:37:51.579001\n",
      "(10, 128, 128, 3)\n",
      "0.9383132\n",
      "[Epoch 4/10] [Batch 501/1081] [D loss: 0.096016] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.103745] time: 0:37:51.981569\n",
      "(10, 128, 128, 3)\n",
      "0.8696401\n",
      "[Epoch 4/10] [Batch 502/1081] [D loss: 0.098132] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.436098] time: 0:37:52.376044\n",
      "(10, 128, 128, 3)\n",
      "0.9346576\n",
      "[Epoch 4/10] [Batch 503/1081] [D loss: 0.097810] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.267230] time: 0:37:52.796319\n",
      "(10, 128, 128, 3)\n",
      "0.9572103\n",
      "[Epoch 4/10] [Batch 504/1081] [D loss: 0.098520] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.305683] time: 0:37:53.214799\n",
      "(10, 128, 128, 3)\n",
      "0.8784192\n",
      "[Epoch 4/10] [Batch 505/1081] [D loss: 0.096964] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.931910] time: 0:37:53.630779\n",
      "(10, 128, 128, 3)\n",
      "0.940572\n",
      "[Epoch 4/10] [Batch 506/1081] [D loss: 0.096144] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.078891] time: 0:37:54.037411\n",
      "(10, 128, 128, 3)\n",
      "0.94020516\n",
      "[Epoch 4/10] [Batch 507/1081] [D loss: 0.094548] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.405438] time: 0:37:54.439772\n",
      "(10, 128, 128, 3)\n",
      "0.89394134\n",
      "[Epoch 4/10] [Batch 508/1081] [D loss: 0.094608] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.255301] time: 0:37:54.828683\n",
      "(10, 128, 128, 3)\n",
      "0.896395\n",
      "[Epoch 4/10] [Batch 509/1081] [D loss: 0.094625] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.939155] time: 0:37:55.254777\n",
      "(10, 128, 128, 3)\n",
      "0.92661005\n",
      "[Epoch 4/10] [Batch 510/1081] [D loss: 0.095192] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.629555] time: 0:37:55.650638\n",
      "(10, 128, 128, 3)\n",
      "0.9294881\n",
      "[Epoch 4/10] [Batch 511/1081] [D loss: 0.094310] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.249917] time: 0:37:56.071988\n",
      "(10, 128, 128, 3)\n",
      "0.9338606\n",
      "[Epoch 4/10] [Batch 512/1081] [D loss: 0.093966] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.800368] time: 0:37:56.500976\n",
      "(10, 128, 128, 3)\n",
      "0.91462165\n",
      "[Epoch 4/10] [Batch 513/1081] [D loss: 0.094315] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.951227] time: 0:37:56.889337\n",
      "(10, 128, 128, 3)\n",
      "0.93758243\n",
      "[Epoch 4/10] [Batch 514/1081] [D loss: 0.093620] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.616833] time: 0:37:57.318414\n",
      "(10, 128, 128, 3)\n",
      "0.93670493\n",
      "[Epoch 4/10] [Batch 515/1081] [D loss: 0.095563] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.412688] time: 0:37:57.724142\n",
      "(10, 128, 128, 3)\n",
      "0.94197375\n",
      "[Epoch 4/10] [Batch 516/1081] [D loss: 0.093408] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.234200] time: 0:37:58.152424\n",
      "(10, 128, 128, 3)\n",
      "0.9057317\n",
      "[Epoch 4/10] [Batch 517/1081] [D loss: 0.093351] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.927845] time: 0:37:58.565672\n",
      "(10, 128, 128, 3)\n",
      "0.89606625\n",
      "[Epoch 4/10] [Batch 518/1081] [D loss: 0.093400] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.776909] time: 0:37:59.004967\n",
      "(10, 128, 128, 3)\n",
      "0.93235236\n",
      "[Epoch 4/10] [Batch 519/1081] [D loss: 0.093567] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.098097] time: 0:37:59.444581\n",
      "(10, 128, 128, 3)\n",
      "0.87687844\n",
      "[Epoch 4/10] [Batch 520/1081] [D loss: 0.113157] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.364156] time: 0:37:59.846618\n",
      "(10, 128, 128, 3)\n",
      "0.9411056\n",
      "[Epoch 4/10] [Batch 521/1081] [D loss: 0.093793] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.821356] time: 0:38:00.230502\n",
      "(10, 128, 128, 3)\n",
      "0.8716641\n",
      "[Epoch 4/10] [Batch 522/1081] [D loss: 0.095009] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.816581] time: 0:38:00.642952\n",
      "(10, 128, 128, 3)\n",
      "0.8734405\n",
      "[Epoch 4/10] [Batch 523/1081] [D loss: 0.096057] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.138578] time: 0:38:01.034540\n",
      "(10, 128, 128, 3)\n",
      "0.89784384\n",
      "[Epoch 4/10] [Batch 524/1081] [D loss: 0.093199] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.202588] time: 0:38:01.463071\n",
      "(10, 128, 128, 3)\n",
      "0.9113102\n",
      "[Epoch 4/10] [Batch 525/1081] [D loss: 0.093001] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.872134] time: 0:38:01.875021\n",
      "(10, 128, 128, 3)\n",
      "0.9474616\n",
      "[Epoch 4/10] [Batch 526/1081] [D loss: 0.092514] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.365410] time: 0:38:02.315360\n",
      "(10, 128, 128, 3)\n",
      "0.9060194\n",
      "[Epoch 4/10] [Batch 527/1081] [D loss: 0.093725] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.250342] time: 0:38:02.716822\n",
      "(10, 128, 128, 3)\n",
      "0.9373725\n",
      "[Epoch 4/10] [Batch 528/1081] [D loss: 0.093333] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.583689] time: 0:38:03.137040\n",
      "(10, 128, 128, 3)\n",
      "0.93956155\n",
      "[Epoch 4/10] [Batch 529/1081] [D loss: 0.099502] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.618929] time: 0:38:03.543508\n",
      "(10, 128, 128, 3)\n",
      "0.865937\n",
      "[Epoch 4/10] [Batch 530/1081] [D loss: 0.093069] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.853403] time: 0:38:03.963716\n",
      "(10, 128, 128, 3)\n",
      "0.9278946\n",
      "[Epoch 4/10] [Batch 531/1081] [D loss: 0.092642] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.332591] time: 0:38:04.394708\n",
      "(10, 128, 128, 3)\n",
      "0.8501298\n",
      "[Epoch 4/10] [Batch 532/1081] [D loss: 0.092034] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.036512] time: 0:38:04.814490\n",
      "(10, 128, 128, 3)\n",
      "0.9087415\n",
      "[Epoch 4/10] [Batch 533/1081] [D loss: 0.091992] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.947248] time: 0:38:05.196855\n",
      "(10, 128, 128, 3)\n",
      "0.89458674\n",
      "[Epoch 4/10] [Batch 534/1081] [D loss: 0.091602] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.418787] time: 0:38:05.581587\n",
      "(10, 128, 128, 3)\n",
      "0.9262646\n",
      "[Epoch 4/10] [Batch 535/1081] [D loss: 0.091636] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.878409] time: 0:38:06.001197\n",
      "(10, 128, 128, 3)\n",
      "0.87325287\n",
      "[Epoch 4/10] [Batch 536/1081] [D loss: 0.091843] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.095695] time: 0:38:06.404483\n",
      "(10, 128, 128, 3)\n",
      "0.91012925\n",
      "[Epoch 4/10] [Batch 537/1081] [D loss: 0.091417] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.625531] time: 0:38:06.850358\n",
      "(10, 128, 128, 3)\n",
      "0.88641524\n",
      "[Epoch 4/10] [Batch 538/1081] [D loss: 0.093574] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.624681] time: 0:38:07.270779\n",
      "(10, 128, 128, 3)\n",
      "0.93372875\n",
      "[Epoch 4/10] [Batch 539/1081] [D loss: 0.091816] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.748677] time: 0:38:07.697952\n",
      "(10, 128, 128, 3)\n",
      "0.91780686\n",
      "[Epoch 4/10] [Batch 540/1081] [D loss: 0.090988] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.445594] time: 0:38:08.101389\n",
      "(10, 128, 128, 3)\n",
      "0.88604474\n",
      "[Epoch 4/10] [Batch 541/1081] [D loss: 0.090874] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.730411] time: 0:38:08.513955\n",
      "(10, 128, 128, 3)\n",
      "0.9677231\n",
      "[Epoch 4/10] [Batch 542/1081] [D loss: 0.090661] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.609107] time: 0:38:08.916037\n",
      "(10, 128, 128, 3)\n",
      "0.875885\n",
      "[Epoch 4/10] [Batch 543/1081] [D loss: 0.093989] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.675842] time: 0:38:09.329983\n",
      "(10, 128, 128, 3)\n",
      "0.90809226\n",
      "[Epoch 4/10] [Batch 544/1081] [D loss: 0.091767] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.533238] time: 0:38:09.758390\n",
      "(10, 128, 128, 3)\n",
      "0.96212035\n",
      "[Epoch 4/10] [Batch 545/1081] [D loss: 0.091334] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.093565] time: 0:38:10.151720\n",
      "(10, 128, 128, 3)\n",
      "0.9809106\n",
      "[Epoch 4/10] [Batch 546/1081] [D loss: 0.092604] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.962945] time: 0:38:10.563432\n",
      "(10, 128, 128, 3)\n",
      "0.87996405\n",
      "[Epoch 4/10] [Batch 547/1081] [D loss: 0.090404] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.984641] time: 0:38:10.980094\n",
      "(10, 128, 128, 3)\n",
      "0.9072271\n",
      "[Epoch 4/10] [Batch 548/1081] [D loss: 0.090534] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.303661] time: 0:38:11.373576\n",
      "(10, 128, 128, 3)\n",
      "0.9271217\n",
      "[Epoch 4/10] [Batch 549/1081] [D loss: 0.089774] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.121795] time: 0:38:11.794716\n",
      "(10, 128, 128, 3)\n",
      "0.9243577\n",
      "[Epoch 4/10] [Batch 550/1081] [D loss: 0.090246] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.701435] time: 0:38:12.190164\n",
      "(10, 128, 128, 3)\n",
      "0.9237458\n",
      "[Epoch 4/10] [Batch 551/1081] [D loss: 0.090023] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.013281] time: 0:38:12.649855\n",
      "(10, 128, 128, 3)\n",
      "0.8989522\n",
      "[Epoch 4/10] [Batch 552/1081] [D loss: 0.090081] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.822023] time: 0:38:13.053250\n",
      "(10, 128, 128, 3)\n",
      "0.9521747\n",
      "[Epoch 4/10] [Batch 553/1081] [D loss: 0.089581] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.804233] time: 0:38:13.464316\n",
      "(10, 128, 128, 3)\n",
      "0.88744396\n",
      "[Epoch 4/10] [Batch 554/1081] [D loss: 0.089253] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.629261] time: 0:38:13.884402\n",
      "(10, 128, 128, 3)\n",
      "0.9022358\n",
      "[Epoch 4/10] [Batch 555/1081] [D loss: 0.106708] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.248515] time: 0:38:14.304343\n",
      "(10, 128, 128, 3)\n",
      "0.8389357\n",
      "[Epoch 4/10] [Batch 556/1081] [D loss: 0.119351] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.689162] time: 0:38:14.699427\n",
      "(10, 128, 128, 3)\n",
      "0.9044728\n",
      "[Epoch 4/10] [Batch 557/1081] [D loss: 0.099568] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.917160] time: 0:38:15.097987\n",
      "(10, 128, 128, 3)\n",
      "0.89158136\n",
      "[Epoch 4/10] [Batch 558/1081] [D loss: 0.234916] [D acc: 0.75 (1.00 real, 0.50 fake)] [G loss: 13.016251] time: 0:38:15.492183\n",
      "(10, 128, 128, 3)\n",
      "0.84397155\n",
      "[Epoch 4/10] [Batch 559/1081] [D loss: 0.096272] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 17.588081] time: 0:38:15.896961\n",
      "(10, 128, 128, 3)\n",
      "0.9450853\n",
      "[Epoch 4/10] [Batch 560/1081] [D loss: 0.106775] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.369776] time: 0:38:16.342177\n",
      "(10, 128, 128, 3)\n",
      "0.90749407\n",
      "[Epoch 4/10] [Batch 561/1081] [D loss: 0.127449] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.196087] time: 0:38:16.751269\n",
      "(10, 128, 128, 3)\n",
      "0.8914464\n",
      "[Epoch 4/10] [Batch 562/1081] [D loss: 0.100493] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.422211] time: 0:38:17.128750\n",
      "(10, 128, 128, 3)\n",
      "0.9215037\n",
      "[Epoch 4/10] [Batch 563/1081] [D loss: 0.104878] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.252378] time: 0:38:17.535899\n",
      "(10, 128, 128, 3)\n",
      "0.87665194\n",
      "[Epoch 4/10] [Batch 564/1081] [D loss: 0.106650] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.570252] time: 0:38:17.942223\n",
      "(10, 128, 128, 3)\n",
      "0.89522606\n",
      "[Epoch 4/10] [Batch 565/1081] [D loss: 0.164612] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.421676] time: 0:38:18.349253\n",
      "(10, 128, 128, 3)\n",
      "0.8819113\n",
      "[Epoch 4/10] [Batch 566/1081] [D loss: 0.102950] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.048010] time: 0:38:18.758970\n",
      "(10, 128, 128, 3)\n",
      "0.90893966\n",
      "[Epoch 4/10] [Batch 567/1081] [D loss: 0.101563] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.909902] time: 0:38:19.165034\n",
      "(10, 128, 128, 3)\n",
      "0.8769062\n",
      "[Epoch 4/10] [Batch 568/1081] [D loss: 0.102978] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.682285] time: 0:38:19.561644\n",
      "(10, 128, 128, 3)\n",
      "0.8988387\n",
      "[Epoch 4/10] [Batch 569/1081] [D loss: 0.099930] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.834833] time: 0:38:19.961349\n",
      "(10, 128, 128, 3)\n",
      "0.9215402\n",
      "[Epoch 4/10] [Batch 570/1081] [D loss: 0.099032] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.340446] time: 0:38:20.372335\n",
      "(10, 128, 128, 3)\n",
      "0.9218952\n",
      "[Epoch 4/10] [Batch 571/1081] [D loss: 0.099483] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.922484] time: 0:38:20.784614\n",
      "(10, 128, 128, 3)\n",
      "0.8923946\n",
      "[Epoch 4/10] [Batch 572/1081] [D loss: 0.153541] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.103277] time: 0:38:21.198885\n",
      "(10, 128, 128, 3)\n",
      "0.9140504\n",
      "[Epoch 4/10] [Batch 573/1081] [D loss: 0.112316] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.047238] time: 0:38:21.610878\n",
      "(10, 128, 128, 3)\n",
      "0.9340234\n",
      "[Epoch 4/10] [Batch 574/1081] [D loss: 0.104072] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.918034] time: 0:38:22.014182\n",
      "(10, 128, 128, 3)\n",
      "0.91808397\n",
      "[Epoch 4/10] [Batch 575/1081] [D loss: 0.098230] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.825762] time: 0:38:22.410599\n",
      "(10, 128, 128, 3)\n",
      "0.93895406\n",
      "[Epoch 4/10] [Batch 576/1081] [D loss: 0.099078] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.746454] time: 0:38:22.812355\n",
      "(10, 128, 128, 3)\n",
      "0.91358733\n",
      "[Epoch 4/10] [Batch 577/1081] [D loss: 0.098143] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.585967] time: 0:38:23.227367\n",
      "(10, 128, 128, 3)\n",
      "0.94760674\n",
      "[Epoch 4/10] [Batch 578/1081] [D loss: 0.098541] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.827192] time: 0:38:23.645966\n",
      "(10, 128, 128, 3)\n",
      "0.9011758\n",
      "[Epoch 4/10] [Batch 579/1081] [D loss: 0.098681] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.329597] time: 0:38:24.069463\n",
      "(10, 128, 128, 3)\n",
      "0.9333822\n",
      "[Epoch 4/10] [Batch 580/1081] [D loss: 0.097969] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.948918] time: 0:38:24.500776\n",
      "(10, 128, 128, 3)\n",
      "0.83444613\n",
      "[Epoch 4/10] [Batch 581/1081] [D loss: 0.097717] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.325161] time: 0:38:24.910919\n",
      "(10, 128, 128, 3)\n",
      "0.94639397\n",
      "[Epoch 4/10] [Batch 582/1081] [D loss: 0.097435] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.076277] time: 0:38:25.323532\n",
      "(10, 128, 128, 3)\n",
      "0.9371479\n",
      "[Epoch 4/10] [Batch 583/1081] [D loss: 0.097050] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.580672] time: 0:38:25.768560\n",
      "(10, 128, 128, 3)\n",
      "0.9383245\n",
      "[Epoch 4/10] [Batch 584/1081] [D loss: 0.098415] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.722986] time: 0:38:26.209714\n",
      "(10, 128, 128, 3)\n",
      "0.9342937\n",
      "[Epoch 4/10] [Batch 585/1081] [D loss: 0.097360] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.671828] time: 0:38:26.600816\n",
      "(10, 128, 128, 3)\n",
      "0.9460593\n",
      "[Epoch 4/10] [Batch 586/1081] [D loss: 0.096961] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.443806] time: 0:38:26.996774\n",
      "(10, 128, 128, 3)\n",
      "0.9399012\n",
      "[Epoch 4/10] [Batch 587/1081] [D loss: 0.097042] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.356449] time: 0:38:27.386492\n",
      "(10, 128, 128, 3)\n",
      "0.93208694\n",
      "[Epoch 4/10] [Batch 588/1081] [D loss: 0.099312] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.946839] time: 0:38:27.786638\n",
      "(10, 128, 128, 3)\n",
      "0.9700136\n",
      "[Epoch 4/10] [Batch 589/1081] [D loss: 0.097693] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.671021] time: 0:38:28.201240\n",
      "(10, 128, 128, 3)\n",
      "0.91073465\n",
      "[Epoch 4/10] [Batch 590/1081] [D loss: 0.583930] [D acc: 0.45 (0.90 real, 0.00 fake)] [G loss: 7.187022] time: 0:38:28.617063\n",
      "(10, 128, 128, 3)\n",
      "0.9071316\n",
      "[Epoch 4/10] [Batch 591/1081] [D loss: 0.344970] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 9.606244] time: 0:38:29.008467\n",
      "(10, 128, 128, 3)\n",
      "0.96892685\n",
      "[Epoch 4/10] [Batch 592/1081] [D loss: 0.256186] [D acc: 0.90 (0.90 real, 0.90 fake)] [G loss: 8.583364] time: 0:38:29.447854\n",
      "(10, 128, 128, 3)\n",
      "0.9719429\n",
      "[Epoch 4/10] [Batch 593/1081] [D loss: 0.474698] [D acc: 0.35 (0.00 real, 0.70 fake)] [G loss: 8.267745] time: 0:38:29.857068\n",
      "(10, 128, 128, 3)\n",
      "0.9049959\n",
      "[Epoch 4/10] [Batch 594/1081] [D loss: 0.159515] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 8.138597] time: 0:38:30.260860\n",
      "(10, 128, 128, 3)\n",
      "0.91641694\n",
      "[Epoch 4/10] [Batch 595/1081] [D loss: 0.144921] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.204084] time: 0:38:30.669884\n",
      "(10, 128, 128, 3)\n",
      "0.9036336\n",
      "[Epoch 4/10] [Batch 596/1081] [D loss: 0.646657] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 7.371387] time: 0:38:31.087665\n",
      "(10, 128, 128, 3)\n",
      "0.967261\n",
      "[Epoch 4/10] [Batch 597/1081] [D loss: 0.140482] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.132284] time: 0:38:31.488393\n",
      "(10, 128, 128, 3)\n",
      "0.8838126\n",
      "[Epoch 4/10] [Batch 598/1081] [D loss: 0.126088] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.905852] time: 0:38:31.942108\n",
      "(10, 128, 128, 3)\n",
      "0.8572294\n",
      "[Epoch 4/10] [Batch 599/1081] [D loss: 0.117746] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.254501] time: 0:38:32.376790\n",
      "(10, 128, 128, 3)\n",
      "0.92464715\n",
      "[Epoch 4/10] [Batch 600/1081] [D loss: 0.129859] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 8.535922] time: 0:38:32.787702\n",
      "(10, 128, 128, 3)\n",
      "0.87980884\n",
      "[Epoch 4/10] [Batch 601/1081] [D loss: 0.131442] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.594820] time: 0:38:33.184509\n",
      "(10, 128, 128, 3)\n",
      "0.8712873\n",
      "[Epoch 4/10] [Batch 602/1081] [D loss: 0.109129] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.679550] time: 0:38:33.596810\n",
      "(10, 128, 128, 3)\n",
      "0.91025114\n",
      "[Epoch 4/10] [Batch 603/1081] [D loss: 0.106810] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.780540] time: 0:38:34.013104\n",
      "(10, 128, 128, 3)\n",
      "0.91507167\n",
      "[Epoch 4/10] [Batch 604/1081] [D loss: 0.111055] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.398936] time: 0:38:34.429744\n",
      "(10, 128, 128, 3)\n",
      "0.8379116\n",
      "[Epoch 4/10] [Batch 605/1081] [D loss: 0.110019] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.251896] time: 0:38:34.841591\n",
      "(10, 128, 128, 3)\n",
      "0.91967124\n",
      "[Epoch 4/10] [Batch 606/1081] [D loss: 0.105786] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.339102] time: 0:38:35.240832\n",
      "(10, 128, 128, 3)\n",
      "0.8975243\n",
      "[Epoch 4/10] [Batch 607/1081] [D loss: 0.110324] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.167463] time: 0:38:35.657023\n",
      "(10, 128, 128, 3)\n",
      "0.83724636\n",
      "[Epoch 4/10] [Batch 608/1081] [D loss: 0.107894] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.184631] time: 0:38:36.054996\n",
      "(10, 128, 128, 3)\n",
      "0.93829757\n",
      "[Epoch 4/10] [Batch 609/1081] [D loss: 0.106117] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.963454] time: 0:38:36.460728\n",
      "(10, 128, 128, 3)\n",
      "0.89036626\n",
      "[Epoch 4/10] [Batch 610/1081] [D loss: 0.104306] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.763810] time: 0:38:36.886878\n",
      "(10, 128, 128, 3)\n",
      "0.8916586\n",
      "[Epoch 4/10] [Batch 611/1081] [D loss: 0.106676] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.272963] time: 0:38:37.310488\n",
      "(10, 128, 128, 3)\n",
      "0.9176\n",
      "[Epoch 4/10] [Batch 612/1081] [D loss: 0.108054] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.256081] time: 0:38:37.707896\n",
      "(10, 128, 128, 3)\n",
      "0.9339669\n",
      "[Epoch 4/10] [Batch 613/1081] [D loss: 0.105624] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.498600] time: 0:38:38.144621\n",
      "(10, 128, 128, 3)\n",
      "0.94608027\n",
      "[Epoch 4/10] [Batch 614/1081] [D loss: 0.104990] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.537184] time: 0:38:38.523449\n",
      "(10, 128, 128, 3)\n",
      "0.9449501\n",
      "[Epoch 4/10] [Batch 615/1081] [D loss: 0.104165] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.291797] time: 0:38:38.954028\n",
      "(10, 128, 128, 3)\n",
      "0.9116607\n",
      "[Epoch 4/10] [Batch 616/1081] [D loss: 0.105649] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.708989] time: 0:38:39.368415\n",
      "(10, 128, 128, 3)\n",
      "0.9449304\n",
      "[Epoch 4/10] [Batch 617/1081] [D loss: 0.104303] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.943221] time: 0:38:39.804060\n",
      "(10, 128, 128, 3)\n",
      "0.9331348\n",
      "[Epoch 4/10] [Batch 618/1081] [D loss: 0.104623] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.623425] time: 0:38:40.204513\n",
      "(10, 128, 128, 3)\n",
      "0.88002807\n",
      "[Epoch 4/10] [Batch 619/1081] [D loss: 0.102668] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.107508] time: 0:38:40.605346\n",
      "(10, 128, 128, 3)\n",
      "0.8812906\n",
      "[Epoch 4/10] [Batch 620/1081] [D loss: 0.103498] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.230690] time: 0:38:41.027783\n",
      "(10, 128, 128, 3)\n",
      "0.9301757\n",
      "[Epoch 4/10] [Batch 621/1081] [D loss: 0.102512] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.705565] time: 0:38:41.441712\n",
      "(10, 128, 128, 3)\n",
      "0.9271209\n",
      "[Epoch 4/10] [Batch 622/1081] [D loss: 0.102688] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.132126] time: 0:38:41.829346\n",
      "(10, 128, 128, 3)\n",
      "0.9253306\n",
      "[Epoch 4/10] [Batch 623/1081] [D loss: 0.102495] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.085677] time: 0:38:42.241102\n",
      "(10, 128, 128, 3)\n",
      "0.9263756\n",
      "[Epoch 4/10] [Batch 624/1081] [D loss: 0.103579] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.112281] time: 0:38:42.660815\n",
      "(10, 128, 128, 3)\n",
      "0.9109752\n",
      "[Epoch 4/10] [Batch 625/1081] [D loss: 0.101344] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.156219] time: 0:38:43.045727\n",
      "(10, 128, 128, 3)\n",
      "0.9143753\n",
      "[Epoch 4/10] [Batch 626/1081] [D loss: 0.102785] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.171943] time: 0:38:43.445948\n",
      "(10, 128, 128, 3)\n",
      "0.91212803\n",
      "[Epoch 4/10] [Batch 627/1081] [D loss: 0.102463] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.556609] time: 0:38:43.838161\n",
      "(10, 128, 128, 3)\n",
      "0.8988207\n",
      "[Epoch 4/10] [Batch 628/1081] [D loss: 0.100912] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.946313] time: 0:38:44.221346\n",
      "(10, 128, 128, 3)\n",
      "0.93115133\n",
      "[Epoch 4/10] [Batch 629/1081] [D loss: 0.101838] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.315928] time: 0:38:44.622330\n",
      "(10, 128, 128, 3)\n",
      "0.9530521\n",
      "[Epoch 4/10] [Batch 630/1081] [D loss: 0.106747] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.665356] time: 0:38:45.009389\n",
      "(10, 128, 128, 3)\n",
      "0.9541879\n",
      "[Epoch 4/10] [Batch 631/1081] [D loss: 0.102185] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.742764] time: 0:38:45.409520\n",
      "(10, 128, 128, 3)\n",
      "0.877084\n",
      "[Epoch 4/10] [Batch 632/1081] [D loss: 0.101173] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.218848] time: 0:38:45.811176\n",
      "(10, 128, 128, 3)\n",
      "0.9219262\n",
      "[Epoch 4/10] [Batch 633/1081] [D loss: 0.101102] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.599118] time: 0:38:46.210515\n",
      "(10, 128, 128, 3)\n",
      "0.9050854\n",
      "[Epoch 4/10] [Batch 634/1081] [D loss: 0.100492] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.035152] time: 0:38:46.613677\n",
      "(10, 128, 128, 3)\n",
      "0.8832269\n",
      "[Epoch 4/10] [Batch 635/1081] [D loss: 0.101331] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.182169] time: 0:38:47.031031\n",
      "(10, 128, 128, 3)\n",
      "0.935848\n",
      "[Epoch 4/10] [Batch 636/1081] [D loss: 0.100855] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.741362] time: 0:38:47.464312\n",
      "(10, 128, 128, 3)\n",
      "0.887057\n",
      "[Epoch 4/10] [Batch 637/1081] [D loss: 0.102518] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.223209] time: 0:38:47.876327\n",
      "(10, 128, 128, 3)\n",
      "0.9190326\n",
      "[Epoch 4/10] [Batch 638/1081] [D loss: 0.102375] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.130598] time: 0:38:48.265090\n",
      "(10, 128, 128, 3)\n",
      "0.93678397\n",
      "[Epoch 4/10] [Batch 639/1081] [D loss: 0.101868] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.842658] time: 0:38:48.701495\n",
      "(10, 128, 128, 3)\n",
      "0.9443882\n",
      "[Epoch 4/10] [Batch 640/1081] [D loss: 0.099732] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.680082] time: 0:38:49.097151\n",
      "(10, 128, 128, 3)\n",
      "0.8842843\n",
      "[Epoch 4/10] [Batch 641/1081] [D loss: 0.100075] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.018744] time: 0:38:49.501946\n",
      "(10, 128, 128, 3)\n",
      "0.9540398\n",
      "[Epoch 4/10] [Batch 642/1081] [D loss: 0.099233] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.945334] time: 0:38:49.893886\n",
      "(10, 128, 128, 3)\n",
      "0.9057943\n",
      "[Epoch 4/10] [Batch 643/1081] [D loss: 0.100123] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.238214] time: 0:38:50.328929\n",
      "(10, 128, 128, 3)\n",
      "0.91434985\n",
      "[Epoch 4/10] [Batch 644/1081] [D loss: 0.099099] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.385845] time: 0:38:50.731473\n",
      "(10, 128, 128, 3)\n",
      "0.8947365\n",
      "[Epoch 4/10] [Batch 645/1081] [D loss: 0.098412] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.166001] time: 0:38:51.169154\n",
      "(10, 128, 128, 3)\n",
      "0.8760538\n",
      "[Epoch 4/10] [Batch 646/1081] [D loss: 0.098127] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.005725] time: 0:38:51.551314\n",
      "(10, 128, 128, 3)\n",
      "0.9373161\n",
      "[Epoch 4/10] [Batch 647/1081] [D loss: 0.101566] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.850668] time: 0:38:51.969442\n",
      "(10, 128, 128, 3)\n",
      "0.91535395\n",
      "[Epoch 4/10] [Batch 648/1081] [D loss: 0.101123] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.200297] time: 0:38:52.395426\n",
      "(10, 128, 128, 3)\n",
      "0.9039729\n",
      "[Epoch 4/10] [Batch 649/1081] [D loss: 0.097784] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.489198] time: 0:38:52.820475\n",
      "(10, 128, 128, 3)\n",
      "0.908824\n",
      "[Epoch 4/10] [Batch 650/1081] [D loss: 0.098290] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.674669] time: 0:38:53.239065\n",
      "(10, 128, 128, 3)\n",
      "0.94825786\n",
      "[Epoch 4/10] [Batch 651/1081] [D loss: 0.098323] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.921453] time: 0:38:53.655336\n",
      "(10, 128, 128, 3)\n",
      "0.89625233\n",
      "[Epoch 4/10] [Batch 652/1081] [D loss: 0.097241] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.055846] time: 0:38:54.075033\n",
      "(10, 128, 128, 3)\n",
      "0.8952992\n",
      "[Epoch 4/10] [Batch 653/1081] [D loss: 0.098271] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.890512] time: 0:38:54.487785\n",
      "(10, 128, 128, 3)\n",
      "0.93122214\n",
      "[Epoch 4/10] [Batch 654/1081] [D loss: 0.097386] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.570026] time: 0:38:54.900405\n",
      "(10, 128, 128, 3)\n",
      "0.938476\n",
      "[Epoch 4/10] [Batch 655/1081] [D loss: 0.097615] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.701224] time: 0:38:55.323835\n",
      "(10, 128, 128, 3)\n",
      "0.9361046\n",
      "[Epoch 4/10] [Batch 656/1081] [D loss: 0.098774] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.597942] time: 0:38:55.706947\n",
      "(10, 128, 128, 3)\n",
      "0.89829224\n",
      "[Epoch 4/10] [Batch 657/1081] [D loss: 0.097423] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.025290] time: 0:38:56.087234\n",
      "(10, 128, 128, 3)\n",
      "0.93580884\n",
      "[Epoch 4/10] [Batch 658/1081] [D loss: 0.096727] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.226014] time: 0:38:56.500839\n",
      "(10, 128, 128, 3)\n",
      "0.9471309\n",
      "[Epoch 4/10] [Batch 659/1081] [D loss: 0.098954] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.928084] time: 0:38:56.910903\n",
      "(10, 128, 128, 3)\n",
      "0.8977725\n",
      "[Epoch 4/10] [Batch 660/1081] [D loss: 0.097462] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.752680] time: 0:38:57.321981\n",
      "(10, 128, 128, 3)\n",
      "0.9254748\n",
      "[Epoch 4/10] [Batch 661/1081] [D loss: 0.096640] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.573116] time: 0:38:57.717400\n",
      "(10, 128, 128, 3)\n",
      "0.97388655\n",
      "[Epoch 4/10] [Batch 662/1081] [D loss: 0.096414] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.036273] time: 0:38:58.126620\n",
      "(10, 128, 128, 3)\n",
      "0.9367235\n",
      "[Epoch 4/10] [Batch 663/1081] [D loss: 0.096162] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.961136] time: 0:38:58.502079\n",
      "(10, 128, 128, 3)\n",
      "0.9346385\n",
      "[Epoch 4/10] [Batch 664/1081] [D loss: 0.096414] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.399376] time: 0:38:58.880000\n",
      "(10, 128, 128, 3)\n",
      "0.9233183\n",
      "[Epoch 4/10] [Batch 665/1081] [D loss: 0.095771] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.780127] time: 0:38:59.302881\n",
      "(10, 128, 128, 3)\n",
      "0.9503402\n",
      "[Epoch 4/10] [Batch 666/1081] [D loss: 0.096597] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.507417] time: 0:38:59.681738\n",
      "(10, 128, 128, 3)\n",
      "0.9334965\n",
      "[Epoch 4/10] [Batch 667/1081] [D loss: 0.096315] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.454062] time: 0:39:00.101809\n",
      "(10, 128, 128, 3)\n",
      "0.87881947\n",
      "[Epoch 4/10] [Batch 668/1081] [D loss: 0.554562] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 9.512639] time: 0:39:00.540152\n",
      "(10, 128, 128, 3)\n",
      "0.908804\n",
      "[Epoch 4/10] [Batch 669/1081] [D loss: 0.154421] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.098289] time: 0:39:00.927293\n",
      "(10, 128, 128, 3)\n",
      "0.9450868\n",
      "[Epoch 4/10] [Batch 670/1081] [D loss: 0.130816] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.102675] time: 0:39:01.299827\n",
      "(10, 128, 128, 3)\n",
      "0.9513979\n",
      "[Epoch 4/10] [Batch 671/1081] [D loss: 0.110642] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.504565] time: 0:39:01.712879\n",
      "(10, 128, 128, 3)\n",
      "0.93216896\n",
      "[Epoch 4/10] [Batch 672/1081] [D loss: 0.115257] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.512081] time: 0:39:02.141617\n",
      "(10, 128, 128, 3)\n",
      "0.9448002\n",
      "[Epoch 4/10] [Batch 673/1081] [D loss: 0.095118] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.106275] time: 0:39:02.535881\n",
      "(10, 128, 128, 3)\n",
      "0.9058778\n",
      "[Epoch 4/10] [Batch 674/1081] [D loss: 0.103468] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.809801] time: 0:39:02.943755\n",
      "(10, 128, 128, 3)\n",
      "0.8947367\n",
      "[Epoch 4/10] [Batch 675/1081] [D loss: 0.094795] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.311171] time: 0:39:03.357198\n",
      "(10, 128, 128, 3)\n",
      "0.90836984\n",
      "[Epoch 4/10] [Batch 676/1081] [D loss: 0.095535] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.614029] time: 0:39:03.814477\n",
      "(10, 128, 128, 3)\n",
      "0.9384549\n",
      "[Epoch 4/10] [Batch 677/1081] [D loss: 0.097797] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.548764] time: 0:39:04.257501\n",
      "(10, 128, 128, 3)\n",
      "0.9118585\n",
      "[Epoch 4/10] [Batch 678/1081] [D loss: 0.095728] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.271751] time: 0:39:04.685117\n",
      "(10, 128, 128, 3)\n",
      "0.92783576\n",
      "[Epoch 4/10] [Batch 679/1081] [D loss: 0.105197] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.310567] time: 0:39:05.113310\n",
      "(10, 128, 128, 3)\n",
      "0.9169573\n",
      "[Epoch 4/10] [Batch 680/1081] [D loss: 0.095602] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.102982] time: 0:39:05.525098\n",
      "(10, 128, 128, 3)\n",
      "0.8690579\n",
      "[Epoch 4/10] [Batch 681/1081] [D loss: 0.095584] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.410081] time: 0:39:05.945736\n",
      "(10, 128, 128, 3)\n",
      "0.9090654\n",
      "[Epoch 4/10] [Batch 682/1081] [D loss: 0.096076] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.762609] time: 0:39:06.350642\n",
      "(10, 128, 128, 3)\n",
      "0.8779637\n",
      "[Epoch 4/10] [Batch 683/1081] [D loss: 0.096118] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.297229] time: 0:39:06.780063\n",
      "(10, 128, 128, 3)\n",
      "0.92340344\n",
      "[Epoch 4/10] [Batch 684/1081] [D loss: 0.093786] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.181484] time: 0:39:07.192510\n",
      "(10, 128, 128, 3)\n",
      "0.93054\n",
      "[Epoch 4/10] [Batch 685/1081] [D loss: 0.096868] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.932230] time: 0:39:07.591876\n",
      "(10, 128, 128, 3)\n",
      "0.84974474\n",
      "[Epoch 4/10] [Batch 686/1081] [D loss: 0.094776] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.695700] time: 0:39:08.036025\n",
      "(10, 128, 128, 3)\n",
      "0.9021487\n",
      "[Epoch 4/10] [Batch 687/1081] [D loss: 0.094834] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.128719] time: 0:39:08.467934\n",
      "(10, 128, 128, 3)\n",
      "0.90241313\n",
      "[Epoch 4/10] [Batch 688/1081] [D loss: 0.095384] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.679832] time: 0:39:08.865050\n",
      "(10, 128, 128, 3)\n",
      "0.948935\n",
      "[Epoch 4/10] [Batch 689/1081] [D loss: 0.094939] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.129117] time: 0:39:09.283351\n",
      "(10, 128, 128, 3)\n",
      "0.9038411\n",
      "[Epoch 4/10] [Batch 690/1081] [D loss: 0.094099] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.843208] time: 0:39:09.697817\n",
      "(10, 128, 128, 3)\n",
      "0.8896337\n",
      "[Epoch 4/10] [Batch 691/1081] [D loss: 0.094047] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.714143] time: 0:39:10.117281\n",
      "(10, 128, 128, 3)\n",
      "0.8952878\n",
      "[Epoch 4/10] [Batch 692/1081] [D loss: 0.094277] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.102123] time: 0:39:10.559113\n",
      "(10, 128, 128, 3)\n",
      "0.9405368\n",
      "[Epoch 4/10] [Batch 693/1081] [D loss: 0.093064] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.342989] time: 0:39:10.972489\n",
      "(10, 128, 128, 3)\n",
      "0.9082288\n",
      "[Epoch 4/10] [Batch 694/1081] [D loss: 0.093682] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.408710] time: 0:39:11.416937\n",
      "(10, 128, 128, 3)\n",
      "0.89673495\n",
      "[Epoch 4/10] [Batch 695/1081] [D loss: 0.092422] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.790843] time: 0:39:11.820848\n",
      "(10, 128, 128, 3)\n",
      "0.92699164\n",
      "[Epoch 4/10] [Batch 696/1081] [D loss: 0.094562] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.953729] time: 0:39:12.236455\n",
      "(10, 128, 128, 3)\n",
      "0.94742614\n",
      "[Epoch 4/10] [Batch 697/1081] [D loss: 0.092738] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.465244] time: 0:39:12.652130\n",
      "(10, 128, 128, 3)\n",
      "0.9258874\n",
      "[Epoch 4/10] [Batch 698/1081] [D loss: 0.092124] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.946860] time: 0:39:13.047190\n",
      "(10, 128, 128, 3)\n",
      "0.9030635\n",
      "[Epoch 4/10] [Batch 699/1081] [D loss: 0.091965] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.463948] time: 0:39:13.473106\n",
      "(10, 128, 128, 3)\n",
      "0.90330553\n",
      "[Epoch 4/10] [Batch 700/1081] [D loss: 0.092023] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.259010] time: 0:39:13.874760\n",
      "(10, 128, 128, 3)\n",
      "0.8830368\n",
      "[Epoch 4/10] [Batch 701/1081] [D loss: 0.092772] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.225107] time: 0:39:14.315233\n",
      "(10, 128, 128, 3)\n",
      "0.94715595\n",
      "[Epoch 4/10] [Batch 702/1081] [D loss: 0.091632] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.880395] time: 0:39:14.759458\n",
      "(10, 128, 128, 3)\n",
      "0.9360941\n",
      "[Epoch 4/10] [Batch 703/1081] [D loss: 0.097624] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.602699] time: 0:39:15.199335\n",
      "(10, 128, 128, 3)\n",
      "0.91731614\n",
      "[Epoch 4/10] [Batch 704/1081] [D loss: 0.094770] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.041430] time: 0:39:15.620373\n",
      "(10, 128, 128, 3)\n",
      "0.92028934\n",
      "[Epoch 4/10] [Batch 705/1081] [D loss: 0.092014] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.431303] time: 0:39:16.031151\n",
      "(10, 128, 128, 3)\n",
      "0.89700204\n",
      "[Epoch 4/10] [Batch 706/1081] [D loss: 0.092062] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.613864] time: 0:39:16.461638\n",
      "(10, 128, 128, 3)\n",
      "0.91916865\n",
      "[Epoch 4/10] [Batch 707/1081] [D loss: 0.091248] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.388091] time: 0:39:16.890594\n",
      "(10, 128, 128, 3)\n",
      "0.8265238\n",
      "[Epoch 4/10] [Batch 708/1081] [D loss: 0.091060] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.358692] time: 0:39:17.279273\n",
      "(10, 128, 128, 3)\n",
      "0.94159967\n",
      "[Epoch 4/10] [Batch 709/1081] [D loss: 0.094831] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.624765] time: 0:39:17.660040\n",
      "(10, 128, 128, 3)\n",
      "0.87201166\n",
      "[Epoch 4/10] [Batch 710/1081] [D loss: 0.092331] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.623340] time: 0:39:18.058754\n",
      "(10, 128, 128, 3)\n",
      "0.90702695\n",
      "[Epoch 4/10] [Batch 711/1081] [D loss: 0.090768] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.754763] time: 0:39:18.481033\n",
      "(10, 128, 128, 3)\n",
      "0.9001279\n",
      "[Epoch 4/10] [Batch 712/1081] [D loss: 0.091785] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.675340] time: 0:39:18.872764\n",
      "(10, 128, 128, 3)\n",
      "0.9320874\n",
      "[Epoch 4/10] [Batch 713/1081] [D loss: 0.090875] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.681380] time: 0:39:19.294017\n",
      "(10, 128, 128, 3)\n",
      "0.94643813\n",
      "[Epoch 4/10] [Batch 714/1081] [D loss: 0.090579] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.280778] time: 0:39:19.716043\n",
      "(10, 128, 128, 3)\n",
      "0.8723521\n",
      "[Epoch 4/10] [Batch 715/1081] [D loss: 0.090530] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.709939] time: 0:39:20.152449\n",
      "(10, 128, 128, 3)\n",
      "0.90012187\n",
      "[Epoch 4/10] [Batch 716/1081] [D loss: 0.090447] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.717663] time: 0:39:20.575758\n",
      "(10, 128, 128, 3)\n",
      "0.97614145\n",
      "[Epoch 4/10] [Batch 717/1081] [D loss: 0.090268] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.272457] time: 0:39:20.979387\n",
      "(10, 128, 128, 3)\n",
      "0.9138532\n",
      "[Epoch 4/10] [Batch 718/1081] [D loss: 0.090216] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.498757] time: 0:39:21.407415\n",
      "(10, 128, 128, 3)\n",
      "0.89104253\n",
      "[Epoch 4/10] [Batch 719/1081] [D loss: 0.089980] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.876570] time: 0:39:21.800148\n",
      "(10, 128, 128, 3)\n",
      "0.8760181\n",
      "[Epoch 4/10] [Batch 720/1081] [D loss: 0.090086] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.194191] time: 0:39:22.206441\n",
      "(10, 128, 128, 3)\n",
      "0.88423014\n",
      "[Epoch 4/10] [Batch 721/1081] [D loss: 0.090006] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.929676] time: 0:39:22.640355\n",
      "(10, 128, 128, 3)\n",
      "0.8968007\n",
      "[Epoch 4/10] [Batch 722/1081] [D loss: 0.089742] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.518949] time: 0:39:23.072725\n",
      "(10, 128, 128, 3)\n",
      "0.89877033\n",
      "[Epoch 4/10] [Batch 723/1081] [D loss: 0.089697] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.440695] time: 0:39:23.475418\n",
      "(10, 128, 128, 3)\n",
      "0.9414156\n",
      "[Epoch 4/10] [Batch 724/1081] [D loss: 0.089451] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.007786] time: 0:39:23.914518\n",
      "(10, 128, 128, 3)\n",
      "0.9030802\n",
      "[Epoch 4/10] [Batch 725/1081] [D loss: 0.089832] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.636605] time: 0:39:24.359762\n",
      "(10, 128, 128, 3)\n",
      "0.9349713\n",
      "[Epoch 4/10] [Batch 726/1081] [D loss: 0.089216] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.778140] time: 0:39:24.744113\n",
      "(10, 128, 128, 3)\n",
      "0.9360128\n",
      "[Epoch 4/10] [Batch 727/1081] [D loss: 0.089113] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.897928] time: 0:39:25.168575\n",
      "(10, 128, 128, 3)\n",
      "0.9192222\n",
      "[Epoch 4/10] [Batch 728/1081] [D loss: 0.091101] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.113672] time: 0:39:25.625653\n",
      "(10, 128, 128, 3)\n",
      "0.8929251\n",
      "[Epoch 4/10] [Batch 729/1081] [D loss: 0.090530] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.191821] time: 0:39:26.068085\n",
      "(10, 128, 128, 3)\n",
      "0.92365664\n",
      "[Epoch 4/10] [Batch 730/1081] [D loss: 0.089541] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.664435] time: 0:39:26.514887\n",
      "(10, 128, 128, 3)\n",
      "0.8703916\n",
      "[Epoch 4/10] [Batch 731/1081] [D loss: 0.088635] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.816386] time: 0:39:26.931399\n",
      "(10, 128, 128, 3)\n",
      "0.9139936\n",
      "[Epoch 4/10] [Batch 732/1081] [D loss: 0.089069] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.514462] time: 0:39:27.342496\n",
      "(10, 128, 128, 3)\n",
      "0.87836975\n",
      "[Epoch 4/10] [Batch 733/1081] [D loss: 0.089111] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.379546] time: 0:39:27.790913\n",
      "(10, 128, 128, 3)\n",
      "0.92432755\n",
      "[Epoch 4/10] [Batch 734/1081] [D loss: 0.088656] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.805981] time: 0:39:28.219271\n",
      "(10, 128, 128, 3)\n",
      "0.9173593\n",
      "[Epoch 4/10] [Batch 735/1081] [D loss: 0.089547] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.459689] time: 0:39:28.624237\n",
      "(10, 128, 128, 3)\n",
      "0.9162135\n",
      "[Epoch 4/10] [Batch 736/1081] [D loss: 0.088461] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.897448] time: 0:39:29.042444\n",
      "(10, 128, 128, 3)\n",
      "0.92923564\n",
      "[Epoch 4/10] [Batch 737/1081] [D loss: 0.089435] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.299669] time: 0:39:29.459586\n",
      "(10, 128, 128, 3)\n",
      "0.94076806\n",
      "[Epoch 4/10] [Batch 738/1081] [D loss: 0.088062] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.138000] time: 0:39:29.855630\n",
      "(10, 128, 128, 3)\n",
      "0.89526254\n",
      "[Epoch 4/10] [Batch 739/1081] [D loss: 0.088521] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.162113] time: 0:39:30.277999\n",
      "(10, 128, 128, 3)\n",
      "0.85941344\n",
      "[Epoch 4/10] [Batch 740/1081] [D loss: 0.088464] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.319118] time: 0:39:30.739680\n",
      "(10, 128, 128, 3)\n",
      "0.87645173\n",
      "[Epoch 4/10] [Batch 741/1081] [D loss: 0.088088] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.169243] time: 0:39:31.121886\n",
      "(10, 128, 128, 3)\n",
      "0.87637734\n",
      "[Epoch 4/10] [Batch 742/1081] [D loss: 0.087796] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.953342] time: 0:39:31.544284\n",
      "(10, 128, 128, 3)\n",
      "0.9096249\n",
      "[Epoch 4/10] [Batch 743/1081] [D loss: 0.087635] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.024444] time: 0:39:31.968008\n",
      "(10, 128, 128, 3)\n",
      "0.9129536\n",
      "[Epoch 4/10] [Batch 744/1081] [D loss: 0.087835] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.472381] time: 0:39:32.353037\n",
      "(10, 128, 128, 3)\n",
      "0.92679435\n",
      "[Epoch 4/10] [Batch 745/1081] [D loss: 0.088043] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.142358] time: 0:39:32.784125\n",
      "(10, 128, 128, 3)\n",
      "0.8784671\n",
      "[Epoch 4/10] [Batch 746/1081] [D loss: 0.088150] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.549233] time: 0:39:33.192373\n",
      "(10, 128, 128, 3)\n",
      "0.90789986\n",
      "[Epoch 4/10] [Batch 747/1081] [D loss: 0.087200] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.342682] time: 0:39:33.622161\n",
      "(10, 128, 128, 3)\n",
      "0.9275512\n",
      "[Epoch 4/10] [Batch 748/1081] [D loss: 0.088190] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.811582] time: 0:39:34.044409\n",
      "(10, 128, 128, 3)\n",
      "0.8880069\n",
      "[Epoch 4/10] [Batch 749/1081] [D loss: 0.088073] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.727703] time: 0:39:34.435477\n",
      "(10, 128, 128, 3)\n",
      "0.9596489\n",
      "[Epoch 4/10] [Batch 750/1081] [D loss: 0.087658] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.887016] time: 0:39:34.861432\n",
      "(10, 128, 128, 3)\n",
      "0.924953\n",
      "[Epoch 4/10] [Batch 751/1081] [D loss: 0.087650] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.893754] time: 0:39:35.260689\n",
      "(10, 128, 128, 3)\n",
      "0.9258991\n",
      "[Epoch 4/10] [Batch 752/1081] [D loss: 0.087185] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.638824] time: 0:39:35.658312\n",
      "(10, 128, 128, 3)\n",
      "0.90756696\n",
      "[Epoch 4/10] [Batch 753/1081] [D loss: 0.086629] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.721936] time: 0:39:36.066377\n",
      "(10, 128, 128, 3)\n",
      "0.9003165\n",
      "[Epoch 4/10] [Batch 754/1081] [D loss: 0.087505] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.248363] time: 0:39:36.489195\n",
      "(10, 128, 128, 3)\n",
      "0.9336725\n",
      "[Epoch 4/10] [Batch 755/1081] [D loss: 0.086969] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.605712] time: 0:39:36.928569\n",
      "(10, 128, 128, 3)\n",
      "0.88476306\n",
      "[Epoch 4/10] [Batch 756/1081] [D loss: 0.087562] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.635483] time: 0:39:37.356967\n",
      "(10, 128, 128, 3)\n",
      "0.94047433\n",
      "[Epoch 4/10] [Batch 757/1081] [D loss: 0.087172] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.027534] time: 0:39:37.828005\n",
      "(10, 128, 128, 3)\n",
      "0.87628895\n",
      "[Epoch 4/10] [Batch 758/1081] [D loss: 0.087670] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.830514] time: 0:39:38.236076\n",
      "(10, 128, 128, 3)\n",
      "0.9398648\n",
      "[Epoch 4/10] [Batch 759/1081] [D loss: 0.088107] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.004701] time: 0:39:38.664225\n",
      "(10, 128, 128, 3)\n",
      "0.9241918\n",
      "[Epoch 4/10] [Batch 760/1081] [D loss: 0.086968] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.904452] time: 0:39:39.063797\n",
      "(10, 128, 128, 3)\n",
      "0.90585226\n",
      "[Epoch 4/10] [Batch 761/1081] [D loss: 0.086912] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.460204] time: 0:39:39.508103\n",
      "(10, 128, 128, 3)\n",
      "0.9245507\n",
      "[Epoch 4/10] [Batch 762/1081] [D loss: 0.086459] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.104909] time: 0:39:39.945596\n",
      "(10, 128, 128, 3)\n",
      "0.8672368\n",
      "[Epoch 4/10] [Batch 763/1081] [D loss: 0.086256] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.613011] time: 0:39:40.357274\n",
      "(10, 128, 128, 3)\n",
      "0.9429342\n",
      "[Epoch 4/10] [Batch 764/1081] [D loss: 0.086943] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.252031] time: 0:39:40.774671\n",
      "(10, 128, 128, 3)\n",
      "0.93692654\n",
      "[Epoch 4/10] [Batch 765/1081] [D loss: 0.086939] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.079063] time: 0:39:41.185197\n",
      "(10, 128, 128, 3)\n",
      "0.9265049\n",
      "[Epoch 4/10] [Batch 766/1081] [D loss: 0.086359] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.241828] time: 0:39:41.617757\n",
      "(10, 128, 128, 3)\n",
      "0.91060495\n",
      "[Epoch 4/10] [Batch 767/1081] [D loss: 0.086977] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.416955] time: 0:39:42.006762\n",
      "(10, 128, 128, 3)\n",
      "0.94108087\n",
      "[Epoch 4/10] [Batch 768/1081] [D loss: 0.085655] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.793917] time: 0:39:42.416346\n",
      "(10, 128, 128, 3)\n",
      "0.9109072\n",
      "[Epoch 4/10] [Batch 769/1081] [D loss: 0.085602] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.983862] time: 0:39:42.815350\n",
      "(10, 128, 128, 3)\n",
      "0.8960616\n",
      "[Epoch 4/10] [Batch 770/1081] [D loss: 0.085471] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.052782] time: 0:39:43.256864\n",
      "(10, 128, 128, 3)\n",
      "0.93539923\n",
      "[Epoch 4/10] [Batch 771/1081] [D loss: 0.085218] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.541512] time: 0:39:43.681918\n",
      "(10, 128, 128, 3)\n",
      "0.8910699\n",
      "[Epoch 4/10] [Batch 772/1081] [D loss: 0.085290] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.374114] time: 0:39:44.100514\n",
      "(10, 128, 128, 3)\n",
      "0.8827221\n",
      "[Epoch 4/10] [Batch 773/1081] [D loss: 0.086061] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.988059] time: 0:39:44.549582\n",
      "(10, 128, 128, 3)\n",
      "0.95289415\n",
      "[Epoch 4/10] [Batch 774/1081] [D loss: 0.085903] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.967597] time: 0:39:44.959847\n",
      "(10, 128, 128, 3)\n",
      "0.8657164\n",
      "[Epoch 4/10] [Batch 775/1081] [D loss: 0.085421] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.754942] time: 0:39:45.408104\n",
      "(10, 128, 128, 3)\n",
      "0.94891787\n",
      "[Epoch 4/10] [Batch 776/1081] [D loss: 0.085579] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.712418] time: 0:39:45.812706\n",
      "(10, 128, 128, 3)\n",
      "0.9024585\n",
      "[Epoch 4/10] [Batch 777/1081] [D loss: 0.085966] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.912045] time: 0:39:46.214307\n",
      "(10, 128, 128, 3)\n",
      "0.9708278\n",
      "[Epoch 4/10] [Batch 778/1081] [D loss: 0.085239] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.105119] time: 0:39:46.651215\n",
      "(10, 128, 128, 3)\n",
      "0.9225402\n",
      "[Epoch 4/10] [Batch 779/1081] [D loss: 0.086808] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.803973] time: 0:39:47.059565\n",
      "(10, 128, 128, 3)\n",
      "0.8911545\n",
      "[Epoch 4/10] [Batch 780/1081] [D loss: 0.085015] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.412718] time: 0:39:47.455055\n",
      "(10, 128, 128, 3)\n",
      "0.8556344\n",
      "[Epoch 4/10] [Batch 781/1081] [D loss: 0.085041] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.870022] time: 0:39:47.851859\n",
      "(10, 128, 128, 3)\n",
      "0.9197932\n",
      "[Epoch 4/10] [Batch 782/1081] [D loss: 0.085459] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.350648] time: 0:39:48.268700\n",
      "(10, 128, 128, 3)\n",
      "0.93005013\n",
      "[Epoch 4/10] [Batch 783/1081] [D loss: 0.084578] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.662272] time: 0:39:48.668950\n",
      "(10, 128, 128, 3)\n",
      "0.8855385\n",
      "[Epoch 4/10] [Batch 784/1081] [D loss: 0.086039] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.210407] time: 0:39:49.078442\n",
      "(10, 128, 128, 3)\n",
      "0.8984644\n",
      "[Epoch 4/10] [Batch 785/1081] [D loss: 0.085575] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.196737] time: 0:39:49.510645\n",
      "(10, 128, 128, 3)\n",
      "0.8887832\n",
      "[Epoch 4/10] [Batch 786/1081] [D loss: 0.084567] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.115359] time: 0:39:49.921977\n",
      "(10, 128, 128, 3)\n",
      "0.9157731\n",
      "[Epoch 4/10] [Batch 787/1081] [D loss: 0.085006] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.775482] time: 0:39:50.368847\n",
      "(10, 128, 128, 3)\n",
      "0.87467605\n",
      "[Epoch 4/10] [Batch 788/1081] [D loss: 0.084565] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.198699] time: 0:39:50.828602\n",
      "(10, 128, 128, 3)\n",
      "0.86524534\n",
      "[Epoch 4/10] [Batch 789/1081] [D loss: 0.084675] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.326468] time: 0:39:51.255081\n",
      "(10, 128, 128, 3)\n",
      "0.916766\n",
      "[Epoch 4/10] [Batch 790/1081] [D loss: 0.084401] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.169959] time: 0:39:51.669264\n",
      "(10, 128, 128, 3)\n",
      "0.93190044\n",
      "[Epoch 4/10] [Batch 791/1081] [D loss: 0.084623] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.542830] time: 0:39:52.052797\n",
      "(10, 128, 128, 3)\n",
      "0.95467967\n",
      "[Epoch 4/10] [Batch 792/1081] [D loss: 0.084970] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.228789] time: 0:39:52.467892\n",
      "(10, 128, 128, 3)\n",
      "0.8939681\n",
      "[Epoch 4/10] [Batch 793/1081] [D loss: 0.084379] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.181676] time: 0:39:52.870585\n",
      "(10, 128, 128, 3)\n",
      "0.95821255\n",
      "[Epoch 4/10] [Batch 794/1081] [D loss: 0.083968] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.950965] time: 0:39:53.270752\n",
      "(10, 128, 128, 3)\n",
      "0.9312911\n",
      "[Epoch 4/10] [Batch 795/1081] [D loss: 0.084233] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.689015] time: 0:39:53.683820\n",
      "(10, 128, 128, 3)\n",
      "0.88570976\n",
      "[Epoch 4/10] [Batch 796/1081] [D loss: 0.083791] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.176421] time: 0:39:54.099951\n",
      "(10, 128, 128, 3)\n",
      "0.9373398\n",
      "[Epoch 4/10] [Batch 797/1081] [D loss: 0.083413] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.961143] time: 0:39:54.542976\n",
      "(10, 128, 128, 3)\n",
      "0.9242839\n",
      "[Epoch 4/10] [Batch 798/1081] [D loss: 0.084122] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.951375] time: 0:39:54.971907\n",
      "(10, 128, 128, 3)\n",
      "0.9079074\n",
      "[Epoch 4/10] [Batch 799/1081] [D loss: 0.083789] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.689031] time: 0:39:55.400878\n",
      "(10, 128, 128, 3)\n",
      "0.9388809\n",
      "[Epoch 4/10] [Batch 800/1081] [D loss: 0.083429] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.743987] time: 0:39:55.800544\n",
      "(10, 128, 128, 3)\n",
      "0.91396326\n",
      "[Epoch 4/10] [Batch 801/1081] [D loss: 0.083697] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.646920] time: 0:39:56.199655\n",
      "(10, 128, 128, 3)\n",
      "0.91427106\n",
      "[Epoch 4/10] [Batch 802/1081] [D loss: 0.083685] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.177681] time: 0:39:56.614315\n",
      "(10, 128, 128, 3)\n",
      "0.9385524\n",
      "[Epoch 4/10] [Batch 803/1081] [D loss: 0.083641] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.833026] time: 0:39:57.064113\n",
      "(10, 128, 128, 3)\n",
      "0.91456866\n",
      "[Epoch 4/10] [Batch 804/1081] [D loss: 0.083247] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.144718] time: 0:39:57.462730\n",
      "(10, 128, 128, 3)\n",
      "0.90660185\n",
      "[Epoch 4/10] [Batch 805/1081] [D loss: 0.083131] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.237324] time: 0:39:57.856700\n",
      "(10, 128, 128, 3)\n",
      "0.9716189\n",
      "[Epoch 4/10] [Batch 806/1081] [D loss: 0.082739] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.802010] time: 0:39:58.242485\n",
      "(10, 128, 128, 3)\n",
      "0.88189524\n",
      "[Epoch 4/10] [Batch 807/1081] [D loss: 0.083057] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.270807] time: 0:39:58.627973\n",
      "(10, 128, 128, 3)\n",
      "0.90623826\n",
      "[Epoch 4/10] [Batch 808/1081] [D loss: 0.082821] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.349151] time: 0:39:59.041095\n",
      "(10, 128, 128, 3)\n",
      "0.9023364\n",
      "[Epoch 4/10] [Batch 809/1081] [D loss: 0.083091] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.687094] time: 0:39:59.444278\n",
      "(10, 128, 128, 3)\n",
      "0.9022\n",
      "[Epoch 4/10] [Batch 810/1081] [D loss: 0.083346] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.155576] time: 0:39:59.841416\n",
      "(10, 128, 128, 3)\n",
      "0.9528137\n",
      "[Epoch 4/10] [Batch 811/1081] [D loss: 0.082477] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.360082] time: 0:40:00.282703\n",
      "(10, 128, 128, 3)\n",
      "0.8764944\n",
      "[Epoch 4/10] [Batch 812/1081] [D loss: 0.082309] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.521632] time: 0:40:00.682145\n",
      "(10, 128, 128, 3)\n",
      "0.8812564\n",
      "[Epoch 4/10] [Batch 813/1081] [D loss: 0.082242] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.834333] time: 0:40:01.090101\n",
      "(10, 128, 128, 3)\n",
      "0.92097145\n",
      "[Epoch 4/10] [Batch 814/1081] [D loss: 0.082294] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.687213] time: 0:40:01.550860\n",
      "(10, 128, 128, 3)\n",
      "0.90774614\n",
      "[Epoch 4/10] [Batch 815/1081] [D loss: 0.082725] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.157289] time: 0:40:01.993379\n",
      "(10, 128, 128, 3)\n",
      "0.8778774\n",
      "[Epoch 4/10] [Batch 816/1081] [D loss: 0.082541] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.639898] time: 0:40:02.401708\n",
      "(10, 128, 128, 3)\n",
      "0.8647008\n",
      "[Epoch 4/10] [Batch 817/1081] [D loss: 0.082407] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.857172] time: 0:40:02.836314\n",
      "(10, 128, 128, 3)\n",
      "0.9797376\n",
      "[Epoch 4/10] [Batch 818/1081] [D loss: 0.082602] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.005677] time: 0:40:03.283627\n",
      "(10, 128, 128, 3)\n",
      "0.92839295\n",
      "[Epoch 4/10] [Batch 819/1081] [D loss: 0.082265] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.658529] time: 0:40:03.686974\n",
      "(10, 128, 128, 3)\n",
      "0.9163055\n",
      "[Epoch 4/10] [Batch 820/1081] [D loss: 0.082137] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.022145] time: 0:40:04.068103\n",
      "(10, 128, 128, 3)\n",
      "0.9046564\n",
      "[Epoch 4/10] [Batch 821/1081] [D loss: 0.082497] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.794772] time: 0:40:04.476417\n",
      "(10, 128, 128, 3)\n",
      "0.88821286\n",
      "[Epoch 4/10] [Batch 822/1081] [D loss: 0.081771] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.023531] time: 0:40:04.885019\n",
      "(10, 128, 128, 3)\n",
      "0.87490755\n",
      "[Epoch 4/10] [Batch 823/1081] [D loss: 0.081520] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.486194] time: 0:40:05.271517\n",
      "(10, 128, 128, 3)\n",
      "0.922345\n",
      "[Epoch 4/10] [Batch 824/1081] [D loss: 0.081860] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.609813] time: 0:40:05.667092\n",
      "(10, 128, 128, 3)\n",
      "0.94326735\n",
      "[Epoch 4/10] [Batch 825/1081] [D loss: 0.081596] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.536860] time: 0:40:06.064316\n",
      "(10, 128, 128, 3)\n",
      "0.90269923\n",
      "[Epoch 4/10] [Batch 826/1081] [D loss: 0.081370] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.203596] time: 0:40:06.494447\n",
      "(10, 128, 128, 3)\n",
      "0.8663307\n",
      "[Epoch 4/10] [Batch 827/1081] [D loss: 0.081315] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.492980] time: 0:40:06.902739\n",
      "(10, 128, 128, 3)\n",
      "0.9253009\n",
      "[Epoch 4/10] [Batch 828/1081] [D loss: 0.081240] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.519958] time: 0:40:07.309271\n",
      "(10, 128, 128, 3)\n",
      "0.9024022\n",
      "[Epoch 4/10] [Batch 829/1081] [D loss: 0.082531] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.412458] time: 0:40:07.721777\n",
      "(10, 128, 128, 3)\n",
      "0.9094529\n",
      "[Epoch 4/10] [Batch 830/1081] [D loss: 0.081657] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.552015] time: 0:40:08.145841\n",
      "(10, 128, 128, 3)\n",
      "0.9552717\n",
      "[Epoch 4/10] [Batch 831/1081] [D loss: 0.081958] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.141413] time: 0:40:08.546117\n",
      "(10, 128, 128, 3)\n",
      "0.9362363\n",
      "[Epoch 4/10] [Batch 832/1081] [D loss: 0.081043] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.225175] time: 0:40:08.988678\n",
      "(10, 128, 128, 3)\n",
      "0.8994948\n",
      "[Epoch 4/10] [Batch 833/1081] [D loss: 0.081340] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.232209] time: 0:40:09.401689\n",
      "(10, 128, 128, 3)\n",
      "0.8694009\n",
      "[Epoch 4/10] [Batch 834/1081] [D loss: 0.081354] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.923798] time: 0:40:09.845105\n",
      "(10, 128, 128, 3)\n",
      "0.94894767\n",
      "[Epoch 4/10] [Batch 835/1081] [D loss: 0.081312] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.727732] time: 0:40:10.252761\n",
      "(10, 128, 128, 3)\n",
      "0.95409936\n",
      "[Epoch 4/10] [Batch 836/1081] [D loss: 0.080746] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.165153] time: 0:40:10.676446\n",
      "(10, 128, 128, 3)\n",
      "0.8793533\n",
      "[Epoch 4/10] [Batch 837/1081] [D loss: 0.080880] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.009827] time: 0:40:11.095665\n",
      "(10, 128, 128, 3)\n",
      "0.9341076\n",
      "[Epoch 4/10] [Batch 838/1081] [D loss: 0.080965] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.375724] time: 0:40:11.525984\n",
      "(10, 128, 128, 3)\n",
      "0.8841967\n",
      "[Epoch 4/10] [Batch 839/1081] [D loss: 0.080694] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.205856] time: 0:40:11.943136\n",
      "(10, 128, 128, 3)\n",
      "0.94775504\n",
      "[Epoch 4/10] [Batch 840/1081] [D loss: 0.080580] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.162559] time: 0:40:12.372665\n",
      "(10, 128, 128, 3)\n",
      "0.88045764\n",
      "[Epoch 4/10] [Batch 841/1081] [D loss: 0.080775] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.464799] time: 0:40:12.780051\n",
      "(10, 128, 128, 3)\n",
      "0.940116\n",
      "[Epoch 4/10] [Batch 842/1081] [D loss: 0.080735] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.129368] time: 0:40:13.203643\n",
      "(10, 128, 128, 3)\n",
      "0.9469345\n",
      "[Epoch 4/10] [Batch 843/1081] [D loss: 0.080357] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.713073] time: 0:40:13.624538\n",
      "(10, 128, 128, 3)\n",
      "0.8797839\n",
      "[Epoch 4/10] [Batch 844/1081] [D loss: 0.080634] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.711774] time: 0:40:14.044629\n",
      "(10, 128, 128, 3)\n",
      "0.94199485\n",
      "[Epoch 4/10] [Batch 845/1081] [D loss: 0.080508] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.336408] time: 0:40:14.473527\n",
      "(10, 128, 128, 3)\n",
      "0.88992286\n",
      "[Epoch 4/10] [Batch 846/1081] [D loss: 0.080721] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.035028] time: 0:40:14.894266\n",
      "(10, 128, 128, 3)\n",
      "0.87757015\n",
      "[Epoch 4/10] [Batch 847/1081] [D loss: 0.080607] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.898507] time: 0:40:15.283699\n",
      "(10, 128, 128, 3)\n",
      "0.91313416\n",
      "[Epoch 4/10] [Batch 848/1081] [D loss: 0.080982] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.792239] time: 0:40:15.683182\n",
      "(10, 128, 128, 3)\n",
      "0.9137838\n",
      "[Epoch 4/10] [Batch 849/1081] [D loss: 0.080372] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.944792] time: 0:40:16.056563\n",
      "(10, 128, 128, 3)\n",
      "0.946805\n",
      "[Epoch 4/10] [Batch 850/1081] [D loss: 0.080031] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.595522] time: 0:40:16.462429\n",
      "(10, 128, 128, 3)\n",
      "0.9314197\n",
      "[Epoch 4/10] [Batch 851/1081] [D loss: 0.080405] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.815204] time: 0:40:16.845506\n",
      "(10, 128, 128, 3)\n",
      "0.9155407\n",
      "[Epoch 4/10] [Batch 852/1081] [D loss: 0.079916] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.203571] time: 0:40:17.218860\n",
      "(10, 128, 128, 3)\n",
      "0.90058726\n",
      "[Epoch 4/10] [Batch 853/1081] [D loss: 0.080141] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.092309] time: 0:40:17.584493\n",
      "(10, 128, 128, 3)\n",
      "0.97024316\n",
      "[Epoch 4/10] [Batch 854/1081] [D loss: 0.081821] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.314266] time: 0:40:17.974122\n",
      "(10, 128, 128, 3)\n",
      "0.9067784\n",
      "[Epoch 4/10] [Batch 855/1081] [D loss: 0.080599] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.976304] time: 0:40:18.400046\n",
      "(10, 128, 128, 3)\n",
      "0.887372\n",
      "[Epoch 4/10] [Batch 856/1081] [D loss: 0.080111] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.353747] time: 0:40:18.778717\n",
      "(10, 128, 128, 3)\n",
      "0.9080079\n",
      "[Epoch 4/10] [Batch 857/1081] [D loss: 0.079773] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.757964] time: 0:40:19.178967\n",
      "(10, 128, 128, 3)\n",
      "0.9236627\n",
      "[Epoch 4/10] [Batch 858/1081] [D loss: 0.079859] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.631609] time: 0:40:19.582813\n",
      "(10, 128, 128, 3)\n",
      "0.88760144\n",
      "[Epoch 4/10] [Batch 859/1081] [D loss: 0.079690] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.474608] time: 0:40:19.973480\n",
      "(10, 128, 128, 3)\n",
      "0.9305771\n",
      "[Epoch 4/10] [Batch 860/1081] [D loss: 0.079820] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.523849] time: 0:40:20.374452\n",
      "(10, 128, 128, 3)\n",
      "0.95269734\n",
      "[Epoch 4/10] [Batch 861/1081] [D loss: 0.079559] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.045532] time: 0:40:20.764407\n",
      "(10, 128, 128, 3)\n",
      "0.9668949\n",
      "[Epoch 4/10] [Batch 862/1081] [D loss: 0.080430] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.652794] time: 0:40:21.185483\n",
      "(10, 128, 128, 3)\n",
      "0.91992193\n",
      "[Epoch 4/10] [Batch 863/1081] [D loss: 0.079457] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.580666] time: 0:40:21.588570\n",
      "(10, 128, 128, 3)\n",
      "0.9159632\n",
      "[Epoch 4/10] [Batch 864/1081] [D loss: 0.079489] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.465051] time: 0:40:21.969985\n",
      "(10, 128, 128, 3)\n",
      "0.86767167\n",
      "[Epoch 4/10] [Batch 865/1081] [D loss: 0.079567] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.198724] time: 0:40:22.359763\n",
      "(10, 128, 128, 3)\n",
      "0.93221766\n",
      "[Epoch 4/10] [Batch 866/1081] [D loss: 0.079160] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.060398] time: 0:40:22.782756\n",
      "(10, 128, 128, 3)\n",
      "0.90632623\n",
      "[Epoch 4/10] [Batch 867/1081] [D loss: 0.079622] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.474042] time: 0:40:23.181050\n",
      "(10, 128, 128, 3)\n",
      "0.9066021\n",
      "[Epoch 4/10] [Batch 868/1081] [D loss: 0.079349] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.499899] time: 0:40:23.588866\n",
      "(10, 128, 128, 3)\n",
      "0.92979884\n",
      "[Epoch 4/10] [Batch 869/1081] [D loss: 0.078798] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.837846] time: 0:40:23.995648\n",
      "(10, 128, 128, 3)\n",
      "0.9353251\n",
      "[Epoch 4/10] [Batch 870/1081] [D loss: 0.079533] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.908479] time: 0:40:24.394917\n",
      "(10, 128, 128, 3)\n",
      "0.93069714\n",
      "[Epoch 4/10] [Batch 871/1081] [D loss: 0.079070] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.352393] time: 0:40:24.821987\n",
      "(10, 128, 128, 3)\n",
      "0.9077377\n",
      "[Epoch 4/10] [Batch 872/1081] [D loss: 0.078817] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.508897] time: 0:40:25.228548\n",
      "(10, 128, 128, 3)\n",
      "0.900608\n",
      "[Epoch 4/10] [Batch 873/1081] [D loss: 0.078842] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.068004] time: 0:40:25.636198\n",
      "(10, 128, 128, 3)\n",
      "0.92824507\n",
      "[Epoch 4/10] [Batch 874/1081] [D loss: 0.078648] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.534931] time: 0:40:26.034155\n",
      "(10, 128, 128, 3)\n",
      "0.9405969\n",
      "[Epoch 4/10] [Batch 875/1081] [D loss: 0.079203] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.492890] time: 0:40:26.424327\n",
      "(10, 128, 128, 3)\n",
      "0.9277813\n",
      "[Epoch 4/10] [Batch 876/1081] [D loss: 0.078698] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.332404] time: 0:40:26.830758\n",
      "(10, 128, 128, 3)\n",
      "0.96506625\n",
      "[Epoch 4/10] [Batch 877/1081] [D loss: 0.078424] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.809363] time: 0:40:27.256602\n",
      "(10, 128, 128, 3)\n",
      "0.93747157\n",
      "[Epoch 4/10] [Batch 878/1081] [D loss: 0.078556] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.036658] time: 0:40:27.662738\n",
      "(10, 128, 128, 3)\n",
      "0.96725965\n",
      "[Epoch 4/10] [Batch 879/1081] [D loss: 0.078936] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.496165] time: 0:40:28.076289\n",
      "(10, 128, 128, 3)\n",
      "0.90907025\n",
      "[Epoch 4/10] [Batch 880/1081] [D loss: 0.078273] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.765414] time: 0:40:28.478885\n",
      "(10, 128, 128, 3)\n",
      "0.890179\n",
      "[Epoch 4/10] [Batch 881/1081] [D loss: 0.078259] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.888531] time: 0:40:28.893656\n",
      "(10, 128, 128, 3)\n",
      "0.90008956\n",
      "[Epoch 4/10] [Batch 882/1081] [D loss: 0.078317] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.525914] time: 0:40:29.325180\n",
      "(10, 128, 128, 3)\n",
      "0.92014664\n",
      "[Epoch 4/10] [Batch 883/1081] [D loss: 0.078991] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.735960] time: 0:40:29.762271\n",
      "(10, 128, 128, 3)\n",
      "0.93800646\n",
      "[Epoch 4/10] [Batch 884/1081] [D loss: 0.078109] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.318339] time: 0:40:30.205483\n",
      "(10, 128, 128, 3)\n",
      "0.9361546\n",
      "[Epoch 4/10] [Batch 885/1081] [D loss: 0.078294] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.274867] time: 0:40:30.608228\n",
      "(10, 128, 128, 3)\n",
      "0.8707542\n",
      "[Epoch 4/10] [Batch 886/1081] [D loss: 0.078199] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.571725] time: 0:40:31.054360\n",
      "(10, 128, 128, 3)\n",
      "0.89976645\n",
      "[Epoch 4/10] [Batch 887/1081] [D loss: 0.079111] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.058454] time: 0:40:31.455145\n",
      "(10, 128, 128, 3)\n",
      "0.91970253\n",
      "[Epoch 4/10] [Batch 888/1081] [D loss: 0.078717] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.618123] time: 0:40:31.861588\n",
      "(10, 128, 128, 3)\n",
      "0.9035397\n",
      "[Epoch 4/10] [Batch 889/1081] [D loss: 0.078338] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.462589] time: 0:40:32.285296\n",
      "(10, 128, 128, 3)\n",
      "0.95994616\n",
      "[Epoch 4/10] [Batch 890/1081] [D loss: 0.077800] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.614638] time: 0:40:32.672698\n",
      "(10, 128, 128, 3)\n",
      "0.9013045\n",
      "[Epoch 4/10] [Batch 891/1081] [D loss: 0.078490] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.354750] time: 0:40:33.077219\n",
      "(10, 128, 128, 3)\n",
      "0.8804383\n",
      "[Epoch 4/10] [Batch 892/1081] [D loss: 0.078214] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.143049] time: 0:40:33.480461\n",
      "(10, 128, 128, 3)\n",
      "0.910786\n",
      "[Epoch 4/10] [Batch 893/1081] [D loss: 0.077488] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.724998] time: 0:40:33.895292\n",
      "(10, 128, 128, 3)\n",
      "0.9381769\n",
      "[Epoch 4/10] [Batch 894/1081] [D loss: 0.077915] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.894324] time: 0:40:34.290421\n",
      "(10, 128, 128, 3)\n",
      "0.89225394\n",
      "[Epoch 4/10] [Batch 895/1081] [D loss: 0.078099] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.201167] time: 0:40:34.695604\n",
      "(10, 128, 128, 3)\n",
      "0.90279675\n",
      "[Epoch 4/10] [Batch 896/1081] [D loss: 0.077449] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.576965] time: 0:40:35.158009\n",
      "(10, 128, 128, 3)\n",
      "0.924002\n",
      "[Epoch 4/10] [Batch 897/1081] [D loss: 0.077387] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.524812] time: 0:40:35.586435\n",
      "(10, 128, 128, 3)\n",
      "0.9144778\n",
      "[Epoch 4/10] [Batch 898/1081] [D loss: 0.077443] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.853516] time: 0:40:36.019905\n",
      "(10, 128, 128, 3)\n",
      "0.8820445\n",
      "[Epoch 4/10] [Batch 899/1081] [D loss: 0.077233] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.200913] time: 0:40:36.446749\n",
      "(10, 128, 128, 3)\n",
      "0.9160945\n",
      "[Epoch 4/10] [Batch 900/1081] [D loss: 0.077423] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.382380] time: 0:40:36.866690\n",
      "(10, 128, 128, 3)\n",
      "0.90568846\n",
      "[Epoch 4/10] [Batch 901/1081] [D loss: 0.077957] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.966936] time: 0:40:37.269393\n",
      "(10, 128, 128, 3)\n",
      "0.97343963\n",
      "[Epoch 4/10] [Batch 902/1081] [D loss: 0.077449] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.325780] time: 0:40:37.679481\n",
      "(10, 128, 128, 3)\n",
      "0.9068716\n",
      "[Epoch 4/10] [Batch 903/1081] [D loss: 0.077115] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.696959] time: 0:40:38.095841\n",
      "(10, 128, 128, 3)\n",
      "0.9056271\n",
      "[Epoch 4/10] [Batch 904/1081] [D loss: 0.077346] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.583524] time: 0:40:38.507740\n",
      "(10, 128, 128, 3)\n",
      "0.9517715\n",
      "[Epoch 4/10] [Batch 905/1081] [D loss: 0.077074] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.845712] time: 0:40:38.917880\n",
      "(10, 128, 128, 3)\n",
      "0.86967915\n",
      "[Epoch 4/10] [Batch 906/1081] [D loss: 0.076964] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.257063] time: 0:40:39.311290\n",
      "(10, 128, 128, 3)\n",
      "0.93190974\n",
      "[Epoch 4/10] [Batch 907/1081] [D loss: 0.076777] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.085759] time: 0:40:39.700697\n",
      "(10, 128, 128, 3)\n",
      "0.902457\n",
      "[Epoch 4/10] [Batch 908/1081] [D loss: 0.076987] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.440300] time: 0:40:40.121931\n",
      "(10, 128, 128, 3)\n",
      "0.9397285\n",
      "[Epoch 4/10] [Batch 909/1081] [D loss: 0.077199] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.077074] time: 0:40:40.555421\n",
      "(10, 128, 128, 3)\n",
      "0.898279\n",
      "[Epoch 4/10] [Batch 910/1081] [D loss: 0.077247] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.411147] time: 0:40:40.964658\n",
      "(10, 128, 128, 3)\n",
      "0.9247351\n",
      "[Epoch 4/10] [Batch 911/1081] [D loss: 0.076695] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.992963] time: 0:40:41.400111\n",
      "(10, 128, 128, 3)\n",
      "0.93354607\n",
      "[Epoch 4/10] [Batch 912/1081] [D loss: 0.086315] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.573403] time: 0:40:41.784494\n",
      "(10, 128, 128, 3)\n",
      "0.9316575\n",
      "[Epoch 4/10] [Batch 913/1081] [D loss: 0.077618] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.824019] time: 0:40:42.197832\n",
      "(10, 128, 128, 3)\n",
      "0.88806945\n",
      "[Epoch 4/10] [Batch 914/1081] [D loss: 0.078807] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.745816] time: 0:40:42.590763\n",
      "(10, 128, 128, 3)\n",
      "0.84237486\n",
      "[Epoch 4/10] [Batch 915/1081] [D loss: 0.077662] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.193607] time: 0:40:43.015360\n",
      "(10, 128, 128, 3)\n",
      "0.90500575\n",
      "[Epoch 4/10] [Batch 916/1081] [D loss: 0.076775] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.440123] time: 0:40:43.420172\n",
      "(10, 128, 128, 3)\n",
      "0.8999574\n",
      "[Epoch 4/10] [Batch 917/1081] [D loss: 0.077684] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.826852] time: 0:40:43.865290\n",
      "(10, 128, 128, 3)\n",
      "0.92013556\n",
      "[Epoch 4/10] [Batch 918/1081] [D loss: 0.076963] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.941695] time: 0:40:44.274481\n",
      "(10, 128, 128, 3)\n",
      "0.95701\n",
      "[Epoch 4/10] [Batch 919/1081] [D loss: 0.078076] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.314435] time: 0:40:44.703511\n",
      "(10, 128, 128, 3)\n",
      "0.9084921\n",
      "[Epoch 4/10] [Batch 920/1081] [D loss: 0.076810] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.690107] time: 0:40:45.113209\n",
      "(10, 128, 128, 3)\n",
      "0.93215126\n",
      "[Epoch 4/10] [Batch 921/1081] [D loss: 0.077779] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.578873] time: 0:40:45.544343\n",
      "(10, 128, 128, 3)\n",
      "0.9532315\n",
      "[Epoch 4/10] [Batch 922/1081] [D loss: 0.077826] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.007008] time: 0:40:45.993365\n",
      "(10, 128, 128, 3)\n",
      "0.93605024\n",
      "[Epoch 4/10] [Batch 923/1081] [D loss: 0.077192] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.977961] time: 0:40:46.431316\n",
      "(10, 128, 128, 3)\n",
      "0.92914057\n",
      "[Epoch 4/10] [Batch 924/1081] [D loss: 0.076375] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.954629] time: 0:40:46.859263\n",
      "(10, 128, 128, 3)\n",
      "0.89416736\n",
      "[Epoch 4/10] [Batch 925/1081] [D loss: 0.076425] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.069158] time: 0:40:47.244876\n",
      "(10, 128, 128, 3)\n",
      "0.8518043\n",
      "[Epoch 4/10] [Batch 926/1081] [D loss: 0.076868] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.770600] time: 0:40:47.689977\n",
      "(10, 128, 128, 3)\n",
      "0.9335511\n",
      "[Epoch 4/10] [Batch 927/1081] [D loss: 0.076808] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.730536] time: 0:40:48.097337\n",
      "(10, 128, 128, 3)\n",
      "0.88811904\n",
      "[Epoch 4/10] [Batch 928/1081] [D loss: 0.076392] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.896704] time: 0:40:48.533455\n",
      "(10, 128, 128, 3)\n",
      "0.9174371\n",
      "[Epoch 4/10] [Batch 929/1081] [D loss: 0.076483] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.770916] time: 0:40:48.960133\n",
      "(10, 128, 128, 3)\n",
      "0.9472325\n",
      "[Epoch 4/10] [Batch 930/1081] [D loss: 0.076216] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.507630] time: 0:40:49.382833\n",
      "(10, 128, 128, 3)\n",
      "0.93563277\n",
      "[Epoch 4/10] [Batch 931/1081] [D loss: 0.076165] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.375605] time: 0:40:49.798304\n",
      "(10, 128, 128, 3)\n",
      "0.8858296\n",
      "[Epoch 4/10] [Batch 932/1081] [D loss: 0.076101] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.466878] time: 0:40:50.239981\n",
      "(10, 128, 128, 3)\n",
      "0.8749333\n",
      "[Epoch 4/10] [Batch 933/1081] [D loss: 0.076178] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.093298] time: 0:40:50.692310\n",
      "(10, 128, 128, 3)\n",
      "0.9209885\n",
      "[Epoch 4/10] [Batch 934/1081] [D loss: 0.076662] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.192483] time: 0:40:51.102083\n",
      "(10, 128, 128, 3)\n",
      "0.8786957\n",
      "[Epoch 4/10] [Batch 935/1081] [D loss: 0.076703] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.069855] time: 0:40:51.534904\n",
      "(10, 128, 128, 3)\n",
      "0.9298113\n",
      "[Epoch 4/10] [Batch 936/1081] [D loss: 0.076403] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.940331] time: 0:40:51.971123\n",
      "(10, 128, 128, 3)\n",
      "0.9029234\n",
      "[Epoch 4/10] [Batch 937/1081] [D loss: 0.075975] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.950025] time: 0:40:52.382663\n",
      "(10, 128, 128, 3)\n",
      "0.9313376\n",
      "[Epoch 4/10] [Batch 938/1081] [D loss: 0.076849] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.324472] time: 0:40:52.816719\n",
      "(10, 128, 128, 3)\n",
      "0.90948194\n",
      "[Epoch 4/10] [Batch 939/1081] [D loss: 0.076017] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.352328] time: 0:40:53.224074\n",
      "(10, 128, 128, 3)\n",
      "0.8925182\n",
      "[Epoch 4/10] [Batch 940/1081] [D loss: 0.075516] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.710601] time: 0:40:53.628473\n",
      "(10, 128, 128, 3)\n",
      "0.92330235\n",
      "[Epoch 4/10] [Batch 941/1081] [D loss: 0.075501] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.841244] time: 0:40:54.025950\n",
      "(10, 128, 128, 3)\n",
      "0.90554357\n",
      "[Epoch 4/10] [Batch 942/1081] [D loss: 0.077657] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.709822] time: 0:40:54.411317\n",
      "(10, 128, 128, 3)\n",
      "0.9025174\n",
      "[Epoch 4/10] [Batch 943/1081] [D loss: 0.075502] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.936054] time: 0:40:54.817056\n",
      "(10, 128, 128, 3)\n",
      "0.86704373\n",
      "[Epoch 4/10] [Batch 944/1081] [D loss: 0.075575] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.982181] time: 0:40:55.247621\n",
      "(10, 128, 128, 3)\n",
      "0.9330171\n",
      "[Epoch 4/10] [Batch 945/1081] [D loss: 0.075498] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.148431] time: 0:40:55.639704\n",
      "(10, 128, 128, 3)\n",
      "0.9394436\n",
      "[Epoch 4/10] [Batch 946/1081] [D loss: 0.076137] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.982437] time: 0:40:56.063506\n",
      "(10, 128, 128, 3)\n",
      "0.917867\n",
      "[Epoch 4/10] [Batch 947/1081] [D loss: 0.082173] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.460585] time: 0:40:56.486337\n",
      "(10, 128, 128, 3)\n",
      "0.86031055\n",
      "[Epoch 4/10] [Batch 948/1081] [D loss: 0.080410] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.931159] time: 0:40:56.880720\n",
      "(10, 128, 128, 3)\n",
      "0.89711976\n",
      "[Epoch 4/10] [Batch 949/1081] [D loss: 0.079063] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.951266] time: 0:40:57.263816\n",
      "(10, 128, 128, 3)\n",
      "0.9109025\n",
      "[Epoch 4/10] [Batch 950/1081] [D loss: 0.076499] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.416894] time: 0:40:57.695996\n",
      "(10, 128, 128, 3)\n",
      "0.9204872\n",
      "[Epoch 4/10] [Batch 951/1081] [D loss: 0.076175] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.315456] time: 0:40:58.083627\n",
      "(10, 128, 128, 3)\n",
      "0.9000583\n",
      "[Epoch 4/10] [Batch 952/1081] [D loss: 0.076805] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.149921] time: 0:40:58.488255\n",
      "(10, 128, 128, 3)\n",
      "0.92642254\n",
      "[Epoch 4/10] [Batch 953/1081] [D loss: 0.077187] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.859946] time: 0:40:58.887642\n",
      "(10, 128, 128, 3)\n",
      "0.91710544\n",
      "[Epoch 4/10] [Batch 954/1081] [D loss: 0.287596] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 6.546542] time: 0:40:59.296915\n",
      "(10, 128, 128, 3)\n",
      "0.9367642\n",
      "[Epoch 4/10] [Batch 955/1081] [D loss: 0.090820] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.152555] time: 0:40:59.720185\n",
      "(10, 128, 128, 3)\n",
      "0.93184155\n",
      "[Epoch 4/10] [Batch 956/1081] [D loss: 0.095189] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.304223] time: 0:41:00.144754\n",
      "(10, 128, 128, 3)\n",
      "0.9062745\n",
      "[Epoch 4/10] [Batch 957/1081] [D loss: 0.120356] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.223990] time: 0:41:00.595491\n",
      "(10, 128, 128, 3)\n",
      "0.916498\n",
      "[Epoch 4/10] [Batch 958/1081] [D loss: 0.147785] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.383982] time: 0:41:01.012706\n",
      "(10, 128, 128, 3)\n",
      "0.9145708\n",
      "[Epoch 4/10] [Batch 959/1081] [D loss: 0.270091] [D acc: 0.70 (1.00 real, 0.40 fake)] [G loss: 6.968417] time: 0:41:01.448795\n",
      "(10, 128, 128, 3)\n",
      "0.82968503\n",
      "[Epoch 4/10] [Batch 960/1081] [D loss: 0.120584] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.128329] time: 0:41:01.875956\n",
      "(10, 128, 128, 3)\n",
      "0.93507266\n",
      "[Epoch 4/10] [Batch 961/1081] [D loss: 0.105461] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.217874] time: 0:41:02.283651\n",
      "(10, 128, 128, 3)\n",
      "0.8802767\n",
      "[Epoch 4/10] [Batch 962/1081] [D loss: 0.094862] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.716506] time: 0:41:02.698270\n",
      "(10, 128, 128, 3)\n",
      "0.92381555\n",
      "[Epoch 4/10] [Batch 963/1081] [D loss: 0.104673] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.572386] time: 0:41:03.122225\n",
      "(10, 128, 128, 3)\n",
      "0.8974488\n",
      "[Epoch 4/10] [Batch 964/1081] [D loss: 0.101293] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.108555] time: 0:41:03.493962\n",
      "(10, 128, 128, 3)\n",
      "0.9093597\n",
      "[Epoch 4/10] [Batch 965/1081] [D loss: 0.094766] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.312763] time: 0:41:03.909417\n",
      "(10, 128, 128, 3)\n",
      "0.97700197\n",
      "[Epoch 4/10] [Batch 966/1081] [D loss: 0.095885] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.725762] time: 0:41:04.343328\n",
      "(10, 128, 128, 3)\n",
      "0.9422837\n",
      "[Epoch 4/10] [Batch 967/1081] [D loss: 0.094084] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.205411] time: 0:41:04.759637\n",
      "(10, 128, 128, 3)\n",
      "0.9369219\n",
      "[Epoch 4/10] [Batch 968/1081] [D loss: 0.093357] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.565119] time: 0:41:05.181164\n",
      "(10, 128, 128, 3)\n",
      "0.91109663\n",
      "[Epoch 4/10] [Batch 969/1081] [D loss: 0.091626] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.051421] time: 0:41:05.568743\n",
      "(10, 128, 128, 3)\n",
      "0.9415164\n",
      "[Epoch 4/10] [Batch 970/1081] [D loss: 0.091470] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.329063] time: 0:41:05.976809\n",
      "(10, 128, 128, 3)\n",
      "0.90197676\n",
      "[Epoch 4/10] [Batch 971/1081] [D loss: 0.091947] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.106409] time: 0:41:06.413841\n",
      "(10, 128, 128, 3)\n",
      "0.9337066\n",
      "[Epoch 4/10] [Batch 972/1081] [D loss: 0.092700] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.383314] time: 0:41:06.847500\n",
      "(10, 128, 128, 3)\n",
      "0.925145\n",
      "[Epoch 4/10] [Batch 973/1081] [D loss: 0.090315] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.453138] time: 0:41:07.258063\n",
      "(10, 128, 128, 3)\n",
      "0.9327356\n",
      "[Epoch 4/10] [Batch 974/1081] [D loss: 0.090394] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.741314] time: 0:41:07.667314\n",
      "(10, 128, 128, 3)\n",
      "0.9229727\n",
      "[Epoch 4/10] [Batch 975/1081] [D loss: 0.091971] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.995742] time: 0:41:08.075800\n",
      "(10, 128, 128, 3)\n",
      "0.86766434\n",
      "[Epoch 4/10] [Batch 976/1081] [D loss: 0.091488] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.321000] time: 0:41:08.515763\n",
      "(10, 128, 128, 3)\n",
      "0.9228913\n",
      "[Epoch 4/10] [Batch 977/1081] [D loss: 0.089828] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.910531] time: 0:41:08.932460\n",
      "(10, 128, 128, 3)\n",
      "0.8510468\n",
      "[Epoch 4/10] [Batch 978/1081] [D loss: 0.090097] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.061268] time: 0:41:09.358379\n",
      "(10, 128, 128, 3)\n",
      "0.96645766\n",
      "[Epoch 4/10] [Batch 979/1081] [D loss: 0.090507] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.438886] time: 0:41:09.789067\n",
      "(10, 128, 128, 3)\n",
      "0.9297808\n",
      "[Epoch 4/10] [Batch 980/1081] [D loss: 0.089543] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.831421] time: 0:41:10.190977\n",
      "(10, 128, 128, 3)\n",
      "0.95662236\n",
      "[Epoch 4/10] [Batch 981/1081] [D loss: 0.089088] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.436627] time: 0:41:10.612652\n",
      "(10, 128, 128, 3)\n",
      "0.86619717\n",
      "[Epoch 4/10] [Batch 982/1081] [D loss: 0.089250] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.734612] time: 0:41:11.036866\n",
      "(10, 128, 128, 3)\n",
      "0.9326907\n",
      "[Epoch 4/10] [Batch 983/1081] [D loss: 0.088817] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.617741] time: 0:41:11.449413\n",
      "(10, 128, 128, 3)\n",
      "0.9257753\n",
      "[Epoch 4/10] [Batch 984/1081] [D loss: 0.088279] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.015189] time: 0:41:11.875331\n",
      "(10, 128, 128, 3)\n",
      "0.89794034\n",
      "[Epoch 4/10] [Batch 985/1081] [D loss: 0.088100] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.770171] time: 0:41:12.312379\n",
      "(10, 128, 128, 3)\n",
      "0.93770576\n",
      "[Epoch 4/10] [Batch 986/1081] [D loss: 0.089624] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.171616] time: 0:41:12.723621\n",
      "(10, 128, 128, 3)\n",
      "0.8646972\n",
      "[Epoch 4/10] [Batch 987/1081] [D loss: 0.087760] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.378274] time: 0:41:13.146019\n",
      "(10, 128, 128, 3)\n",
      "0.97754127\n",
      "[Epoch 4/10] [Batch 988/1081] [D loss: 0.088076] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.083584] time: 0:41:13.580584\n",
      "(10, 128, 128, 3)\n",
      "0.901872\n",
      "[Epoch 4/10] [Batch 989/1081] [D loss: 0.088604] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.675585] time: 0:41:14.030262\n",
      "(10, 128, 128, 3)\n",
      "0.9328718\n",
      "[Epoch 4/10] [Batch 990/1081] [D loss: 0.088767] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.698267] time: 0:41:14.427024\n",
      "(10, 128, 128, 3)\n",
      "0.94766974\n",
      "[Epoch 4/10] [Batch 991/1081] [D loss: 0.087530] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.929776] time: 0:41:14.847195\n",
      "(10, 128, 128, 3)\n",
      "0.86382824\n",
      "[Epoch 4/10] [Batch 992/1081] [D loss: 0.087645] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.017621] time: 0:41:15.287862\n",
      "(10, 128, 128, 3)\n",
      "0.91312426\n",
      "[Epoch 4/10] [Batch 993/1081] [D loss: 0.086658] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.163617] time: 0:41:15.718760\n",
      "(10, 128, 128, 3)\n",
      "0.92172766\n",
      "[Epoch 4/10] [Batch 994/1081] [D loss: 0.086611] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.871581] time: 0:41:16.111724\n",
      "(10, 128, 128, 3)\n",
      "0.9294901\n",
      "[Epoch 4/10] [Batch 995/1081] [D loss: 0.086440] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.790283] time: 0:41:16.535405\n",
      "(10, 128, 128, 3)\n",
      "0.9334313\n",
      "[Epoch 4/10] [Batch 996/1081] [D loss: 0.086423] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.859954] time: 0:41:16.934726\n",
      "(10, 128, 128, 3)\n",
      "0.90012765\n",
      "[Epoch 4/10] [Batch 997/1081] [D loss: 0.086624] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.848895] time: 0:41:17.360823\n",
      "(10, 128, 128, 3)\n",
      "0.94221455\n",
      "[Epoch 4/10] [Batch 998/1081] [D loss: 0.086955] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.166566] time: 0:41:17.766567\n",
      "(10, 128, 128, 3)\n",
      "0.931958\n",
      "[Epoch 4/10] [Batch 999/1081] [D loss: 0.087830] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.402421] time: 0:41:18.167816\n",
      "(10, 128, 128, 3)\n",
      "0.9622166\n",
      "[Epoch 4/10] [Batch 1000/1081] [D loss: 0.086386] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.853033] time: 0:41:18.584330\n",
      "(10, 128, 128, 3)\n",
      "0.88400716\n",
      "[Epoch 4/10] [Batch 1001/1081] [D loss: 0.086495] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.868377] time: 0:41:19.013837\n",
      "(10, 128, 128, 3)\n",
      "0.9003942\n",
      "[Epoch 4/10] [Batch 1002/1081] [D loss: 0.086052] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.849029] time: 0:41:19.449699\n",
      "(10, 128, 128, 3)\n",
      "0.87242204\n",
      "[Epoch 4/10] [Batch 1003/1081] [D loss: 0.086060] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.534760] time: 0:41:20.273833\n",
      "(10, 128, 128, 3)\n",
      "0.97082114\n",
      "[Epoch 4/10] [Batch 1004/1081] [D loss: 0.085335] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.435441] time: 0:41:20.726724\n",
      "(10, 128, 128, 3)\n",
      "0.8997088\n",
      "[Epoch 4/10] [Batch 1005/1081] [D loss: 0.085160] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.025224] time: 0:41:21.114266\n",
      "(10, 128, 128, 3)\n",
      "0.8789143\n",
      "[Epoch 4/10] [Batch 1006/1081] [D loss: 0.085373] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.269452] time: 0:41:21.555017\n",
      "(10, 128, 128, 3)\n",
      "0.9275219\n",
      "[Epoch 4/10] [Batch 1007/1081] [D loss: 0.084778] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.513725] time: 0:41:22.027333\n",
      "(10, 128, 128, 3)\n",
      "0.9104213\n",
      "[Epoch 4/10] [Batch 1008/1081] [D loss: 0.084723] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.299706] time: 0:41:22.456801\n",
      "(10, 128, 128, 3)\n",
      "0.90954214\n",
      "[Epoch 4/10] [Batch 1009/1081] [D loss: 0.084869] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.124715] time: 0:41:22.889230\n",
      "(10, 128, 128, 3)\n",
      "0.93316907\n",
      "[Epoch 4/10] [Batch 1010/1081] [D loss: 0.084751] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.347335] time: 0:41:23.294201\n",
      "(10, 128, 128, 3)\n",
      "0.9487701\n",
      "[Epoch 4/10] [Batch 1011/1081] [D loss: 0.084505] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.989310] time: 0:41:23.725466\n",
      "(10, 128, 128, 3)\n",
      "0.91281193\n",
      "[Epoch 4/10] [Batch 1012/1081] [D loss: 0.084621] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.295654] time: 0:41:24.152227\n",
      "(10, 128, 128, 3)\n",
      "0.9223086\n",
      "[Epoch 4/10] [Batch 1013/1081] [D loss: 0.084693] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.462241] time: 0:41:24.597683\n",
      "(10, 128, 128, 3)\n",
      "0.8799836\n",
      "[Epoch 4/10] [Batch 1014/1081] [D loss: 0.084206] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.017160] time: 0:41:25.025987\n",
      "(10, 128, 128, 3)\n",
      "0.94392055\n",
      "[Epoch 4/10] [Batch 1015/1081] [D loss: 0.085798] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.175136] time: 0:41:25.480347\n",
      "(10, 128, 128, 3)\n",
      "0.9201128\n",
      "[Epoch 4/10] [Batch 1016/1081] [D loss: 0.083897] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.936232] time: 0:41:25.924128\n",
      "(10, 128, 128, 3)\n",
      "0.90631837\n",
      "[Epoch 4/10] [Batch 1017/1081] [D loss: 0.084235] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.798774] time: 0:41:26.356558\n",
      "(10, 128, 128, 3)\n",
      "0.84258765\n",
      "[Epoch 4/10] [Batch 1018/1081] [D loss: 0.083394] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.349345] time: 0:41:26.746235\n",
      "(10, 128, 128, 3)\n",
      "0.93670434\n",
      "[Epoch 4/10] [Batch 1019/1081] [D loss: 0.083124] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.618405] time: 0:41:27.158550\n",
      "(10, 128, 128, 3)\n",
      "0.9054775\n",
      "[Epoch 4/10] [Batch 1020/1081] [D loss: 0.083118] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.866537] time: 0:41:27.552686\n",
      "(10, 128, 128, 3)\n",
      "0.91922694\n",
      "[Epoch 4/10] [Batch 1021/1081] [D loss: 0.082715] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.515991] time: 0:41:27.972350\n",
      "(10, 128, 128, 3)\n",
      "0.91867906\n",
      "[Epoch 4/10] [Batch 1022/1081] [D loss: 0.084268] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.874036] time: 0:41:28.361602\n",
      "(10, 128, 128, 3)\n",
      "0.91149694\n",
      "[Epoch 4/10] [Batch 1023/1081] [D loss: 0.083169] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.382816] time: 0:41:28.803883\n",
      "(10, 128, 128, 3)\n",
      "0.9363288\n",
      "[Epoch 4/10] [Batch 1024/1081] [D loss: 0.082865] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.628187] time: 0:41:29.248578\n",
      "(10, 128, 128, 3)\n",
      "0.9197275\n",
      "[Epoch 4/10] [Batch 1025/1081] [D loss: 0.082234] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.168714] time: 0:41:29.691235\n",
      "(10, 128, 128, 3)\n",
      "0.928566\n",
      "[Epoch 4/10] [Batch 1026/1081] [D loss: 0.178251] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.096971] time: 0:41:30.106911\n",
      "(10, 128, 128, 3)\n",
      "0.90582496\n",
      "[Epoch 4/10] [Batch 1027/1081] [D loss: 0.114408] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.318887] time: 0:41:30.524029\n",
      "(10, 128, 128, 3)\n",
      "0.9257581\n",
      "[Epoch 4/10] [Batch 1028/1081] [D loss: 0.116091] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.700064] time: 0:41:30.917878\n",
      "(10, 128, 128, 3)\n",
      "0.91103953\n",
      "[Epoch 4/10] [Batch 1029/1081] [D loss: 0.094269] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.112460] time: 0:41:31.317348\n",
      "(10, 128, 128, 3)\n",
      "0.8611381\n",
      "[Epoch 4/10] [Batch 1030/1081] [D loss: 0.100261] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.187360] time: 0:41:31.739585\n",
      "(10, 128, 128, 3)\n",
      "0.9297113\n",
      "[Epoch 4/10] [Batch 1031/1081] [D loss: 0.093849] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.680907] time: 0:41:32.165303\n",
      "(10, 128, 128, 3)\n",
      "0.8946068\n",
      "[Epoch 4/10] [Batch 1032/1081] [D loss: 0.091175] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.462813] time: 0:41:32.583739\n",
      "(10, 128, 128, 3)\n",
      "0.9100626\n",
      "[Epoch 4/10] [Batch 1033/1081] [D loss: 0.091105] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.911251] time: 0:41:32.993158\n",
      "(10, 128, 128, 3)\n",
      "0.8899042\n",
      "[Epoch 4/10] [Batch 1034/1081] [D loss: 0.092069] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.456099] time: 0:41:33.386559\n",
      "(10, 128, 128, 3)\n",
      "0.859272\n",
      "[Epoch 4/10] [Batch 1035/1081] [D loss: 0.097078] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.739043] time: 0:41:33.793667\n",
      "(10, 128, 128, 3)\n",
      "0.91801095\n",
      "[Epoch 4/10] [Batch 1036/1081] [D loss: 0.094526] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.444908] time: 0:41:34.182650\n",
      "(10, 128, 128, 3)\n",
      "0.90869075\n",
      "[Epoch 4/10] [Batch 1037/1081] [D loss: 0.093293] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.494937] time: 0:41:34.594342\n",
      "(10, 128, 128, 3)\n",
      "0.8732105\n",
      "[Epoch 4/10] [Batch 1038/1081] [D loss: 0.090333] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.247811] time: 0:41:35.013064\n",
      "(10, 128, 128, 3)\n",
      "0.9112518\n",
      "[Epoch 4/10] [Batch 1039/1081] [D loss: 0.091108] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.927527] time: 0:41:35.408612\n",
      "(10, 128, 128, 3)\n",
      "0.89679074\n",
      "[Epoch 4/10] [Batch 1040/1081] [D loss: 0.089806] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.170157] time: 0:41:35.831961\n",
      "(10, 128, 128, 3)\n",
      "0.8893679\n",
      "[Epoch 4/10] [Batch 1041/1081] [D loss: 0.089664] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.418669] time: 0:41:36.215770\n",
      "(10, 128, 128, 3)\n",
      "0.9584076\n",
      "[Epoch 4/10] [Batch 1042/1081] [D loss: 0.088908] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.917309] time: 0:41:36.616519\n",
      "(10, 128, 128, 3)\n",
      "0.9083168\n",
      "[Epoch 4/10] [Batch 1043/1081] [D loss: 0.088964] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.846908] time: 0:41:37.010648\n",
      "(10, 128, 128, 3)\n",
      "0.92305\n",
      "[Epoch 4/10] [Batch 1044/1081] [D loss: 0.088574] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.007898] time: 0:41:37.415735\n",
      "(10, 128, 128, 3)\n",
      "0.9248341\n",
      "[Epoch 4/10] [Batch 1045/1081] [D loss: 0.088974] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.870897] time: 0:41:37.873553\n",
      "(10, 128, 128, 3)\n",
      "0.91502386\n",
      "[Epoch 4/10] [Batch 1046/1081] [D loss: 0.090314] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.548575] time: 0:41:38.323482\n",
      "(10, 128, 128, 3)\n",
      "0.91491413\n",
      "[Epoch 4/10] [Batch 1047/1081] [D loss: 0.089028] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.826201] time: 0:41:38.735356\n",
      "(10, 128, 128, 3)\n",
      "0.86897856\n",
      "[Epoch 4/10] [Batch 1048/1081] [D loss: 0.088835] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.338708] time: 0:41:39.127976\n",
      "(10, 128, 128, 3)\n",
      "0.8726619\n",
      "[Epoch 4/10] [Batch 1049/1081] [D loss: 0.090421] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.854318] time: 0:41:39.553199\n",
      "(10, 128, 128, 3)\n",
      "0.91340524\n",
      "[Epoch 4/10] [Batch 1050/1081] [D loss: 0.091243] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.055129] time: 0:41:40.007938\n",
      "(10, 128, 128, 3)\n",
      "0.9036543\n",
      "[Epoch 4/10] [Batch 1051/1081] [D loss: 0.118285] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.415339] time: 0:41:40.404782\n",
      "(10, 128, 128, 3)\n",
      "0.90104276\n",
      "[Epoch 4/10] [Batch 1052/1081] [D loss: 0.715745] [D acc: 0.25 (0.50 real, 0.00 fake)] [G loss: 40.070705] time: 0:41:40.803739\n",
      "(10, 128, 128, 3)\n",
      "0.9009607\n",
      "[Epoch 4/10] [Batch 1053/1081] [D loss: 0.111064] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 15.072639] time: 0:41:41.221137\n",
      "(10, 128, 128, 3)\n",
      "0.92213243\n",
      "[Epoch 4/10] [Batch 1054/1081] [D loss: 0.123184] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.677680] time: 0:41:41.644451\n",
      "(10, 128, 128, 3)\n",
      "0.879211\n",
      "[Epoch 4/10] [Batch 1055/1081] [D loss: 0.315945] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 10.090508] time: 0:41:42.087993\n",
      "(10, 128, 128, 3)\n",
      "0.93898296\n",
      "[Epoch 4/10] [Batch 1056/1081] [D loss: 0.121527] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.347488] time: 0:41:42.513303\n",
      "(10, 128, 128, 3)\n",
      "0.8740942\n",
      "[Epoch 4/10] [Batch 1057/1081] [D loss: 0.147596] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.162579] time: 0:41:42.931037\n",
      "(10, 128, 128, 3)\n",
      "0.9078321\n",
      "[Epoch 4/10] [Batch 1058/1081] [D loss: 0.532799] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 8.521352] time: 0:41:43.347658\n",
      "(10, 128, 128, 3)\n",
      "0.8448999\n",
      "[Epoch 4/10] [Batch 1059/1081] [D loss: 0.170023] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 8.076808] time: 0:41:43.768640\n",
      "(10, 128, 128, 3)\n",
      "0.889322\n",
      "[Epoch 4/10] [Batch 1060/1081] [D loss: 0.139129] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 8.107085] time: 0:41:44.181948\n",
      "(10, 128, 128, 3)\n",
      "0.90115076\n",
      "[Epoch 4/10] [Batch 1061/1081] [D loss: 0.108522] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.170369] time: 0:41:44.571077\n",
      "(10, 128, 128, 3)\n",
      "0.91730016\n",
      "[Epoch 4/10] [Batch 1062/1081] [D loss: 0.103428] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.044703] time: 0:41:44.947378\n",
      "(10, 128, 128, 3)\n",
      "0.86224395\n",
      "[Epoch 4/10] [Batch 1063/1081] [D loss: 0.092177] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.791388] time: 0:41:45.378065\n",
      "(10, 128, 128, 3)\n",
      "0.9310801\n",
      "[Epoch 4/10] [Batch 1064/1081] [D loss: 0.092995] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.032144] time: 0:41:45.759222\n",
      "(10, 128, 128, 3)\n",
      "0.930522\n",
      "[Epoch 4/10] [Batch 1065/1081] [D loss: 0.091951] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.030611] time: 0:41:46.173095\n",
      "(10, 128, 128, 3)\n",
      "0.91031814\n",
      "[Epoch 4/10] [Batch 1066/1081] [D loss: 0.091518] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.721688] time: 0:41:46.572353\n",
      "(10, 128, 128, 3)\n",
      "0.8763339\n",
      "[Epoch 4/10] [Batch 1067/1081] [D loss: 0.091269] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.520144] time: 0:41:46.971120\n",
      "(10, 128, 128, 3)\n",
      "0.92559355\n",
      "[Epoch 4/10] [Batch 1068/1081] [D loss: 0.249428] [D acc: 0.60 (0.20 real, 1.00 fake)] [G loss: 6.854262] time: 0:41:47.374815\n",
      "(10, 128, 128, 3)\n",
      "0.932703\n",
      "[Epoch 4/10] [Batch 1069/1081] [D loss: 0.099669] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.742371] time: 0:41:47.824792\n",
      "(10, 128, 128, 3)\n",
      "0.92421764\n",
      "[Epoch 4/10] [Batch 1070/1081] [D loss: 0.095919] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.624886] time: 0:41:48.235122\n",
      "(10, 128, 128, 3)\n",
      "0.8612806\n",
      "[Epoch 4/10] [Batch 1071/1081] [D loss: 0.093257] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.167021] time: 0:41:48.681760\n",
      "(10, 128, 128, 3)\n",
      "0.908364\n",
      "[Epoch 4/10] [Batch 1072/1081] [D loss: 0.095981] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.679058] time: 0:41:49.069307\n",
      "(10, 128, 128, 3)\n",
      "0.8869827\n",
      "[Epoch 4/10] [Batch 1073/1081] [D loss: 0.092223] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.459549] time: 0:41:49.496445\n",
      "(10, 128, 128, 3)\n",
      "0.8715796\n",
      "[Epoch 4/10] [Batch 1074/1081] [D loss: 0.092167] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.129312] time: 0:41:49.915319\n",
      "(10, 128, 128, 3)\n",
      "0.9609635\n",
      "[Epoch 4/10] [Batch 1075/1081] [D loss: 0.092688] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.761127] time: 0:41:50.329482\n",
      "(10, 128, 128, 3)\n",
      "0.8917799\n",
      "[Epoch 4/10] [Batch 1076/1081] [D loss: 0.091547] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.182286] time: 0:41:50.727427\n",
      "(10, 128, 128, 3)\n",
      "0.9083247\n",
      "[Epoch 4/10] [Batch 1077/1081] [D loss: 0.099614] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.116148] time: 0:41:51.149251\n",
      "(10, 128, 128, 3)\n",
      "0.91629\n",
      "[Epoch 4/10] [Batch 1078/1081] [D loss: 0.092991] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.971624] time: 0:41:51.526321\n",
      "(10, 128, 128, 3)\n",
      "0.953279\n",
      "[Epoch 4/10] [Batch 1079/1081] [D loss: 0.092343] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.246816] time: 0:41:51.912637\n",
      "(10, 128, 128, 3)\n",
      "0.92037034\n",
      "[Epoch 4/10] [Batch 1080/1081] [D loss: 0.094005] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.176110] time: 0:41:52.309887\n",
      "############ VALIDATION OF EPOCH 4 ############\n",
      "############ TRAINING OF EPOCH 5 ############\n",
      "(10, 128, 128, 3)\n",
      "0.9409129\n",
      "[Epoch 5/10] [Batch 0/1081] [D loss: 0.092813] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.786363] time: 0:42:34.626819\n",
      "(10, 128, 128, 3)\n",
      "0.94106644\n",
      "[Epoch 5/10] [Batch 1/1081] [D loss: 0.092022] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.881637] time: 0:42:35.042292\n",
      "(10, 128, 128, 3)\n",
      "0.94104403\n",
      "[Epoch 5/10] [Batch 2/1081] [D loss: 0.090203] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.846602] time: 0:42:35.455524\n",
      "(10, 128, 128, 3)\n",
      "0.95063305\n",
      "[Epoch 5/10] [Batch 4/1081] [D loss: 0.091897] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.107610] time: 0:42:35.888424\n",
      "(10, 128, 128, 3)\n",
      "0.9380434\n",
      "[Epoch 5/10] [Batch 5/1081] [D loss: 0.089894] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.606032] time: 0:42:36.330089\n",
      "(10, 128, 128, 3)\n",
      "0.88784003\n",
      "[Epoch 5/10] [Batch 6/1081] [D loss: 0.089662] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.695253] time: 0:42:36.766718\n",
      "(10, 128, 128, 3)\n",
      "0.93122935\n",
      "[Epoch 5/10] [Batch 7/1081] [D loss: 0.090684] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.581632] time: 0:42:37.192105\n",
      "(10, 128, 128, 3)\n",
      "0.9490139\n",
      "[Epoch 5/10] [Batch 8/1081] [D loss: 0.093335] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.873909] time: 0:42:37.622684\n",
      "(10, 128, 128, 3)\n",
      "0.8980257\n",
      "[Epoch 5/10] [Batch 9/1081] [D loss: 0.089967] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.343039] time: 0:42:38.018832\n",
      "(10, 128, 128, 3)\n",
      "0.9289196\n",
      "[Epoch 5/10] [Batch 10/1081] [D loss: 0.089810] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.172717] time: 0:42:38.444700\n",
      "(10, 128, 128, 3)\n",
      "0.9056141\n",
      "[Epoch 5/10] [Batch 11/1081] [D loss: 0.089191] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.856372] time: 0:42:38.898562\n",
      "(10, 128, 128, 3)\n",
      "0.97610044\n",
      "[Epoch 5/10] [Batch 12/1081] [D loss: 0.088699] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.472024] time: 0:42:39.302329\n",
      "(10, 128, 128, 3)\n",
      "0.93053466\n",
      "[Epoch 5/10] [Batch 13/1081] [D loss: 0.087626] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.741693] time: 0:42:39.708994\n",
      "(10, 128, 128, 3)\n",
      "0.8780496\n",
      "[Epoch 5/10] [Batch 14/1081] [D loss: 0.087364] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.515665] time: 0:42:40.116314\n",
      "(10, 128, 128, 3)\n",
      "0.9072015\n",
      "[Epoch 5/10] [Batch 15/1081] [D loss: 0.087502] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.215650] time: 0:42:40.515405\n",
      "(10, 128, 128, 3)\n",
      "0.90308636\n",
      "[Epoch 5/10] [Batch 16/1081] [D loss: 0.093954] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.887457] time: 0:42:40.932083\n",
      "(10, 128, 128, 3)\n",
      "0.9194946\n",
      "[Epoch 5/10] [Batch 17/1081] [D loss: 0.088400] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.554539] time: 0:42:41.355147\n",
      "(10, 128, 128, 3)\n",
      "0.9125955\n",
      "[Epoch 5/10] [Batch 18/1081] [D loss: 0.088310] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.422864] time: 0:42:41.746577\n",
      "(10, 128, 128, 3)\n",
      "0.9517762\n",
      "[Epoch 5/10] [Batch 19/1081] [D loss: 0.087189] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.632493] time: 0:42:42.158353\n",
      "(10, 128, 128, 3)\n",
      "0.85816216\n",
      "[Epoch 5/10] [Batch 20/1081] [D loss: 0.091354] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.845106] time: 0:42:42.556777\n",
      "(10, 128, 128, 3)\n",
      "0.917145\n",
      "[Epoch 5/10] [Batch 21/1081] [D loss: 0.086481] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.910487] time: 0:42:42.970471\n",
      "(10, 128, 128, 3)\n",
      "0.8669383\n",
      "[Epoch 5/10] [Batch 22/1081] [D loss: 0.087153] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.085281] time: 0:42:43.429501\n",
      "(10, 128, 128, 3)\n",
      "0.94359857\n",
      "[Epoch 5/10] [Batch 23/1081] [D loss: 0.087735] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.226164] time: 0:42:43.859655\n",
      "(10, 128, 128, 3)\n",
      "0.8505356\n",
      "[Epoch 5/10] [Batch 24/1081] [D loss: 0.089889] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.261915] time: 0:42:44.283755\n",
      "(10, 128, 128, 3)\n",
      "0.9071064\n",
      "[Epoch 5/10] [Batch 25/1081] [D loss: 0.088475] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.374545] time: 0:42:44.719694\n",
      "(10, 128, 128, 3)\n",
      "0.913407\n",
      "[Epoch 5/10] [Batch 26/1081] [D loss: 0.087409] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.161902] time: 0:42:45.137088\n",
      "(10, 128, 128, 3)\n",
      "0.8968508\n",
      "[Epoch 5/10] [Batch 27/1081] [D loss: 0.086653] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.119067] time: 0:42:45.541783\n",
      "(10, 128, 128, 3)\n",
      "0.9355156\n",
      "[Epoch 5/10] [Batch 28/1081] [D loss: 0.090937] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.509993] time: 0:42:45.974449\n",
      "(10, 128, 128, 3)\n",
      "0.9469953\n",
      "[Epoch 5/10] [Batch 29/1081] [D loss: 0.094612] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 11.840810] time: 0:42:46.385458\n",
      "(10, 128, 128, 3)\n",
      "0.8529246\n",
      "[Epoch 5/10] [Batch 30/1081] [D loss: 0.087615] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.695621] time: 0:42:46.793921\n",
      "(10, 128, 128, 3)\n",
      "0.95682573\n",
      "[Epoch 5/10] [Batch 31/1081] [D loss: 0.085256] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.176329] time: 0:42:47.211072\n",
      "(10, 128, 128, 3)\n",
      "0.9044474\n",
      "[Epoch 5/10] [Batch 32/1081] [D loss: 0.087742] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.646594] time: 0:42:47.607126\n",
      "(10, 128, 128, 3)\n",
      "0.9272411\n",
      "[Epoch 5/10] [Batch 33/1081] [D loss: 0.086038] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.323260] time: 0:42:48.012694\n",
      "(10, 128, 128, 3)\n",
      "0.90743214\n",
      "[Epoch 5/10] [Batch 34/1081] [D loss: 0.086196] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.660817] time: 0:42:48.413038\n",
      "(10, 128, 128, 3)\n",
      "0.9171414\n",
      "[Epoch 5/10] [Batch 35/1081] [D loss: 0.084990] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.305897] time: 0:42:48.825483\n",
      "(10, 128, 128, 3)\n",
      "0.92661697\n",
      "[Epoch 5/10] [Batch 36/1081] [D loss: 0.086715] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.112276] time: 0:42:49.207905\n",
      "(10, 128, 128, 3)\n",
      "0.91612434\n",
      "[Epoch 5/10] [Batch 37/1081] [D loss: 0.084918] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.447772] time: 0:42:49.626597\n",
      "(10, 128, 128, 3)\n",
      "0.9370381\n",
      "[Epoch 5/10] [Batch 38/1081] [D loss: 0.084315] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.754152] time: 0:42:50.031865\n",
      "(10, 128, 128, 3)\n",
      "0.97668386\n",
      "[Epoch 5/10] [Batch 39/1081] [D loss: 0.084902] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.306792] time: 0:42:50.467738\n",
      "(10, 128, 128, 3)\n",
      "0.8853319\n",
      "[Epoch 5/10] [Batch 40/1081] [D loss: 0.084876] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.746226] time: 0:42:50.894348\n",
      "(10, 128, 128, 3)\n",
      "0.923682\n",
      "[Epoch 5/10] [Batch 41/1081] [D loss: 0.084410] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.775015] time: 0:42:51.294171\n",
      "(10, 128, 128, 3)\n",
      "0.9043378\n",
      "[Epoch 5/10] [Batch 42/1081] [D loss: 0.083709] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.504594] time: 0:42:51.675590\n",
      "(10, 128, 128, 3)\n",
      "0.94633174\n",
      "[Epoch 5/10] [Batch 43/1081] [D loss: 0.084233] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.241940] time: 0:42:52.109200\n",
      "(10, 128, 128, 3)\n",
      "0.9407368\n",
      "[Epoch 5/10] [Batch 44/1081] [D loss: 0.085764] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.871906] time: 0:42:52.515661\n",
      "(10, 128, 128, 3)\n",
      "0.8946819\n",
      "[Epoch 5/10] [Batch 45/1081] [D loss: 0.083363] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.956672] time: 0:42:52.959524\n",
      "(10, 128, 128, 3)\n",
      "0.9252723\n",
      "[Epoch 5/10] [Batch 46/1081] [D loss: 0.083456] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.463209] time: 0:42:53.362127\n",
      "(10, 128, 128, 3)\n",
      "0.9436185\n",
      "[Epoch 5/10] [Batch 47/1081] [D loss: 0.083121] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.275497] time: 0:42:53.771841\n",
      "(10, 128, 128, 3)\n",
      "0.91370565\n",
      "[Epoch 5/10] [Batch 48/1081] [D loss: 0.083431] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.714438] time: 0:42:54.202846\n",
      "(10, 128, 128, 3)\n",
      "0.9257571\n",
      "[Epoch 5/10] [Batch 49/1081] [D loss: 0.082966] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.471982] time: 0:42:54.614795\n",
      "(10, 128, 128, 3)\n",
      "0.89180326\n",
      "[Epoch 5/10] [Batch 50/1081] [D loss: 0.083513] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.301641] time: 0:42:55.016736\n",
      "(10, 128, 128, 3)\n",
      "0.921041\n",
      "[Epoch 5/10] [Batch 51/1081] [D loss: 0.082917] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.161833] time: 0:42:55.420727\n",
      "(10, 128, 128, 3)\n",
      "0.88560945\n",
      "[Epoch 5/10] [Batch 52/1081] [D loss: 0.083812] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.857343] time: 0:42:55.829894\n",
      "(10, 128, 128, 3)\n",
      "0.9102402\n",
      "[Epoch 5/10] [Batch 53/1081] [D loss: 0.087697] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.356152] time: 0:42:56.216075\n",
      "(10, 128, 128, 3)\n",
      "0.9069261\n",
      "[Epoch 5/10] [Batch 54/1081] [D loss: 0.088980] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.070748] time: 0:42:56.635679\n",
      "(10, 128, 128, 3)\n",
      "0.98275566\n",
      "[Epoch 5/10] [Batch 55/1081] [D loss: 0.084429] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.363310] time: 0:42:57.065422\n",
      "(10, 128, 128, 3)\n",
      "0.93065023\n",
      "[Epoch 5/10] [Batch 56/1081] [D loss: 0.082901] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.537241] time: 0:42:57.494580\n",
      "(10, 128, 128, 3)\n",
      "0.933316\n",
      "[Epoch 5/10] [Batch 57/1081] [D loss: 0.082019] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.720671] time: 0:42:57.897756\n",
      "(10, 128, 128, 3)\n",
      "0.95480424\n",
      "[Epoch 5/10] [Batch 58/1081] [D loss: 0.082002] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.916745] time: 0:42:58.311638\n",
      "(10, 128, 128, 3)\n",
      "0.960073\n",
      "[Epoch 5/10] [Batch 59/1081] [D loss: 0.082317] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.950988] time: 0:42:58.718922\n",
      "(10, 128, 128, 3)\n",
      "0.864209\n",
      "[Epoch 5/10] [Batch 60/1081] [D loss: 0.082309] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.221515] time: 0:42:59.161878\n",
      "(10, 128, 128, 3)\n",
      "0.90525675\n",
      "[Epoch 5/10] [Batch 61/1081] [D loss: 0.083298] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.900674] time: 0:42:59.558982\n",
      "(10, 128, 128, 3)\n",
      "0.8945642\n",
      "[Epoch 5/10] [Batch 62/1081] [D loss: 0.085362] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.838288] time: 0:42:59.960329\n",
      "(10, 128, 128, 3)\n",
      "0.94490504\n",
      "[Epoch 5/10] [Batch 63/1081] [D loss: 0.081685] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.195014] time: 0:43:00.386173\n",
      "(10, 128, 128, 3)\n",
      "0.9085594\n",
      "[Epoch 5/10] [Batch 64/1081] [D loss: 0.081310] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.057576] time: 0:43:00.825393\n",
      "(10, 128, 128, 3)\n",
      "0.8703372\n",
      "[Epoch 5/10] [Batch 65/1081] [D loss: 0.304651] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 6.907653] time: 0:43:01.203399\n",
      "(10, 128, 128, 3)\n",
      "0.93576807\n",
      "[Epoch 5/10] [Batch 66/1081] [D loss: 0.111764] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.394083] time: 0:43:01.624677\n",
      "(10, 128, 128, 3)\n",
      "0.8415203\n",
      "[Epoch 5/10] [Batch 67/1081] [D loss: 0.379041] [D acc: 0.55 (0.10 real, 1.00 fake)] [G loss: 8.597092] time: 0:43:02.038814\n",
      "(10, 128, 128, 3)\n",
      "0.9244687\n",
      "[Epoch 5/10] [Batch 68/1081] [D loss: 0.189731] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.853664] time: 0:43:02.467170\n",
      "(10, 128, 128, 3)\n",
      "0.8632355\n",
      "[Epoch 5/10] [Batch 69/1081] [D loss: 0.130982] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.862527] time: 0:43:02.866680\n",
      "(10, 128, 128, 3)\n",
      "0.9484086\n",
      "[Epoch 5/10] [Batch 70/1081] [D loss: 0.090835] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.639125] time: 0:43:03.300745\n",
      "(10, 128, 128, 3)\n",
      "0.8981741\n",
      "[Epoch 5/10] [Batch 71/1081] [D loss: 0.092578] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.283288] time: 0:43:03.706199\n",
      "(10, 128, 128, 3)\n",
      "0.95603365\n",
      "[Epoch 5/10] [Batch 72/1081] [D loss: 0.100885] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.083899] time: 0:43:04.118404\n",
      "(10, 128, 128, 3)\n",
      "0.9505105\n",
      "[Epoch 5/10] [Batch 73/1081] [D loss: 0.098621] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.139965] time: 0:43:04.494554\n",
      "(10, 128, 128, 3)\n",
      "0.9065519\n",
      "[Epoch 5/10] [Batch 74/1081] [D loss: 0.098872] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.838105] time: 0:43:04.872895\n",
      "(10, 128, 128, 3)\n",
      "0.94902927\n",
      "[Epoch 5/10] [Batch 75/1081] [D loss: 0.092569] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.079597] time: 0:43:05.296940\n",
      "(10, 128, 128, 3)\n",
      "0.90712863\n",
      "[Epoch 5/10] [Batch 76/1081] [D loss: 0.095610] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.269687] time: 0:43:05.710609\n",
      "(10, 128, 128, 3)\n",
      "0.9029476\n",
      "[Epoch 5/10] [Batch 77/1081] [D loss: 0.096982] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.914598] time: 0:43:06.111064\n",
      "(10, 128, 128, 3)\n",
      "0.84747815\n",
      "[Epoch 5/10] [Batch 78/1081] [D loss: 0.096488] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.972366] time: 0:43:06.507637\n",
      "(10, 128, 128, 3)\n",
      "0.91611886\n",
      "[Epoch 5/10] [Batch 79/1081] [D loss: 0.098917] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.837949] time: 0:43:06.901046\n",
      "(10, 128, 128, 3)\n",
      "0.9317289\n",
      "[Epoch 5/10] [Batch 80/1081] [D loss: 0.090388] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.366765] time: 0:43:07.318077\n",
      "(10, 128, 128, 3)\n",
      "0.8896144\n",
      "[Epoch 5/10] [Batch 81/1081] [D loss: 0.094191] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.683782] time: 0:43:07.743322\n",
      "(10, 128, 128, 3)\n",
      "0.9013767\n",
      "[Epoch 5/10] [Batch 82/1081] [D loss: 0.091353] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.523644] time: 0:43:08.168289\n",
      "(10, 128, 128, 3)\n",
      "0.9365754\n",
      "[Epoch 5/10] [Batch 83/1081] [D loss: 0.090217] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.922788] time: 0:43:08.582500\n",
      "(10, 128, 128, 3)\n",
      "0.88945776\n",
      "[Epoch 5/10] [Batch 84/1081] [D loss: 0.089334] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.859337] time: 0:43:08.984055\n",
      "(10, 128, 128, 3)\n",
      "0.90507096\n",
      "[Epoch 5/10] [Batch 85/1081] [D loss: 0.092310] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.995206] time: 0:43:09.394746\n",
      "(10, 128, 128, 3)\n",
      "0.960063\n",
      "[Epoch 5/10] [Batch 86/1081] [D loss: 0.090399] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.360715] time: 0:43:09.787113\n",
      "(10, 128, 128, 3)\n",
      "0.8525374\n",
      "[Epoch 5/10] [Batch 87/1081] [D loss: 0.089167] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.280529] time: 0:43:10.239141\n",
      "(10, 128, 128, 3)\n",
      "0.92199427\n",
      "[Epoch 5/10] [Batch 88/1081] [D loss: 0.090692] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.330706] time: 0:43:10.624959\n",
      "(10, 128, 128, 3)\n",
      "0.9085811\n",
      "[Epoch 5/10] [Batch 89/1081] [D loss: 0.088231] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.239939] time: 0:43:11.017110\n",
      "(10, 128, 128, 3)\n",
      "0.91621447\n",
      "[Epoch 5/10] [Batch 90/1081] [D loss: 0.088507] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.088089] time: 0:43:11.431871\n",
      "(10, 128, 128, 3)\n",
      "0.9459217\n",
      "[Epoch 5/10] [Batch 91/1081] [D loss: 0.088799] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.298409] time: 0:43:11.837583\n",
      "(10, 128, 128, 3)\n",
      "0.94293815\n",
      "[Epoch 5/10] [Batch 92/1081] [D loss: 0.087975] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.746770] time: 0:43:12.222437\n",
      "(10, 128, 128, 3)\n",
      "0.9155924\n",
      "[Epoch 5/10] [Batch 93/1081] [D loss: 0.092324] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.347511] time: 0:43:12.623106\n",
      "(10, 128, 128, 3)\n",
      "0.8848699\n",
      "[Epoch 5/10] [Batch 94/1081] [D loss: 0.088096] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.104472] time: 0:43:13.037715\n",
      "(10, 128, 128, 3)\n",
      "0.916869\n",
      "[Epoch 5/10] [Batch 95/1081] [D loss: 0.088893] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.561229] time: 0:43:13.469868\n",
      "(10, 128, 128, 3)\n",
      "0.91881037\n",
      "[Epoch 5/10] [Batch 96/1081] [D loss: 0.093914] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.723428] time: 0:43:13.913132\n",
      "(10, 128, 128, 3)\n",
      "0.92985153\n",
      "[Epoch 5/10] [Batch 97/1081] [D loss: 0.093323] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.307589] time: 0:43:14.341304\n",
      "(10, 128, 128, 3)\n",
      "0.9574559\n",
      "[Epoch 5/10] [Batch 98/1081] [D loss: 0.089392] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.879326] time: 0:43:14.771162\n",
      "(10, 128, 128, 3)\n",
      "0.9399483\n",
      "[Epoch 5/10] [Batch 99/1081] [D loss: 0.089229] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.967391] time: 0:43:15.164339\n",
      "(10, 128, 128, 3)\n",
      "0.94150704\n",
      "[Epoch 5/10] [Batch 100/1081] [D loss: 0.087427] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.937681] time: 0:43:15.601694\n",
      "(10, 128, 128, 3)\n",
      "0.85506815\n",
      "[Epoch 5/10] [Batch 101/1081] [D loss: 0.087232] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.039125] time: 0:43:16.008285\n",
      "(10, 128, 128, 3)\n",
      "0.8960448\n",
      "[Epoch 5/10] [Batch 102/1081] [D loss: 0.087640] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.031192] time: 0:43:16.418470\n",
      "(10, 128, 128, 3)\n",
      "0.91683006\n",
      "[Epoch 5/10] [Batch 103/1081] [D loss: 0.087097] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.495581] time: 0:43:16.828222\n",
      "(10, 128, 128, 3)\n",
      "0.9051998\n",
      "[Epoch 5/10] [Batch 104/1081] [D loss: 0.086410] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.006963] time: 0:43:17.256503\n",
      "(10, 128, 128, 3)\n",
      "0.9079948\n",
      "[Epoch 5/10] [Batch 105/1081] [D loss: 0.087409] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.177133] time: 0:43:17.649021\n",
      "(10, 128, 128, 3)\n",
      "0.8480823\n",
      "[Epoch 5/10] [Batch 106/1081] [D loss: 0.087305] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.010700] time: 0:43:18.104848\n",
      "(10, 128, 128, 3)\n",
      "0.89897704\n",
      "[Epoch 5/10] [Batch 107/1081] [D loss: 0.087831] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.635239] time: 0:43:18.544828\n",
      "(10, 128, 128, 3)\n",
      "0.90703243\n",
      "[Epoch 5/10] [Batch 108/1081] [D loss: 0.085857] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.364346] time: 0:43:18.939818\n",
      "(10, 128, 128, 3)\n",
      "0.94090104\n",
      "[Epoch 5/10] [Batch 109/1081] [D loss: 0.087032] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.010664] time: 0:43:19.319019\n",
      "(10, 128, 128, 3)\n",
      "0.9264323\n",
      "[Epoch 5/10] [Batch 110/1081] [D loss: 0.086109] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.770560] time: 0:43:19.713067\n",
      "(10, 128, 128, 3)\n",
      "0.960262\n",
      "[Epoch 5/10] [Batch 111/1081] [D loss: 0.085749] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.734972] time: 0:43:20.151158\n",
      "(10, 128, 128, 3)\n",
      "0.9396568\n",
      "[Epoch 5/10] [Batch 112/1081] [D loss: 0.085732] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.743299] time: 0:43:20.565677\n",
      "(10, 128, 128, 3)\n",
      "0.88415813\n",
      "[Epoch 5/10] [Batch 113/1081] [D loss: 0.084490] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.948407] time: 0:43:20.986540\n",
      "(10, 128, 128, 3)\n",
      "0.91411084\n",
      "[Epoch 5/10] [Batch 114/1081] [D loss: 0.085307] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.499176] time: 0:43:21.401416\n",
      "(10, 128, 128, 3)\n",
      "0.9333578\n",
      "[Epoch 5/10] [Batch 115/1081] [D loss: 0.084390] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.577927] time: 0:43:21.825635\n",
      "(10, 128, 128, 3)\n",
      "0.91600543\n",
      "[Epoch 5/10] [Batch 116/1081] [D loss: 0.084326] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.403220] time: 0:43:22.245364\n",
      "(10, 128, 128, 3)\n",
      "0.9447302\n",
      "[Epoch 5/10] [Batch 117/1081] [D loss: 0.084488] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.355109] time: 0:43:22.652512\n",
      "(10, 128, 128, 3)\n",
      "0.9317029\n",
      "[Epoch 5/10] [Batch 118/1081] [D loss: 0.084611] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.370183] time: 0:43:23.062133\n",
      "(10, 128, 128, 3)\n",
      "0.8822215\n",
      "[Epoch 5/10] [Batch 119/1081] [D loss: 0.084333] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.773379] time: 0:43:23.498645\n",
      "(10, 128, 128, 3)\n",
      "0.96370906\n",
      "[Epoch 5/10] [Batch 120/1081] [D loss: 0.085742] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.107044] time: 0:43:23.908609\n",
      "(10, 128, 128, 3)\n",
      "0.9082965\n",
      "[Epoch 5/10] [Batch 121/1081] [D loss: 0.083739] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.680344] time: 0:43:24.309189\n",
      "(10, 128, 128, 3)\n",
      "0.8756717\n",
      "[Epoch 5/10] [Batch 122/1081] [D loss: 0.083899] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.103391] time: 0:43:24.735091\n",
      "(10, 128, 128, 3)\n",
      "0.9155767\n",
      "[Epoch 5/10] [Batch 123/1081] [D loss: 0.084088] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.765512] time: 0:43:25.131285\n",
      "(10, 128, 128, 3)\n",
      "0.907901\n",
      "[Epoch 5/10] [Batch 124/1081] [D loss: 0.083546] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.232266] time: 0:43:25.559426\n",
      "(10, 128, 128, 3)\n",
      "0.88776463\n",
      "[Epoch 5/10] [Batch 125/1081] [D loss: 0.083713] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.678951] time: 0:43:25.974398\n",
      "(10, 128, 128, 3)\n",
      "0.9367821\n",
      "[Epoch 5/10] [Batch 126/1081] [D loss: 0.084419] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.995834] time: 0:43:26.381115\n",
      "(10, 128, 128, 3)\n",
      "0.911557\n",
      "[Epoch 5/10] [Batch 127/1081] [D loss: 0.083233] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.849935] time: 0:43:26.814300\n",
      "(10, 128, 128, 3)\n",
      "0.8756301\n",
      "[Epoch 5/10] [Batch 128/1081] [D loss: 0.083621] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.560275] time: 0:43:27.263073\n",
      "(10, 128, 128, 3)\n",
      "0.93731576\n",
      "[Epoch 5/10] [Batch 129/1081] [D loss: 0.083042] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.084140] time: 0:43:27.668383\n",
      "(10, 128, 128, 3)\n",
      "0.8906059\n",
      "[Epoch 5/10] [Batch 130/1081] [D loss: 0.082614] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.260842] time: 0:43:28.119284\n",
      "(10, 128, 128, 3)\n",
      "0.9103109\n",
      "[Epoch 5/10] [Batch 131/1081] [D loss: 0.082575] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.306176] time: 0:43:28.536487\n",
      "(10, 128, 128, 3)\n",
      "0.8830071\n",
      "[Epoch 5/10] [Batch 132/1081] [D loss: 0.082305] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.117148] time: 0:43:28.940366\n",
      "(10, 128, 128, 3)\n",
      "0.940543\n",
      "[Epoch 5/10] [Batch 133/1081] [D loss: 0.084525] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.789012] time: 0:43:29.357107\n",
      "(10, 128, 128, 3)\n",
      "0.8838563\n",
      "[Epoch 5/10] [Batch 134/1081] [D loss: 0.082463] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.524527] time: 0:43:29.772055\n",
      "(10, 128, 128, 3)\n",
      "0.9334077\n",
      "[Epoch 5/10] [Batch 135/1081] [D loss: 0.082232] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.396818] time: 0:43:30.184152\n",
      "(10, 128, 128, 3)\n",
      "0.93817955\n",
      "[Epoch 5/10] [Batch 136/1081] [D loss: 0.082096] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.862706] time: 0:43:30.647688\n",
      "(10, 128, 128, 3)\n",
      "0.88900566\n",
      "[Epoch 5/10] [Batch 137/1081] [D loss: 0.082101] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.368353] time: 0:43:31.073863\n",
      "(10, 128, 128, 3)\n",
      "0.85068583\n",
      "[Epoch 5/10] [Batch 138/1081] [D loss: 0.081836] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.188778] time: 0:43:31.478968\n",
      "(10, 128, 128, 3)\n",
      "0.8985756\n",
      "[Epoch 5/10] [Batch 139/1081] [D loss: 0.081559] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.402351] time: 0:43:31.885075\n",
      "(10, 128, 128, 3)\n",
      "0.91200143\n",
      "[Epoch 5/10] [Batch 140/1081] [D loss: 0.082256] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.998610] time: 0:43:32.275976\n",
      "(10, 128, 128, 3)\n",
      "0.9230202\n",
      "[Epoch 5/10] [Batch 141/1081] [D loss: 0.082558] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.883704] time: 0:43:32.712679\n",
      "(10, 128, 128, 3)\n",
      "0.9037444\n",
      "[Epoch 5/10] [Batch 142/1081] [D loss: 0.082052] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.900303] time: 0:43:33.127335\n",
      "(10, 128, 128, 3)\n",
      "0.9116252\n",
      "[Epoch 5/10] [Batch 143/1081] [D loss: 0.081594] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.558748] time: 0:43:33.552245\n",
      "(10, 128, 128, 3)\n",
      "0.935363\n",
      "[Epoch 5/10] [Batch 144/1081] [D loss: 0.081730] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.955640] time: 0:43:34.002256\n",
      "(10, 128, 128, 3)\n",
      "0.9143133\n",
      "[Epoch 5/10] [Batch 145/1081] [D loss: 0.081397] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.746745] time: 0:43:34.400518\n",
      "(10, 128, 128, 3)\n",
      "0.8703967\n",
      "[Epoch 5/10] [Batch 146/1081] [D loss: 0.081480] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.073996] time: 0:43:34.856124\n",
      "(10, 128, 128, 3)\n",
      "0.9176064\n",
      "[Epoch 5/10] [Batch 147/1081] [D loss: 0.080898] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.520831] time: 0:43:35.298416\n",
      "(10, 128, 128, 3)\n",
      "0.9384718\n",
      "[Epoch 5/10] [Batch 148/1081] [D loss: 0.083865] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.408807] time: 0:43:35.714393\n",
      "(10, 128, 128, 3)\n",
      "0.88660145\n",
      "[Epoch 5/10] [Batch 149/1081] [D loss: 0.080935] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.032188] time: 0:43:36.158886\n",
      "(10, 128, 128, 3)\n",
      "0.9533625\n",
      "[Epoch 5/10] [Batch 150/1081] [D loss: 0.081064] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.286968] time: 0:43:36.598379\n",
      "(10, 128, 128, 3)\n",
      "0.8724819\n",
      "[Epoch 5/10] [Batch 151/1081] [D loss: 0.080905] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.836621] time: 0:43:37.039847\n",
      "(10, 128, 128, 3)\n",
      "0.8994632\n",
      "[Epoch 5/10] [Batch 152/1081] [D loss: 0.080858] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.522624] time: 0:43:37.443779\n",
      "(10, 128, 128, 3)\n",
      "0.9624638\n",
      "[Epoch 5/10] [Batch 153/1081] [D loss: 0.080842] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.592753] time: 0:43:37.900031\n",
      "(10, 128, 128, 3)\n",
      "0.8881151\n",
      "[Epoch 5/10] [Batch 154/1081] [D loss: 0.080802] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.890646] time: 0:43:38.304647\n",
      "(10, 128, 128, 3)\n",
      "0.9319999\n",
      "[Epoch 5/10] [Batch 155/1081] [D loss: 0.080902] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.456511] time: 0:43:38.737173\n",
      "(10, 128, 128, 3)\n",
      "0.9438274\n",
      "[Epoch 5/10] [Batch 156/1081] [D loss: 0.079729] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.889958] time: 0:43:39.120827\n",
      "(10, 128, 128, 3)\n",
      "0.9037418\n",
      "[Epoch 5/10] [Batch 157/1081] [D loss: 0.079619] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.377122] time: 0:43:39.530482\n",
      "(10, 128, 128, 3)\n",
      "0.9147742\n",
      "[Epoch 5/10] [Batch 158/1081] [D loss: 0.079830] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.530311] time: 0:43:39.921913\n",
      "(10, 128, 128, 3)\n",
      "0.96223027\n",
      "[Epoch 5/10] [Batch 159/1081] [D loss: 0.079505] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.653510] time: 0:43:40.352471\n",
      "(10, 128, 128, 3)\n",
      "0.9039158\n",
      "[Epoch 5/10] [Batch 160/1081] [D loss: 0.079318] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.574235] time: 0:43:40.758801\n",
      "(10, 128, 128, 3)\n",
      "0.86403614\n",
      "[Epoch 5/10] [Batch 161/1081] [D loss: 0.079504] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.254590] time: 0:43:41.167891\n",
      "(10, 128, 128, 3)\n",
      "0.9149106\n",
      "[Epoch 5/10] [Batch 162/1081] [D loss: 0.080099] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.165386] time: 0:43:41.579182\n",
      "(10, 128, 128, 3)\n",
      "0.9223699\n",
      "[Epoch 5/10] [Batch 163/1081] [D loss: 0.078951] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.677533] time: 0:43:41.975267\n",
      "(10, 128, 128, 3)\n",
      "0.9180034\n",
      "[Epoch 5/10] [Batch 164/1081] [D loss: 0.080383] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.499184] time: 0:43:42.369868\n",
      "(10, 128, 128, 3)\n",
      "0.906807\n",
      "[Epoch 5/10] [Batch 165/1081] [D loss: 0.079610] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.961951] time: 0:43:42.755507\n",
      "(10, 128, 128, 3)\n",
      "0.9453366\n",
      "[Epoch 5/10] [Batch 166/1081] [D loss: 0.078762] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.248077] time: 0:43:43.159441\n",
      "(10, 128, 128, 3)\n",
      "0.9658025\n",
      "[Epoch 5/10] [Batch 167/1081] [D loss: 0.079066] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.644153] time: 0:43:43.592133\n",
      "(10, 128, 128, 3)\n",
      "0.9203833\n",
      "[Epoch 5/10] [Batch 168/1081] [D loss: 0.079522] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.088920] time: 0:43:43.975249\n",
      "(10, 128, 128, 3)\n",
      "0.8963533\n",
      "[Epoch 5/10] [Batch 169/1081] [D loss: 0.078608] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.593903] time: 0:43:44.397644\n",
      "(10, 128, 128, 3)\n",
      "0.893812\n",
      "[Epoch 5/10] [Batch 170/1081] [D loss: 0.078852] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.491418] time: 0:43:44.807658\n",
      "(10, 128, 128, 3)\n",
      "0.8878751\n",
      "[Epoch 5/10] [Batch 171/1081] [D loss: 0.078622] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.958757] time: 0:43:45.240353\n",
      "(10, 128, 128, 3)\n",
      "0.8886853\n",
      "[Epoch 5/10] [Batch 172/1081] [D loss: 0.078633] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.806661] time: 0:43:45.688181\n",
      "(10, 128, 128, 3)\n",
      "0.8307155\n",
      "[Epoch 5/10] [Batch 173/1081] [D loss: 0.078653] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.250362] time: 0:43:46.129673\n",
      "(10, 128, 128, 3)\n",
      "0.90148467\n",
      "[Epoch 5/10] [Batch 174/1081] [D loss: 0.078120] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.380414] time: 0:43:46.557169\n",
      "(10, 128, 128, 3)\n",
      "0.92942303\n",
      "[Epoch 5/10] [Batch 175/1081] [D loss: 0.078863] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.770232] time: 0:43:46.967731\n",
      "(10, 128, 128, 3)\n",
      "0.85526913\n",
      "[Epoch 5/10] [Batch 176/1081] [D loss: 0.078767] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.725953] time: 0:43:47.415126\n",
      "(10, 128, 128, 3)\n",
      "0.93867356\n",
      "[Epoch 5/10] [Batch 177/1081] [D loss: 0.077784] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.746800] time: 0:43:47.840348\n",
      "(10, 128, 128, 3)\n",
      "0.8769873\n",
      "[Epoch 5/10] [Batch 178/1081] [D loss: 0.079774] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.384727] time: 0:43:48.262129\n",
      "(10, 128, 128, 3)\n",
      "0.89262646\n",
      "[Epoch 5/10] [Batch 179/1081] [D loss: 0.078035] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.355748] time: 0:43:48.694048\n",
      "(10, 128, 128, 3)\n",
      "0.92103845\n",
      "[Epoch 5/10] [Batch 180/1081] [D loss: 0.079395] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.445595] time: 0:43:49.116689\n",
      "(10, 128, 128, 3)\n",
      "0.8921447\n",
      "[Epoch 5/10] [Batch 181/1081] [D loss: 0.079751] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.097809] time: 0:43:49.532752\n",
      "(10, 128, 128, 3)\n",
      "0.94712305\n",
      "[Epoch 5/10] [Batch 182/1081] [D loss: 0.078095] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.304837] time: 0:43:49.973902\n",
      "(10, 128, 128, 3)\n",
      "0.91276115\n",
      "[Epoch 5/10] [Batch 183/1081] [D loss: 0.078996] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.357533] time: 0:43:50.378802\n",
      "(10, 128, 128, 3)\n",
      "0.94628716\n",
      "[Epoch 5/10] [Batch 184/1081] [D loss: 0.077349] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.231849] time: 0:43:50.803852\n",
      "(10, 128, 128, 3)\n",
      "0.96879935\n",
      "[Epoch 5/10] [Batch 185/1081] [D loss: 0.077578] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.608753] time: 0:43:51.204563\n",
      "(10, 128, 128, 3)\n",
      "0.9693082\n",
      "[Epoch 5/10] [Batch 186/1081] [D loss: 0.077289] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.666030] time: 0:43:51.626819\n",
      "(10, 128, 128, 3)\n",
      "0.87327904\n",
      "[Epoch 5/10] [Batch 187/1081] [D loss: 0.077257] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.080453] time: 0:43:52.036061\n",
      "(10, 128, 128, 3)\n",
      "0.9287177\n",
      "[Epoch 5/10] [Batch 188/1081] [D loss: 0.079331] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.252080] time: 0:43:52.426106\n",
      "(10, 128, 128, 3)\n",
      "0.93904966\n",
      "[Epoch 5/10] [Batch 189/1081] [D loss: 0.077650] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.556224] time: 0:43:52.841695\n",
      "(10, 128, 128, 3)\n",
      "0.8976701\n",
      "[Epoch 5/10] [Batch 190/1081] [D loss: 0.077370] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.517293] time: 0:43:53.242790\n",
      "(10, 128, 128, 3)\n",
      "0.92404455\n",
      "[Epoch 5/10] [Batch 191/1081] [D loss: 0.077541] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.555377] time: 0:43:53.665793\n",
      "(10, 128, 128, 3)\n",
      "0.88719755\n",
      "[Epoch 5/10] [Batch 192/1081] [D loss: 0.077442] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.704465] time: 0:43:54.092129\n",
      "(10, 128, 128, 3)\n",
      "0.93296\n",
      "[Epoch 5/10] [Batch 193/1081] [D loss: 0.076898] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.083006] time: 0:43:54.520807\n",
      "(10, 128, 128, 3)\n",
      "0.9438215\n",
      "[Epoch 5/10] [Batch 194/1081] [D loss: 0.078156] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.980828] time: 0:43:54.941883\n",
      "(10, 128, 128, 3)\n",
      "0.95083624\n",
      "[Epoch 5/10] [Batch 195/1081] [D loss: 0.076918] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.800204] time: 0:43:55.355180\n",
      "(10, 128, 128, 3)\n",
      "0.85932857\n",
      "[Epoch 5/10] [Batch 196/1081] [D loss: 0.076500] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.476472] time: 0:43:55.768587\n",
      "(10, 128, 128, 3)\n",
      "0.93134147\n",
      "[Epoch 5/10] [Batch 197/1081] [D loss: 0.076431] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.690973] time: 0:43:56.205463\n",
      "(10, 128, 128, 3)\n",
      "0.917567\n",
      "[Epoch 5/10] [Batch 198/1081] [D loss: 0.076378] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.954574] time: 0:43:56.640674\n",
      "(10, 128, 128, 3)\n",
      "0.8964041\n",
      "[Epoch 5/10] [Batch 199/1081] [D loss: 0.076145] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.311727] time: 0:43:57.079685\n",
      "(10, 128, 128, 3)\n",
      "0.9182784\n",
      "[Epoch 5/10] [Batch 200/1081] [D loss: 0.076155] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.194565] time: 0:43:57.509958\n",
      "(10, 128, 128, 3)\n",
      "0.9452012\n",
      "[Epoch 5/10] [Batch 201/1081] [D loss: 0.076263] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.677076] time: 0:43:57.928397\n",
      "(10, 128, 128, 3)\n",
      "0.92755824\n",
      "[Epoch 5/10] [Batch 202/1081] [D loss: 0.078530] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.511287] time: 0:43:58.349235\n",
      "(10, 128, 128, 3)\n",
      "0.9271286\n",
      "[Epoch 5/10] [Batch 203/1081] [D loss: 0.539590] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 6.925817] time: 0:43:58.788207\n",
      "(10, 128, 128, 3)\n",
      "0.9336954\n",
      "[Epoch 5/10] [Batch 204/1081] [D loss: 0.113465] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.341399] time: 0:43:59.201553\n",
      "(10, 128, 128, 3)\n",
      "0.9026497\n",
      "[Epoch 5/10] [Batch 205/1081] [D loss: 0.218382] [D acc: 0.90 (1.00 real, 0.80 fake)] [G loss: 7.998829] time: 0:43:59.625040\n",
      "(10, 128, 128, 3)\n",
      "0.9384579\n",
      "[Epoch 5/10] [Batch 206/1081] [D loss: 0.102000] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.052218] time: 0:44:00.063712\n",
      "(10, 128, 128, 3)\n",
      "0.93439436\n",
      "[Epoch 5/10] [Batch 207/1081] [D loss: 0.205417] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 5.795150] time: 0:44:00.478229\n",
      "(10, 128, 128, 3)\n",
      "0.9315257\n",
      "[Epoch 5/10] [Batch 208/1081] [D loss: 0.089411] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.906078] time: 0:44:00.888734\n",
      "(10, 128, 128, 3)\n",
      "0.88638204\n",
      "[Epoch 5/10] [Batch 209/1081] [D loss: 0.081885] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.081185] time: 0:44:01.291754\n",
      "(10, 128, 128, 3)\n",
      "0.924964\n",
      "[Epoch 5/10] [Batch 210/1081] [D loss: 0.081904] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.208201] time: 0:44:01.704989\n",
      "(10, 128, 128, 3)\n",
      "0.91687703\n",
      "[Epoch 5/10] [Batch 211/1081] [D loss: 0.080988] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.607881] time: 0:44:02.150829\n",
      "(10, 128, 128, 3)\n",
      "0.9223823\n",
      "[Epoch 5/10] [Batch 212/1081] [D loss: 0.081719] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.597006] time: 0:44:02.572698\n",
      "(10, 128, 128, 3)\n",
      "0.91117954\n",
      "[Epoch 5/10] [Batch 213/1081] [D loss: 0.080234] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.119119] time: 0:44:03.001939\n",
      "(10, 128, 128, 3)\n",
      "0.87865514\n",
      "[Epoch 5/10] [Batch 214/1081] [D loss: 0.080344] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.640944] time: 0:44:03.436461\n",
      "(10, 128, 128, 3)\n",
      "0.9340126\n",
      "[Epoch 5/10] [Batch 215/1081] [D loss: 0.093349] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.047374] time: 0:44:03.835104\n",
      "(10, 128, 128, 3)\n",
      "0.8819664\n",
      "[Epoch 5/10] [Batch 216/1081] [D loss: 0.079345] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.178674] time: 0:44:04.250165\n",
      "(10, 128, 128, 3)\n",
      "0.892132\n",
      "[Epoch 5/10] [Batch 217/1081] [D loss: 0.085678] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.441251] time: 0:44:04.687358\n",
      "(10, 128, 128, 3)\n",
      "0.90813345\n",
      "[Epoch 5/10] [Batch 218/1081] [D loss: 0.080852] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.518035] time: 0:44:05.102452\n",
      "(10, 128, 128, 3)\n",
      "0.904938\n",
      "[Epoch 5/10] [Batch 219/1081] [D loss: 0.078043] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.469346] time: 0:44:05.516772\n",
      "(10, 128, 128, 3)\n",
      "0.9275697\n",
      "[Epoch 5/10] [Batch 220/1081] [D loss: 0.080724] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.845963] time: 0:44:05.940409\n",
      "(10, 128, 128, 3)\n",
      "0.9590788\n",
      "[Epoch 5/10] [Batch 221/1081] [D loss: 0.080882] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.877183] time: 0:44:06.363863\n",
      "(10, 128, 128, 3)\n",
      "0.9586563\n",
      "[Epoch 5/10] [Batch 222/1081] [D loss: 0.078797] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.080832] time: 0:44:06.759334\n",
      "(10, 128, 128, 3)\n",
      "0.98123485\n",
      "[Epoch 5/10] [Batch 223/1081] [D loss: 0.079368] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.987829] time: 0:44:07.157325\n",
      "(10, 128, 128, 3)\n",
      "0.89881593\n",
      "[Epoch 5/10] [Batch 224/1081] [D loss: 0.078100] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.801403] time: 0:44:07.561076\n",
      "(10, 128, 128, 3)\n",
      "0.937092\n",
      "[Epoch 5/10] [Batch 225/1081] [D loss: 0.077403] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.423148] time: 0:44:07.975745\n",
      "(10, 128, 128, 3)\n",
      "0.9107311\n",
      "[Epoch 5/10] [Batch 226/1081] [D loss: 0.078198] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.208373] time: 0:44:08.406867\n",
      "(10, 128, 128, 3)\n",
      "0.9540855\n",
      "[Epoch 5/10] [Batch 227/1081] [D loss: 0.077545] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.730236] time: 0:44:08.828118\n",
      "(10, 128, 128, 3)\n",
      "0.92417526\n",
      "[Epoch 5/10] [Batch 228/1081] [D loss: 0.077369] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.183602] time: 0:44:09.256592\n",
      "(10, 128, 128, 3)\n",
      "0.95383185\n",
      "[Epoch 5/10] [Batch 229/1081] [D loss: 0.076882] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.085801] time: 0:44:09.683302\n",
      "(10, 128, 128, 3)\n",
      "0.9096604\n",
      "[Epoch 5/10] [Batch 230/1081] [D loss: 0.076821] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.346516] time: 0:44:10.157133\n",
      "(10, 128, 128, 3)\n",
      "0.91500884\n",
      "[Epoch 5/10] [Batch 231/1081] [D loss: 0.076555] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.381977] time: 0:44:10.596385\n",
      "(10, 128, 128, 3)\n",
      "0.91934806\n",
      "[Epoch 5/10] [Batch 232/1081] [D loss: 0.076949] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.009521] time: 0:44:11.015342\n",
      "(10, 128, 128, 3)\n",
      "0.94977087\n",
      "[Epoch 5/10] [Batch 233/1081] [D loss: 0.076833] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.530997] time: 0:44:11.414947\n",
      "(10, 128, 128, 3)\n",
      "0.9395755\n",
      "[Epoch 5/10] [Batch 234/1081] [D loss: 0.076364] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.512932] time: 0:44:11.847099\n",
      "(10, 128, 128, 3)\n",
      "0.93631786\n",
      "[Epoch 5/10] [Batch 235/1081] [D loss: 0.089127] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.685655] time: 0:44:12.267245\n",
      "(10, 128, 128, 3)\n",
      "0.8990182\n",
      "[Epoch 5/10] [Batch 236/1081] [D loss: 0.076634] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.286275] time: 0:44:12.659756\n",
      "(10, 128, 128, 3)\n",
      "0.9228496\n",
      "[Epoch 5/10] [Batch 237/1081] [D loss: 0.080429] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.216099] time: 0:44:13.048347\n",
      "(10, 128, 128, 3)\n",
      "0.9172111\n",
      "[Epoch 5/10] [Batch 238/1081] [D loss: 0.077719] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.382079] time: 0:44:13.493138\n",
      "(10, 128, 128, 3)\n",
      "0.88609093\n",
      "[Epoch 5/10] [Batch 239/1081] [D loss: 0.076894] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.086633] time: 0:44:13.910350\n",
      "(10, 128, 128, 3)\n",
      "0.9546725\n",
      "[Epoch 5/10] [Batch 240/1081] [D loss: 0.076000] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.711585] time: 0:44:14.335597\n",
      "(10, 128, 128, 3)\n",
      "0.88871104\n",
      "[Epoch 5/10] [Batch 241/1081] [D loss: 0.079415] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.128127] time: 0:44:14.764499\n",
      "(10, 128, 128, 3)\n",
      "0.9266882\n",
      "[Epoch 5/10] [Batch 242/1081] [D loss: 0.076521] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.035640] time: 0:44:15.193081\n",
      "(10, 128, 128, 3)\n",
      "0.9344767\n",
      "[Epoch 5/10] [Batch 243/1081] [D loss: 0.076073] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.707315] time: 0:44:15.607765\n",
      "(10, 128, 128, 3)\n",
      "0.93406886\n",
      "[Epoch 5/10] [Batch 244/1081] [D loss: 0.076777] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.863469] time: 0:44:15.998540\n",
      "(10, 128, 128, 3)\n",
      "0.9412288\n",
      "[Epoch 5/10] [Batch 245/1081] [D loss: 0.075946] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.476253] time: 0:44:16.394158\n",
      "(10, 128, 128, 3)\n",
      "0.9143582\n",
      "[Epoch 5/10] [Batch 246/1081] [D loss: 0.077210] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.209518] time: 0:44:16.800519\n",
      "(10, 128, 128, 3)\n",
      "0.89674425\n",
      "[Epoch 5/10] [Batch 247/1081] [D loss: 0.076008] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.798455] time: 0:44:17.212449\n",
      "(10, 128, 128, 3)\n",
      "0.8836747\n",
      "[Epoch 5/10] [Batch 248/1081] [D loss: 0.077969] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.428162] time: 0:44:17.604903\n",
      "(10, 128, 128, 3)\n",
      "0.9286867\n",
      "[Epoch 5/10] [Batch 249/1081] [D loss: 0.076073] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.038936] time: 0:44:18.024273\n",
      "(10, 128, 128, 3)\n",
      "0.88656026\n",
      "[Epoch 5/10] [Batch 250/1081] [D loss: 0.077380] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.938527] time: 0:44:18.441200\n",
      "(10, 128, 128, 3)\n",
      "0.8827445\n",
      "[Epoch 5/10] [Batch 251/1081] [D loss: 0.077547] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.977143] time: 0:44:18.879244\n",
      "(10, 128, 128, 3)\n",
      "0.89114285\n",
      "[Epoch 5/10] [Batch 252/1081] [D loss: 0.075237] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.475497] time: 0:44:19.287437\n",
      "(10, 128, 128, 3)\n",
      "0.9005732\n",
      "[Epoch 5/10] [Batch 253/1081] [D loss: 0.075026] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.404546] time: 0:44:19.672659\n",
      "(10, 128, 128, 3)\n",
      "0.9278443\n",
      "[Epoch 5/10] [Batch 254/1081] [D loss: 0.089369] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.242747] time: 0:44:20.079129\n",
      "(10, 128, 128, 3)\n",
      "0.9694417\n",
      "[Epoch 5/10] [Batch 255/1081] [D loss: 0.078679] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.219991] time: 0:44:20.489313\n",
      "(10, 128, 128, 3)\n",
      "0.9300235\n",
      "[Epoch 5/10] [Batch 256/1081] [D loss: 0.074644] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.019895] time: 0:44:20.913483\n",
      "(10, 128, 128, 3)\n",
      "0.89306825\n",
      "[Epoch 5/10] [Batch 257/1081] [D loss: 0.076748] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.813052] time: 0:44:21.296449\n",
      "(10, 128, 128, 3)\n",
      "0.92722183\n",
      "[Epoch 5/10] [Batch 258/1081] [D loss: 0.078023] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.602397] time: 0:44:21.715743\n",
      "(10, 128, 128, 3)\n",
      "0.9310792\n",
      "[Epoch 5/10] [Batch 259/1081] [D loss: 0.074486] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.492552] time: 0:44:22.150390\n",
      "(10, 128, 128, 3)\n",
      "0.90415144\n",
      "[Epoch 5/10] [Batch 260/1081] [D loss: 0.074979] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.392894] time: 0:44:22.580716\n",
      "(10, 128, 128, 3)\n",
      "0.90600747\n",
      "[Epoch 5/10] [Batch 261/1081] [D loss: 0.075969] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.848468] time: 0:44:22.988894\n",
      "(10, 128, 128, 3)\n",
      "0.9264013\n",
      "[Epoch 5/10] [Batch 262/1081] [D loss: 0.075364] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.088225] time: 0:44:23.385250\n",
      "(10, 128, 128, 3)\n",
      "0.90212053\n",
      "[Epoch 5/10] [Batch 263/1081] [D loss: 0.074189] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.082342] time: 0:44:23.805727\n",
      "(10, 128, 128, 3)\n",
      "0.91607976\n",
      "[Epoch 5/10] [Batch 264/1081] [D loss: 0.074166] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.653993] time: 0:44:24.211391\n",
      "(10, 128, 128, 3)\n",
      "0.8681058\n",
      "[Epoch 5/10] [Batch 265/1081] [D loss: 0.074894] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.261773] time: 0:44:24.647869\n",
      "(10, 128, 128, 3)\n",
      "0.9803107\n",
      "[Epoch 5/10] [Batch 266/1081] [D loss: 0.074739] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.158700] time: 0:44:25.071529\n",
      "(10, 128, 128, 3)\n",
      "0.9486857\n",
      "[Epoch 5/10] [Batch 267/1081] [D loss: 0.076669] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.127374] time: 0:44:25.463679\n",
      "(10, 128, 128, 3)\n",
      "0.92423946\n",
      "[Epoch 5/10] [Batch 268/1081] [D loss: 0.074551] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.834651] time: 0:44:25.877690\n",
      "(10, 128, 128, 3)\n",
      "0.93179303\n",
      "[Epoch 5/10] [Batch 269/1081] [D loss: 0.074037] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.194655] time: 0:44:26.291800\n",
      "(10, 128, 128, 3)\n",
      "0.91508794\n",
      "[Epoch 5/10] [Batch 270/1081] [D loss: 0.074228] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.894849] time: 0:44:26.716120\n",
      "(10, 128, 128, 3)\n",
      "0.89775616\n",
      "[Epoch 5/10] [Batch 271/1081] [D loss: 0.074969] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.642451] time: 0:44:27.110131\n",
      "(10, 128, 128, 3)\n",
      "0.87781364\n",
      "[Epoch 5/10] [Batch 272/1081] [D loss: 0.074578] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.079198] time: 0:44:27.512368\n",
      "(10, 128, 128, 3)\n",
      "0.9161236\n",
      "[Epoch 5/10] [Batch 273/1081] [D loss: 0.073808] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.817752] time: 0:44:27.955564\n",
      "(10, 128, 128, 3)\n",
      "0.9416029\n",
      "[Epoch 5/10] [Batch 274/1081] [D loss: 0.073182] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.552690] time: 0:44:28.385026\n",
      "(10, 128, 128, 3)\n",
      "0.88228697\n",
      "[Epoch 5/10] [Batch 275/1081] [D loss: 0.073261] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.066432] time: 0:44:28.831136\n",
      "(10, 128, 128, 3)\n",
      "0.93183726\n",
      "[Epoch 5/10] [Batch 276/1081] [D loss: 0.073299] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.801217] time: 0:44:29.233471\n",
      "(10, 128, 128, 3)\n",
      "0.91424185\n",
      "[Epoch 5/10] [Batch 277/1081] [D loss: 0.072813] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.096931] time: 0:44:29.633614\n",
      "(10, 128, 128, 3)\n",
      "0.94390005\n",
      "[Epoch 5/10] [Batch 278/1081] [D loss: 0.073670] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.727362] time: 0:44:30.039088\n",
      "(10, 128, 128, 3)\n",
      "0.92349815\n",
      "[Epoch 5/10] [Batch 279/1081] [D loss: 0.073426] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.779689] time: 0:44:30.436203\n",
      "(10, 128, 128, 3)\n",
      "0.94654894\n",
      "[Epoch 5/10] [Batch 280/1081] [D loss: 0.073771] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.783751] time: 0:44:30.863075\n",
      "(10, 128, 128, 3)\n",
      "0.9371236\n",
      "[Epoch 5/10] [Batch 281/1081] [D loss: 0.074179] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.121219] time: 0:44:31.282505\n",
      "(10, 128, 128, 3)\n",
      "0.9003124\n",
      "[Epoch 5/10] [Batch 282/1081] [D loss: 0.073148] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.859410] time: 0:44:31.674852\n",
      "(10, 128, 128, 3)\n",
      "0.8728571\n",
      "[Epoch 5/10] [Batch 283/1081] [D loss: 0.072781] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.567047] time: 0:44:32.078782\n",
      "(10, 128, 128, 3)\n",
      "0.87960696\n",
      "[Epoch 5/10] [Batch 284/1081] [D loss: 0.072755] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.306174] time: 0:44:32.500297\n",
      "(10, 128, 128, 3)\n",
      "0.9850795\n",
      "[Epoch 5/10] [Batch 285/1081] [D loss: 0.072371] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.164454] time: 0:44:32.902450\n",
      "(10, 128, 128, 3)\n",
      "0.94612694\n",
      "[Epoch 5/10] [Batch 286/1081] [D loss: 0.072515] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.869165] time: 0:44:33.304756\n",
      "(10, 128, 128, 3)\n",
      "0.9412813\n",
      "[Epoch 5/10] [Batch 287/1081] [D loss: 0.072776] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.458400] time: 0:44:33.749381\n",
      "(10, 128, 128, 3)\n",
      "0.94256586\n",
      "[Epoch 5/10] [Batch 288/1081] [D loss: 0.074277] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.048328] time: 0:44:34.191607\n",
      "(10, 128, 128, 3)\n",
      "0.9015813\n",
      "[Epoch 5/10] [Batch 289/1081] [D loss: 0.072859] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.345289] time: 0:44:34.590497\n",
      "(10, 128, 128, 3)\n",
      "0.92023283\n",
      "[Epoch 5/10] [Batch 290/1081] [D loss: 0.072201] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.794778] time: 0:44:34.991917\n",
      "(10, 128, 128, 3)\n",
      "0.9162173\n",
      "[Epoch 5/10] [Batch 291/1081] [D loss: 0.072235] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.571912] time: 0:44:35.398592\n",
      "(10, 128, 128, 3)\n",
      "0.8868885\n",
      "[Epoch 5/10] [Batch 292/1081] [D loss: 0.073182] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.726743] time: 0:44:35.852667\n",
      "(10, 128, 128, 3)\n",
      "0.88131166\n",
      "[Epoch 5/10] [Batch 293/1081] [D loss: 0.071888] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.208033] time: 0:44:36.249794\n",
      "(10, 128, 128, 3)\n",
      "0.9047708\n",
      "[Epoch 5/10] [Batch 294/1081] [D loss: 0.071846] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.311810] time: 0:44:36.665484\n",
      "(10, 128, 128, 3)\n",
      "0.8870372\n",
      "[Epoch 5/10] [Batch 295/1081] [D loss: 0.072124] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.706621] time: 0:44:37.081323\n",
      "(10, 128, 128, 3)\n",
      "0.8574689\n",
      "[Epoch 5/10] [Batch 296/1081] [D loss: 0.072052] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.535439] time: 0:44:37.476299\n",
      "(10, 128, 128, 3)\n",
      "0.9106026\n",
      "[Epoch 5/10] [Batch 297/1081] [D loss: 0.072671] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.725842] time: 0:44:37.887970\n",
      "(10, 128, 128, 3)\n",
      "0.9407638\n",
      "[Epoch 5/10] [Batch 298/1081] [D loss: 0.072823] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.256166] time: 0:44:38.323963\n",
      "(10, 128, 128, 3)\n",
      "0.9467271\n",
      "[Epoch 5/10] [Batch 299/1081] [D loss: 0.071700] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.328114] time: 0:44:38.759084\n",
      "(10, 128, 128, 3)\n",
      "0.91280574\n",
      "[Epoch 5/10] [Batch 300/1081] [D loss: 0.071759] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.512574] time: 0:44:39.160998\n",
      "(10, 128, 128, 3)\n",
      "0.90685135\n",
      "[Epoch 5/10] [Batch 301/1081] [D loss: 0.071608] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.367013] time: 0:44:39.581264\n",
      "(10, 128, 128, 3)\n",
      "0.8979294\n",
      "[Epoch 5/10] [Batch 302/1081] [D loss: 0.071310] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.917604] time: 0:44:39.995064\n",
      "(10, 128, 128, 3)\n",
      "0.91999024\n",
      "[Epoch 5/10] [Batch 303/1081] [D loss: 0.071960] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.053258] time: 0:44:40.427465\n",
      "(10, 128, 128, 3)\n",
      "0.9269554\n",
      "[Epoch 5/10] [Batch 304/1081] [D loss: 0.071640] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.060415] time: 0:44:40.837405\n",
      "(10, 128, 128, 3)\n",
      "0.931216\n",
      "[Epoch 5/10] [Batch 305/1081] [D loss: 0.071147] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.581134] time: 0:44:41.250239\n",
      "(10, 128, 128, 3)\n",
      "0.8757255\n",
      "[Epoch 5/10] [Batch 306/1081] [D loss: 0.071498] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.181891] time: 0:44:41.662894\n",
      "(10, 128, 128, 3)\n",
      "0.9085347\n",
      "[Epoch 5/10] [Batch 307/1081] [D loss: 0.071215] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.245994] time: 0:44:42.109345\n",
      "(10, 128, 128, 3)\n",
      "0.89107877\n",
      "[Epoch 5/10] [Batch 308/1081] [D loss: 0.071094] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.741858] time: 0:44:42.523601\n",
      "(10, 128, 128, 3)\n",
      "0.94589025\n",
      "[Epoch 5/10] [Batch 309/1081] [D loss: 0.073227] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.799047] time: 0:44:42.938465\n",
      "(10, 128, 128, 3)\n",
      "0.92610073\n",
      "[Epoch 5/10] [Batch 310/1081] [D loss: 0.070753] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.446257] time: 0:44:43.375778\n",
      "(10, 128, 128, 3)\n",
      "0.86986303\n",
      "[Epoch 5/10] [Batch 311/1081] [D loss: 0.070888] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.060781] time: 0:44:43.776134\n",
      "(10, 128, 128, 3)\n",
      "0.9414747\n",
      "[Epoch 5/10] [Batch 312/1081] [D loss: 0.070695] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.662588] time: 0:44:44.199300\n",
      "(10, 128, 128, 3)\n",
      "0.92018217\n",
      "[Epoch 5/10] [Batch 313/1081] [D loss: 0.070838] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.772845] time: 0:44:44.638635\n",
      "(10, 128, 128, 3)\n",
      "0.85187\n",
      "[Epoch 5/10] [Batch 314/1081] [D loss: 0.070540] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.941894] time: 0:44:45.068319\n",
      "(10, 128, 128, 3)\n",
      "0.9060121\n",
      "[Epoch 5/10] [Batch 315/1081] [D loss: 0.071076] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.852426] time: 0:44:45.499219\n",
      "(10, 128, 128, 3)\n",
      "0.9293644\n",
      "[Epoch 5/10] [Batch 316/1081] [D loss: 0.071022] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.015207] time: 0:44:45.903005\n",
      "(10, 128, 128, 3)\n",
      "0.86781806\n",
      "[Epoch 5/10] [Batch 317/1081] [D loss: 0.070975] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.691056] time: 0:44:46.292221\n",
      "(10, 128, 128, 3)\n",
      "0.9259084\n",
      "[Epoch 5/10] [Batch 318/1081] [D loss: 0.070472] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.417634] time: 0:44:46.668883\n",
      "(10, 128, 128, 3)\n",
      "0.9158471\n",
      "[Epoch 5/10] [Batch 319/1081] [D loss: 0.070307] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.280858] time: 0:44:47.072257\n",
      "(10, 128, 128, 3)\n",
      "0.91850543\n",
      "[Epoch 5/10] [Batch 320/1081] [D loss: 0.071233] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.784043] time: 0:44:47.481800\n",
      "(10, 128, 128, 3)\n",
      "0.92652535\n",
      "[Epoch 5/10] [Batch 321/1081] [D loss: 0.070778] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.885967] time: 0:44:47.906587\n",
      "(10, 128, 128, 3)\n",
      "0.90001553\n",
      "[Epoch 5/10] [Batch 322/1081] [D loss: 0.070098] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.652888] time: 0:44:48.321440\n",
      "(10, 128, 128, 3)\n",
      "0.9197661\n",
      "[Epoch 5/10] [Batch 323/1081] [D loss: 0.069970] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.149428] time: 0:44:48.783989\n",
      "(10, 128, 128, 3)\n",
      "0.9204657\n",
      "[Epoch 5/10] [Batch 324/1081] [D loss: 0.070339] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.244663] time: 0:44:49.223900\n",
      "(10, 128, 128, 3)\n",
      "0.91846085\n",
      "[Epoch 5/10] [Batch 325/1081] [D loss: 0.070701] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.898356] time: 0:44:49.686675\n",
      "(10, 128, 128, 3)\n",
      "0.91231036\n",
      "[Epoch 5/10] [Batch 326/1081] [D loss: 0.070181] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.077628] time: 0:44:50.108277\n",
      "(10, 128, 128, 3)\n",
      "0.90853405\n",
      "[Epoch 5/10] [Batch 327/1081] [D loss: 0.069878] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.825227] time: 0:44:50.531636\n",
      "(10, 128, 128, 3)\n",
      "0.9083335\n",
      "[Epoch 5/10] [Batch 328/1081] [D loss: 0.070032] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.901278] time: 0:44:50.994432\n",
      "(10, 128, 128, 3)\n",
      "0.9344504\n",
      "[Epoch 5/10] [Batch 329/1081] [D loss: 0.071504] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.732533] time: 0:44:51.403483\n",
      "(10, 128, 128, 3)\n",
      "0.87840575\n",
      "[Epoch 5/10] [Batch 330/1081] [D loss: 0.069676] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.877237] time: 0:44:51.839737\n",
      "(10, 128, 128, 3)\n",
      "0.8464029\n",
      "[Epoch 5/10] [Batch 331/1081] [D loss: 0.071642] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.385617] time: 0:44:52.262715\n",
      "(10, 128, 128, 3)\n",
      "0.9264703\n",
      "[Epoch 5/10] [Batch 332/1081] [D loss: 0.070952] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.650109] time: 0:44:52.662026\n",
      "(10, 128, 128, 3)\n",
      "0.9329116\n",
      "[Epoch 5/10] [Batch 333/1081] [D loss: 0.069784] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.115130] time: 0:44:53.063533\n",
      "(10, 128, 128, 3)\n",
      "0.92225\n",
      "[Epoch 5/10] [Batch 334/1081] [D loss: 0.069960] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.725575] time: 0:44:53.466066\n",
      "(10, 128, 128, 3)\n",
      "0.93437195\n",
      "[Epoch 5/10] [Batch 335/1081] [D loss: 0.069516] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.147980] time: 0:44:53.867046\n",
      "(10, 128, 128, 3)\n",
      "0.88864875\n",
      "[Epoch 5/10] [Batch 336/1081] [D loss: 0.069778] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.174602] time: 0:44:54.282635\n",
      "(10, 128, 128, 3)\n",
      "0.9039321\n",
      "[Epoch 5/10] [Batch 337/1081] [D loss: 0.070855] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.645512] time: 0:44:54.674743\n",
      "(10, 128, 128, 3)\n",
      "0.8995754\n",
      "[Epoch 5/10] [Batch 338/1081] [D loss: 0.069279] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.882849] time: 0:44:55.067023\n",
      "(10, 128, 128, 3)\n",
      "0.91222626\n",
      "[Epoch 5/10] [Batch 339/1081] [D loss: 0.069307] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.642938] time: 0:44:55.463532\n",
      "(10, 128, 128, 3)\n",
      "0.8674142\n",
      "[Epoch 5/10] [Batch 340/1081] [D loss: 0.069693] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.058008] time: 0:44:55.876418\n",
      "(10, 128, 128, 3)\n",
      "0.8698066\n",
      "[Epoch 5/10] [Batch 341/1081] [D loss: 0.069511] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.018976] time: 0:44:56.302873\n",
      "(10, 128, 128, 3)\n",
      "0.9087968\n",
      "[Epoch 5/10] [Batch 342/1081] [D loss: 0.069651] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.077965] time: 0:44:56.719296\n",
      "(10, 128, 128, 3)\n",
      "0.94226974\n",
      "[Epoch 5/10] [Batch 343/1081] [D loss: 0.069190] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.822801] time: 0:44:57.138393\n",
      "(10, 128, 128, 3)\n",
      "0.94994754\n",
      "[Epoch 5/10] [Batch 344/1081] [D loss: 0.069506] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.682962] time: 0:44:57.560217\n",
      "(10, 128, 128, 3)\n",
      "0.89682704\n",
      "[Epoch 5/10] [Batch 345/1081] [D loss: 0.072263] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.892936] time: 0:44:57.952458\n",
      "(10, 128, 128, 3)\n",
      "0.90342313\n",
      "[Epoch 5/10] [Batch 346/1081] [D loss: 0.070321] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.533797] time: 0:44:58.360835\n",
      "(10, 128, 128, 3)\n",
      "0.88646746\n",
      "[Epoch 5/10] [Batch 347/1081] [D loss: 0.068866] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.038604] time: 0:44:58.790816\n",
      "(10, 128, 128, 3)\n",
      "0.91735095\n",
      "[Epoch 5/10] [Batch 348/1081] [D loss: 0.068835] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.925951] time: 0:44:59.191088\n",
      "(10, 128, 128, 3)\n",
      "0.8938148\n",
      "[Epoch 5/10] [Batch 349/1081] [D loss: 0.068545] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.883973] time: 0:44:59.593824\n",
      "(10, 128, 128, 3)\n",
      "0.8697583\n",
      "[Epoch 5/10] [Batch 350/1081] [D loss: 0.070462] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.814288] time: 0:44:59.967125\n",
      "(10, 128, 128, 3)\n",
      "0.92026824\n",
      "[Epoch 5/10] [Batch 351/1081] [D loss: 0.068817] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.622581] time: 0:45:00.396536\n",
      "(10, 128, 128, 3)\n",
      "0.93597984\n",
      "[Epoch 5/10] [Batch 352/1081] [D loss: 0.068601] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.318973] time: 0:45:00.782338\n",
      "(10, 128, 128, 3)\n",
      "0.89659697\n",
      "[Epoch 5/10] [Batch 353/1081] [D loss: 0.068417] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.022832] time: 0:45:01.183388\n",
      "(10, 128, 128, 3)\n",
      "0.8973426\n",
      "[Epoch 5/10] [Batch 354/1081] [D loss: 0.068489] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.834805] time: 0:45:01.585034\n",
      "(10, 128, 128, 3)\n",
      "0.92185456\n",
      "[Epoch 5/10] [Batch 355/1081] [D loss: 0.068332] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.955863] time: 0:45:02.000512\n",
      "(10, 128, 128, 3)\n",
      "0.92553407\n",
      "[Epoch 5/10] [Batch 356/1081] [D loss: 0.068825] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.156859] time: 0:45:02.395445\n",
      "(10, 128, 128, 3)\n",
      "0.9245753\n",
      "[Epoch 5/10] [Batch 357/1081] [D loss: 0.068196] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.411397] time: 0:45:02.823640\n",
      "(10, 128, 128, 3)\n",
      "0.9224608\n",
      "[Epoch 5/10] [Batch 358/1081] [D loss: 0.068919] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.618536] time: 0:45:03.253253\n",
      "(10, 128, 128, 3)\n",
      "0.932671\n",
      "[Epoch 5/10] [Batch 359/1081] [D loss: 0.068482] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.027432] time: 0:45:03.661365\n",
      "(10, 128, 128, 3)\n",
      "0.90210724\n",
      "[Epoch 5/10] [Batch 360/1081] [D loss: 0.068793] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.651559] time: 0:45:04.072008\n",
      "(10, 128, 128, 3)\n",
      "0.87009054\n",
      "[Epoch 5/10] [Batch 361/1081] [D loss: 0.068489] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.792458] time: 0:45:04.461127\n",
      "(10, 128, 128, 3)\n",
      "0.877687\n",
      "[Epoch 5/10] [Batch 362/1081] [D loss: 0.068195] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.261960] time: 0:45:04.898551\n",
      "(10, 128, 128, 3)\n",
      "0.9341573\n",
      "[Epoch 5/10] [Batch 363/1081] [D loss: 0.068334] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.281749] time: 0:45:05.330096\n",
      "(10, 128, 128, 3)\n",
      "0.9200044\n",
      "[Epoch 5/10] [Batch 364/1081] [D loss: 0.069160] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.924172] time: 0:45:05.759819\n",
      "(10, 128, 128, 3)\n",
      "0.85707337\n",
      "[Epoch 5/10] [Batch 365/1081] [D loss: 0.068019] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.864841] time: 0:45:06.155849\n",
      "(10, 128, 128, 3)\n",
      "0.879718\n",
      "[Epoch 5/10] [Batch 366/1081] [D loss: 0.068245] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.070633] time: 0:45:06.563841\n",
      "(10, 128, 128, 3)\n",
      "0.9755804\n",
      "[Epoch 5/10] [Batch 367/1081] [D loss: 0.067752] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.923732] time: 0:45:07.016409\n",
      "(10, 128, 128, 3)\n",
      "0.9266488\n",
      "[Epoch 5/10] [Batch 368/1081] [D loss: 0.068752] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.744025] time: 0:45:07.451107\n",
      "(10, 128, 128, 3)\n",
      "0.95473415\n",
      "[Epoch 5/10] [Batch 369/1081] [D loss: 0.068651] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.689322] time: 0:45:07.847249\n",
      "(10, 128, 128, 3)\n",
      "0.9126485\n",
      "[Epoch 5/10] [Batch 370/1081] [D loss: 0.068426] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.261937] time: 0:45:08.274059\n",
      "(10, 128, 128, 3)\n",
      "0.933158\n",
      "[Epoch 5/10] [Batch 371/1081] [D loss: 0.068626] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.780344] time: 0:45:08.691860\n",
      "(10, 128, 128, 3)\n",
      "0.91637605\n",
      "[Epoch 5/10] [Batch 372/1081] [D loss: 0.067692] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.434054] time: 0:45:09.105690\n",
      "(10, 128, 128, 3)\n",
      "0.93709666\n",
      "[Epoch 5/10] [Batch 373/1081] [D loss: 0.068454] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.845631] time: 0:45:09.534822\n",
      "(10, 128, 128, 3)\n",
      "0.9491611\n",
      "[Epoch 5/10] [Batch 374/1081] [D loss: 0.068903] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.358764] time: 0:45:09.931926\n",
      "(10, 128, 128, 3)\n",
      "0.9220622\n",
      "[Epoch 5/10] [Batch 375/1081] [D loss: 0.068062] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.391717] time: 0:45:10.333893\n",
      "(10, 128, 128, 3)\n",
      "0.83122516\n",
      "[Epoch 5/10] [Batch 376/1081] [D loss: 0.068404] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.280138] time: 0:45:10.763802\n",
      "(10, 128, 128, 3)\n",
      "0.92826825\n",
      "[Epoch 5/10] [Batch 377/1081] [D loss: 0.067475] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.636589] time: 0:45:11.208889\n",
      "(10, 128, 128, 3)\n",
      "0.91386706\n",
      "[Epoch 5/10] [Batch 378/1081] [D loss: 0.067317] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.899044] time: 0:45:11.607627\n",
      "(10, 128, 128, 3)\n",
      "0.92043465\n",
      "[Epoch 5/10] [Batch 379/1081] [D loss: 0.067624] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.133708] time: 0:45:12.037400\n",
      "(10, 128, 128, 3)\n",
      "0.9269436\n",
      "[Epoch 5/10] [Batch 380/1081] [D loss: 0.067231] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.903567] time: 0:45:12.456926\n",
      "(10, 128, 128, 3)\n",
      "0.9284863\n",
      "[Epoch 5/10] [Batch 381/1081] [D loss: 0.068102] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.874506] time: 0:45:12.888910\n",
      "(10, 128, 128, 3)\n",
      "0.878457\n",
      "[Epoch 5/10] [Batch 382/1081] [D loss: 0.067086] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.546671] time: 0:45:13.332501\n",
      "(10, 128, 128, 3)\n",
      "0.8768797\n",
      "[Epoch 5/10] [Batch 383/1081] [D loss: 0.067314] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.794539] time: 0:45:13.800269\n",
      "(10, 128, 128, 3)\n",
      "0.9330817\n",
      "[Epoch 5/10] [Batch 384/1081] [D loss: 0.067727] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.727197] time: 0:45:14.216384\n",
      "(10, 128, 128, 3)\n",
      "0.93018836\n",
      "[Epoch 5/10] [Batch 385/1081] [D loss: 0.067040] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.089798] time: 0:45:14.646836\n",
      "(10, 128, 128, 3)\n",
      "0.8538978\n",
      "[Epoch 5/10] [Batch 386/1081] [D loss: 0.067171] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.608531] time: 0:45:15.055385\n",
      "(10, 128, 128, 3)\n",
      "0.89181083\n",
      "[Epoch 5/10] [Batch 387/1081] [D loss: 0.068624] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.049215] time: 0:45:15.448327\n",
      "(10, 128, 128, 3)\n",
      "0.90366834\n",
      "[Epoch 5/10] [Batch 388/1081] [D loss: 0.067543] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.063558] time: 0:45:15.926816\n",
      "(10, 128, 128, 3)\n",
      "0.91149354\n",
      "[Epoch 5/10] [Batch 389/1081] [D loss: 0.066809] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.994247] time: 0:45:16.364898\n",
      "(10, 128, 128, 3)\n",
      "0.92574805\n",
      "[Epoch 5/10] [Batch 390/1081] [D loss: 0.068511] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.649369] time: 0:45:16.796346\n",
      "(10, 128, 128, 3)\n",
      "0.91042024\n",
      "[Epoch 5/10] [Batch 391/1081] [D loss: 0.067532] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.904558] time: 0:45:17.242788\n",
      "(10, 128, 128, 3)\n",
      "0.89691687\n",
      "[Epoch 5/10] [Batch 392/1081] [D loss: 0.067644] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.400975] time: 0:45:17.665242\n",
      "(10, 128, 128, 3)\n",
      "0.8734525\n",
      "[Epoch 5/10] [Batch 393/1081] [D loss: 0.066839] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.654826] time: 0:45:18.071114\n",
      "(10, 128, 128, 3)\n",
      "0.91703266\n",
      "[Epoch 5/10] [Batch 394/1081] [D loss: 0.066778] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.872456] time: 0:45:18.503427\n",
      "(10, 128, 128, 3)\n",
      "0.8751951\n",
      "[Epoch 5/10] [Batch 395/1081] [D loss: 0.067699] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.503524] time: 0:45:18.919377\n",
      "(10, 128, 128, 3)\n",
      "0.8910401\n",
      "[Epoch 5/10] [Batch 396/1081] [D loss: 0.067693] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.922288] time: 0:45:19.314659\n",
      "(10, 128, 128, 3)\n",
      "0.92425174\n",
      "[Epoch 5/10] [Batch 397/1081] [D loss: 0.066843] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.467117] time: 0:45:19.716219\n",
      "(10, 128, 128, 3)\n",
      "0.92533463\n",
      "[Epoch 5/10] [Batch 398/1081] [D loss: 0.066681] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.303325] time: 0:45:20.121229\n",
      "(10, 128, 128, 3)\n",
      "0.91678804\n",
      "[Epoch 5/10] [Batch 399/1081] [D loss: 0.066644] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.375146] time: 0:45:20.566918\n",
      "(10, 128, 128, 3)\n",
      "0.93374467\n",
      "[Epoch 5/10] [Batch 400/1081] [D loss: 0.066412] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.500537] time: 0:45:20.962248\n",
      "(10, 128, 128, 3)\n",
      "0.88566494\n",
      "[Epoch 5/10] [Batch 401/1081] [D loss: 0.066428] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.007262] time: 0:45:21.405560\n",
      "(10, 128, 128, 3)\n",
      "0.93572617\n",
      "[Epoch 5/10] [Batch 402/1081] [D loss: 0.244329] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 7.639271] time: 0:45:21.798488\n",
      "(10, 128, 128, 3)\n",
      "0.9266347\n",
      "[Epoch 5/10] [Batch 403/1081] [D loss: 0.592898] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 5.857594] time: 0:45:22.204598\n",
      "(10, 128, 128, 3)\n",
      "0.8863073\n",
      "[Epoch 5/10] [Batch 404/1081] [D loss: 0.107619] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.284277] time: 0:45:22.579068\n",
      "(10, 128, 128, 3)\n",
      "0.8690607\n",
      "[Epoch 5/10] [Batch 405/1081] [D loss: 0.086804] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.998780] time: 0:45:22.953937\n",
      "(10, 128, 128, 3)\n",
      "0.90552574\n",
      "[Epoch 5/10] [Batch 406/1081] [D loss: 0.085067] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.660096] time: 0:45:23.363193\n",
      "(10, 128, 128, 3)\n",
      "0.9693546\n",
      "[Epoch 5/10] [Batch 407/1081] [D loss: 0.090807] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.116445] time: 0:45:23.753316\n",
      "(10, 128, 128, 3)\n",
      "0.9235609\n",
      "[Epoch 5/10] [Batch 408/1081] [D loss: 0.087215] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.264198] time: 0:45:24.168473\n",
      "(10, 128, 128, 3)\n",
      "0.853574\n",
      "[Epoch 5/10] [Batch 409/1081] [D loss: 0.082311] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.937158] time: 0:45:24.563442\n",
      "(10, 128, 128, 3)\n",
      "0.89430267\n",
      "[Epoch 5/10] [Batch 410/1081] [D loss: 0.087619] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.252145] time: 0:45:24.977850\n",
      "(10, 128, 128, 3)\n",
      "0.9257433\n",
      "[Epoch 5/10] [Batch 411/1081] [D loss: 0.082152] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.224210] time: 0:45:25.373231\n",
      "(10, 128, 128, 3)\n",
      "0.9101076\n",
      "[Epoch 5/10] [Batch 412/1081] [D loss: 0.089126] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.447269] time: 0:45:25.776221\n",
      "(10, 128, 128, 3)\n",
      "0.8824559\n",
      "[Epoch 5/10] [Batch 413/1081] [D loss: 0.082464] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.122865] time: 0:45:26.187666\n",
      "(10, 128, 128, 3)\n",
      "0.91417485\n",
      "[Epoch 5/10] [Batch 414/1081] [D loss: 0.084586] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.179845] time: 0:45:26.597980\n",
      "(10, 128, 128, 3)\n",
      "0.9203265\n",
      "[Epoch 5/10] [Batch 415/1081] [D loss: 0.081731] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.138471] time: 0:45:26.999692\n",
      "(10, 128, 128, 3)\n",
      "0.90491277\n",
      "[Epoch 5/10] [Batch 416/1081] [D loss: 0.081463] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.603548] time: 0:45:27.411484\n",
      "(10, 128, 128, 3)\n",
      "0.9220527\n",
      "[Epoch 5/10] [Batch 417/1081] [D loss: 0.082555] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.366991] time: 0:45:27.827201\n",
      "(10, 128, 128, 3)\n",
      "0.8760357\n",
      "[Epoch 5/10] [Batch 418/1081] [D loss: 0.079742] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.059448] time: 0:45:28.230151\n",
      "(10, 128, 128, 3)\n",
      "0.87649137\n",
      "[Epoch 5/10] [Batch 419/1081] [D loss: 0.081254] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.773042] time: 0:45:28.636702\n",
      "(10, 128, 128, 3)\n",
      "0.91410047\n",
      "[Epoch 5/10] [Batch 420/1081] [D loss: 0.079779] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.964569] time: 0:45:29.032347\n",
      "(10, 128, 128, 3)\n",
      "0.8804106\n",
      "[Epoch 5/10] [Batch 421/1081] [D loss: 0.081793] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.264809] time: 0:45:29.435916\n",
      "(10, 128, 128, 3)\n",
      "0.9110768\n",
      "[Epoch 5/10] [Batch 422/1081] [D loss: 0.078236] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.777372] time: 0:45:29.867638\n",
      "(10, 128, 128, 3)\n",
      "0.91814643\n",
      "[Epoch 5/10] [Batch 423/1081] [D loss: 0.080152] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.082189] time: 0:45:30.289525\n",
      "(10, 128, 128, 3)\n",
      "0.9094122\n",
      "[Epoch 5/10] [Batch 424/1081] [D loss: 0.078349] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.812911] time: 0:45:30.723238\n",
      "(10, 128, 128, 3)\n",
      "0.8629561\n",
      "[Epoch 5/10] [Batch 425/1081] [D loss: 0.078484] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.286166] time: 0:45:31.124306\n",
      "(10, 128, 128, 3)\n",
      "0.90715903\n",
      "[Epoch 5/10] [Batch 426/1081] [D loss: 0.079446] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.348986] time: 0:45:31.538650\n",
      "(10, 128, 128, 3)\n",
      "0.947591\n",
      "[Epoch 5/10] [Batch 427/1081] [D loss: 0.080868] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.797966] time: 0:45:31.981101\n",
      "(10, 128, 128, 3)\n",
      "0.8798607\n",
      "[Epoch 5/10] [Batch 428/1081] [D loss: 0.079362] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.431069] time: 0:45:32.366577\n",
      "(10, 128, 128, 3)\n",
      "0.9599295\n",
      "[Epoch 5/10] [Batch 429/1081] [D loss: 0.078194] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.643942] time: 0:45:32.800962\n",
      "(10, 128, 128, 3)\n",
      "0.8947692\n",
      "[Epoch 5/10] [Batch 430/1081] [D loss: 0.080579] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.262712] time: 0:45:33.227449\n",
      "(10, 128, 128, 3)\n",
      "0.92082834\n",
      "[Epoch 5/10] [Batch 431/1081] [D loss: 0.081929] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.879592] time: 0:45:33.620575\n",
      "(10, 128, 128, 3)\n",
      "0.9043769\n",
      "[Epoch 5/10] [Batch 432/1081] [D loss: 0.081941] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.140775] time: 0:45:34.042562\n",
      "(10, 128, 128, 3)\n",
      "0.8953967\n",
      "[Epoch 5/10] [Batch 433/1081] [D loss: 0.077515] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.095919] time: 0:45:34.479984\n",
      "(10, 128, 128, 3)\n",
      "0.92061424\n",
      "[Epoch 5/10] [Batch 434/1081] [D loss: 0.077655] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.213226] time: 0:45:34.904914\n",
      "(10, 128, 128, 3)\n",
      "0.9014961\n",
      "[Epoch 5/10] [Batch 435/1081] [D loss: 0.079356] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.429259] time: 0:45:35.361886\n",
      "(10, 128, 128, 3)\n",
      "0.8889739\n",
      "[Epoch 5/10] [Batch 436/1081] [D loss: 0.078635] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.965343] time: 0:45:35.772653\n",
      "(10, 128, 128, 3)\n",
      "0.91284436\n",
      "[Epoch 5/10] [Batch 437/1081] [D loss: 0.080235] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.559711] time: 0:45:36.179105\n",
      "(10, 128, 128, 3)\n",
      "0.932134\n",
      "[Epoch 5/10] [Batch 438/1081] [D loss: 0.077204] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.537712] time: 0:45:36.577701\n",
      "(10, 128, 128, 3)\n",
      "0.89654297\n",
      "[Epoch 5/10] [Batch 439/1081] [D loss: 0.076792] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.050496] time: 0:45:37.047249\n",
      "(10, 128, 128, 3)\n",
      "0.9418402\n",
      "[Epoch 5/10] [Batch 440/1081] [D loss: 0.077406] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.472454] time: 0:45:37.488515\n",
      "(10, 128, 128, 3)\n",
      "0.9561537\n",
      "[Epoch 5/10] [Batch 441/1081] [D loss: 0.075052] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.809907] time: 0:45:37.896598\n",
      "(10, 128, 128, 3)\n",
      "0.90916324\n",
      "[Epoch 5/10] [Batch 442/1081] [D loss: 0.082576] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.279130] time: 0:45:38.337527\n",
      "(10, 128, 128, 3)\n",
      "0.9329319\n",
      "[Epoch 5/10] [Batch 443/1081] [D loss: 0.075828] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.372633] time: 0:45:38.746854\n",
      "(10, 128, 128, 3)\n",
      "0.9324441\n",
      "[Epoch 5/10] [Batch 444/1081] [D loss: 0.076952] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.273406] time: 0:45:39.191523\n",
      "(10, 128, 128, 3)\n",
      "0.8954862\n",
      "[Epoch 5/10] [Batch 445/1081] [D loss: 0.075647] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.859882] time: 0:45:39.603512\n",
      "(10, 128, 128, 3)\n",
      "0.9086427\n",
      "[Epoch 5/10] [Batch 446/1081] [D loss: 0.074252] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.137781] time: 0:45:40.008918\n",
      "(10, 128, 128, 3)\n",
      "0.88035774\n",
      "[Epoch 5/10] [Batch 447/1081] [D loss: 0.073972] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.429940] time: 0:45:40.426123\n",
      "(10, 128, 128, 3)\n",
      "0.89684457\n",
      "[Epoch 5/10] [Batch 448/1081] [D loss: 0.082835] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.976468] time: 0:45:40.838223\n",
      "(10, 128, 128, 3)\n",
      "0.97088426\n",
      "[Epoch 5/10] [Batch 449/1081] [D loss: 0.076328] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.559299] time: 0:45:41.239414\n",
      "(10, 128, 128, 3)\n",
      "0.94537884\n",
      "[Epoch 5/10] [Batch 450/1081] [D loss: 0.077023] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.507119] time: 0:45:41.663436\n",
      "(10, 128, 128, 3)\n",
      "0.9410568\n",
      "[Epoch 5/10] [Batch 451/1081] [D loss: 0.075234] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.535285] time: 0:45:42.071499\n",
      "(10, 128, 128, 3)\n",
      "0.918386\n",
      "[Epoch 5/10] [Batch 452/1081] [D loss: 0.073795] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.855813] time: 0:45:42.511954\n",
      "(10, 128, 128, 3)\n",
      "0.885504\n",
      "[Epoch 5/10] [Batch 453/1081] [D loss: 0.076902] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.703722] time: 0:45:42.913317\n",
      "(10, 128, 128, 3)\n",
      "0.9278813\n",
      "[Epoch 5/10] [Batch 454/1081] [D loss: 0.075537] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.943824] time: 0:45:43.317510\n",
      "(10, 128, 128, 3)\n",
      "0.9268749\n",
      "[Epoch 5/10] [Batch 455/1081] [D loss: 0.073513] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.518268] time: 0:45:43.717890\n",
      "(10, 128, 128, 3)\n",
      "0.9580245\n",
      "[Epoch 5/10] [Batch 456/1081] [D loss: 0.074802] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.183297] time: 0:45:44.124353\n",
      "(10, 128, 128, 3)\n",
      "0.88870066\n",
      "[Epoch 5/10] [Batch 457/1081] [D loss: 0.073083] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.945333] time: 0:45:44.535965\n",
      "(10, 128, 128, 3)\n",
      "0.91260344\n",
      "[Epoch 5/10] [Batch 458/1081] [D loss: 0.075237] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.182188] time: 0:45:44.939866\n",
      "(10, 128, 128, 3)\n",
      "0.87744874\n",
      "[Epoch 5/10] [Batch 459/1081] [D loss: 0.075757] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.943624] time: 0:45:45.335112\n",
      "(10, 128, 128, 3)\n",
      "0.9348421\n",
      "[Epoch 5/10] [Batch 460/1081] [D loss: 0.073520] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.940407] time: 0:45:45.737615\n",
      "(10, 128, 128, 3)\n",
      "0.93138593\n",
      "[Epoch 5/10] [Batch 461/1081] [D loss: 0.073975] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.809631] time: 0:45:46.186634\n",
      "(10, 128, 128, 3)\n",
      "0.8801437\n",
      "[Epoch 5/10] [Batch 462/1081] [D loss: 0.073408] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.608186] time: 0:45:46.591312\n",
      "(10, 128, 128, 3)\n",
      "0.9186252\n",
      "[Epoch 5/10] [Batch 463/1081] [D loss: 0.073166] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.817892] time: 0:45:47.013184\n",
      "(10, 128, 128, 3)\n",
      "0.8582883\n",
      "[Epoch 5/10] [Batch 464/1081] [D loss: 0.073720] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.951610] time: 0:45:47.451219\n",
      "(10, 128, 128, 3)\n",
      "0.94126767\n",
      "[Epoch 5/10] [Batch 465/1081] [D loss: 0.074308] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.423048] time: 0:45:47.862651\n",
      "(10, 128, 128, 3)\n",
      "0.87519646\n",
      "[Epoch 5/10] [Batch 466/1081] [D loss: 0.071982] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.662382] time: 0:45:48.289547\n",
      "(10, 128, 128, 3)\n",
      "0.9296946\n",
      "[Epoch 5/10] [Batch 467/1081] [D loss: 0.074045] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.967204] time: 0:45:48.712819\n",
      "(10, 128, 128, 3)\n",
      "0.9054796\n",
      "[Epoch 5/10] [Batch 468/1081] [D loss: 0.072876] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.644922] time: 0:45:49.114527\n",
      "(10, 128, 128, 3)\n",
      "0.95258886\n",
      "[Epoch 5/10] [Batch 469/1081] [D loss: 0.072550] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.688054] time: 0:45:49.499280\n",
      "(10, 128, 128, 3)\n",
      "0.9223755\n",
      "[Epoch 5/10] [Batch 470/1081] [D loss: 0.072048] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.322664] time: 0:45:49.905563\n",
      "(10, 128, 128, 3)\n",
      "0.89538604\n",
      "[Epoch 5/10] [Batch 471/1081] [D loss: 0.071604] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.424506] time: 0:45:50.324720\n",
      "(10, 128, 128, 3)\n",
      "0.9364864\n",
      "[Epoch 5/10] [Batch 472/1081] [D loss: 0.071249] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.704329] time: 0:45:50.737065\n",
      "(10, 128, 128, 3)\n",
      "0.9314974\n",
      "[Epoch 5/10] [Batch 473/1081] [D loss: 0.071125] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.037311] time: 0:45:51.165035\n",
      "(10, 128, 128, 3)\n",
      "0.94227916\n",
      "[Epoch 5/10] [Batch 474/1081] [D loss: 0.070620] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.573032] time: 0:45:51.609013\n",
      "(10, 128, 128, 3)\n",
      "0.9207034\n",
      "[Epoch 5/10] [Batch 475/1081] [D loss: 0.070557] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.977488] time: 0:45:52.048455\n",
      "(10, 128, 128, 3)\n",
      "0.95668334\n",
      "[Epoch 5/10] [Batch 476/1081] [D loss: 0.070552] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.462050] time: 0:45:52.455093\n",
      "(10, 128, 128, 3)\n",
      "0.93742055\n",
      "[Epoch 5/10] [Batch 477/1081] [D loss: 0.070455] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.761945] time: 0:45:52.850443\n",
      "(10, 128, 128, 3)\n",
      "0.9273443\n",
      "[Epoch 5/10] [Batch 478/1081] [D loss: 0.071123] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.738343] time: 0:45:53.266172\n",
      "(10, 128, 128, 3)\n",
      "0.96809024\n",
      "[Epoch 5/10] [Batch 479/1081] [D loss: 0.070639] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.430256] time: 0:45:53.700044\n",
      "(10, 128, 128, 3)\n",
      "0.8953766\n",
      "[Epoch 5/10] [Batch 480/1081] [D loss: 0.069912] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.299611] time: 0:45:54.152701\n",
      "(10, 128, 128, 3)\n",
      "0.9414889\n",
      "[Epoch 5/10] [Batch 481/1081] [D loss: 0.070209] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.310479] time: 0:45:54.610241\n",
      "(10, 128, 128, 3)\n",
      "0.9112816\n",
      "[Epoch 5/10] [Batch 482/1081] [D loss: 0.070002] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.685549] time: 0:45:55.002201\n",
      "(10, 128, 128, 3)\n",
      "0.93460417\n",
      "[Epoch 5/10] [Batch 483/1081] [D loss: 0.070911] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.278056] time: 0:45:55.407712\n",
      "(10, 128, 128, 3)\n",
      "0.8662855\n",
      "[Epoch 5/10] [Batch 484/1081] [D loss: 0.071727] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.492523] time: 0:45:55.867728\n",
      "(10, 128, 128, 3)\n",
      "0.9275594\n",
      "[Epoch 5/10] [Batch 485/1081] [D loss: 0.070469] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.700810] time: 0:45:56.317219\n",
      "(10, 128, 128, 3)\n",
      "0.90123016\n",
      "[Epoch 5/10] [Batch 486/1081] [D loss: 0.070576] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.820138] time: 0:45:56.742615\n",
      "(10, 128, 128, 3)\n",
      "0.90925\n",
      "[Epoch 5/10] [Batch 487/1081] [D loss: 0.069350] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.125531] time: 0:45:57.190422\n",
      "(10, 128, 128, 3)\n",
      "0.88670737\n",
      "[Epoch 5/10] [Batch 488/1081] [D loss: 0.069288] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.735201] time: 0:45:57.603494\n",
      "(10, 128, 128, 3)\n",
      "0.89463526\n",
      "[Epoch 5/10] [Batch 489/1081] [D loss: 0.069444] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.871404] time: 0:45:58.036832\n",
      "(10, 128, 128, 3)\n",
      "0.8544267\n",
      "[Epoch 5/10] [Batch 490/1081] [D loss: 0.069389] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.860683] time: 0:45:58.445108\n",
      "(10, 128, 128, 3)\n",
      "0.8803659\n",
      "[Epoch 5/10] [Batch 491/1081] [D loss: 0.069603] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.231681] time: 0:45:58.836955\n",
      "(10, 128, 128, 3)\n",
      "0.9057312\n",
      "[Epoch 5/10] [Batch 492/1081] [D loss: 0.069187] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.806094] time: 0:45:59.243058\n",
      "(10, 128, 128, 3)\n",
      "0.9104757\n",
      "[Epoch 5/10] [Batch 493/1081] [D loss: 0.068943] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.487746] time: 0:45:59.641226\n",
      "(10, 128, 128, 3)\n",
      "0.8924546\n",
      "[Epoch 5/10] [Batch 494/1081] [D loss: 0.068791] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.961198] time: 0:46:00.052085\n",
      "(10, 128, 128, 3)\n",
      "0.9419603\n",
      "[Epoch 5/10] [Batch 495/1081] [D loss: 0.069408] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.860884] time: 0:46:00.475890\n",
      "(10, 128, 128, 3)\n",
      "0.9194779\n",
      "[Epoch 5/10] [Batch 496/1081] [D loss: 0.069098] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.762999] time: 0:46:00.888919\n",
      "(10, 128, 128, 3)\n",
      "0.9462978\n",
      "[Epoch 5/10] [Batch 497/1081] [D loss: 0.068597] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.878435] time: 0:46:01.297223\n",
      "(10, 128, 128, 3)\n",
      "0.9301147\n",
      "[Epoch 5/10] [Batch 498/1081] [D loss: 0.069114] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.604418] time: 0:46:01.710991\n",
      "(10, 128, 128, 3)\n",
      "0.87635684\n",
      "[Epoch 5/10] [Batch 499/1081] [D loss: 0.068451] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.620989] time: 0:46:02.127197\n",
      "(10, 128, 128, 3)\n",
      "0.9423298\n",
      "[Epoch 5/10] [Batch 500/1081] [D loss: 0.068756] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.394958] time: 0:46:02.559995\n",
      "(10, 128, 128, 3)\n",
      "0.90588146\n",
      "[Epoch 5/10] [Batch 501/1081] [D loss: 0.068901] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.022266] time: 0:46:02.978782\n",
      "(10, 128, 128, 3)\n",
      "0.9058643\n",
      "[Epoch 5/10] [Batch 502/1081] [D loss: 0.069038] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.740796] time: 0:46:03.390798\n",
      "(10, 128, 128, 3)\n",
      "0.9136428\n",
      "[Epoch 5/10] [Batch 503/1081] [D loss: 0.067935] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.142649] time: 0:46:03.836902\n",
      "(10, 128, 128, 3)\n",
      "0.888107\n",
      "[Epoch 5/10] [Batch 504/1081] [D loss: 0.067781] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.232802] time: 0:46:04.255737\n",
      "(10, 128, 128, 3)\n",
      "0.8992432\n",
      "[Epoch 5/10] [Batch 505/1081] [D loss: 0.067623] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.861393] time: 0:46:04.675427\n",
      "(10, 128, 128, 3)\n",
      "0.9305585\n",
      "[Epoch 5/10] [Batch 506/1081] [D loss: 0.067825] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.756484] time: 0:46:05.060319\n",
      "(10, 128, 128, 3)\n",
      "0.9381481\n",
      "[Epoch 5/10] [Batch 507/1081] [D loss: 0.068586] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.387961] time: 0:46:05.468665\n",
      "(10, 128, 128, 3)\n",
      "0.9555165\n",
      "[Epoch 5/10] [Batch 508/1081] [D loss: 0.069217] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.385233] time: 0:46:05.893515\n",
      "(10, 128, 128, 3)\n",
      "0.89265424\n",
      "[Epoch 5/10] [Batch 509/1081] [D loss: 0.068063] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.769883] time: 0:46:06.277510\n",
      "(10, 128, 128, 3)\n",
      "0.8807516\n",
      "[Epoch 5/10] [Batch 510/1081] [D loss: 0.067466] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.401305] time: 0:46:06.680316\n",
      "(10, 128, 128, 3)\n",
      "0.9082203\n",
      "[Epoch 5/10] [Batch 511/1081] [D loss: 0.068755] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.621999] time: 0:46:07.088517\n",
      "(10, 128, 128, 3)\n",
      "0.95142055\n",
      "[Epoch 5/10] [Batch 512/1081] [D loss: 0.068961] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.245769] time: 0:46:07.503854\n",
      "(10, 128, 128, 3)\n",
      "0.95120305\n",
      "[Epoch 5/10] [Batch 513/1081] [D loss: 0.067923] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.769323] time: 0:46:07.931030\n",
      "(10, 128, 128, 3)\n",
      "0.9360369\n",
      "[Epoch 5/10] [Batch 514/1081] [D loss: 0.067860] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.427522] time: 0:46:08.363367\n",
      "(10, 128, 128, 3)\n",
      "0.87740797\n",
      "[Epoch 5/10] [Batch 515/1081] [D loss: 0.067423] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.077332] time: 0:46:08.774341\n",
      "(10, 128, 128, 3)\n",
      "0.896475\n",
      "[Epoch 5/10] [Batch 516/1081] [D loss: 0.067483] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.317523] time: 0:46:09.219369\n",
      "(10, 128, 128, 3)\n",
      "0.9397974\n",
      "[Epoch 5/10] [Batch 517/1081] [D loss: 0.069175] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.656400] time: 0:46:09.640375\n",
      "(10, 128, 128, 3)\n",
      "0.883096\n",
      "[Epoch 5/10] [Batch 518/1081] [D loss: 0.067352] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.246763] time: 0:46:10.069508\n",
      "(10, 128, 128, 3)\n",
      "0.9317606\n",
      "[Epoch 5/10] [Batch 519/1081] [D loss: 0.066923] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.694479] time: 0:46:10.473691\n",
      "(10, 128, 128, 3)\n",
      "0.9145844\n",
      "[Epoch 5/10] [Batch 520/1081] [D loss: 0.068148] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.339781] time: 0:46:10.841858\n",
      "(10, 128, 128, 3)\n",
      "0.9035253\n",
      "[Epoch 5/10] [Batch 521/1081] [D loss: 0.067967] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.851077] time: 0:46:11.219522\n",
      "(10, 128, 128, 3)\n",
      "0.88387066\n",
      "[Epoch 5/10] [Batch 522/1081] [D loss: 0.067593] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.557389] time: 0:46:11.651468\n",
      "(10, 128, 128, 3)\n",
      "0.9323578\n",
      "[Epoch 5/10] [Batch 523/1081] [D loss: 0.066893] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.275699] time: 0:46:12.054479\n",
      "(10, 128, 128, 3)\n",
      "0.90498\n",
      "[Epoch 5/10] [Batch 524/1081] [D loss: 0.066372] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.827631] time: 0:46:12.493116\n",
      "(10, 128, 128, 3)\n",
      "0.9033184\n",
      "[Epoch 5/10] [Batch 525/1081] [D loss: 0.066473] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.697185] time: 0:46:12.908399\n",
      "(10, 128, 128, 3)\n",
      "0.942152\n",
      "[Epoch 5/10] [Batch 526/1081] [D loss: 0.066469] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.213577] time: 0:46:13.335756\n",
      "(10, 128, 128, 3)\n",
      "0.9021433\n",
      "[Epoch 5/10] [Batch 527/1081] [D loss: 0.066228] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.077295] time: 0:46:13.776608\n",
      "(10, 128, 128, 3)\n",
      "0.9353153\n",
      "[Epoch 5/10] [Batch 528/1081] [D loss: 0.066074] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.155812] time: 0:46:14.176544\n",
      "(10, 128, 128, 3)\n",
      "0.93145585\n",
      "[Epoch 5/10] [Batch 529/1081] [D loss: 0.065775] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.721993] time: 0:46:14.610081\n",
      "(10, 128, 128, 3)\n",
      "0.9743498\n",
      "[Epoch 5/10] [Batch 530/1081] [D loss: 0.066069] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.095948] time: 0:46:14.998966\n",
      "(10, 128, 128, 3)\n",
      "0.97229475\n",
      "[Epoch 5/10] [Batch 531/1081] [D loss: 0.066092] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.777514] time: 0:46:15.425661\n",
      "(10, 128, 128, 3)\n",
      "0.8861291\n",
      "[Epoch 5/10] [Batch 532/1081] [D loss: 0.066113] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.927631] time: 0:46:15.861155\n",
      "(10, 128, 128, 3)\n",
      "0.8975479\n",
      "[Epoch 5/10] [Batch 533/1081] [D loss: 0.065668] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.028082] time: 0:46:16.244324\n",
      "(10, 128, 128, 3)\n",
      "0.91633314\n",
      "[Epoch 5/10] [Batch 534/1081] [D loss: 0.065974] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.247742] time: 0:46:16.636153\n",
      "(10, 128, 128, 3)\n",
      "0.9268334\n",
      "[Epoch 5/10] [Batch 535/1081] [D loss: 0.065352] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.220070] time: 0:46:17.040645\n",
      "(10, 128, 128, 3)\n",
      "0.95701927\n",
      "[Epoch 5/10] [Batch 536/1081] [D loss: 0.065621] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.405970] time: 0:46:17.470040\n",
      "(10, 128, 128, 3)\n",
      "0.9295161\n",
      "[Epoch 5/10] [Batch 537/1081] [D loss: 0.065795] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.139841] time: 0:46:17.859050\n",
      "(10, 128, 128, 3)\n",
      "0.8807259\n",
      "[Epoch 5/10] [Batch 538/1081] [D loss: 0.065930] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.669278] time: 0:46:18.268798\n",
      "(10, 128, 128, 3)\n",
      "0.9125243\n",
      "[Epoch 5/10] [Batch 539/1081] [D loss: 0.066376] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.287022] time: 0:46:18.712497\n",
      "(10, 128, 128, 3)\n",
      "0.9159801\n",
      "[Epoch 5/10] [Batch 540/1081] [D loss: 0.065590] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.194850] time: 0:46:19.144063\n",
      "(10, 128, 128, 3)\n",
      "0.9247179\n",
      "[Epoch 5/10] [Batch 541/1081] [D loss: 0.066638] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.092160] time: 0:46:19.588169\n",
      "(10, 128, 128, 3)\n",
      "0.90556127\n",
      "[Epoch 5/10] [Batch 542/1081] [D loss: 0.066741] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.895795] time: 0:46:20.045130\n",
      "(10, 128, 128, 3)\n",
      "0.896455\n",
      "[Epoch 5/10] [Batch 543/1081] [D loss: 0.065269] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.834744] time: 0:46:20.494701\n",
      "(10, 128, 128, 3)\n",
      "0.87462616\n",
      "[Epoch 5/10] [Batch 544/1081] [D loss: 0.065554] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.937646] time: 0:46:20.932560\n",
      "(10, 128, 128, 3)\n",
      "0.8890893\n",
      "[Epoch 5/10] [Batch 545/1081] [D loss: 0.066338] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.528849] time: 0:46:21.363373\n",
      "(10, 128, 128, 3)\n",
      "0.9106938\n",
      "[Epoch 5/10] [Batch 546/1081] [D loss: 0.065431] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.132058] time: 0:46:21.755944\n",
      "(10, 128, 128, 3)\n",
      "0.9111361\n",
      "[Epoch 5/10] [Batch 547/1081] [D loss: 0.065883] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.692921] time: 0:46:22.181820\n",
      "(10, 128, 128, 3)\n",
      "0.93197775\n",
      "[Epoch 5/10] [Batch 548/1081] [D loss: 0.065764] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.768288] time: 0:46:22.585834\n",
      "(10, 128, 128, 3)\n",
      "0.8662371\n",
      "[Epoch 5/10] [Batch 549/1081] [D loss: 0.068429] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.140110] time: 0:46:22.980725\n",
      "(10, 128, 128, 3)\n",
      "0.9325194\n",
      "[Epoch 5/10] [Batch 550/1081] [D loss: 0.066382] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.809013] time: 0:46:23.385391\n",
      "(10, 128, 128, 3)\n",
      "0.93619275\n",
      "[Epoch 5/10] [Batch 551/1081] [D loss: 0.066090] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.594347] time: 0:46:23.885575\n",
      "(10, 128, 128, 3)\n",
      "0.97605354\n",
      "[Epoch 5/10] [Batch 552/1081] [D loss: 0.065218] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.027983] time: 0:46:24.287769\n",
      "(10, 128, 128, 3)\n",
      "0.9087279\n",
      "[Epoch 5/10] [Batch 553/1081] [D loss: 0.067387] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.665995] time: 0:46:24.684255\n",
      "(10, 128, 128, 3)\n",
      "0.9242621\n",
      "[Epoch 5/10] [Batch 554/1081] [D loss: 0.069196] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.153187] time: 0:46:25.092537\n",
      "(10, 128, 128, 3)\n",
      "0.86049867\n",
      "[Epoch 5/10] [Batch 555/1081] [D loss: 0.064637] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.616479] time: 0:46:25.560178\n",
      "(10, 128, 128, 3)\n",
      "0.88796663\n",
      "[Epoch 5/10] [Batch 556/1081] [D loss: 0.067393] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.410844] time: 0:46:25.978718\n",
      "(10, 128, 128, 3)\n",
      "0.90446466\n",
      "[Epoch 5/10] [Batch 557/1081] [D loss: 0.065564] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.579766] time: 0:46:26.370733\n",
      "(10, 128, 128, 3)\n",
      "0.9133051\n",
      "[Epoch 5/10] [Batch 558/1081] [D loss: 0.064112] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.009928] time: 0:46:26.793328\n",
      "(10, 128, 128, 3)\n",
      "0.91162896\n",
      "[Epoch 5/10] [Batch 559/1081] [D loss: 0.074206] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.853017] time: 0:46:27.190494\n",
      "(10, 128, 128, 3)\n",
      "0.92340374\n",
      "[Epoch 5/10] [Batch 560/1081] [D loss: 0.069050] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.944800] time: 0:46:27.596792\n",
      "(10, 128, 128, 3)\n",
      "0.87668014\n",
      "[Epoch 5/10] [Batch 561/1081] [D loss: 0.065593] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.532855] time: 0:46:27.996785\n",
      "(10, 128, 128, 3)\n",
      "0.91345996\n",
      "[Epoch 5/10] [Batch 562/1081] [D loss: 0.068469] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.101268] time: 0:46:28.424274\n",
      "(10, 128, 128, 3)\n",
      "0.9109874\n",
      "[Epoch 5/10] [Batch 563/1081] [D loss: 0.064582] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.523154] time: 0:46:28.867793\n",
      "(10, 128, 128, 3)\n",
      "0.8758171\n",
      "[Epoch 5/10] [Batch 564/1081] [D loss: 0.064627] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.287118] time: 0:46:29.290919\n",
      "(10, 128, 128, 3)\n",
      "0.9020682\n",
      "[Epoch 5/10] [Batch 565/1081] [D loss: 0.064263] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.045996] time: 0:46:29.723110\n",
      "(10, 128, 128, 3)\n",
      "0.9083925\n",
      "[Epoch 5/10] [Batch 566/1081] [D loss: 0.066064] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.487841] time: 0:46:30.144294\n",
      "(10, 128, 128, 3)\n",
      "0.88066816\n",
      "[Epoch 5/10] [Batch 567/1081] [D loss: 0.064393] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.156748] time: 0:46:30.607340\n",
      "(10, 128, 128, 3)\n",
      "0.89208394\n",
      "[Epoch 5/10] [Batch 568/1081] [D loss: 0.071656] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.715630] time: 0:46:31.039376\n",
      "(10, 128, 128, 3)\n",
      "0.9346263\n",
      "[Epoch 5/10] [Batch 569/1081] [D loss: 0.068136] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.746991] time: 0:46:31.470558\n",
      "(10, 128, 128, 3)\n",
      "0.84418887\n",
      "[Epoch 5/10] [Batch 570/1081] [D loss: 0.063881] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.272512] time: 0:46:31.900982\n",
      "(10, 128, 128, 3)\n",
      "0.8613944\n",
      "[Epoch 5/10] [Batch 571/1081] [D loss: 0.064116] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.563672] time: 0:46:32.348432\n",
      "(10, 128, 128, 3)\n",
      "0.88171667\n",
      "[Epoch 5/10] [Batch 572/1081] [D loss: 0.064814] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.120907] time: 0:46:32.743224\n",
      "(10, 128, 128, 3)\n",
      "0.8819594\n",
      "[Epoch 5/10] [Batch 573/1081] [D loss: 0.066908] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.610773] time: 0:46:33.130160\n",
      "(10, 128, 128, 3)\n",
      "0.9359655\n",
      "[Epoch 5/10] [Batch 574/1081] [D loss: 0.063477] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.429486] time: 0:46:33.542577\n",
      "(10, 128, 128, 3)\n",
      "0.91605115\n",
      "[Epoch 5/10] [Batch 575/1081] [D loss: 0.064568] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.320492] time: 0:46:33.964577\n",
      "(10, 128, 128, 3)\n",
      "0.94277555\n",
      "[Epoch 5/10] [Batch 576/1081] [D loss: 0.063766] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.533254] time: 0:46:34.355651\n",
      "(10, 128, 128, 3)\n",
      "0.90146357\n",
      "[Epoch 5/10] [Batch 577/1081] [D loss: 0.064326] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.770825] time: 0:46:34.788515\n",
      "(10, 128, 128, 3)\n",
      "0.9212737\n",
      "[Epoch 5/10] [Batch 578/1081] [D loss: 0.064944] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.989547] time: 0:46:35.227075\n",
      "(10, 128, 128, 3)\n",
      "0.919406\n",
      "[Epoch 5/10] [Batch 579/1081] [D loss: 0.063415] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.752553] time: 0:46:35.692293\n",
      "(10, 128, 128, 3)\n",
      "0.9377379\n",
      "[Epoch 5/10] [Batch 580/1081] [D loss: 0.063223] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.156931] time: 0:46:36.125233\n",
      "(10, 128, 128, 3)\n",
      "0.91642594\n",
      "[Epoch 5/10] [Batch 581/1081] [D loss: 0.063926] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.452400] time: 0:46:36.564984\n",
      "(10, 128, 128, 3)\n",
      "0.90564686\n",
      "[Epoch 5/10] [Batch 582/1081] [D loss: 0.063208] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.470315] time: 0:46:36.988200\n",
      "(10, 128, 128, 3)\n",
      "0.8742364\n",
      "[Epoch 5/10] [Batch 583/1081] [D loss: 0.064331] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.646877] time: 0:46:37.424697\n",
      "(10, 128, 128, 3)\n",
      "0.9154737\n",
      "[Epoch 5/10] [Batch 584/1081] [D loss: 0.064257] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.890746] time: 0:46:37.863020\n",
      "(10, 128, 128, 3)\n",
      "0.9131789\n",
      "[Epoch 5/10] [Batch 585/1081] [D loss: 0.062770] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.718735] time: 0:46:38.289919\n",
      "(10, 128, 128, 3)\n",
      "0.90744704\n",
      "[Epoch 5/10] [Batch 586/1081] [D loss: 0.063466] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.495071] time: 0:46:38.699113\n",
      "(10, 128, 128, 3)\n",
      "0.92538303\n",
      "[Epoch 5/10] [Batch 587/1081] [D loss: 0.063666] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.748717] time: 0:46:39.139510\n",
      "(10, 128, 128, 3)\n",
      "0.9019027\n",
      "[Epoch 5/10] [Batch 588/1081] [D loss: 0.062657] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.304766] time: 0:46:39.559377\n",
      "(10, 128, 128, 3)\n",
      "0.8785054\n",
      "[Epoch 5/10] [Batch 589/1081] [D loss: 0.062688] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.006819] time: 0:46:39.987918\n",
      "(10, 128, 128, 3)\n",
      "0.8684575\n",
      "[Epoch 5/10] [Batch 590/1081] [D loss: 0.063386] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.232720] time: 0:46:40.413717\n",
      "(10, 128, 128, 3)\n",
      "0.94473976\n",
      "[Epoch 5/10] [Batch 591/1081] [D loss: 1.070216] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 4.748650] time: 0:46:40.846044\n",
      "(10, 128, 128, 3)\n",
      "0.8649214\n",
      "[Epoch 5/10] [Batch 592/1081] [D loss: 0.445839] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 6.638186] time: 0:46:41.266803\n",
      "(10, 128, 128, 3)\n",
      "0.8985818\n",
      "[Epoch 5/10] [Batch 593/1081] [D loss: 0.368839] [D acc: 0.65 (0.70 real, 0.60 fake)] [G loss: 5.723458] time: 0:46:41.686134\n",
      "(10, 128, 128, 3)\n",
      "0.90661806\n",
      "[Epoch 5/10] [Batch 594/1081] [D loss: 0.423706] [D acc: 0.35 (0.20 real, 0.50 fake)] [G loss: 5.840862] time: 0:46:42.122634\n",
      "(10, 128, 128, 3)\n",
      "0.8295975\n",
      "[Epoch 5/10] [Batch 595/1081] [D loss: 0.326987] [D acc: 0.55 (0.90 real, 0.20 fake)] [G loss: 5.886083] time: 0:46:42.576178\n",
      "(10, 128, 128, 3)\n",
      "0.9149399\n",
      "[Epoch 5/10] [Batch 596/1081] [D loss: 0.403876] [D acc: 0.25 (0.10 real, 0.40 fake)] [G loss: 5.610820] time: 0:46:42.999061\n",
      "(10, 128, 128, 3)\n",
      "0.88311267\n",
      "[Epoch 5/10] [Batch 597/1081] [D loss: 0.343063] [D acc: 0.40 (0.60 real, 0.20 fake)] [G loss: 5.873402] time: 0:46:43.502931\n",
      "(10, 128, 128, 3)\n",
      "0.90255934\n",
      "[Epoch 5/10] [Batch 598/1081] [D loss: 0.395901] [D acc: 0.25 (0.40 real, 0.10 fake)] [G loss: 5.812141] time: 0:46:43.910141\n",
      "(10, 128, 128, 3)\n",
      "0.9626954\n",
      "[Epoch 5/10] [Batch 599/1081] [D loss: 0.274648] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 6.348243] time: 0:46:44.314578\n",
      "(10, 128, 128, 3)\n",
      "0.9065841\n",
      "[Epoch 5/10] [Batch 600/1081] [D loss: 0.417415] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 5.358195] time: 0:46:44.746190\n",
      "(10, 128, 128, 3)\n",
      "0.89464635\n",
      "[Epoch 5/10] [Batch 601/1081] [D loss: 0.275161] [D acc: 0.80 (0.70 real, 0.90 fake)] [G loss: 6.046054] time: 0:46:45.160634\n",
      "(10, 128, 128, 3)\n",
      "0.905608\n",
      "[Epoch 5/10] [Batch 602/1081] [D loss: 0.265038] [D acc: 0.65 (1.00 real, 0.30 fake)] [G loss: 5.694571] time: 0:46:45.586807\n",
      "(10, 128, 128, 3)\n",
      "0.92999625\n",
      "[Epoch 5/10] [Batch 603/1081] [D loss: 0.356418] [D acc: 0.50 (0.80 real, 0.20 fake)] [G loss: 5.208492] time: 0:46:46.024665\n",
      "(10, 128, 128, 3)\n",
      "0.8807669\n",
      "[Epoch 5/10] [Batch 604/1081] [D loss: 0.233936] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 6.028287] time: 0:46:46.474942\n",
      "(10, 128, 128, 3)\n",
      "0.9285014\n",
      "[Epoch 5/10] [Batch 605/1081] [D loss: 0.197549] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.705705] time: 0:46:46.903968\n",
      "(10, 128, 128, 3)\n",
      "0.89912224\n",
      "[Epoch 5/10] [Batch 606/1081] [D loss: 0.284730] [D acc: 0.65 (0.40 real, 0.90 fake)] [G loss: 5.783901] time: 0:46:47.319723\n",
      "(10, 128, 128, 3)\n",
      "0.9151322\n",
      "[Epoch 5/10] [Batch 607/1081] [D loss: 0.616978] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 5.483412] time: 0:46:47.747487\n",
      "(10, 128, 128, 3)\n",
      "0.898907\n",
      "[Epoch 5/10] [Batch 608/1081] [D loss: 0.306476] [D acc: 0.55 (1.00 real, 0.10 fake)] [G loss: 6.444402] time: 0:46:48.158372\n",
      "(10, 128, 128, 3)\n",
      "0.9202338\n",
      "[Epoch 5/10] [Batch 609/1081] [D loss: 0.270732] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 5.371527] time: 0:46:48.567949\n",
      "(10, 128, 128, 3)\n",
      "0.9251242\n",
      "[Epoch 5/10] [Batch 610/1081] [D loss: 0.367386] [D acc: 0.15 (0.10 real, 0.20 fake)] [G loss: 6.085562] time: 0:46:49.006472\n",
      "(10, 128, 128, 3)\n",
      "0.8914971\n",
      "[Epoch 5/10] [Batch 611/1081] [D loss: 0.280994] [D acc: 0.80 (0.60 real, 1.00 fake)] [G loss: 5.635421] time: 0:46:49.395040\n",
      "(10, 128, 128, 3)\n",
      "0.89425105\n",
      "[Epoch 5/10] [Batch 612/1081] [D loss: 0.432805] [D acc: 0.15 (0.10 real, 0.20 fake)] [G loss: 7.272026] time: 0:46:49.801106\n",
      "(10, 128, 128, 3)\n",
      "0.8992904\n",
      "[Epoch 5/10] [Batch 613/1081] [D loss: 0.184639] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 6.592776] time: 0:46:50.232559\n",
      "(10, 128, 128, 3)\n",
      "0.8999947\n",
      "[Epoch 5/10] [Batch 614/1081] [D loss: 0.399764] [D acc: 0.35 (0.10 real, 0.60 fake)] [G loss: 6.531999] time: 0:46:50.613294\n",
      "(10, 128, 128, 3)\n",
      "0.8880674\n",
      "[Epoch 5/10] [Batch 615/1081] [D loss: 0.248145] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 5.420713] time: 0:46:51.006907\n",
      "(10, 128, 128, 3)\n",
      "0.8807252\n",
      "[Epoch 5/10] [Batch 616/1081] [D loss: 0.356989] [D acc: 0.50 (0.90 real, 0.10 fake)] [G loss: 6.142270] time: 0:46:51.411950\n",
      "(10, 128, 128, 3)\n",
      "0.92020446\n",
      "[Epoch 5/10] [Batch 617/1081] [D loss: 0.196084] [D acc: 0.80 (0.60 real, 1.00 fake)] [G loss: 5.990018] time: 0:46:51.819231\n",
      "(10, 128, 128, 3)\n",
      "0.9465143\n",
      "[Epoch 5/10] [Batch 618/1081] [D loss: 0.417653] [D acc: 0.45 (0.90 real, 0.00 fake)] [G loss: 5.217081] time: 0:46:52.205938\n",
      "(10, 128, 128, 3)\n",
      "0.93483776\n",
      "[Epoch 5/10] [Batch 619/1081] [D loss: 0.268108] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 5.899317] time: 0:46:52.614529\n",
      "(10, 128, 128, 3)\n",
      "0.8823571\n",
      "[Epoch 5/10] [Batch 620/1081] [D loss: 0.182118] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.337706] time: 0:46:53.038409\n",
      "(10, 128, 128, 3)\n",
      "0.85517246\n",
      "[Epoch 5/10] [Batch 621/1081] [D loss: 0.236938] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 5.457539] time: 0:46:53.449366\n",
      "(10, 128, 128, 3)\n",
      "0.94619775\n",
      "[Epoch 5/10] [Batch 622/1081] [D loss: 0.185462] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 5.868135] time: 0:46:53.871529\n",
      "(10, 128, 128, 3)\n",
      "0.9330247\n",
      "[Epoch 5/10] [Batch 623/1081] [D loss: 0.239029] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 6.601640] time: 0:46:54.277443\n",
      "(10, 128, 128, 3)\n",
      "0.8963048\n",
      "[Epoch 5/10] [Batch 624/1081] [D loss: 0.334654] [D acc: 0.60 (0.90 real, 0.30 fake)] [G loss: 7.572548] time: 0:46:54.724679\n",
      "(10, 128, 128, 3)\n",
      "0.8810436\n",
      "[Epoch 5/10] [Batch 625/1081] [D loss: 0.364566] [D acc: 0.30 (0.60 real, 0.00 fake)] [G loss: 6.255875] time: 0:46:55.160014\n",
      "(10, 128, 128, 3)\n",
      "0.93174696\n",
      "[Epoch 5/10] [Batch 626/1081] [D loss: 0.278469] [D acc: 0.55 (1.00 real, 0.10 fake)] [G loss: 5.597898] time: 0:46:55.555559\n",
      "(10, 128, 128, 3)\n",
      "0.852523\n",
      "[Epoch 5/10] [Batch 627/1081] [D loss: 0.176994] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 5.985155] time: 0:46:55.974549\n",
      "(10, 128, 128, 3)\n",
      "0.9238742\n",
      "[Epoch 5/10] [Batch 628/1081] [D loss: 0.559565] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 6.398606] time: 0:46:56.386336\n",
      "(10, 128, 128, 3)\n",
      "0.9011807\n",
      "[Epoch 5/10] [Batch 629/1081] [D loss: 0.148086] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.144886] time: 0:46:56.778612\n",
      "(10, 128, 128, 3)\n",
      "0.93379503\n",
      "[Epoch 5/10] [Batch 630/1081] [D loss: 0.279260] [D acc: 0.80 (0.70 real, 0.90 fake)] [G loss: 7.097538] time: 0:46:57.207675\n",
      "(10, 128, 128, 3)\n",
      "0.937275\n",
      "[Epoch 5/10] [Batch 631/1081] [D loss: 0.174578] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 6.097041] time: 0:46:57.634396\n",
      "(10, 128, 128, 3)\n",
      "0.87831825\n",
      "[Epoch 5/10] [Batch 632/1081] [D loss: 0.184296] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.600838] time: 0:46:58.025069\n",
      "(10, 128, 128, 3)\n",
      "0.9071167\n",
      "[Epoch 5/10] [Batch 633/1081] [D loss: 0.093391] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 10.378637] time: 0:46:58.443943\n",
      "(10, 128, 128, 3)\n",
      "0.935185\n",
      "[Epoch 5/10] [Batch 634/1081] [D loss: 0.104031] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.152634] time: 0:46:58.852396\n",
      "(10, 128, 128, 3)\n",
      "0.88554764\n",
      "[Epoch 5/10] [Batch 635/1081] [D loss: 0.258579] [D acc: 0.60 (0.20 real, 1.00 fake)] [G loss: 5.314717] time: 0:46:59.278288\n",
      "(10, 128, 128, 3)\n",
      "0.9252152\n",
      "[Epoch 5/10] [Batch 636/1081] [D loss: 0.505611] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 5.888245] time: 0:46:59.718868\n",
      "(10, 128, 128, 3)\n",
      "0.9466514\n",
      "[Epoch 5/10] [Batch 637/1081] [D loss: 0.388906] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 5.930050] time: 0:47:00.122503\n",
      "(10, 128, 128, 3)\n",
      "0.94214743\n",
      "[Epoch 5/10] [Batch 638/1081] [D loss: 0.118081] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.713617] time: 0:47:00.516420\n",
      "(10, 128, 128, 3)\n",
      "0.9115949\n",
      "[Epoch 5/10] [Batch 639/1081] [D loss: 0.250453] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 22.652378] time: 0:47:00.919052\n",
      "(10, 128, 128, 3)\n",
      "0.9015565\n",
      "[Epoch 5/10] [Batch 640/1081] [D loss: 0.113336] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.413283] time: 0:47:01.318604\n",
      "(10, 128, 128, 3)\n",
      "0.9276226\n",
      "[Epoch 5/10] [Batch 641/1081] [D loss: 0.161901] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 6.189978] time: 0:47:01.745654\n",
      "(10, 128, 128, 3)\n",
      "0.9445419\n",
      "[Epoch 5/10] [Batch 642/1081] [D loss: 0.116682] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.913507] time: 0:47:02.154617\n",
      "(10, 128, 128, 3)\n",
      "0.9090357\n",
      "[Epoch 5/10] [Batch 643/1081] [D loss: 0.129818] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.785348] time: 0:47:02.596541\n",
      "(10, 128, 128, 3)\n",
      "0.9338364\n",
      "[Epoch 5/10] [Batch 644/1081] [D loss: 0.089319] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.921560] time: 0:47:03.012545\n",
      "(10, 128, 128, 3)\n",
      "0.91406417\n",
      "[Epoch 5/10] [Batch 645/1081] [D loss: 0.085456] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.283449] time: 0:47:03.468341\n",
      "(10, 128, 128, 3)\n",
      "0.91440964\n",
      "[Epoch 5/10] [Batch 646/1081] [D loss: 0.082726] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.404490] time: 0:47:03.915287\n",
      "(10, 128, 128, 3)\n",
      "0.8842578\n",
      "[Epoch 5/10] [Batch 647/1081] [D loss: 0.080839] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.487405] time: 0:47:04.343148\n",
      "(10, 128, 128, 3)\n",
      "0.92087936\n",
      "[Epoch 5/10] [Batch 648/1081] [D loss: 0.080527] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.358641] time: 0:47:04.793958\n",
      "(10, 128, 128, 3)\n",
      "0.94751114\n",
      "[Epoch 5/10] [Batch 649/1081] [D loss: 0.081593] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.225074] time: 0:47:05.175728\n",
      "(10, 128, 128, 3)\n",
      "0.9252949\n",
      "[Epoch 5/10] [Batch 650/1081] [D loss: 0.082556] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.914210] time: 0:47:05.604626\n",
      "(10, 128, 128, 3)\n",
      "0.8946249\n",
      "[Epoch 5/10] [Batch 651/1081] [D loss: 0.148415] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.969801] time: 0:47:06.025517\n",
      "(10, 128, 128, 3)\n",
      "0.88601875\n",
      "[Epoch 5/10] [Batch 652/1081] [D loss: 0.085760] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.134951] time: 0:47:06.447164\n",
      "(10, 128, 128, 3)\n",
      "0.9303166\n",
      "[Epoch 5/10] [Batch 653/1081] [D loss: 0.079191] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.270563] time: 0:47:06.857812\n",
      "(10, 128, 128, 3)\n",
      "0.9077491\n",
      "[Epoch 5/10] [Batch 654/1081] [D loss: 0.080494] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.221496] time: 0:47:07.254913\n",
      "(10, 128, 128, 3)\n",
      "0.91467255\n",
      "[Epoch 5/10] [Batch 655/1081] [D loss: 0.082078] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.206629] time: 0:47:07.655684\n",
      "(10, 128, 128, 3)\n",
      "0.9222236\n",
      "[Epoch 5/10] [Batch 656/1081] [D loss: 0.083983] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.904193] time: 0:47:08.067088\n",
      "(10, 128, 128, 3)\n",
      "0.92584866\n",
      "[Epoch 5/10] [Batch 657/1081] [D loss: 0.076775] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.388713] time: 0:47:08.471600\n",
      "(10, 128, 128, 3)\n",
      "0.9421275\n",
      "[Epoch 5/10] [Batch 658/1081] [D loss: 0.076521] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.376589] time: 0:47:08.899744\n",
      "(10, 128, 128, 3)\n",
      "0.95928836\n",
      "[Epoch 5/10] [Batch 659/1081] [D loss: 0.077185] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.833267] time: 0:47:09.328791\n",
      "(10, 128, 128, 3)\n",
      "0.86811846\n",
      "[Epoch 5/10] [Batch 660/1081] [D loss: 0.076635] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.871989] time: 0:47:09.760658\n",
      "(10, 128, 128, 3)\n",
      "0.89659375\n",
      "[Epoch 5/10] [Batch 661/1081] [D loss: 0.076836] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.775907] time: 0:47:10.166468\n",
      "(10, 128, 128, 3)\n",
      "0.90701205\n",
      "[Epoch 5/10] [Batch 662/1081] [D loss: 0.079340] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.416752] time: 0:47:10.587470\n",
      "(10, 128, 128, 3)\n",
      "0.9162751\n",
      "[Epoch 5/10] [Batch 663/1081] [D loss: 0.076618] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.392289] time: 0:47:11.018105\n",
      "(10, 128, 128, 3)\n",
      "0.9082945\n",
      "[Epoch 5/10] [Batch 664/1081] [D loss: 0.077271] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.457803] time: 0:47:11.452379\n",
      "(10, 128, 128, 3)\n",
      "0.9540325\n",
      "[Epoch 5/10] [Batch 665/1081] [D loss: 0.090311] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.199213] time: 0:47:11.846121\n",
      "(10, 128, 128, 3)\n",
      "0.94114524\n",
      "[Epoch 5/10] [Batch 666/1081] [D loss: 0.075966] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.055182] time: 0:47:12.266459\n",
      "(10, 128, 128, 3)\n",
      "0.9167313\n",
      "[Epoch 5/10] [Batch 667/1081] [D loss: 0.076942] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.630383] time: 0:47:12.672066\n",
      "(10, 128, 128, 3)\n",
      "0.9090712\n",
      "[Epoch 5/10] [Batch 668/1081] [D loss: 0.076761] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.958602] time: 0:47:13.071173\n",
      "(10, 128, 128, 3)\n",
      "0.8814559\n",
      "[Epoch 5/10] [Batch 669/1081] [D loss: 0.075115] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.381370] time: 0:47:13.454898\n",
      "(10, 128, 128, 3)\n",
      "0.92135185\n",
      "[Epoch 5/10] [Batch 670/1081] [D loss: 0.074606] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.130311] time: 0:47:13.850901\n",
      "(10, 128, 128, 3)\n",
      "0.9214869\n",
      "[Epoch 5/10] [Batch 671/1081] [D loss: 0.076487] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.221793] time: 0:47:14.313428\n",
      "(10, 128, 128, 3)\n",
      "0.92699593\n",
      "[Epoch 5/10] [Batch 672/1081] [D loss: 0.077184] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.026603] time: 0:47:14.723946\n",
      "(10, 128, 128, 3)\n",
      "0.87186813\n",
      "[Epoch 5/10] [Batch 673/1081] [D loss: 0.077562] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.744367] time: 0:47:15.117020\n",
      "(10, 128, 128, 3)\n",
      "0.90708876\n",
      "[Epoch 5/10] [Batch 674/1081] [D loss: 0.079353] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.170212] time: 0:47:15.542463\n",
      "(10, 128, 128, 3)\n",
      "0.9377606\n",
      "[Epoch 5/10] [Batch 675/1081] [D loss: 0.076075] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.923139] time: 0:47:15.983683\n",
      "(10, 128, 128, 3)\n",
      "0.86843085\n",
      "[Epoch 5/10] [Batch 676/1081] [D loss: 0.526049] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 5.645185] time: 0:47:16.421086\n",
      "(10, 128, 128, 3)\n",
      "0.90812\n",
      "[Epoch 5/10] [Batch 677/1081] [D loss: 0.338435] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 5.950065] time: 0:47:16.852446\n",
      "(10, 128, 128, 3)\n",
      "0.92792207\n",
      "[Epoch 5/10] [Batch 678/1081] [D loss: 0.225877] [D acc: 0.90 (1.00 real, 0.80 fake)] [G loss: 5.663551] time: 0:47:17.284774\n",
      "(10, 128, 128, 3)\n",
      "0.89076215\n",
      "[Epoch 5/10] [Batch 679/1081] [D loss: 0.433599] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 5.604364] time: 0:47:17.742829\n",
      "(10, 128, 128, 3)\n",
      "0.905113\n",
      "[Epoch 5/10] [Batch 680/1081] [D loss: 0.130687] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.885129] time: 0:47:18.148140\n",
      "(10, 128, 128, 3)\n",
      "0.91808206\n",
      "[Epoch 5/10] [Batch 681/1081] [D loss: 0.121631] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.958228] time: 0:47:18.574157\n",
      "(10, 128, 128, 3)\n",
      "0.942394\n",
      "[Epoch 5/10] [Batch 682/1081] [D loss: 0.182489] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 4.569543] time: 0:47:19.002531\n",
      "(10, 128, 128, 3)\n",
      "0.91007495\n",
      "[Epoch 5/10] [Batch 683/1081] [D loss: 0.108511] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.029350] time: 0:47:19.394568\n",
      "(10, 128, 128, 3)\n",
      "0.9193563\n",
      "[Epoch 5/10] [Batch 684/1081] [D loss: 0.089544] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.366564] time: 0:47:19.821254\n",
      "(10, 128, 128, 3)\n",
      "0.8896823\n",
      "[Epoch 5/10] [Batch 685/1081] [D loss: 0.128348] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.304899] time: 0:47:20.213230\n",
      "(10, 128, 128, 3)\n",
      "0.9412463\n",
      "[Epoch 5/10] [Batch 686/1081] [D loss: 0.106121] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.991429] time: 0:47:20.625487\n",
      "(10, 128, 128, 3)\n",
      "0.9035127\n",
      "[Epoch 5/10] [Batch 687/1081] [D loss: 0.079354] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.862995] time: 0:47:21.057476\n",
      "(10, 128, 128, 3)\n",
      "0.88152194\n",
      "[Epoch 5/10] [Batch 688/1081] [D loss: 0.081040] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.002700] time: 0:47:21.518280\n",
      "(10, 128, 128, 3)\n",
      "0.9446508\n",
      "[Epoch 5/10] [Batch 689/1081] [D loss: 0.078886] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.089313] time: 0:47:21.936534\n",
      "(10, 128, 128, 3)\n",
      "0.96589786\n",
      "[Epoch 5/10] [Batch 690/1081] [D loss: 0.082905] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.760842] time: 0:47:22.354645\n",
      "(10, 128, 128, 3)\n",
      "0.9371342\n",
      "[Epoch 5/10] [Batch 691/1081] [D loss: 0.078590] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.942061] time: 0:47:22.773554\n",
      "(10, 128, 128, 3)\n",
      "0.86944443\n",
      "[Epoch 5/10] [Batch 692/1081] [D loss: 0.080722] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.287854] time: 0:47:23.200578\n",
      "(10, 128, 128, 3)\n",
      "0.93336123\n",
      "[Epoch 5/10] [Batch 693/1081] [D loss: 0.077320] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.736639] time: 0:47:23.646217\n",
      "(10, 128, 128, 3)\n",
      "0.9314262\n",
      "[Epoch 5/10] [Batch 694/1081] [D loss: 0.083013] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.879459] time: 0:47:24.089348\n",
      "(10, 128, 128, 3)\n",
      "0.8954823\n",
      "[Epoch 5/10] [Batch 695/1081] [D loss: 0.080464] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.993838] time: 0:47:24.503347\n",
      "(10, 128, 128, 3)\n",
      "0.88840485\n",
      "[Epoch 5/10] [Batch 696/1081] [D loss: 0.074984] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.265980] time: 0:47:24.944094\n",
      "(10, 128, 128, 3)\n",
      "0.890043\n",
      "[Epoch 5/10] [Batch 697/1081] [D loss: 0.076766] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.871429] time: 0:47:25.368039\n",
      "(10, 128, 128, 3)\n",
      "0.9116561\n",
      "[Epoch 5/10] [Batch 698/1081] [D loss: 0.076439] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.898761] time: 0:47:25.790032\n",
      "(10, 128, 128, 3)\n",
      "0.93826103\n",
      "[Epoch 5/10] [Batch 699/1081] [D loss: 0.075352] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.997352] time: 0:47:26.217325\n",
      "(10, 128, 128, 3)\n",
      "0.9492809\n",
      "[Epoch 5/10] [Batch 700/1081] [D loss: 0.078197] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.115024] time: 0:47:26.670981\n",
      "(10, 128, 128, 3)\n",
      "0.88333076\n",
      "[Epoch 5/10] [Batch 701/1081] [D loss: 0.075148] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.035494] time: 0:47:27.105896\n",
      "(10, 128, 128, 3)\n",
      "0.88829106\n",
      "[Epoch 5/10] [Batch 702/1081] [D loss: 0.075264] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.769458] time: 0:47:27.510002\n",
      "(10, 128, 128, 3)\n",
      "0.94689757\n",
      "[Epoch 5/10] [Batch 703/1081] [D loss: 0.076677] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.631560] time: 0:47:27.934685\n",
      "(10, 128, 128, 3)\n",
      "0.92614454\n",
      "[Epoch 5/10] [Batch 704/1081] [D loss: 0.074030] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.527751] time: 0:47:28.357477\n",
      "(10, 128, 128, 3)\n",
      "0.94557196\n",
      "[Epoch 5/10] [Batch 705/1081] [D loss: 0.074555] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.339620] time: 0:47:28.764867\n",
      "(10, 128, 128, 3)\n",
      "0.9580479\n",
      "[Epoch 5/10] [Batch 706/1081] [D loss: 0.073842] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.513698] time: 0:47:29.181665\n",
      "(10, 128, 128, 3)\n",
      "0.9083819\n",
      "[Epoch 5/10] [Batch 707/1081] [D loss: 0.072473] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.237411] time: 0:47:29.601649\n",
      "(10, 128, 128, 3)\n",
      "0.8796985\n",
      "[Epoch 5/10] [Batch 708/1081] [D loss: 0.077345] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.095033] time: 0:47:30.001108\n",
      "(10, 128, 128, 3)\n",
      "0.9757772\n",
      "[Epoch 5/10] [Batch 709/1081] [D loss: 0.075329] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.346144] time: 0:47:30.427731\n",
      "(10, 128, 128, 3)\n",
      "0.9354674\n",
      "[Epoch 5/10] [Batch 710/1081] [D loss: 0.076054] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.058341] time: 0:47:30.818333\n",
      "(10, 128, 128, 3)\n",
      "0.8941932\n",
      "[Epoch 5/10] [Batch 711/1081] [D loss: 0.073441] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.116700] time: 0:47:31.280379\n",
      "(10, 128, 128, 3)\n",
      "0.9043951\n",
      "[Epoch 5/10] [Batch 712/1081] [D loss: 0.072544] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.361536] time: 0:47:31.709318\n",
      "(10, 128, 128, 3)\n",
      "0.86634463\n",
      "[Epoch 5/10] [Batch 713/1081] [D loss: 0.075244] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.603921] time: 0:47:32.143483\n",
      "(10, 128, 128, 3)\n",
      "0.9434853\n",
      "[Epoch 5/10] [Batch 714/1081] [D loss: 0.073796] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.122569] time: 0:47:32.576054\n",
      "(10, 128, 128, 3)\n",
      "0.8556449\n",
      "[Epoch 5/10] [Batch 715/1081] [D loss: 0.073149] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.425290] time: 0:47:33.010627\n",
      "(10, 128, 128, 3)\n",
      "0.9115984\n",
      "[Epoch 5/10] [Batch 716/1081] [D loss: 0.073343] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.933651] time: 0:47:33.447641\n",
      "(10, 128, 128, 3)\n",
      "0.9115122\n",
      "[Epoch 5/10] [Batch 717/1081] [D loss: 0.071376] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.495358] time: 0:47:33.871856\n",
      "(10, 128, 128, 3)\n",
      "0.93481666\n",
      "[Epoch 5/10] [Batch 718/1081] [D loss: 0.074113] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.809502] time: 0:47:34.298041\n",
      "(10, 128, 128, 3)\n",
      "0.91657144\n",
      "[Epoch 5/10] [Batch 719/1081] [D loss: 0.073515] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.004911] time: 0:47:34.736373\n",
      "(10, 128, 128, 3)\n",
      "0.9442194\n",
      "[Epoch 5/10] [Batch 720/1081] [D loss: 0.072440] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.869787] time: 0:47:35.182921\n",
      "(10, 128, 128, 3)\n",
      "0.9352047\n",
      "[Epoch 5/10] [Batch 721/1081] [D loss: 0.071964] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.053088] time: 0:47:35.596098\n",
      "(10, 128, 128, 3)\n",
      "0.9290991\n",
      "[Epoch 5/10] [Batch 722/1081] [D loss: 0.070819] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.319365] time: 0:47:35.991727\n",
      "(10, 128, 128, 3)\n",
      "0.9679485\n",
      "[Epoch 5/10] [Batch 723/1081] [D loss: 0.070797] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.617284] time: 0:47:36.396039\n",
      "(10, 128, 128, 3)\n",
      "0.9326825\n",
      "[Epoch 5/10] [Batch 724/1081] [D loss: 0.071703] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.346304] time: 0:47:36.816064\n",
      "(10, 128, 128, 3)\n",
      "0.9298728\n",
      "[Epoch 5/10] [Batch 725/1081] [D loss: 0.070619] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.755805] time: 0:47:37.215464\n",
      "(10, 128, 128, 3)\n",
      "0.9095809\n",
      "[Epoch 5/10] [Batch 726/1081] [D loss: 0.072814] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.532137] time: 0:47:37.623882\n",
      "(10, 128, 128, 3)\n",
      "0.88201827\n",
      "[Epoch 5/10] [Batch 727/1081] [D loss: 0.075481] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.858529] time: 0:47:38.033270\n",
      "(10, 128, 128, 3)\n",
      "0.9228613\n",
      "[Epoch 5/10] [Batch 728/1081] [D loss: 0.070157] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.615979] time: 0:47:38.454630\n",
      "(10, 128, 128, 3)\n",
      "0.93566275\n",
      "[Epoch 5/10] [Batch 729/1081] [D loss: 0.070558] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.399293] time: 0:47:38.879667\n",
      "(10, 128, 128, 3)\n",
      "0.9234658\n",
      "[Epoch 5/10] [Batch 730/1081] [D loss: 0.070486] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.522702] time: 0:47:39.317036\n",
      "(10, 128, 128, 3)\n",
      "0.92037535\n",
      "[Epoch 5/10] [Batch 731/1081] [D loss: 0.070542] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.684211] time: 0:47:39.767438\n",
      "(10, 128, 128, 3)\n",
      "0.9497587\n",
      "[Epoch 5/10] [Batch 732/1081] [D loss: 0.069466] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.998687] time: 0:47:40.219072\n",
      "(10, 128, 128, 3)\n",
      "0.9378531\n",
      "[Epoch 5/10] [Batch 733/1081] [D loss: 0.070495] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.868490] time: 0:47:40.612335\n",
      "(10, 128, 128, 3)\n",
      "0.9474818\n",
      "[Epoch 5/10] [Batch 734/1081] [D loss: 0.071798] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.857652] time: 0:47:40.982723\n",
      "(10, 128, 128, 3)\n",
      "0.9088983\n",
      "[Epoch 5/10] [Batch 735/1081] [D loss: 0.069714] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.954245] time: 0:47:41.380353\n",
      "(10, 128, 128, 3)\n",
      "0.8762207\n",
      "[Epoch 5/10] [Batch 736/1081] [D loss: 0.069475] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.625570] time: 0:47:41.804370\n",
      "(10, 128, 128, 3)\n",
      "0.88530046\n",
      "[Epoch 5/10] [Batch 737/1081] [D loss: 0.069508] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.655883] time: 0:47:42.212185\n",
      "(10, 128, 128, 3)\n",
      "0.9207929\n",
      "[Epoch 5/10] [Batch 738/1081] [D loss: 0.070353] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.958073] time: 0:47:42.639667\n",
      "(10, 128, 128, 3)\n",
      "0.9387242\n",
      "[Epoch 5/10] [Batch 739/1081] [D loss: 0.069198] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.875563] time: 0:47:43.068197\n",
      "(10, 128, 128, 3)\n",
      "0.8832743\n",
      "[Epoch 5/10] [Batch 740/1081] [D loss: 0.075094] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.083614] time: 0:47:43.496861\n",
      "(10, 128, 128, 3)\n",
      "0.9171199\n",
      "[Epoch 5/10] [Batch 741/1081] [D loss: 0.068831] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.376925] time: 0:47:43.932806\n",
      "(10, 128, 128, 3)\n",
      "0.8883856\n",
      "[Epoch 5/10] [Batch 742/1081] [D loss: 0.069503] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.842911] time: 0:47:44.328621\n",
      "(10, 128, 128, 3)\n",
      "0.87990147\n",
      "[Epoch 5/10] [Batch 743/1081] [D loss: 0.068770] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.956819] time: 0:47:44.747411\n",
      "(10, 128, 128, 3)\n",
      "0.87375593\n",
      "[Epoch 5/10] [Batch 744/1081] [D loss: 0.072050] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.771084] time: 0:47:45.180144\n",
      "(10, 128, 128, 3)\n",
      "0.90743756\n",
      "[Epoch 5/10] [Batch 745/1081] [D loss: 0.069307] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.436889] time: 0:47:45.591507\n",
      "(10, 128, 128, 3)\n",
      "0.9155343\n",
      "[Epoch 5/10] [Batch 746/1081] [D loss: 0.068986] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.853274] time: 0:47:46.050902\n",
      "(10, 128, 128, 3)\n",
      "0.895701\n",
      "[Epoch 5/10] [Batch 747/1081] [D loss: 0.068818] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.118842] time: 0:47:46.462718\n",
      "(10, 128, 128, 3)\n",
      "0.889244\n",
      "[Epoch 5/10] [Batch 748/1081] [D loss: 0.068173] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.326785] time: 0:47:46.859373\n",
      "(10, 128, 128, 3)\n",
      "0.9406946\n",
      "[Epoch 5/10] [Batch 749/1081] [D loss: 0.069545] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.889420] time: 0:47:47.278038\n",
      "(10, 128, 128, 3)\n",
      "0.905302\n",
      "[Epoch 5/10] [Batch 750/1081] [D loss: 0.068577] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.458506] time: 0:47:47.715477\n",
      "(10, 128, 128, 3)\n",
      "0.9171095\n",
      "[Epoch 5/10] [Batch 751/1081] [D loss: 0.092235] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.605892] time: 0:47:48.173796\n",
      "(10, 128, 128, 3)\n",
      "0.8786362\n",
      "[Epoch 5/10] [Batch 752/1081] [D loss: 0.079913] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.547350] time: 0:47:48.611932\n",
      "(10, 128, 128, 3)\n",
      "0.9338994\n",
      "[Epoch 5/10] [Batch 753/1081] [D loss: 0.240756] [D acc: 0.75 (1.00 real, 0.50 fake)] [G loss: 5.351837] time: 0:47:49.064969\n",
      "(10, 128, 128, 3)\n",
      "0.9278426\n",
      "[Epoch 5/10] [Batch 754/1081] [D loss: 0.092460] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.649842] time: 0:47:49.499972\n",
      "(10, 128, 128, 3)\n",
      "0.9338948\n",
      "[Epoch 5/10] [Batch 755/1081] [D loss: 0.087889] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.362364] time: 0:47:49.942830\n",
      "(10, 128, 128, 3)\n",
      "0.92002887\n",
      "[Epoch 5/10] [Batch 756/1081] [D loss: 0.089990] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.112271] time: 0:47:50.657167\n",
      "(10, 128, 128, 3)\n",
      "0.86543435\n",
      "[Epoch 5/10] [Batch 757/1081] [D loss: 0.123583] [D acc: 0.90 (0.90 real, 0.90 fake)] [G loss: 7.128804] time: 0:47:51.050221\n",
      "(10, 128, 128, 3)\n",
      "0.9073331\n",
      "[Epoch 5/10] [Batch 758/1081] [D loss: 0.192043] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 7.131345] time: 0:47:51.521622\n",
      "(10, 128, 128, 3)\n",
      "0.88995105\n",
      "[Epoch 5/10] [Batch 759/1081] [D loss: 0.082719] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.532500] time: 0:47:51.949831\n",
      "(10, 128, 128, 3)\n",
      "0.9026343\n",
      "[Epoch 5/10] [Batch 760/1081] [D loss: 0.083860] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.314681] time: 0:47:52.384076\n",
      "(10, 128, 128, 3)\n",
      "0.88615704\n",
      "[Epoch 5/10] [Batch 761/1081] [D loss: 0.160703] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.969969] time: 0:47:52.855040\n",
      "(10, 128, 128, 3)\n",
      "0.87029314\n",
      "[Epoch 5/10] [Batch 762/1081] [D loss: 0.286175] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 140.238220] time: 0:47:53.278190\n",
      "(10, 128, 128, 3)\n",
      "0.97807235\n",
      "[Epoch 5/10] [Batch 763/1081] [D loss: 0.515508] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 9.616156] time: 0:47:53.709022\n",
      "(10, 128, 128, 3)\n",
      "0.9545951\n",
      "[Epoch 5/10] [Batch 764/1081] [D loss: 0.236236] [D acc: 0.85 (1.00 real, 0.70 fake)] [G loss: 8.565066] time: 0:47:54.145690\n",
      "(10, 128, 128, 3)\n",
      "0.8709267\n",
      "[Epoch 5/10] [Batch 765/1081] [D loss: 0.308829] [D acc: 0.60 (0.30 real, 0.90 fake)] [G loss: 6.536894] time: 0:47:54.560965\n",
      "(10, 128, 128, 3)\n",
      "0.9251873\n",
      "[Epoch 5/10] [Batch 766/1081] [D loss: 0.203843] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 7.594733] time: 0:47:54.974085\n",
      "(10, 128, 128, 3)\n",
      "0.94103056\n",
      "[Epoch 5/10] [Batch 767/1081] [D loss: 0.138263] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.307318] time: 0:47:55.406355\n",
      "(10, 128, 128, 3)\n",
      "0.8886873\n",
      "[Epoch 5/10] [Batch 768/1081] [D loss: 0.122646] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.780334] time: 0:47:55.868284\n",
      "(10, 128, 128, 3)\n",
      "0.91335225\n",
      "[Epoch 5/10] [Batch 769/1081] [D loss: 0.106685] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.145538] time: 0:47:56.271488\n",
      "(10, 128, 128, 3)\n",
      "0.8300652\n",
      "[Epoch 5/10] [Batch 770/1081] [D loss: 0.099314] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.585121] time: 0:47:56.682815\n",
      "(10, 128, 128, 3)\n",
      "0.937555\n",
      "[Epoch 5/10] [Batch 771/1081] [D loss: 0.094829] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.488849] time: 0:47:57.119101\n",
      "(10, 128, 128, 3)\n",
      "0.9030311\n",
      "[Epoch 5/10] [Batch 772/1081] [D loss: 0.093796] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.717921] time: 0:47:57.522332\n",
      "(10, 128, 128, 3)\n",
      "0.9133839\n",
      "[Epoch 5/10] [Batch 773/1081] [D loss: 0.093983] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.503266] time: 0:47:57.927406\n",
      "(10, 128, 128, 3)\n",
      "0.95122385\n",
      "[Epoch 5/10] [Batch 774/1081] [D loss: 0.093705] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.898667] time: 0:47:58.337355\n",
      "(10, 128, 128, 3)\n",
      "0.9089075\n",
      "[Epoch 5/10] [Batch 775/1081] [D loss: 0.090843] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.532567] time: 0:47:58.761035\n",
      "(10, 128, 128, 3)\n",
      "0.9017322\n",
      "[Epoch 5/10] [Batch 776/1081] [D loss: 0.094628] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.082081] time: 0:47:59.186235\n",
      "(10, 128, 128, 3)\n",
      "0.8793302\n",
      "[Epoch 5/10] [Batch 777/1081] [D loss: 0.118531] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.050399] time: 0:47:59.569345\n",
      "(10, 128, 128, 3)\n",
      "0.93927765\n",
      "[Epoch 5/10] [Batch 778/1081] [D loss: 0.090230] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.444871] time: 0:47:59.971414\n",
      "(10, 128, 128, 3)\n",
      "0.9339385\n",
      "[Epoch 5/10] [Batch 779/1081] [D loss: 0.140415] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.458359] time: 0:48:00.367882\n",
      "(10, 128, 128, 3)\n",
      "0.9491314\n",
      "[Epoch 5/10] [Batch 780/1081] [D loss: 0.090563] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.521024] time: 0:48:00.761269\n",
      "(10, 128, 128, 3)\n",
      "0.8749295\n",
      "[Epoch 5/10] [Batch 781/1081] [D loss: 0.091693] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.167409] time: 0:48:01.194151\n",
      "(10, 128, 128, 3)\n",
      "0.9322342\n",
      "[Epoch 5/10] [Batch 782/1081] [D loss: 0.113974] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.902342] time: 0:48:01.605146\n",
      "(10, 128, 128, 3)\n",
      "0.9034849\n",
      "[Epoch 5/10] [Batch 783/1081] [D loss: 0.099675] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.431415] time: 0:48:02.012214\n",
      "(10, 128, 128, 3)\n",
      "0.82718915\n",
      "[Epoch 5/10] [Batch 784/1081] [D loss: 0.091866] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.389424] time: 0:48:02.471793\n",
      "(10, 128, 128, 3)\n",
      "0.9223964\n",
      "[Epoch 5/10] [Batch 785/1081] [D loss: 0.089306] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.462622] time: 0:48:02.875617\n",
      "(10, 128, 128, 3)\n",
      "0.94798136\n",
      "[Epoch 5/10] [Batch 786/1081] [D loss: 0.091301] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.411699] time: 0:48:03.292450\n",
      "(10, 128, 128, 3)\n",
      "0.94408125\n",
      "[Epoch 5/10] [Batch 787/1081] [D loss: 0.086970] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.743003] time: 0:48:03.732252\n",
      "(10, 128, 128, 3)\n",
      "0.9232073\n",
      "[Epoch 5/10] [Batch 788/1081] [D loss: 0.086634] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.800820] time: 0:48:04.131955\n",
      "(10, 128, 128, 3)\n",
      "0.8916823\n",
      "[Epoch 5/10] [Batch 789/1081] [D loss: 0.087494] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.303583] time: 0:48:04.573059\n",
      "(10, 128, 128, 3)\n",
      "0.9270472\n",
      "[Epoch 5/10] [Batch 790/1081] [D loss: 0.087269] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.689477] time: 0:48:05.020403\n",
      "(10, 128, 128, 3)\n",
      "0.9157984\n",
      "[Epoch 5/10] [Batch 791/1081] [D loss: 0.093844] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.781579] time: 0:48:05.441172\n",
      "(10, 128, 128, 3)\n",
      "0.9343199\n",
      "[Epoch 5/10] [Batch 792/1081] [D loss: 0.088960] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.367415] time: 0:48:05.842083\n",
      "(10, 128, 128, 3)\n",
      "0.8701005\n",
      "[Epoch 5/10] [Batch 793/1081] [D loss: 0.090771] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.878530] time: 0:48:06.267250\n",
      "(10, 128, 128, 3)\n",
      "0.93116075\n",
      "[Epoch 5/10] [Batch 794/1081] [D loss: 0.088161] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.348387] time: 0:48:06.661312\n",
      "(10, 128, 128, 3)\n",
      "0.9003485\n",
      "[Epoch 5/10] [Batch 795/1081] [D loss: 0.088698] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.150125] time: 0:48:07.082136\n",
      "(10, 128, 128, 3)\n",
      "0.8523245\n",
      "[Epoch 5/10] [Batch 796/1081] [D loss: 0.085159] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.195284] time: 0:48:07.493972\n",
      "(10, 128, 128, 3)\n",
      "0.8834041\n",
      "[Epoch 5/10] [Batch 797/1081] [D loss: 0.084872] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.031865] time: 0:48:07.911038\n",
      "(10, 128, 128, 3)\n",
      "0.9524691\n",
      "[Epoch 5/10] [Batch 798/1081] [D loss: 0.085181] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.940450] time: 0:48:08.353671\n",
      "(10, 128, 128, 3)\n",
      "0.9454374\n",
      "[Epoch 5/10] [Batch 799/1081] [D loss: 0.087628] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.071258] time: 0:48:08.767070\n",
      "(10, 128, 128, 3)\n",
      "0.87150747\n",
      "[Epoch 5/10] [Batch 800/1081] [D loss: 0.086547] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.416883] time: 0:48:09.184987\n",
      "(10, 128, 128, 3)\n",
      "0.87556034\n",
      "[Epoch 5/10] [Batch 801/1081] [D loss: 0.093546] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.084343] time: 0:48:09.622406\n",
      "(10, 128, 128, 3)\n",
      "0.9105882\n",
      "[Epoch 5/10] [Batch 802/1081] [D loss: 0.084765] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.763589] time: 0:48:10.082002\n",
      "(10, 128, 128, 3)\n",
      "0.9479596\n",
      "[Epoch 5/10] [Batch 803/1081] [D loss: 0.084532] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.620149] time: 0:48:10.487445\n",
      "(10, 128, 128, 3)\n",
      "0.905799\n",
      "[Epoch 5/10] [Batch 804/1081] [D loss: 0.085464] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.533342] time: 0:48:10.935876\n",
      "(10, 128, 128, 3)\n",
      "0.9327075\n",
      "[Epoch 5/10] [Batch 805/1081] [D loss: 0.084239] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.575866] time: 0:48:11.369833\n",
      "(10, 128, 128, 3)\n",
      "0.90047854\n",
      "[Epoch 5/10] [Batch 806/1081] [D loss: 0.083759] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.595960] time: 0:48:11.808530\n",
      "(10, 128, 128, 3)\n",
      "0.9233363\n",
      "[Epoch 5/10] [Batch 807/1081] [D loss: 0.085206] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.492674] time: 0:48:12.224671\n",
      "(10, 128, 128, 3)\n",
      "0.9004372\n",
      "[Epoch 5/10] [Batch 808/1081] [D loss: 0.082998] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.115159] time: 0:48:12.663740\n",
      "(10, 128, 128, 3)\n",
      "0.9105077\n",
      "[Epoch 5/10] [Batch 809/1081] [D loss: 0.082247] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.868451] time: 0:48:13.079950\n",
      "(10, 128, 128, 3)\n",
      "0.93149704\n",
      "[Epoch 5/10] [Batch 810/1081] [D loss: 0.082913] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.998771] time: 0:48:13.500477\n",
      "(10, 128, 128, 3)\n",
      "0.92822784\n",
      "[Epoch 5/10] [Batch 811/1081] [D loss: 0.083142] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.868758] time: 0:48:13.919424\n",
      "(10, 128, 128, 3)\n",
      "0.8807814\n",
      "[Epoch 5/10] [Batch 812/1081] [D loss: 0.081004] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.408385] time: 0:48:14.370304\n",
      "(10, 128, 128, 3)\n",
      "0.93375975\n",
      "[Epoch 5/10] [Batch 813/1081] [D loss: 0.082885] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.070104] time: 0:48:14.818815\n",
      "(10, 128, 128, 3)\n",
      "0.8796379\n",
      "[Epoch 5/10] [Batch 814/1081] [D loss: 0.082700] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.356870] time: 0:48:15.206314\n",
      "(10, 128, 128, 3)\n",
      "0.9014025\n",
      "[Epoch 5/10] [Batch 815/1081] [D loss: 0.083021] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.997410] time: 0:48:15.613296\n",
      "(10, 128, 128, 3)\n",
      "0.9056135\n",
      "[Epoch 5/10] [Batch 816/1081] [D loss: 0.080877] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.062578] time: 0:48:16.033153\n",
      "(10, 128, 128, 3)\n",
      "0.887899\n",
      "[Epoch 5/10] [Batch 817/1081] [D loss: 0.083205] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.734235] time: 0:48:16.453969\n",
      "(10, 128, 128, 3)\n",
      "0.9475443\n",
      "[Epoch 5/10] [Batch 818/1081] [D loss: 0.081748] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.807352] time: 0:48:16.851656\n",
      "(10, 128, 128, 3)\n",
      "0.8656269\n",
      "[Epoch 5/10] [Batch 819/1081] [D loss: 0.080748] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.815001] time: 0:48:17.243441\n",
      "(10, 128, 128, 3)\n",
      "0.887024\n",
      "[Epoch 5/10] [Batch 820/1081] [D loss: 0.079793] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.083291] time: 0:48:17.684939\n",
      "(10, 128, 128, 3)\n",
      "0.9140301\n",
      "[Epoch 5/10] [Batch 821/1081] [D loss: 0.082639] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.401029] time: 0:48:18.084436\n",
      "(10, 128, 128, 3)\n",
      "0.9090212\n",
      "[Epoch 5/10] [Batch 822/1081] [D loss: 0.081604] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.004899] time: 0:48:18.470539\n",
      "(10, 128, 128, 3)\n",
      "0.9090533\n",
      "[Epoch 5/10] [Batch 823/1081] [D loss: 0.079158] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.947218] time: 0:48:18.887637\n",
      "(10, 128, 128, 3)\n",
      "0.88419443\n",
      "[Epoch 5/10] [Batch 824/1081] [D loss: 0.080814] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.150414] time: 0:48:19.302789\n",
      "(10, 128, 128, 3)\n",
      "0.9433031\n",
      "[Epoch 5/10] [Batch 825/1081] [D loss: 0.080579] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.560127] time: 0:48:19.735904\n",
      "(10, 128, 128, 3)\n",
      "0.93365926\n",
      "[Epoch 5/10] [Batch 826/1081] [D loss: 0.078998] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.651893] time: 0:48:20.160870\n",
      "(10, 128, 128, 3)\n",
      "0.920048\n",
      "[Epoch 5/10] [Batch 827/1081] [D loss: 0.078402] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.121779] time: 0:48:20.583748\n",
      "(10, 128, 128, 3)\n",
      "0.9008851\n",
      "[Epoch 5/10] [Batch 828/1081] [D loss: 0.085305] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.163629] time: 0:48:20.988463\n",
      "(10, 128, 128, 3)\n",
      "0.8884959\n",
      "[Epoch 5/10] [Batch 829/1081] [D loss: 0.078944] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.065721] time: 0:48:21.411930\n",
      "(10, 128, 128, 3)\n",
      "0.9339885\n",
      "[Epoch 5/10] [Batch 830/1081] [D loss: 0.078063] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.017952] time: 0:48:21.817891\n",
      "(10, 128, 128, 3)\n",
      "0.9047319\n",
      "[Epoch 5/10] [Batch 831/1081] [D loss: 0.077883] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.290707] time: 0:48:22.225056\n",
      "(10, 128, 128, 3)\n",
      "0.9537294\n",
      "[Epoch 5/10] [Batch 832/1081] [D loss: 0.077683] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.265444] time: 0:48:22.646223\n",
      "(10, 128, 128, 3)\n",
      "0.9296994\n",
      "[Epoch 5/10] [Batch 833/1081] [D loss: 0.078609] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.335116] time: 0:48:23.043671\n",
      "(10, 128, 128, 3)\n",
      "0.91444355\n",
      "[Epoch 5/10] [Batch 834/1081] [D loss: 0.077375] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.878752] time: 0:48:23.462005\n",
      "(10, 128, 128, 3)\n",
      "0.91030127\n",
      "[Epoch 5/10] [Batch 835/1081] [D loss: 0.077634] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.251701] time: 0:48:23.851954\n",
      "(10, 128, 128, 3)\n",
      "0.91889954\n",
      "[Epoch 5/10] [Batch 836/1081] [D loss: 0.079110] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.963619] time: 0:48:24.314800\n",
      "(10, 128, 128, 3)\n",
      "0.95242804\n",
      "[Epoch 5/10] [Batch 837/1081] [D loss: 0.079787] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.766749] time: 0:48:24.738551\n",
      "(10, 128, 128, 3)\n",
      "0.91334635\n",
      "[Epoch 5/10] [Batch 838/1081] [D loss: 0.077742] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.738931] time: 0:48:25.153915\n",
      "(10, 128, 128, 3)\n",
      "0.9630553\n",
      "[Epoch 5/10] [Batch 839/1081] [D loss: 0.077379] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.209869] time: 0:48:25.574763\n",
      "(10, 128, 128, 3)\n",
      "0.9585318\n",
      "[Epoch 5/10] [Batch 840/1081] [D loss: 0.079643] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.702370] time: 0:48:26.053665\n",
      "(10, 128, 128, 3)\n",
      "0.9405844\n",
      "[Epoch 5/10] [Batch 841/1081] [D loss: 0.076668] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.882957] time: 0:48:26.468207\n",
      "(10, 128, 128, 3)\n",
      "0.87279797\n",
      "[Epoch 5/10] [Batch 842/1081] [D loss: 0.078422] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.331513] time: 0:48:26.891499\n",
      "(10, 128, 128, 3)\n",
      "0.9709459\n",
      "[Epoch 5/10] [Batch 843/1081] [D loss: 0.077053] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.439574] time: 0:48:27.330482\n",
      "(10, 128, 128, 3)\n",
      "0.8335473\n",
      "[Epoch 5/10] [Batch 844/1081] [D loss: 0.076477] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.414363] time: 0:48:27.746470\n",
      "(10, 128, 128, 3)\n",
      "0.9226794\n",
      "[Epoch 5/10] [Batch 845/1081] [D loss: 0.076697] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.479937] time: 0:48:28.176007\n",
      "(10, 128, 128, 3)\n",
      "0.89199424\n",
      "[Epoch 5/10] [Batch 846/1081] [D loss: 0.076670] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.414171] time: 0:48:28.581913\n",
      "(10, 128, 128, 3)\n",
      "0.8938075\n",
      "[Epoch 5/10] [Batch 847/1081] [D loss: 0.075927] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.948457] time: 0:48:28.972456\n",
      "(10, 128, 128, 3)\n",
      "0.94022346\n",
      "[Epoch 5/10] [Batch 848/1081] [D loss: 0.080261] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.033956] time: 0:48:29.376728\n",
      "(10, 128, 128, 3)\n",
      "0.892451\n",
      "[Epoch 5/10] [Batch 849/1081] [D loss: 0.076387] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.455994] time: 0:48:29.782167\n",
      "(10, 128, 128, 3)\n",
      "0.90822786\n",
      "[Epoch 5/10] [Batch 850/1081] [D loss: 0.075777] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.900042] time: 0:48:30.166200\n",
      "(10, 128, 128, 3)\n",
      "0.94445324\n",
      "[Epoch 5/10] [Batch 851/1081] [D loss: 0.074499] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.064743] time: 0:48:30.573526\n",
      "(10, 128, 128, 3)\n",
      "0.93185145\n",
      "[Epoch 5/10] [Batch 852/1081] [D loss: 0.074210] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.888691] time: 0:48:31.010053\n",
      "(10, 128, 128, 3)\n",
      "0.90904456\n",
      "[Epoch 5/10] [Batch 853/1081] [D loss: 0.079126] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.852695] time: 0:48:31.431846\n",
      "(10, 128, 128, 3)\n",
      "0.9217817\n",
      "[Epoch 5/10] [Batch 854/1081] [D loss: 0.075206] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.908009] time: 0:48:31.851817\n",
      "(10, 128, 128, 3)\n",
      "0.948909\n",
      "[Epoch 5/10] [Batch 855/1081] [D loss: 0.074657] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.932693] time: 0:48:32.280100\n",
      "(10, 128, 128, 3)\n",
      "0.882309\n",
      "[Epoch 5/10] [Batch 856/1081] [D loss: 0.073627] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.706915] time: 0:48:32.724290\n",
      "(10, 128, 128, 3)\n",
      "0.9003245\n",
      "[Epoch 5/10] [Batch 857/1081] [D loss: 0.076890] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.631918] time: 0:48:33.151680\n",
      "(10, 128, 128, 3)\n",
      "0.8873003\n",
      "[Epoch 5/10] [Batch 858/1081] [D loss: 0.073979] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.242548] time: 0:48:33.591077\n",
      "(10, 128, 128, 3)\n",
      "0.9300439\n",
      "[Epoch 5/10] [Batch 859/1081] [D loss: 0.073638] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.211711] time: 0:48:33.977802\n",
      "(10, 128, 128, 3)\n",
      "0.8995891\n",
      "[Epoch 5/10] [Batch 860/1081] [D loss: 0.074355] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.290709] time: 0:48:34.398453\n",
      "(10, 128, 128, 3)\n",
      "0.9018944\n",
      "[Epoch 5/10] [Batch 861/1081] [D loss: 0.075064] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.626793] time: 0:48:34.805584\n",
      "(10, 128, 128, 3)\n",
      "0.966827\n",
      "[Epoch 5/10] [Batch 862/1081] [D loss: 0.073423] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.920150] time: 0:48:35.232420\n",
      "(10, 128, 128, 3)\n",
      "0.90461653\n",
      "[Epoch 5/10] [Batch 863/1081] [D loss: 0.072742] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.459566] time: 0:48:35.659089\n",
      "(10, 128, 128, 3)\n",
      "0.91083956\n",
      "[Epoch 5/10] [Batch 864/1081] [D loss: 0.073087] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.747007] time: 0:48:36.108152\n",
      "(10, 128, 128, 3)\n",
      "0.97043616\n",
      "[Epoch 5/10] [Batch 865/1081] [D loss: 0.072733] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.149305] time: 0:48:36.554796\n",
      "(10, 128, 128, 3)\n",
      "0.8871355\n",
      "[Epoch 5/10] [Batch 866/1081] [D loss: 0.073137] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.935185] time: 0:48:36.990846\n",
      "(10, 128, 128, 3)\n",
      "0.92583203\n",
      "[Epoch 5/10] [Batch 867/1081] [D loss: 0.073147] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.298717] time: 0:48:37.416352\n",
      "(10, 128, 128, 3)\n",
      "0.9271501\n",
      "[Epoch 5/10] [Batch 868/1081] [D loss: 0.076661] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.088604] time: 0:48:37.831879\n",
      "(10, 128, 128, 3)\n",
      "0.91067976\n",
      "[Epoch 5/10] [Batch 869/1081] [D loss: 0.398090] [D acc: 0.25 (0.20 real, 0.30 fake)] [G loss: 4.481173] time: 0:48:38.256719\n",
      "(10, 128, 128, 3)\n",
      "0.9443767\n",
      "[Epoch 5/10] [Batch 870/1081] [D loss: 0.107989] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.922013] time: 0:48:38.674375\n",
      "(10, 128, 128, 3)\n",
      "0.92520046\n",
      "[Epoch 5/10] [Batch 871/1081] [D loss: 0.107093] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.767032] time: 0:48:39.113643\n",
      "(10, 128, 128, 3)\n",
      "0.95456934\n",
      "[Epoch 5/10] [Batch 872/1081] [D loss: 0.081058] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.879590] time: 0:48:39.555592\n",
      "(10, 128, 128, 3)\n",
      "0.8780937\n",
      "[Epoch 5/10] [Batch 873/1081] [D loss: 0.078801] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.374465] time: 0:48:39.984141\n",
      "(10, 128, 128, 3)\n",
      "0.88931113\n",
      "[Epoch 5/10] [Batch 874/1081] [D loss: 0.078562] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.015673] time: 0:48:40.424630\n",
      "(10, 128, 128, 3)\n",
      "0.9131563\n",
      "[Epoch 5/10] [Batch 875/1081] [D loss: 0.078435] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.052823] time: 0:48:40.846764\n",
      "(10, 128, 128, 3)\n",
      "0.87780195\n",
      "[Epoch 5/10] [Batch 876/1081] [D loss: 0.092499] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.308375] time: 0:48:41.280469\n",
      "(10, 128, 128, 3)\n",
      "0.8732849\n",
      "[Epoch 5/10] [Batch 877/1081] [D loss: 0.076956] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.876342] time: 0:48:41.719054\n",
      "(10, 128, 128, 3)\n",
      "0.96104616\n",
      "[Epoch 5/10] [Batch 878/1081] [D loss: 0.076760] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.846153] time: 0:48:42.154387\n",
      "(10, 128, 128, 3)\n",
      "0.92934614\n",
      "[Epoch 5/10] [Batch 879/1081] [D loss: 0.077271] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.198075] time: 0:48:42.555967\n",
      "(10, 128, 128, 3)\n",
      "0.9241809\n",
      "[Epoch 5/10] [Batch 880/1081] [D loss: 0.076326] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.475237] time: 0:48:42.967409\n",
      "(10, 128, 128, 3)\n",
      "0.85906935\n",
      "[Epoch 5/10] [Batch 881/1081] [D loss: 0.076279] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.759544] time: 0:48:43.401592\n",
      "(10, 128, 128, 3)\n",
      "0.8972304\n",
      "[Epoch 5/10] [Batch 882/1081] [D loss: 0.076536] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.163051] time: 0:48:43.833407\n",
      "(10, 128, 128, 3)\n",
      "0.9258527\n",
      "[Epoch 5/10] [Batch 883/1081] [D loss: 0.077684] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.619249] time: 0:48:44.269701\n",
      "(10, 128, 128, 3)\n",
      "0.8919106\n",
      "[Epoch 5/10] [Batch 884/1081] [D loss: 0.076316] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.780094] time: 0:48:44.696706\n",
      "(10, 128, 128, 3)\n",
      "0.97588605\n",
      "[Epoch 5/10] [Batch 885/1081] [D loss: 0.075717] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.127457] time: 0:48:45.125617\n",
      "(10, 128, 128, 3)\n",
      "0.8775931\n",
      "[Epoch 5/10] [Batch 886/1081] [D loss: 0.079944] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.440426] time: 0:48:45.519828\n",
      "(10, 128, 128, 3)\n",
      "0.8790688\n",
      "[Epoch 5/10] [Batch 887/1081] [D loss: 0.078992] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.665438] time: 0:48:45.913566\n",
      "(10, 128, 128, 3)\n",
      "0.89413404\n",
      "[Epoch 5/10] [Batch 888/1081] [D loss: 0.077502] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.114735] time: 0:48:46.339738\n",
      "(10, 128, 128, 3)\n",
      "0.8978426\n",
      "[Epoch 5/10] [Batch 889/1081] [D loss: 0.078155] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.651528] time: 0:48:46.770400\n",
      "(10, 128, 128, 3)\n",
      "0.9052212\n",
      "[Epoch 5/10] [Batch 890/1081] [D loss: 0.075664] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.273447] time: 0:48:47.217634\n",
      "(10, 128, 128, 3)\n",
      "0.9319666\n",
      "[Epoch 5/10] [Batch 891/1081] [D loss: 0.075055] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.516402] time: 0:48:47.684272\n",
      "(10, 128, 128, 3)\n",
      "0.9163248\n",
      "[Epoch 5/10] [Batch 892/1081] [D loss: 0.075209] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.635124] time: 0:48:48.157949\n",
      "(10, 128, 128, 3)\n",
      "0.90596575\n",
      "[Epoch 5/10] [Batch 893/1081] [D loss: 0.074237] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.883485] time: 0:48:48.574000\n",
      "(10, 128, 128, 3)\n",
      "0.8694327\n",
      "[Epoch 5/10] [Batch 894/1081] [D loss: 0.073947] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.794734] time: 0:48:49.025078\n",
      "(10, 128, 128, 3)\n",
      "0.9122999\n",
      "[Epoch 5/10] [Batch 895/1081] [D loss: 0.074016] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.954186] time: 0:48:49.442155\n",
      "(10, 128, 128, 3)\n",
      "0.97557706\n",
      "[Epoch 5/10] [Batch 896/1081] [D loss: 0.074024] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.221269] time: 0:48:49.864005\n",
      "(10, 128, 128, 3)\n",
      "0.9154491\n",
      "[Epoch 5/10] [Batch 897/1081] [D loss: 0.073749] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.537607] time: 0:48:50.266099\n",
      "(10, 128, 128, 3)\n",
      "0.9352868\n",
      "[Epoch 5/10] [Batch 898/1081] [D loss: 0.074192] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.071135] time: 0:48:50.675562\n",
      "(10, 128, 128, 3)\n",
      "0.9149003\n",
      "[Epoch 5/10] [Batch 899/1081] [D loss: 0.073692] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.594911] time: 0:48:51.122147\n",
      "(10, 128, 128, 3)\n",
      "0.898828\n",
      "[Epoch 5/10] [Batch 900/1081] [D loss: 0.073289] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.935741] time: 0:48:51.537222\n",
      "(10, 128, 128, 3)\n",
      "0.9176478\n",
      "[Epoch 5/10] [Batch 901/1081] [D loss: 0.074266] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.644178] time: 0:48:51.956795\n",
      "(10, 128, 128, 3)\n",
      "0.8988774\n",
      "[Epoch 5/10] [Batch 902/1081] [D loss: 0.073524] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.222743] time: 0:48:52.388878\n",
      "(10, 128, 128, 3)\n",
      "0.91135406\n",
      "[Epoch 5/10] [Batch 903/1081] [D loss: 0.078090] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.451959] time: 0:48:52.820480\n",
      "(10, 128, 128, 3)\n",
      "0.8562085\n",
      "[Epoch 5/10] [Batch 904/1081] [D loss: 0.075691] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.195316] time: 0:48:53.251095\n",
      "(10, 128, 128, 3)\n",
      "0.8933339\n",
      "[Epoch 5/10] [Batch 905/1081] [D loss: 0.073632] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.845243] time: 0:48:53.682635\n",
      "(10, 128, 128, 3)\n",
      "0.89648557\n",
      "[Epoch 5/10] [Batch 906/1081] [D loss: 0.075035] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.753329] time: 0:48:54.115434\n",
      "(10, 128, 128, 3)\n",
      "0.9335049\n",
      "[Epoch 5/10] [Batch 907/1081] [D loss: 0.073162] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.056226] time: 0:48:54.551558\n",
      "(10, 128, 128, 3)\n",
      "0.9037078\n",
      "[Epoch 5/10] [Batch 908/1081] [D loss: 0.073220] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.047253] time: 0:48:54.989748\n",
      "(10, 128, 128, 3)\n",
      "0.9007464\n",
      "[Epoch 5/10] [Batch 909/1081] [D loss: 0.072900] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.374873] time: 0:48:55.419861\n",
      "(10, 128, 128, 3)\n",
      "0.89293027\n",
      "[Epoch 5/10] [Batch 910/1081] [D loss: 0.072088] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.232263] time: 0:48:55.827151\n",
      "(10, 128, 128, 3)\n",
      "0.907046\n",
      "[Epoch 5/10] [Batch 911/1081] [D loss: 0.071916] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.843337] time: 0:48:56.232343\n",
      "(10, 128, 128, 3)\n",
      "0.9354088\n",
      "[Epoch 5/10] [Batch 912/1081] [D loss: 0.071709] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.216619] time: 0:48:56.678436\n",
      "(10, 128, 128, 3)\n",
      "0.919975\n",
      "[Epoch 5/10] [Batch 913/1081] [D loss: 0.072022] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.431800] time: 0:48:57.095736\n",
      "(10, 128, 128, 3)\n",
      "0.92191315\n",
      "[Epoch 5/10] [Batch 914/1081] [D loss: 0.073034] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.819950] time: 0:48:57.508570\n",
      "(10, 128, 128, 3)\n",
      "0.9038582\n",
      "[Epoch 5/10] [Batch 915/1081] [D loss: 0.071989] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.718358] time: 0:48:57.912896\n",
      "(10, 128, 128, 3)\n",
      "0.8943842\n",
      "[Epoch 5/10] [Batch 916/1081] [D loss: 0.071414] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.893120] time: 0:48:58.326373\n",
      "(10, 128, 128, 3)\n",
      "0.9105589\n",
      "[Epoch 5/10] [Batch 917/1081] [D loss: 0.072431] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.262728] time: 0:48:58.715199\n",
      "(10, 128, 128, 3)\n",
      "0.9353733\n",
      "[Epoch 5/10] [Batch 918/1081] [D loss: 0.071599] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.852921] time: 0:48:59.111484\n",
      "(10, 128, 128, 3)\n",
      "0.93980384\n",
      "[Epoch 5/10] [Batch 919/1081] [D loss: 0.072063] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.768525] time: 0:48:59.501199\n",
      "(10, 128, 128, 3)\n",
      "0.9193692\n",
      "[Epoch 5/10] [Batch 920/1081] [D loss: 0.071342] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.668833] time: 0:48:59.919297\n",
      "(10, 128, 128, 3)\n",
      "0.8933882\n",
      "[Epoch 5/10] [Batch 921/1081] [D loss: 0.070877] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.406206] time: 0:49:00.301113\n",
      "(10, 128, 128, 3)\n",
      "0.89508986\n",
      "[Epoch 5/10] [Batch 922/1081] [D loss: 0.070571] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.063644] time: 0:49:00.697517\n",
      "(10, 128, 128, 3)\n",
      "0.940068\n",
      "[Epoch 5/10] [Batch 923/1081] [D loss: 0.070711] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.117413] time: 0:49:01.071191\n",
      "(10, 128, 128, 3)\n",
      "0.9408822\n",
      "[Epoch 5/10] [Batch 924/1081] [D loss: 0.070957] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.279947] time: 0:49:01.481650\n",
      "(10, 128, 128, 3)\n",
      "0.9123977\n",
      "[Epoch 5/10] [Batch 925/1081] [D loss: 0.070742] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.067881] time: 0:49:01.928626\n",
      "(10, 128, 128, 3)\n",
      "0.8959251\n",
      "[Epoch 5/10] [Batch 926/1081] [D loss: 0.070350] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.416289] time: 0:49:02.396489\n",
      "(10, 128, 128, 3)\n",
      "0.92344385\n",
      "[Epoch 5/10] [Batch 927/1081] [D loss: 0.070795] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.972840] time: 0:49:02.839944\n",
      "(10, 128, 128, 3)\n",
      "0.9077654\n",
      "[Epoch 5/10] [Batch 928/1081] [D loss: 0.069801] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.289823] time: 0:49:03.300804\n",
      "(10, 128, 128, 3)\n",
      "0.9056568\n",
      "[Epoch 5/10] [Batch 929/1081] [D loss: 0.070073] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.177897] time: 0:49:03.724804\n",
      "(10, 128, 128, 3)\n",
      "0.915787\n",
      "[Epoch 5/10] [Batch 930/1081] [D loss: 0.070399] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.343691] time: 0:49:04.162331\n",
      "(10, 128, 128, 3)\n",
      "0.9249818\n",
      "[Epoch 5/10] [Batch 931/1081] [D loss: 0.069988] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.520523] time: 0:49:04.598349\n",
      "(10, 128, 128, 3)\n",
      "0.9137595\n",
      "[Epoch 5/10] [Batch 932/1081] [D loss: 0.070345] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.174717] time: 0:49:05.035581\n",
      "(10, 128, 128, 3)\n",
      "0.9303965\n",
      "[Epoch 5/10] [Batch 933/1081] [D loss: 0.072321] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.993865] time: 0:49:05.453916\n",
      "(10, 128, 128, 3)\n",
      "0.8998037\n",
      "[Epoch 5/10] [Batch 934/1081] [D loss: 0.070508] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.848838] time: 0:49:05.872567\n",
      "(10, 128, 128, 3)\n",
      "0.91141397\n",
      "[Epoch 5/10] [Batch 935/1081] [D loss: 0.070577] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.034782] time: 0:49:06.324146\n",
      "(10, 128, 128, 3)\n",
      "0.95155495\n",
      "[Epoch 5/10] [Batch 936/1081] [D loss: 0.069731] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.873891] time: 0:49:06.725444\n",
      "(10, 128, 128, 3)\n",
      "0.92430717\n",
      "[Epoch 5/10] [Batch 937/1081] [D loss: 0.069242] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.570480] time: 0:49:07.147315\n",
      "(10, 128, 128, 3)\n",
      "0.95369744\n",
      "[Epoch 5/10] [Batch 938/1081] [D loss: 0.070135] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.018868] time: 0:49:07.596773\n",
      "(10, 128, 128, 3)\n",
      "0.8983796\n",
      "[Epoch 5/10] [Batch 939/1081] [D loss: 0.070533] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.336495] time: 0:49:08.022993\n",
      "(10, 128, 128, 3)\n",
      "0.9547386\n",
      "[Epoch 5/10] [Batch 940/1081] [D loss: 0.070823] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.169837] time: 0:49:08.457484\n",
      "(10, 128, 128, 3)\n",
      "0.9179904\n",
      "[Epoch 5/10] [Batch 941/1081] [D loss: 0.069725] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.733788] time: 0:49:08.869921\n",
      "(10, 128, 128, 3)\n",
      "0.935184\n",
      "[Epoch 5/10] [Batch 942/1081] [D loss: 0.086581] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.514355] time: 0:49:09.277807\n",
      "(10, 128, 128, 3)\n",
      "0.88492495\n",
      "[Epoch 5/10] [Batch 943/1081] [D loss: 0.073132] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.440067] time: 0:49:09.704182\n",
      "(10, 128, 128, 3)\n",
      "0.9194613\n",
      "[Epoch 5/10] [Batch 944/1081] [D loss: 0.069801] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.491496] time: 0:49:10.167237\n",
      "(10, 128, 128, 3)\n",
      "0.93595177\n",
      "[Epoch 5/10] [Batch 945/1081] [D loss: 0.068932] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.889103] time: 0:49:10.572961\n",
      "(10, 128, 128, 3)\n",
      "0.9702584\n",
      "[Epoch 5/10] [Batch 946/1081] [D loss: 0.071360] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.623561] time: 0:49:11.002861\n",
      "(10, 128, 128, 3)\n",
      "0.8825631\n",
      "[Epoch 5/10] [Batch 947/1081] [D loss: 0.069773] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.714991] time: 0:49:11.428302\n",
      "(10, 128, 128, 3)\n",
      "0.9088339\n",
      "[Epoch 5/10] [Batch 948/1081] [D loss: 0.071369] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.822675] time: 0:49:11.857092\n",
      "(10, 128, 128, 3)\n",
      "0.8414717\n",
      "[Epoch 5/10] [Batch 949/1081] [D loss: 0.068971] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.521338] time: 0:49:12.325848\n",
      "(10, 128, 128, 3)\n",
      "0.9090693\n",
      "[Epoch 5/10] [Batch 950/1081] [D loss: 0.068218] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.089906] time: 0:49:12.746960\n",
      "(10, 128, 128, 3)\n",
      "0.9485387\n",
      "[Epoch 5/10] [Batch 951/1081] [D loss: 0.068329] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.018528] time: 0:49:13.218053\n",
      "(10, 128, 128, 3)\n",
      "0.90728116\n",
      "[Epoch 5/10] [Batch 952/1081] [D loss: 0.069452] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.553868] time: 0:49:13.646380\n",
      "(10, 128, 128, 3)\n",
      "0.9178188\n",
      "[Epoch 5/10] [Batch 953/1081] [D loss: 0.068511] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.677178] time: 0:49:14.050351\n",
      "(10, 128, 128, 3)\n",
      "0.9693937\n",
      "[Epoch 5/10] [Batch 954/1081] [D loss: 0.068006] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.356716] time: 0:49:14.448134\n",
      "(10, 128, 128, 3)\n",
      "0.94597054\n",
      "[Epoch 5/10] [Batch 955/1081] [D loss: 0.068018] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.882641] time: 0:49:14.820298\n",
      "(10, 128, 128, 3)\n",
      "0.94080096\n",
      "[Epoch 5/10] [Batch 956/1081] [D loss: 0.067874] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.917683] time: 0:49:15.208254\n",
      "(10, 128, 128, 3)\n",
      "0.9175391\n",
      "[Epoch 5/10] [Batch 957/1081] [D loss: 0.068121] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.857667] time: 0:49:15.623276\n",
      "(10, 128, 128, 3)\n",
      "0.9077337\n",
      "[Epoch 5/10] [Batch 958/1081] [D loss: 0.067697] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.360714] time: 0:49:16.005475\n",
      "(10, 128, 128, 3)\n",
      "0.9822313\n",
      "[Epoch 5/10] [Batch 959/1081] [D loss: 0.067760] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.493264] time: 0:49:16.411225\n",
      "(10, 128, 128, 3)\n",
      "0.8517373\n",
      "[Epoch 5/10] [Batch 960/1081] [D loss: 0.067890] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.834764] time: 0:49:16.856921\n",
      "(10, 128, 128, 3)\n",
      "0.95572394\n",
      "[Epoch 5/10] [Batch 961/1081] [D loss: 0.067426] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.955782] time: 0:49:17.293696\n",
      "(10, 128, 128, 3)\n",
      "0.9541133\n",
      "[Epoch 5/10] [Batch 962/1081] [D loss: 0.067282] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.956607] time: 0:49:17.722664\n",
      "(10, 128, 128, 3)\n",
      "0.9230142\n",
      "[Epoch 5/10] [Batch 963/1081] [D loss: 0.067154] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.337806] time: 0:49:18.125930\n",
      "(10, 128, 128, 3)\n",
      "0.96318746\n",
      "[Epoch 5/10] [Batch 964/1081] [D loss: 0.066887] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.672831] time: 0:49:18.544563\n",
      "(10, 128, 128, 3)\n",
      "0.8892434\n",
      "[Epoch 5/10] [Batch 965/1081] [D loss: 0.066989] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.401422] time: 0:49:18.975443\n",
      "(10, 128, 128, 3)\n",
      "0.9086488\n",
      "[Epoch 5/10] [Batch 966/1081] [D loss: 0.067801] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.813885] time: 0:49:19.371192\n",
      "(10, 128, 128, 3)\n",
      "0.9006794\n",
      "[Epoch 5/10] [Batch 967/1081] [D loss: 0.067466] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.361593] time: 0:49:19.797296\n",
      "(10, 128, 128, 3)\n",
      "0.9386573\n",
      "[Epoch 5/10] [Batch 968/1081] [D loss: 0.067502] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.342670] time: 0:49:20.254925\n",
      "(10, 128, 128, 3)\n",
      "0.86144286\n",
      "[Epoch 5/10] [Batch 969/1081] [D loss: 0.067630] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.088775] time: 0:49:20.657664\n",
      "(10, 128, 128, 3)\n",
      "0.9374803\n",
      "[Epoch 5/10] [Batch 970/1081] [D loss: 0.066289] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.390544] time: 0:49:21.094971\n",
      "(10, 128, 128, 3)\n",
      "0.96539736\n",
      "[Epoch 5/10] [Batch 971/1081] [D loss: 0.066532] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.981339] time: 0:49:21.510016\n",
      "(10, 128, 128, 3)\n",
      "0.9208233\n",
      "[Epoch 5/10] [Batch 972/1081] [D loss: 0.068493] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.482577] time: 0:49:21.968874\n",
      "(10, 128, 128, 3)\n",
      "0.9394087\n",
      "[Epoch 5/10] [Batch 973/1081] [D loss: 0.066734] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.374940] time: 0:49:22.388494\n",
      "(10, 128, 128, 3)\n",
      "0.9164141\n",
      "[Epoch 5/10] [Batch 974/1081] [D loss: 0.066992] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.428796] time: 0:49:22.826950\n",
      "(10, 128, 128, 3)\n",
      "0.90913534\n",
      "[Epoch 5/10] [Batch 975/1081] [D loss: 0.066319] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.645056] time: 0:49:23.271403\n",
      "(10, 128, 128, 3)\n",
      "0.9244509\n",
      "[Epoch 5/10] [Batch 976/1081] [D loss: 0.066482] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.439277] time: 0:49:23.728457\n",
      "(10, 128, 128, 3)\n",
      "0.889235\n",
      "[Epoch 5/10] [Batch 977/1081] [D loss: 0.065684] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.161227] time: 0:49:24.166958\n",
      "(10, 128, 128, 3)\n",
      "0.9312418\n",
      "[Epoch 5/10] [Batch 978/1081] [D loss: 0.065801] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.068472] time: 0:49:24.607825\n",
      "(10, 128, 128, 3)\n",
      "0.97363347\n",
      "[Epoch 5/10] [Batch 979/1081] [D loss: 0.065655] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.742831] time: 0:49:25.040557\n",
      "(10, 128, 128, 3)\n",
      "0.9363032\n",
      "[Epoch 5/10] [Batch 980/1081] [D loss: 0.065595] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.032683] time: 0:49:25.413620\n",
      "(10, 128, 128, 3)\n",
      "0.856606\n",
      "[Epoch 5/10] [Batch 981/1081] [D loss: 0.065460] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.216826] time: 0:49:25.830603\n",
      "(10, 128, 128, 3)\n",
      "0.91003174\n",
      "[Epoch 5/10] [Batch 982/1081] [D loss: 0.065785] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.279472] time: 0:49:26.254874\n",
      "(10, 128, 128, 3)\n",
      "0.91689414\n",
      "[Epoch 5/10] [Batch 983/1081] [D loss: 0.065327] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.064179] time: 0:49:26.667289\n",
      "(10, 128, 128, 3)\n",
      "0.90723807\n",
      "[Epoch 5/10] [Batch 984/1081] [D loss: 0.065315] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.293480] time: 0:49:27.085014\n",
      "(10, 128, 128, 3)\n",
      "0.86153966\n",
      "[Epoch 5/10] [Batch 985/1081] [D loss: 0.065482] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.730339] time: 0:49:27.493987\n",
      "(10, 128, 128, 3)\n",
      "0.8973148\n",
      "[Epoch 5/10] [Batch 986/1081] [D loss: 0.065130] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.288419] time: 0:49:27.887058\n",
      "(10, 128, 128, 3)\n",
      "0.9390088\n",
      "[Epoch 5/10] [Batch 987/1081] [D loss: 0.064996] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.126573] time: 0:49:28.313026\n",
      "(10, 128, 128, 3)\n",
      "0.95403033\n",
      "[Epoch 5/10] [Batch 988/1081] [D loss: 0.065256] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.828273] time: 0:49:28.710115\n",
      "(10, 128, 128, 3)\n",
      "0.8664818\n",
      "[Epoch 5/10] [Batch 989/1081] [D loss: 0.065168] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.814044] time: 0:49:29.111575\n",
      "(10, 128, 128, 3)\n",
      "0.9098323\n",
      "[Epoch 5/10] [Batch 990/1081] [D loss: 0.064921] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.972354] time: 0:49:29.541869\n",
      "(10, 128, 128, 3)\n",
      "0.8821717\n",
      "[Epoch 5/10] [Batch 991/1081] [D loss: 0.065283] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.117413] time: 0:49:29.966942\n",
      "(10, 128, 128, 3)\n",
      "0.8890911\n",
      "[Epoch 5/10] [Batch 992/1081] [D loss: 0.065391] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.074573] time: 0:49:30.398958\n",
      "(10, 128, 128, 3)\n",
      "0.92817307\n",
      "[Epoch 5/10] [Batch 993/1081] [D loss: 0.065922] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.934645] time: 0:49:30.821368\n",
      "(10, 128, 128, 3)\n",
      "0.9538238\n",
      "[Epoch 5/10] [Batch 994/1081] [D loss: 0.066074] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.772587] time: 0:49:31.245635\n",
      "(10, 128, 128, 3)\n",
      "0.9396967\n",
      "[Epoch 5/10] [Batch 995/1081] [D loss: 0.064878] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.432535] time: 0:49:31.677240\n",
      "(10, 128, 128, 3)\n",
      "0.86162424\n",
      "[Epoch 5/10] [Batch 996/1081] [D loss: 0.064549] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.224265] time: 0:49:32.080946\n",
      "(10, 128, 128, 3)\n",
      "0.94232744\n",
      "[Epoch 5/10] [Batch 997/1081] [D loss: 0.064461] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.107331] time: 0:49:32.491677\n",
      "(10, 128, 128, 3)\n",
      "0.84721655\n",
      "[Epoch 5/10] [Batch 998/1081] [D loss: 0.064462] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.467089] time: 0:49:32.911011\n",
      "(10, 128, 128, 3)\n",
      "0.9405727\n",
      "[Epoch 5/10] [Batch 999/1081] [D loss: 0.064313] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.774381] time: 0:49:33.325957\n",
      "(10, 128, 128, 3)\n",
      "0.8833594\n",
      "[Epoch 5/10] [Batch 1000/1081] [D loss: 0.065556] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.063707] time: 0:49:33.709476\n",
      "(10, 128, 128, 3)\n",
      "0.8071864\n",
      "[Epoch 5/10] [Batch 1001/1081] [D loss: 0.064434] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.340554] time: 0:49:34.153919\n",
      "(10, 128, 128, 3)\n",
      "0.8848379\n",
      "[Epoch 5/10] [Batch 1002/1081] [D loss: 0.064454] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.476629] time: 0:49:34.586028\n",
      "(10, 128, 128, 3)\n",
      "0.8995848\n",
      "[Epoch 5/10] [Batch 1003/1081] [D loss: 0.109764] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.458514] time: 0:49:34.984206\n",
      "(10, 128, 128, 3)\n",
      "0.8948787\n",
      "[Epoch 5/10] [Batch 1004/1081] [D loss: 0.546304] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 4.827941] time: 0:49:35.387387\n",
      "(10, 128, 128, 3)\n",
      "0.9143904\n",
      "[Epoch 5/10] [Batch 1005/1081] [D loss: 0.216603] [D acc: 0.60 (1.00 real, 0.20 fake)] [G loss: 10.182655] time: 0:49:35.771260\n",
      "(10, 128, 128, 3)\n",
      "0.83557314\n",
      "[Epoch 5/10] [Batch 1006/1081] [D loss: 0.118743] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 8.624286] time: 0:49:36.192168\n",
      "(10, 128, 128, 3)\n",
      "0.93542784\n",
      "[Epoch 5/10] [Batch 1007/1081] [D loss: 0.095461] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.112802] time: 0:49:36.583391\n",
      "(10, 128, 128, 3)\n",
      "0.93811566\n",
      "[Epoch 5/10] [Batch 1008/1081] [D loss: 0.091386] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.559354] time: 0:49:36.993109\n",
      "(10, 128, 128, 3)\n",
      "0.91946054\n",
      "[Epoch 5/10] [Batch 1009/1081] [D loss: 0.080618] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.818396] time: 0:49:37.418362\n",
      "(10, 128, 128, 3)\n",
      "0.903466\n",
      "[Epoch 5/10] [Batch 1010/1081] [D loss: 0.075515] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.784492] time: 0:49:37.842124\n",
      "(10, 128, 128, 3)\n",
      "0.8806259\n",
      "[Epoch 5/10] [Batch 1011/1081] [D loss: 0.125846] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.651693] time: 0:49:38.262817\n",
      "(10, 128, 128, 3)\n",
      "0.9159711\n",
      "[Epoch 5/10] [Batch 1012/1081] [D loss: 0.085532] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.687345] time: 0:49:38.709112\n",
      "(10, 128, 128, 3)\n",
      "0.9168475\n",
      "[Epoch 5/10] [Batch 1013/1081] [D loss: 0.079824] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.747622] time: 0:49:39.154657\n",
      "(10, 128, 128, 3)\n",
      "0.9267561\n",
      "[Epoch 5/10] [Batch 1014/1081] [D loss: 0.081088] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.569800] time: 0:49:39.574426\n",
      "(10, 128, 128, 3)\n",
      "0.8836503\n",
      "[Epoch 5/10] [Batch 1015/1081] [D loss: 0.189830] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 5.267474] time: 0:49:40.013263\n",
      "(10, 128, 128, 3)\n",
      "0.9426318\n",
      "[Epoch 5/10] [Batch 1016/1081] [D loss: 0.085213] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.296456] time: 0:49:40.424281\n",
      "(10, 128, 128, 3)\n",
      "0.93439746\n",
      "[Epoch 5/10] [Batch 1017/1081] [D loss: 0.081568] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.882381] time: 0:49:40.844384\n",
      "(10, 128, 128, 3)\n",
      "0.89497715\n",
      "[Epoch 5/10] [Batch 1018/1081] [D loss: 0.077711] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.584382] time: 0:49:41.274749\n",
      "(10, 128, 128, 3)\n",
      "0.94427776\n",
      "[Epoch 5/10] [Batch 1019/1081] [D loss: 0.075068] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.635575] time: 0:49:41.676653\n",
      "(10, 128, 128, 3)\n",
      "0.909702\n",
      "[Epoch 5/10] [Batch 1020/1081] [D loss: 0.073447] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.248953] time: 0:49:42.103949\n",
      "(10, 128, 128, 3)\n",
      "0.9287041\n",
      "[Epoch 5/10] [Batch 1021/1081] [D loss: 0.074039] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.049817] time: 0:49:42.496662\n",
      "(10, 128, 128, 3)\n",
      "0.8768475\n",
      "[Epoch 5/10] [Batch 1022/1081] [D loss: 0.074809] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.544968] time: 0:49:42.880079\n",
      "(10, 128, 128, 3)\n",
      "0.9442199\n",
      "[Epoch 5/10] [Batch 1023/1081] [D loss: 0.074149] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.831139] time: 0:49:43.311641\n",
      "(10, 128, 128, 3)\n",
      "0.96742606\n",
      "[Epoch 5/10] [Batch 1024/1081] [D loss: 0.073125] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.489915] time: 0:49:43.732486\n",
      "(10, 128, 128, 3)\n",
      "0.9014383\n",
      "[Epoch 5/10] [Batch 1025/1081] [D loss: 0.076482] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.396433] time: 0:49:44.175724\n",
      "(10, 128, 128, 3)\n",
      "0.8924131\n",
      "[Epoch 5/10] [Batch 1026/1081] [D loss: 0.072686] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.306989] time: 0:49:44.616212\n",
      "(10, 128, 128, 3)\n",
      "0.90489894\n",
      "[Epoch 5/10] [Batch 1027/1081] [D loss: 0.072920] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.068245] time: 0:49:45.055983\n",
      "(10, 128, 128, 3)\n",
      "0.891578\n",
      "[Epoch 5/10] [Batch 1028/1081] [D loss: 0.071975] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.200487] time: 0:49:45.491962\n",
      "(10, 128, 128, 3)\n",
      "0.9465311\n",
      "[Epoch 5/10] [Batch 1029/1081] [D loss: 0.073108] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.087563] time: 0:49:45.929406\n",
      "(10, 128, 128, 3)\n",
      "0.9361412\n",
      "[Epoch 5/10] [Batch 1030/1081] [D loss: 0.072465] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.528753] time: 0:49:46.364292\n",
      "(10, 128, 128, 3)\n",
      "0.8836665\n",
      "[Epoch 5/10] [Batch 1031/1081] [D loss: 0.072499] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.468310] time: 0:49:46.776817\n",
      "(10, 128, 128, 3)\n",
      "0.89438957\n",
      "[Epoch 5/10] [Batch 1032/1081] [D loss: 0.072379] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.105600] time: 0:49:47.222566\n",
      "(10, 128, 128, 3)\n",
      "0.8519583\n",
      "[Epoch 5/10] [Batch 1033/1081] [D loss: 0.071700] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.780437] time: 0:49:47.632554\n",
      "(10, 128, 128, 3)\n",
      "0.92664057\n",
      "[Epoch 5/10] [Batch 1034/1081] [D loss: 0.077178] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.365494] time: 0:49:48.030559\n",
      "(10, 128, 128, 3)\n",
      "0.92986655\n",
      "[Epoch 5/10] [Batch 1035/1081] [D loss: 0.073928] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.448550] time: 0:49:48.406358\n",
      "(10, 128, 128, 3)\n",
      "0.916738\n",
      "[Epoch 5/10] [Batch 1036/1081] [D loss: 0.073901] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.734347] time: 0:49:48.852528\n",
      "(10, 128, 128, 3)\n",
      "0.94656485\n",
      "[Epoch 5/10] [Batch 1037/1081] [D loss: 0.071838] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.429360] time: 0:49:49.258187\n",
      "(10, 128, 128, 3)\n",
      "0.91719526\n",
      "[Epoch 5/10] [Batch 1038/1081] [D loss: 0.071115] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.016550] time: 0:49:49.689094\n",
      "(10, 128, 128, 3)\n",
      "0.85968035\n",
      "[Epoch 5/10] [Batch 1039/1081] [D loss: 0.071412] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.958487] time: 0:49:50.102269\n",
      "(10, 128, 128, 3)\n",
      "0.8393714\n",
      "[Epoch 5/10] [Batch 1040/1081] [D loss: 0.074619] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.989125] time: 0:49:50.547297\n",
      "(10, 128, 128, 3)\n",
      "0.9192863\n",
      "[Epoch 5/10] [Batch 1041/1081] [D loss: 0.073244] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.795140] time: 0:49:50.996387\n",
      "(10, 128, 128, 3)\n",
      "0.8660557\n",
      "[Epoch 5/10] [Batch 1042/1081] [D loss: 0.070670] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.689582] time: 0:49:51.410692\n",
      "(10, 128, 128, 3)\n",
      "0.9334821\n",
      "[Epoch 5/10] [Batch 1043/1081] [D loss: 0.071532] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.199627] time: 0:49:51.865945\n",
      "(10, 128, 128, 3)\n",
      "0.9359433\n",
      "[Epoch 5/10] [Batch 1044/1081] [D loss: 0.072456] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.868861] time: 0:49:52.279281\n",
      "(10, 128, 128, 3)\n",
      "0.90209824\n",
      "[Epoch 5/10] [Batch 1045/1081] [D loss: 0.070823] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.647441] time: 0:49:52.683672\n",
      "(10, 128, 128, 3)\n",
      "0.91803735\n",
      "[Epoch 5/10] [Batch 1046/1081] [D loss: 0.070204] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.740804] time: 0:49:53.079492\n",
      "(10, 128, 128, 3)\n",
      "0.8992807\n",
      "[Epoch 5/10] [Batch 1047/1081] [D loss: 0.071026] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.452235] time: 0:49:53.495014\n",
      "(10, 128, 128, 3)\n",
      "0.9127341\n",
      "[Epoch 5/10] [Batch 1048/1081] [D loss: 0.323560] [D acc: 0.60 (1.00 real, 0.20 fake)] [G loss: 4.432884] time: 0:49:53.918162\n",
      "(10, 128, 128, 3)\n",
      "0.9162185\n",
      "[Epoch 5/10] [Batch 1049/1081] [D loss: 0.077820] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.049980] time: 0:49:54.333995\n",
      "(10, 128, 128, 3)\n",
      "0.9008639\n",
      "[Epoch 5/10] [Batch 1050/1081] [D loss: 0.110415] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.783037] time: 0:49:54.760270\n",
      "(10, 128, 128, 3)\n",
      "0.889267\n",
      "[Epoch 5/10] [Batch 1051/1081] [D loss: 0.086450] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.296642] time: 0:49:55.166188\n",
      "(10, 128, 128, 3)\n",
      "0.8647518\n",
      "[Epoch 5/10] [Batch 1052/1081] [D loss: 0.081975] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.206345] time: 0:49:55.586431\n",
      "(10, 128, 128, 3)\n",
      "0.93079877\n",
      "[Epoch 5/10] [Batch 1053/1081] [D loss: 0.082191] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.713334] time: 0:49:55.993398\n",
      "(10, 128, 128, 3)\n",
      "0.96062994\n",
      "[Epoch 5/10] [Batch 1054/1081] [D loss: 0.083247] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.253195] time: 0:49:56.440204\n",
      "(10, 128, 128, 3)\n",
      "0.902997\n",
      "[Epoch 5/10] [Batch 1055/1081] [D loss: 0.079523] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.231503] time: 0:49:56.840501\n",
      "(10, 128, 128, 3)\n",
      "0.8766238\n",
      "[Epoch 5/10] [Batch 1056/1081] [D loss: 0.080275] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.670888] time: 0:49:57.284935\n",
      "(10, 128, 128, 3)\n",
      "0.91383314\n",
      "[Epoch 5/10] [Batch 1057/1081] [D loss: 0.171974] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 4.876101] time: 0:49:57.713669\n",
      "(10, 128, 128, 3)\n",
      "0.903505\n",
      "[Epoch 5/10] [Batch 1058/1081] [D loss: 0.081396] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.146183] time: 0:49:58.152459\n",
      "(10, 128, 128, 3)\n",
      "0.89964175\n",
      "[Epoch 5/10] [Batch 1059/1081] [D loss: 0.085820] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.080598] time: 0:49:58.581056\n",
      "(10, 128, 128, 3)\n",
      "0.9336605\n",
      "[Epoch 5/10] [Batch 1060/1081] [D loss: 0.081531] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.237067] time: 0:49:58.991174\n",
      "(10, 128, 128, 3)\n",
      "0.8841997\n",
      "[Epoch 5/10] [Batch 1061/1081] [D loss: 0.079658] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.798972] time: 0:49:59.396148\n",
      "(10, 128, 128, 3)\n",
      "0.8621109\n",
      "[Epoch 5/10] [Batch 1062/1081] [D loss: 0.078626] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.166088] time: 0:49:59.803646\n",
      "(10, 128, 128, 3)\n",
      "0.92504954\n",
      "[Epoch 5/10] [Batch 1063/1081] [D loss: 0.081164] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.963252] time: 0:50:00.191904\n",
      "(10, 128, 128, 3)\n",
      "0.8706219\n",
      "[Epoch 5/10] [Batch 1064/1081] [D loss: 0.078909] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.801805] time: 0:50:00.582994\n",
      "(10, 128, 128, 3)\n",
      "0.9676369\n",
      "[Epoch 5/10] [Batch 1065/1081] [D loss: 0.077737] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.624177] time: 0:50:00.968361\n",
      "(10, 128, 128, 3)\n",
      "0.88539225\n",
      "[Epoch 5/10] [Batch 1066/1081] [D loss: 0.079024] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.906358] time: 0:50:01.380834\n",
      "(10, 128, 128, 3)\n",
      "0.95391434\n",
      "[Epoch 5/10] [Batch 1067/1081] [D loss: 0.077219] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.752567] time: 0:50:01.785039\n",
      "(10, 128, 128, 3)\n",
      "0.95984286\n",
      "[Epoch 5/10] [Batch 1068/1081] [D loss: 0.077725] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.328173] time: 0:50:02.187660\n",
      "(10, 128, 128, 3)\n",
      "0.8983558\n",
      "[Epoch 5/10] [Batch 1069/1081] [D loss: 0.077086] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.682220] time: 0:50:02.596469\n",
      "(10, 128, 128, 3)\n",
      "0.9447038\n",
      "[Epoch 5/10] [Batch 1070/1081] [D loss: 0.084045] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.896278] time: 0:50:03.013926\n",
      "(10, 128, 128, 3)\n",
      "0.94058114\n",
      "[Epoch 5/10] [Batch 1071/1081] [D loss: 0.077024] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.457518] time: 0:50:03.453041\n",
      "(10, 128, 128, 3)\n",
      "0.89969224\n",
      "[Epoch 5/10] [Batch 1072/1081] [D loss: 0.076335] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.237741] time: 0:50:03.896510\n",
      "(10, 128, 128, 3)\n",
      "0.91242105\n",
      "[Epoch 5/10] [Batch 1073/1081] [D loss: 0.076126] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.937377] time: 0:50:04.288032\n",
      "(10, 128, 128, 3)\n",
      "0.963603\n",
      "[Epoch 5/10] [Batch 1074/1081] [D loss: 0.118769] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.930176] time: 0:50:04.724685\n",
      "(10, 128, 128, 3)\n",
      "0.9070354\n",
      "[Epoch 5/10] [Batch 1075/1081] [D loss: 0.092115] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.254046] time: 0:50:05.133409\n",
      "(10, 128, 128, 3)\n",
      "0.88214475\n",
      "[Epoch 5/10] [Batch 1076/1081] [D loss: 0.076525] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.286592] time: 0:50:05.559658\n",
      "(10, 128, 128, 3)\n",
      "0.957433\n",
      "[Epoch 5/10] [Batch 1077/1081] [D loss: 0.090450] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.035565] time: 0:50:05.973623\n",
      "(10, 128, 128, 3)\n",
      "0.8892868\n",
      "[Epoch 5/10] [Batch 1078/1081] [D loss: 0.078548] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.699562] time: 0:50:06.367319\n",
      "(10, 128, 128, 3)\n",
      "0.88641644\n",
      "[Epoch 5/10] [Batch 1079/1081] [D loss: 0.075162] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.639045] time: 0:50:06.759049\n",
      "(10, 128, 128, 3)\n",
      "0.8765828\n",
      "[Epoch 5/10] [Batch 1080/1081] [D loss: 0.076149] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.062467] time: 0:50:07.142740\n",
      "############ VALIDATION OF EPOCH 5 ############\n",
      "############ TRAINING OF EPOCH 6 ############\n",
      "(10, 128, 128, 3)\n",
      "0.8887151\n",
      "[Epoch 6/10] [Batch 0/1081] [D loss: 0.078648] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.283639] time: 0:50:49.069933\n",
      "(10, 128, 128, 3)\n",
      "0.88949496\n",
      "[Epoch 6/10] [Batch 1/1081] [D loss: 0.074934] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.544084] time: 0:50:49.478931\n",
      "(10, 128, 128, 3)\n",
      "0.9236949\n",
      "[Epoch 6/10] [Batch 2/1081] [D loss: 0.078402] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.918182] time: 0:50:49.907729\n",
      "(10, 128, 128, 3)\n",
      "0.9606581\n",
      "[Epoch 6/10] [Batch 3/1081] [D loss: 0.075741] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.341081] time: 0:50:50.320702\n",
      "(10, 128, 128, 3)\n",
      "0.91114235\n",
      "[Epoch 6/10] [Batch 5/1081] [D loss: 0.077353] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.278604] time: 0:50:50.723754\n",
      "(10, 128, 128, 3)\n",
      "0.9058587\n",
      "[Epoch 6/10] [Batch 6/1081] [D loss: 0.074928] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.041643] time: 0:50:51.168811\n",
      "(10, 128, 128, 3)\n",
      "0.91331863\n",
      "[Epoch 6/10] [Batch 7/1081] [D loss: 0.083554] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.294477] time: 0:50:51.559908\n",
      "(10, 128, 128, 3)\n",
      "0.88482326\n",
      "[Epoch 6/10] [Batch 8/1081] [D loss: 0.079370] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.369380] time: 0:50:51.971956\n",
      "(10, 128, 128, 3)\n",
      "0.90624684\n",
      "[Epoch 6/10] [Batch 9/1081] [D loss: 0.074041] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.883195] time: 0:50:52.394601\n",
      "(10, 128, 128, 3)\n",
      "0.8943828\n",
      "[Epoch 6/10] [Batch 10/1081] [D loss: 0.073086] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.830459] time: 0:50:52.846624\n",
      "(10, 128, 128, 3)\n",
      "0.87247807\n",
      "[Epoch 6/10] [Batch 11/1081] [D loss: 0.074851] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.964370] time: 0:50:53.260946\n",
      "(10, 128, 128, 3)\n",
      "0.92513365\n",
      "[Epoch 6/10] [Batch 12/1081] [D loss: 0.073260] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.584133] time: 0:50:53.712015\n",
      "(10, 128, 128, 3)\n",
      "0.9036436\n",
      "[Epoch 6/10] [Batch 13/1081] [D loss: 0.073165] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.551369] time: 0:50:54.112662\n",
      "(10, 128, 128, 3)\n",
      "0.8854267\n",
      "[Epoch 6/10] [Batch 14/1081] [D loss: 0.079257] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.461224] time: 0:50:54.527973\n",
      "(10, 128, 128, 3)\n",
      "0.9045771\n",
      "[Epoch 6/10] [Batch 15/1081] [D loss: 0.072931] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.149546] time: 0:50:54.952627\n",
      "(10, 128, 128, 3)\n",
      "0.9236199\n",
      "[Epoch 6/10] [Batch 16/1081] [D loss: 0.076291] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.626617] time: 0:50:55.408425\n",
      "(10, 128, 128, 3)\n",
      "0.9260878\n",
      "[Epoch 6/10] [Batch 17/1081] [D loss: 0.074167] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.036798] time: 0:50:55.823189\n",
      "(10, 128, 128, 3)\n",
      "0.90907246\n",
      "[Epoch 6/10] [Batch 18/1081] [D loss: 0.072858] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.275855] time: 0:50:56.251042\n",
      "(10, 128, 128, 3)\n",
      "0.8684878\n",
      "[Epoch 6/10] [Batch 19/1081] [D loss: 0.076524] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.085889] time: 0:50:56.645656\n",
      "(10, 128, 128, 3)\n",
      "0.9339765\n",
      "[Epoch 6/10] [Batch 20/1081] [D loss: 0.071847] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.600053] time: 0:50:57.079759\n",
      "(10, 128, 128, 3)\n",
      "0.9607137\n",
      "[Epoch 6/10] [Batch 21/1081] [D loss: 0.072325] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.894710] time: 0:50:57.499049\n",
      "(10, 128, 128, 3)\n",
      "0.9343068\n",
      "[Epoch 6/10] [Batch 22/1081] [D loss: 0.071405] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.779155] time: 0:50:57.916245\n",
      "(10, 128, 128, 3)\n",
      "0.92275554\n",
      "[Epoch 6/10] [Batch 23/1081] [D loss: 0.071356] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.852893] time: 0:50:58.334179\n",
      "(10, 128, 128, 3)\n",
      "0.89821357\n",
      "[Epoch 6/10] [Batch 24/1081] [D loss: 0.071234] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.508769] time: 0:50:58.749057\n",
      "(10, 128, 128, 3)\n",
      "0.93151164\n",
      "[Epoch 6/10] [Batch 25/1081] [D loss: 0.071535] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.328567] time: 0:50:59.162406\n",
      "(10, 128, 128, 3)\n",
      "0.93029064\n",
      "[Epoch 6/10] [Batch 26/1081] [D loss: 0.071534] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.484702] time: 0:50:59.562342\n",
      "(10, 128, 128, 3)\n",
      "0.8906884\n",
      "[Epoch 6/10] [Batch 27/1081] [D loss: 0.070473] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.569780] time: 0:50:59.971822\n",
      "(10, 128, 128, 3)\n",
      "0.89343697\n",
      "[Epoch 6/10] [Batch 28/1081] [D loss: 0.071972] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.720730] time: 0:51:00.392435\n",
      "(10, 128, 128, 3)\n",
      "0.97569776\n",
      "[Epoch 6/10] [Batch 29/1081] [D loss: 0.071520] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.569774] time: 0:51:00.793813\n",
      "(10, 128, 128, 3)\n",
      "0.914406\n",
      "[Epoch 6/10] [Batch 30/1081] [D loss: 0.070395] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.763512] time: 0:51:01.192830\n",
      "(10, 128, 128, 3)\n",
      "0.94285995\n",
      "[Epoch 6/10] [Batch 31/1081] [D loss: 0.508139] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 4.106431] time: 0:51:01.626386\n",
      "(10, 128, 128, 3)\n",
      "0.8502677\n",
      "[Epoch 6/10] [Batch 32/1081] [D loss: 0.128658] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.573336] time: 0:51:02.076198\n",
      "(10, 128, 128, 3)\n",
      "0.861382\n",
      "[Epoch 6/10] [Batch 33/1081] [D loss: 0.144796] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 390.651764] time: 0:51:02.504161\n",
      "(10, 128, 128, 3)\n",
      "0.8506219\n",
      "[Epoch 6/10] [Batch 34/1081] [D loss: 0.330589] [D acc: 0.60 (1.00 real, 0.20 fake)] [G loss: 58.547432] time: 0:51:02.912614\n",
      "(10, 128, 128, 3)\n",
      "0.93143266\n",
      "[Epoch 6/10] [Batch 35/1081] [D loss: 0.457053] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 18.346817] time: 0:51:03.364133\n",
      "(10, 128, 128, 3)\n",
      "0.84184694\n",
      "[Epoch 6/10] [Batch 36/1081] [D loss: 0.195328] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 13.052656] time: 0:51:03.772695\n",
      "(10, 128, 128, 3)\n",
      "0.86514634\n",
      "[Epoch 6/10] [Batch 37/1081] [D loss: 0.144343] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 9.765800] time: 0:51:04.216958\n",
      "(10, 128, 128, 3)\n",
      "0.643024\n",
      "[Epoch 6/10] [Batch 38/1081] [D loss: 0.320155] [D acc: 0.55 (1.00 real, 0.10 fake)] [G loss: 7.603949] time: 0:51:04.631820\n",
      "(10, 128, 128, 3)\n",
      "0.878892\n",
      "[Epoch 6/10] [Batch 39/1081] [D loss: 0.179005] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 6.956364] time: 0:51:05.052568\n",
      "(10, 128, 128, 3)\n",
      "0.873013\n",
      "[Epoch 6/10] [Batch 40/1081] [D loss: 0.215408] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.600094] time: 0:51:05.441663\n",
      "(10, 128, 128, 3)\n",
      "0.9109874\n",
      "[Epoch 6/10] [Batch 41/1081] [D loss: 0.134532] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.206866] time: 0:51:05.866331\n",
      "(10, 128, 128, 3)\n",
      "0.87235624\n",
      "[Epoch 6/10] [Batch 42/1081] [D loss: 0.104122] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.736758] time: 0:51:06.280922\n",
      "(10, 128, 128, 3)\n",
      "0.89636636\n",
      "[Epoch 6/10] [Batch 43/1081] [D loss: 0.081436] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.712523] time: 0:51:06.683407\n",
      "(10, 128, 128, 3)\n",
      "0.89722604\n",
      "[Epoch 6/10] [Batch 44/1081] [D loss: 0.083423] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.455864] time: 0:51:07.085119\n",
      "(10, 128, 128, 3)\n",
      "0.93246984\n",
      "[Epoch 6/10] [Batch 45/1081] [D loss: 0.079850] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.479011] time: 0:51:07.485759\n",
      "(10, 128, 128, 3)\n",
      "0.933772\n",
      "[Epoch 6/10] [Batch 46/1081] [D loss: 0.085984] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.179660] time: 0:51:07.904013\n",
      "(10, 128, 128, 3)\n",
      "0.93410707\n",
      "[Epoch 6/10] [Batch 47/1081] [D loss: 0.098260] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.972169] time: 0:51:08.363685\n",
      "(10, 128, 128, 3)\n",
      "0.91782254\n",
      "[Epoch 6/10] [Batch 48/1081] [D loss: 0.085280] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.694179] time: 0:51:08.819158\n",
      "(10, 128, 128, 3)\n",
      "0.87460095\n",
      "[Epoch 6/10] [Batch 49/1081] [D loss: 0.083504] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.607695] time: 0:51:09.267104\n",
      "(10, 128, 128, 3)\n",
      "0.92134434\n",
      "[Epoch 6/10] [Batch 50/1081] [D loss: 0.187260] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.670196] time: 0:51:09.677959\n",
      "(10, 128, 128, 3)\n",
      "0.8885081\n",
      "[Epoch 6/10] [Batch 51/1081] [D loss: 0.111337] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.635232] time: 0:51:10.094990\n",
      "(10, 128, 128, 3)\n",
      "0.88847095\n",
      "[Epoch 6/10] [Batch 52/1081] [D loss: 0.083380] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.669130] time: 0:51:10.526888\n",
      "(10, 128, 128, 3)\n",
      "0.9107802\n",
      "[Epoch 6/10] [Batch 53/1081] [D loss: 0.081774] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.222736] time: 0:51:10.920092\n",
      "(10, 128, 128, 3)\n",
      "0.9198038\n",
      "[Epoch 6/10] [Batch 54/1081] [D loss: 0.081030] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.016239] time: 0:51:11.337935\n",
      "(10, 128, 128, 3)\n",
      "0.87346697\n",
      "[Epoch 6/10] [Batch 55/1081] [D loss: 0.077695] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.985175] time: 0:51:11.750405\n",
      "(10, 128, 128, 3)\n",
      "0.95317084\n",
      "[Epoch 6/10] [Batch 56/1081] [D loss: 0.080174] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.518996] time: 0:51:12.159880\n",
      "(10, 128, 128, 3)\n",
      "0.9066374\n",
      "[Epoch 6/10] [Batch 57/1081] [D loss: 0.082975] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.731419] time: 0:51:12.578182\n",
      "(10, 128, 128, 3)\n",
      "0.96931696\n",
      "[Epoch 6/10] [Batch 58/1081] [D loss: 0.094655] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.958770] time: 0:51:12.984909\n",
      "(10, 128, 128, 3)\n",
      "0.9276441\n",
      "[Epoch 6/10] [Batch 59/1081] [D loss: 0.077410] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.348279] time: 0:51:13.414369\n",
      "(10, 128, 128, 3)\n",
      "0.9141331\n",
      "[Epoch 6/10] [Batch 60/1081] [D loss: 0.080323] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.608228] time: 0:51:13.837286\n",
      "(10, 128, 128, 3)\n",
      "0.9173525\n",
      "[Epoch 6/10] [Batch 61/1081] [D loss: 0.090347] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.958141] time: 0:51:14.272357\n",
      "(10, 128, 128, 3)\n",
      "0.93467337\n",
      "[Epoch 6/10] [Batch 62/1081] [D loss: 0.081172] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.155570] time: 0:51:14.706346\n",
      "(10, 128, 128, 3)\n",
      "0.91945785\n",
      "[Epoch 6/10] [Batch 63/1081] [D loss: 0.077419] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.551908] time: 0:51:15.123721\n",
      "(10, 128, 128, 3)\n",
      "0.9232088\n",
      "[Epoch 6/10] [Batch 64/1081] [D loss: 0.077610] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.977729] time: 0:51:15.536241\n",
      "(10, 128, 128, 3)\n",
      "0.9419858\n",
      "[Epoch 6/10] [Batch 65/1081] [D loss: 0.079193] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.581962] time: 0:51:15.960960\n",
      "(10, 128, 128, 3)\n",
      "0.91267276\n",
      "[Epoch 6/10] [Batch 66/1081] [D loss: 0.076294] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.379595] time: 0:51:16.393228\n",
      "(10, 128, 128, 3)\n",
      "0.9544587\n",
      "[Epoch 6/10] [Batch 67/1081] [D loss: 0.077185] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.214012] time: 0:51:16.797178\n",
      "(10, 128, 128, 3)\n",
      "0.9149172\n",
      "[Epoch 6/10] [Batch 68/1081] [D loss: 0.084048] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.036483] time: 0:51:17.210060\n",
      "(10, 128, 128, 3)\n",
      "0.8686926\n",
      "[Epoch 6/10] [Batch 69/1081] [D loss: 0.076850] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.305952] time: 0:51:17.646246\n",
      "(10, 128, 128, 3)\n",
      "0.9283722\n",
      "[Epoch 6/10] [Batch 70/1081] [D loss: 0.074679] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.604040] time: 0:51:18.086534\n",
      "(10, 128, 128, 3)\n",
      "0.89817834\n",
      "[Epoch 6/10] [Batch 71/1081] [D loss: 0.076901] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.147011] time: 0:51:18.541797\n",
      "(10, 128, 128, 3)\n",
      "0.9124811\n",
      "[Epoch 6/10] [Batch 72/1081] [D loss: 0.076365] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.644928] time: 0:51:18.971560\n",
      "(10, 128, 128, 3)\n",
      "0.91582966\n",
      "[Epoch 6/10] [Batch 73/1081] [D loss: 0.075221] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.128105] time: 0:51:19.375858\n",
      "(10, 128, 128, 3)\n",
      "0.89825493\n",
      "[Epoch 6/10] [Batch 74/1081] [D loss: 0.075350] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.178725] time: 0:51:19.804331\n",
      "(10, 128, 128, 3)\n",
      "0.90634423\n",
      "[Epoch 6/10] [Batch 75/1081] [D loss: 0.074836] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.027677] time: 0:51:20.231411\n",
      "(10, 128, 128, 3)\n",
      "0.87973386\n",
      "[Epoch 6/10] [Batch 76/1081] [D loss: 0.078593] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.382550] time: 0:51:20.660827\n",
      "(10, 128, 128, 3)\n",
      "0.9085736\n",
      "[Epoch 6/10] [Batch 77/1081] [D loss: 0.078860] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.930066] time: 0:51:21.113615\n",
      "(10, 128, 128, 3)\n",
      "0.87289\n",
      "[Epoch 6/10] [Batch 78/1081] [D loss: 0.081835] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.764744] time: 0:51:21.513280\n",
      "(10, 128, 128, 3)\n",
      "0.9064351\n",
      "[Epoch 6/10] [Batch 79/1081] [D loss: 0.076094] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.310403] time: 0:51:21.901435\n",
      "(10, 128, 128, 3)\n",
      "0.9430475\n",
      "[Epoch 6/10] [Batch 80/1081] [D loss: 0.075003] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.209325] time: 0:51:22.293852\n",
      "(10, 128, 128, 3)\n",
      "0.88874674\n",
      "[Epoch 6/10] [Batch 81/1081] [D loss: 0.076980] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.999146] time: 0:51:22.716292\n",
      "(10, 128, 128, 3)\n",
      "0.914488\n",
      "[Epoch 6/10] [Batch 82/1081] [D loss: 0.086234] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.702472] time: 0:51:23.160656\n",
      "(10, 128, 128, 3)\n",
      "0.9033143\n",
      "[Epoch 6/10] [Batch 83/1081] [D loss: 0.074844] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.950040] time: 0:51:23.586061\n",
      "(10, 128, 128, 3)\n",
      "0.9112254\n",
      "[Epoch 6/10] [Batch 84/1081] [D loss: 0.073319] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.921900] time: 0:51:24.051110\n",
      "(10, 128, 128, 3)\n",
      "0.9389488\n",
      "[Epoch 6/10] [Batch 85/1081] [D loss: 0.072509] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.186073] time: 0:51:24.457255\n",
      "(10, 128, 128, 3)\n",
      "0.92733335\n",
      "[Epoch 6/10] [Batch 86/1081] [D loss: 0.075155] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.186465] time: 0:51:24.897619\n",
      "(10, 128, 128, 3)\n",
      "0.9076683\n",
      "[Epoch 6/10] [Batch 87/1081] [D loss: 0.091079] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.686956] time: 0:51:25.297723\n",
      "(10, 128, 128, 3)\n",
      "0.91891646\n",
      "[Epoch 6/10] [Batch 88/1081] [D loss: 0.075218] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.534930] time: 0:51:25.708628\n",
      "(10, 128, 128, 3)\n",
      "0.9153237\n",
      "[Epoch 6/10] [Batch 89/1081] [D loss: 0.074207] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.848251] time: 0:51:26.135087\n",
      "(10, 128, 128, 3)\n",
      "0.8566465\n",
      "[Epoch 6/10] [Batch 90/1081] [D loss: 0.073505] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.399137] time: 0:51:26.555993\n",
      "(10, 128, 128, 3)\n",
      "0.9403952\n",
      "[Epoch 6/10] [Batch 91/1081] [D loss: 0.072114] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.574457] time: 0:51:26.952732\n",
      "(10, 128, 128, 3)\n",
      "0.8878999\n",
      "[Epoch 6/10] [Batch 92/1081] [D loss: 0.071317] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.207762] time: 0:51:27.344750\n",
      "(10, 128, 128, 3)\n",
      "0.89852595\n",
      "[Epoch 6/10] [Batch 93/1081] [D loss: 0.071340] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.014297] time: 0:51:27.761906\n",
      "(10, 128, 128, 3)\n",
      "0.91394585\n",
      "[Epoch 6/10] [Batch 94/1081] [D loss: 0.071893] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.442542] time: 0:51:28.181072\n",
      "(10, 128, 128, 3)\n",
      "0.93223995\n",
      "[Epoch 6/10] [Batch 95/1081] [D loss: 0.071008] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.404194] time: 0:51:28.589733\n",
      "(10, 128, 128, 3)\n",
      "0.93089247\n",
      "[Epoch 6/10] [Batch 96/1081] [D loss: 0.072239] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.095992] time: 0:51:29.015255\n",
      "(10, 128, 128, 3)\n",
      "0.93641335\n",
      "[Epoch 6/10] [Batch 97/1081] [D loss: 0.072380] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.466353] time: 0:51:29.430409\n",
      "(10, 128, 128, 3)\n",
      "0.913119\n",
      "[Epoch 6/10] [Batch 98/1081] [D loss: 0.071066] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.008960] time: 0:51:29.859927\n",
      "(10, 128, 128, 3)\n",
      "0.8483534\n",
      "[Epoch 6/10] [Batch 99/1081] [D loss: 0.070709] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.004990] time: 0:51:30.311092\n",
      "(10, 128, 128, 3)\n",
      "0.90276545\n",
      "[Epoch 6/10] [Batch 100/1081] [D loss: 0.070931] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.770410] time: 0:51:30.723454\n",
      "(10, 128, 128, 3)\n",
      "0.94883686\n",
      "[Epoch 6/10] [Batch 101/1081] [D loss: 0.072737] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.219709] time: 0:51:31.168776\n",
      "(10, 128, 128, 3)\n",
      "0.91639966\n",
      "[Epoch 6/10] [Batch 102/1081] [D loss: 0.070751] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.117716] time: 0:51:31.586743\n",
      "(10, 128, 128, 3)\n",
      "0.89622337\n",
      "[Epoch 6/10] [Batch 103/1081] [D loss: 0.070614] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.647066] time: 0:51:31.982446\n",
      "(10, 128, 128, 3)\n",
      "0.8947429\n",
      "[Epoch 6/10] [Batch 104/1081] [D loss: 0.073388] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.049737] time: 0:51:32.438438\n",
      "(10, 128, 128, 3)\n",
      "0.91776395\n",
      "[Epoch 6/10] [Batch 105/1081] [D loss: 0.071780] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.815712] time: 0:51:32.853768\n",
      "(10, 128, 128, 3)\n",
      "0.918628\n",
      "[Epoch 6/10] [Batch 106/1081] [D loss: 0.070493] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.134438] time: 0:51:33.248563\n",
      "(10, 128, 128, 3)\n",
      "0.88402957\n",
      "[Epoch 6/10] [Batch 107/1081] [D loss: 0.070986] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.537582] time: 0:51:33.683591\n",
      "(10, 128, 128, 3)\n",
      "0.91567725\n",
      "[Epoch 6/10] [Batch 108/1081] [D loss: 0.071032] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.122614] time: 0:51:34.124456\n",
      "(10, 128, 128, 3)\n",
      "0.8880649\n",
      "[Epoch 6/10] [Batch 109/1081] [D loss: 0.070140] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.643848] time: 0:51:34.515827\n",
      "(10, 128, 128, 3)\n",
      "0.9143681\n",
      "[Epoch 6/10] [Batch 110/1081] [D loss: 0.069831] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.500810] time: 0:51:34.935175\n",
      "(10, 128, 128, 3)\n",
      "0.82422805\n",
      "[Epoch 6/10] [Batch 111/1081] [D loss: 0.070573] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.277871] time: 0:51:35.313881\n",
      "(10, 128, 128, 3)\n",
      "0.92124224\n",
      "[Epoch 6/10] [Batch 112/1081] [D loss: 0.071534] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.832828] time: 0:51:35.726396\n",
      "(10, 128, 128, 3)\n",
      "0.906491\n",
      "[Epoch 6/10] [Batch 113/1081] [D loss: 0.069992] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.497622] time: 0:51:36.149836\n",
      "(10, 128, 128, 3)\n",
      "0.9405152\n",
      "[Epoch 6/10] [Batch 114/1081] [D loss: 0.069537] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.312845] time: 0:51:36.576147\n",
      "(10, 128, 128, 3)\n",
      "0.88839895\n",
      "[Epoch 6/10] [Batch 115/1081] [D loss: 0.069630] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.196012] time: 0:51:37.020784\n",
      "(10, 128, 128, 3)\n",
      "0.91468215\n",
      "[Epoch 6/10] [Batch 116/1081] [D loss: 0.069505] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.561667] time: 0:51:37.475664\n",
      "(10, 128, 128, 3)\n",
      "0.8760546\n",
      "[Epoch 6/10] [Batch 117/1081] [D loss: 0.069234] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.006199] time: 0:51:37.894432\n",
      "(10, 128, 128, 3)\n",
      "0.9067671\n",
      "[Epoch 6/10] [Batch 118/1081] [D loss: 0.070523] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.846405] time: 0:51:38.311232\n",
      "(10, 128, 128, 3)\n",
      "0.95435524\n",
      "[Epoch 6/10] [Batch 119/1081] [D loss: 0.068801] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.712955] time: 0:51:38.766096\n",
      "(10, 128, 128, 3)\n",
      "0.95143133\n",
      "[Epoch 6/10] [Batch 120/1081] [D loss: 0.068486] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.744425] time: 0:51:39.183414\n",
      "(10, 128, 128, 3)\n",
      "0.9815114\n",
      "[Epoch 6/10] [Batch 121/1081] [D loss: 0.069096] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.724429] time: 0:51:39.575804\n",
      "(10, 128, 128, 3)\n",
      "0.880004\n",
      "[Epoch 6/10] [Batch 122/1081] [D loss: 0.068495] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.560889] time: 0:51:39.972344\n",
      "(10, 128, 128, 3)\n",
      "0.9232853\n",
      "[Epoch 6/10] [Batch 123/1081] [D loss: 0.071697] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.834364] time: 0:51:40.385329\n",
      "(10, 128, 128, 3)\n",
      "0.9062436\n",
      "[Epoch 6/10] [Batch 124/1081] [D loss: 0.071709] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.614414] time: 0:51:40.813954\n",
      "(10, 128, 128, 3)\n",
      "0.9205635\n",
      "[Epoch 6/10] [Batch 125/1081] [D loss: 0.082505] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.637850] time: 0:51:41.227453\n",
      "(10, 128, 128, 3)\n",
      "0.94282216\n",
      "[Epoch 6/10] [Batch 126/1081] [D loss: 0.072585] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.603862] time: 0:51:41.659865\n",
      "(10, 128, 128, 3)\n",
      "0.9126354\n",
      "[Epoch 6/10] [Batch 127/1081] [D loss: 0.070361] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.681052] time: 0:51:42.051788\n",
      "(10, 128, 128, 3)\n",
      "0.92361206\n",
      "[Epoch 6/10] [Batch 128/1081] [D loss: 0.070828] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.663979] time: 0:51:42.480203\n",
      "(10, 128, 128, 3)\n",
      "0.88186723\n",
      "[Epoch 6/10] [Batch 129/1081] [D loss: 0.068419] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.763626] time: 0:51:42.894805\n",
      "(10, 128, 128, 3)\n",
      "0.9188072\n",
      "[Epoch 6/10] [Batch 130/1081] [D loss: 0.068680] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.821377] time: 0:51:43.317307\n",
      "(10, 128, 128, 3)\n",
      "0.8779071\n",
      "[Epoch 6/10] [Batch 131/1081] [D loss: 0.068758] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.675248] time: 0:51:43.783559\n",
      "(10, 128, 128, 3)\n",
      "0.93322974\n",
      "[Epoch 6/10] [Batch 132/1081] [D loss: 0.067434] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.359363] time: 0:51:44.239913\n",
      "(10, 128, 128, 3)\n",
      "0.95323586\n",
      "[Epoch 6/10] [Batch 133/1081] [D loss: 0.071649] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.834792] time: 0:51:44.680179\n",
      "(10, 128, 128, 3)\n",
      "0.9369491\n",
      "[Epoch 6/10] [Batch 134/1081] [D loss: 0.067375] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.844535] time: 0:51:45.103325\n",
      "(10, 128, 128, 3)\n",
      "0.952452\n",
      "[Epoch 6/10] [Batch 135/1081] [D loss: 0.067490] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.924864] time: 0:51:45.512968\n",
      "(10, 128, 128, 3)\n",
      "0.9011553\n",
      "[Epoch 6/10] [Batch 136/1081] [D loss: 0.067550] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.283337] time: 0:51:45.936738\n",
      "(10, 128, 128, 3)\n",
      "0.94394845\n",
      "[Epoch 6/10] [Batch 137/1081] [D loss: 0.067925] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.545656] time: 0:51:46.382686\n",
      "(10, 128, 128, 3)\n",
      "0.9362832\n",
      "[Epoch 6/10] [Batch 138/1081] [D loss: 0.068979] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.968378] time: 0:51:46.800730\n",
      "(10, 128, 128, 3)\n",
      "0.91311556\n",
      "[Epoch 6/10] [Batch 139/1081] [D loss: 0.067610] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.827025] time: 0:51:47.226684\n",
      "(10, 128, 128, 3)\n",
      "0.91308093\n",
      "[Epoch 6/10] [Batch 140/1081] [D loss: 0.067046] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.863432] time: 0:51:47.655830\n",
      "(10, 128, 128, 3)\n",
      "0.9359384\n",
      "[Epoch 6/10] [Batch 141/1081] [D loss: 0.067414] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.603983] time: 0:51:48.083606\n",
      "(10, 128, 128, 3)\n",
      "0.9093566\n",
      "[Epoch 6/10] [Batch 142/1081] [D loss: 0.067154] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.819656] time: 0:51:48.498434\n",
      "(10, 128, 128, 3)\n",
      "0.93349904\n",
      "[Epoch 6/10] [Batch 143/1081] [D loss: 0.066263] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.708454] time: 0:51:48.927970\n",
      "(10, 128, 128, 3)\n",
      "0.9226952\n",
      "[Epoch 6/10] [Batch 144/1081] [D loss: 0.066787] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.335252] time: 0:51:49.347799\n",
      "(10, 128, 128, 3)\n",
      "0.8807644\n",
      "[Epoch 6/10] [Batch 145/1081] [D loss: 0.066738] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.310995] time: 0:51:49.763761\n",
      "(10, 128, 128, 3)\n",
      "0.9252508\n",
      "[Epoch 6/10] [Batch 146/1081] [D loss: 0.066187] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.575939] time: 0:51:50.181626\n",
      "(10, 128, 128, 3)\n",
      "0.86262625\n",
      "[Epoch 6/10] [Batch 147/1081] [D loss: 0.066723] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.636514] time: 0:51:50.595148\n",
      "(10, 128, 128, 3)\n",
      "0.93724173\n",
      "[Epoch 6/10] [Batch 148/1081] [D loss: 0.066160] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.910053] time: 0:51:51.017437\n",
      "(10, 128, 128, 3)\n",
      "0.9256678\n",
      "[Epoch 6/10] [Batch 149/1081] [D loss: 0.066079] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.011345] time: 0:51:51.465175\n",
      "(10, 128, 128, 3)\n",
      "0.95455027\n",
      "[Epoch 6/10] [Batch 150/1081] [D loss: 0.070142] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.556953] time: 0:51:51.913854\n",
      "(10, 128, 128, 3)\n",
      "0.941487\n",
      "[Epoch 6/10] [Batch 151/1081] [D loss: 0.066781] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.548213] time: 0:51:52.337322\n",
      "(10, 128, 128, 3)\n",
      "0.88042265\n",
      "[Epoch 6/10] [Batch 152/1081] [D loss: 0.066644] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.971992] time: 0:51:52.752987\n",
      "(10, 128, 128, 3)\n",
      "0.91388583\n",
      "[Epoch 6/10] [Batch 153/1081] [D loss: 0.071052] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.927470] time: 0:51:53.202397\n",
      "(10, 128, 128, 3)\n",
      "0.91886336\n",
      "[Epoch 6/10] [Batch 154/1081] [D loss: 0.069585] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.476706] time: 0:51:53.622730\n",
      "(10, 128, 128, 3)\n",
      "0.97120816\n",
      "[Epoch 6/10] [Batch 155/1081] [D loss: 0.066271] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.265471] time: 0:51:54.089212\n",
      "(10, 128, 128, 3)\n",
      "0.89168674\n",
      "[Epoch 6/10] [Batch 156/1081] [D loss: 0.065552] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.112386] time: 0:51:54.551136\n",
      "(10, 128, 128, 3)\n",
      "0.8622276\n",
      "[Epoch 6/10] [Batch 157/1081] [D loss: 0.065236] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.792202] time: 0:51:55.026224\n",
      "(10, 128, 128, 3)\n",
      "0.91535014\n",
      "[Epoch 6/10] [Batch 158/1081] [D loss: 0.067095] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.119056] time: 0:51:55.428661\n",
      "(10, 128, 128, 3)\n",
      "0.94153804\n",
      "[Epoch 6/10] [Batch 159/1081] [D loss: 0.066648] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.760359] time: 0:51:55.821357\n",
      "(10, 128, 128, 3)\n",
      "0.9027265\n",
      "[Epoch 6/10] [Batch 160/1081] [D loss: 0.065241] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.981253] time: 0:51:56.234967\n",
      "(10, 128, 128, 3)\n",
      "0.9389894\n",
      "[Epoch 6/10] [Batch 161/1081] [D loss: 0.066140] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.478307] time: 0:51:56.665985\n",
      "(10, 128, 128, 3)\n",
      "0.8814675\n",
      "[Epoch 6/10] [Batch 162/1081] [D loss: 0.065809] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.477704] time: 0:51:57.094992\n",
      "(10, 128, 128, 3)\n",
      "0.88985586\n",
      "[Epoch 6/10] [Batch 163/1081] [D loss: 0.065804] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.925879] time: 0:51:57.539282\n",
      "(10, 128, 128, 3)\n",
      "0.89477843\n",
      "[Epoch 6/10] [Batch 164/1081] [D loss: 0.064897] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.584235] time: 0:51:57.977718\n",
      "(10, 128, 128, 3)\n",
      "0.89732534\n",
      "[Epoch 6/10] [Batch 165/1081] [D loss: 0.064583] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.433490] time: 0:51:58.391954\n",
      "(10, 128, 128, 3)\n",
      "0.92000514\n",
      "[Epoch 6/10] [Batch 166/1081] [D loss: 0.068622] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.270514] time: 0:51:58.827984\n",
      "(10, 128, 128, 3)\n",
      "0.8882289\n",
      "[Epoch 6/10] [Batch 167/1081] [D loss: 0.064942] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.179998] time: 0:51:59.253968\n",
      "(10, 128, 128, 3)\n",
      "0.9289389\n",
      "[Epoch 6/10] [Batch 168/1081] [D loss: 0.064349] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.924215] time: 0:51:59.688587\n",
      "(10, 128, 128, 3)\n",
      "0.91075116\n",
      "[Epoch 6/10] [Batch 169/1081] [D loss: 0.065675] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.673259] time: 0:52:00.117742\n",
      "(10, 128, 128, 3)\n",
      "0.92207646\n",
      "[Epoch 6/10] [Batch 170/1081] [D loss: 0.064869] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.131445] time: 0:52:00.535648\n",
      "(10, 128, 128, 3)\n",
      "0.947427\n",
      "[Epoch 6/10] [Batch 171/1081] [D loss: 0.064308] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.390439] time: 0:52:00.987959\n",
      "(10, 128, 128, 3)\n",
      "0.90431696\n",
      "[Epoch 6/10] [Batch 172/1081] [D loss: 0.064437] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.364343] time: 0:52:01.457012\n",
      "(10, 128, 128, 3)\n",
      "0.8760459\n",
      "[Epoch 6/10] [Batch 173/1081] [D loss: 0.064036] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.515253] time: 0:52:01.890463\n",
      "(10, 128, 128, 3)\n",
      "0.8874909\n",
      "[Epoch 6/10] [Batch 174/1081] [D loss: 0.065816] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.660814] time: 0:52:02.339370\n",
      "(10, 128, 128, 3)\n",
      "0.9217839\n",
      "[Epoch 6/10] [Batch 175/1081] [D loss: 0.064215] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.949176] time: 0:52:02.803934\n",
      "(10, 128, 128, 3)\n",
      "0.92988807\n",
      "[Epoch 6/10] [Batch 176/1081] [D loss: 0.064823] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.578085] time: 0:52:03.205001\n",
      "(10, 128, 128, 3)\n",
      "0.9279404\n",
      "[Epoch 6/10] [Batch 177/1081] [D loss: 0.064178] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.228192] time: 0:52:03.633739\n",
      "(10, 128, 128, 3)\n",
      "0.9050469\n",
      "[Epoch 6/10] [Batch 178/1081] [D loss: 0.063993] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.712735] time: 0:52:04.051652\n",
      "(10, 128, 128, 3)\n",
      "0.9072117\n",
      "[Epoch 6/10] [Batch 179/1081] [D loss: 0.064228] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.642878] time: 0:52:04.486514\n",
      "(10, 128, 128, 3)\n",
      "0.96396476\n",
      "[Epoch 6/10] [Batch 180/1081] [D loss: 0.063535] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.963927] time: 0:52:04.935699\n",
      "(10, 128, 128, 3)\n",
      "0.9650123\n",
      "[Epoch 6/10] [Batch 181/1081] [D loss: 0.063798] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.112123] time: 0:52:05.319637\n",
      "(10, 128, 128, 3)\n",
      "0.9298571\n",
      "[Epoch 6/10] [Batch 182/1081] [D loss: 0.063901] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.632160] time: 0:52:05.726001\n",
      "(10, 128, 128, 3)\n",
      "0.88244605\n",
      "[Epoch 6/10] [Batch 183/1081] [D loss: 0.063155] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.567044] time: 0:52:06.152560\n",
      "(10, 128, 128, 3)\n",
      "0.95946234\n",
      "[Epoch 6/10] [Batch 184/1081] [D loss: 0.063118] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.971984] time: 0:52:06.603568\n",
      "(10, 128, 128, 3)\n",
      "0.8983987\n",
      "[Epoch 6/10] [Batch 185/1081] [D loss: 0.063178] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.312054] time: 0:52:07.024735\n",
      "(10, 128, 128, 3)\n",
      "0.9213397\n",
      "[Epoch 6/10] [Batch 186/1081] [D loss: 0.063095] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.704387] time: 0:52:07.430352\n",
      "(10, 128, 128, 3)\n",
      "0.92499304\n",
      "[Epoch 6/10] [Batch 187/1081] [D loss: 0.063554] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.098956] time: 0:52:07.850809\n",
      "(10, 128, 128, 3)\n",
      "0.8866809\n",
      "[Epoch 6/10] [Batch 188/1081] [D loss: 0.064289] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.661322] time: 0:52:08.256175\n",
      "(10, 128, 128, 3)\n",
      "0.9289703\n",
      "[Epoch 6/10] [Batch 189/1081] [D loss: 0.063540] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.746773] time: 0:52:08.665499\n",
      "(10, 128, 128, 3)\n",
      "0.9297459\n",
      "[Epoch 6/10] [Batch 190/1081] [D loss: 0.062809] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.417428] time: 0:52:09.098200\n",
      "(10, 128, 128, 3)\n",
      "0.9667035\n",
      "[Epoch 6/10] [Batch 191/1081] [D loss: 0.063557] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.260163] time: 0:52:09.521153\n",
      "(10, 128, 128, 3)\n",
      "0.9089171\n",
      "[Epoch 6/10] [Batch 192/1081] [D loss: 0.062793] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.887747] time: 0:52:09.937402\n",
      "(10, 128, 128, 3)\n",
      "0.9590103\n",
      "[Epoch 6/10] [Batch 193/1081] [D loss: 0.062875] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.867651] time: 0:52:10.360238\n",
      "(10, 128, 128, 3)\n",
      "0.85232854\n",
      "[Epoch 6/10] [Batch 194/1081] [D loss: 0.063764] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.328525] time: 0:52:10.802674\n",
      "(10, 128, 128, 3)\n",
      "0.93563217\n",
      "[Epoch 6/10] [Batch 195/1081] [D loss: 0.062387] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.805265] time: 0:52:11.227455\n",
      "(10, 128, 128, 3)\n",
      "0.92342955\n",
      "[Epoch 6/10] [Batch 196/1081] [D loss: 0.063391] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.050851] time: 0:52:11.687415\n",
      "(10, 128, 128, 3)\n",
      "0.95213515\n",
      "[Epoch 6/10] [Batch 197/1081] [D loss: 0.062583] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.495347] time: 0:52:12.108487\n",
      "(10, 128, 128, 3)\n",
      "0.920569\n",
      "[Epoch 6/10] [Batch 198/1081] [D loss: 0.062583] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.915029] time: 0:52:12.510588\n",
      "(10, 128, 128, 3)\n",
      "0.9054734\n",
      "[Epoch 6/10] [Batch 199/1081] [D loss: 0.063556] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.436129] time: 0:52:12.951706\n",
      "(10, 128, 128, 3)\n",
      "0.9696944\n",
      "[Epoch 6/10] [Batch 200/1081] [D loss: 0.063077] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.018322] time: 0:52:13.380593\n",
      "(10, 128, 128, 3)\n",
      "0.8884987\n",
      "[Epoch 6/10] [Batch 201/1081] [D loss: 0.062515] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.651690] time: 0:52:13.784916\n",
      "(10, 128, 128, 3)\n",
      "0.9215505\n",
      "[Epoch 6/10] [Batch 202/1081] [D loss: 0.063642] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.628922] time: 0:52:14.198816\n",
      "(10, 128, 128, 3)\n",
      "0.92769665\n",
      "[Epoch 6/10] [Batch 203/1081] [D loss: 0.063014] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.752949] time: 0:52:14.628892\n",
      "(10, 128, 128, 3)\n",
      "0.9468291\n",
      "[Epoch 6/10] [Batch 204/1081] [D loss: 0.062607] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.569252] time: 0:52:15.024416\n",
      "(10, 128, 128, 3)\n",
      "0.947154\n",
      "[Epoch 6/10] [Batch 205/1081] [D loss: 0.062195] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.186450] time: 0:52:15.448818\n",
      "(10, 128, 128, 3)\n",
      "0.9583939\n",
      "[Epoch 6/10] [Batch 206/1081] [D loss: 0.061972] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.855859] time: 0:52:15.895860\n",
      "(10, 128, 128, 3)\n",
      "0.8778072\n",
      "[Epoch 6/10] [Batch 207/1081] [D loss: 0.062136] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.890539] time: 0:52:16.334291\n",
      "(10, 128, 128, 3)\n",
      "0.9159573\n",
      "[Epoch 6/10] [Batch 208/1081] [D loss: 0.062025] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.854729] time: 0:52:16.774152\n",
      "(10, 128, 128, 3)\n",
      "0.86482614\n",
      "[Epoch 6/10] [Batch 209/1081] [D loss: 0.062014] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.896157] time: 0:52:17.200302\n",
      "(10, 128, 128, 3)\n",
      "0.93294984\n",
      "[Epoch 6/10] [Batch 210/1081] [D loss: 0.062164] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.292565] time: 0:52:17.642441\n",
      "(10, 128, 128, 3)\n",
      "0.9650371\n",
      "[Epoch 6/10] [Batch 211/1081] [D loss: 0.061790] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.851936] time: 0:52:18.047629\n",
      "(10, 128, 128, 3)\n",
      "0.88511866\n",
      "[Epoch 6/10] [Batch 212/1081] [D loss: 0.061494] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.036516] time: 0:52:18.465636\n",
      "(10, 128, 128, 3)\n",
      "0.9066479\n",
      "[Epoch 6/10] [Batch 213/1081] [D loss: 0.062679] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.923610] time: 0:52:18.879633\n",
      "(10, 128, 128, 3)\n",
      "0.89765364\n",
      "[Epoch 6/10] [Batch 214/1081] [D loss: 0.061494] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.245946] time: 0:52:19.279826\n",
      "(10, 128, 128, 3)\n",
      "0.9707779\n",
      "[Epoch 6/10] [Batch 215/1081] [D loss: 0.061920] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.631346] time: 0:52:19.726661\n",
      "(10, 128, 128, 3)\n",
      "0.8562143\n",
      "[Epoch 6/10] [Batch 216/1081] [D loss: 0.061420] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.799837] time: 0:52:20.150561\n",
      "(10, 128, 128, 3)\n",
      "0.8581613\n",
      "[Epoch 6/10] [Batch 217/1081] [D loss: 0.061516] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.994911] time: 0:52:20.576440\n",
      "(10, 128, 128, 3)\n",
      "0.89545274\n",
      "[Epoch 6/10] [Batch 218/1081] [D loss: 0.061700] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.197491] time: 0:52:20.982292\n",
      "(10, 128, 128, 3)\n",
      "0.9068838\n",
      "[Epoch 6/10] [Batch 219/1081] [D loss: 0.061501] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.579996] time: 0:52:21.417523\n",
      "(10, 128, 128, 3)\n",
      "0.916099\n",
      "[Epoch 6/10] [Batch 220/1081] [D loss: 0.061652] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.086980] time: 0:52:21.851791\n",
      "(10, 128, 128, 3)\n",
      "0.9067617\n",
      "[Epoch 6/10] [Batch 221/1081] [D loss: 0.061025] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.825975] time: 0:52:22.248359\n",
      "(10, 128, 128, 3)\n",
      "0.93948704\n",
      "[Epoch 6/10] [Batch 222/1081] [D loss: 0.061138] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.987183] time: 0:52:22.650136\n",
      "(10, 128, 128, 3)\n",
      "0.9089635\n",
      "[Epoch 6/10] [Batch 223/1081] [D loss: 0.060915] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.805397] time: 0:52:23.068814\n",
      "(10, 128, 128, 3)\n",
      "0.94174886\n",
      "[Epoch 6/10] [Batch 224/1081] [D loss: 0.060848] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.066890] time: 0:52:23.476492\n",
      "(10, 128, 128, 3)\n",
      "0.91677547\n",
      "[Epoch 6/10] [Batch 225/1081] [D loss: 0.060789] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.856032] time: 0:52:23.884584\n",
      "(10, 128, 128, 3)\n",
      "0.85620564\n",
      "[Epoch 6/10] [Batch 226/1081] [D loss: 0.060923] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.398962] time: 0:52:24.286114\n",
      "(10, 128, 128, 3)\n",
      "0.87685066\n",
      "[Epoch 6/10] [Batch 227/1081] [D loss: 0.068549] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.629205] time: 0:52:24.695929\n",
      "(10, 128, 128, 3)\n",
      "0.915014\n",
      "[Epoch 6/10] [Batch 228/1081] [D loss: 0.060889] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.341917] time: 0:52:25.126533\n",
      "(10, 128, 128, 3)\n",
      "0.89036864\n",
      "[Epoch 6/10] [Batch 229/1081] [D loss: 0.072046] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.960013] time: 0:52:25.521145\n",
      "(10, 128, 128, 3)\n",
      "0.912869\n",
      "[Epoch 6/10] [Batch 230/1081] [D loss: 0.063875] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.784464] time: 0:52:25.933176\n",
      "(10, 128, 128, 3)\n",
      "0.87269783\n",
      "[Epoch 6/10] [Batch 231/1081] [D loss: 0.063437] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.001988] time: 0:52:26.357509\n",
      "(10, 128, 128, 3)\n",
      "0.97653484\n",
      "[Epoch 6/10] [Batch 232/1081] [D loss: 0.064023] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.275613] time: 0:52:26.785689\n",
      "(10, 128, 128, 3)\n",
      "0.8944455\n",
      "[Epoch 6/10] [Batch 233/1081] [D loss: 0.062998] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.157345] time: 0:52:27.194954\n",
      "(10, 128, 128, 3)\n",
      "0.88529825\n",
      "[Epoch 6/10] [Batch 234/1081] [D loss: 0.062810] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.960836] time: 0:52:27.652659\n",
      "(10, 128, 128, 3)\n",
      "0.9525356\n",
      "[Epoch 6/10] [Batch 235/1081] [D loss: 0.062873] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.569526] time: 0:52:28.068160\n",
      "(10, 128, 128, 3)\n",
      "0.9293011\n",
      "[Epoch 6/10] [Batch 236/1081] [D loss: 0.062625] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.852266] time: 0:52:28.493641\n",
      "(10, 128, 128, 3)\n",
      "0.8866275\n",
      "[Epoch 6/10] [Batch 237/1081] [D loss: 0.068574] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.830969] time: 0:52:28.918636\n",
      "(10, 128, 128, 3)\n",
      "0.9031097\n",
      "[Epoch 6/10] [Batch 238/1081] [D loss: 0.063426] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.228920] time: 0:52:29.328826\n",
      "(10, 128, 128, 3)\n",
      "0.9328561\n",
      "[Epoch 6/10] [Batch 239/1081] [D loss: 0.066693] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.363495] time: 0:52:29.760474\n",
      "(10, 128, 128, 3)\n",
      "0.8852527\n",
      "[Epoch 6/10] [Batch 240/1081] [D loss: 0.063456] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.700239] time: 0:52:30.175903\n",
      "(10, 128, 128, 3)\n",
      "0.97453755\n",
      "[Epoch 6/10] [Batch 241/1081] [D loss: 0.063242] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.143950] time: 0:52:30.615776\n",
      "(10, 128, 128, 3)\n",
      "0.8774505\n",
      "[Epoch 6/10] [Batch 242/1081] [D loss: 0.065510] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.903488] time: 0:52:31.002944\n",
      "(10, 128, 128, 3)\n",
      "0.9413817\n",
      "[Epoch 6/10] [Batch 243/1081] [D loss: 0.994185] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 11.466400] time: 0:52:31.411432\n",
      "(10, 128, 128, 3)\n",
      "0.865091\n",
      "[Epoch 6/10] [Batch 244/1081] [D loss: 0.454968] [D acc: 0.45 (0.90 real, 0.00 fake)] [G loss: 10.443756] time: 0:52:31.804409\n",
      "(10, 128, 128, 3)\n",
      "0.934531\n",
      "[Epoch 6/10] [Batch 245/1081] [D loss: 0.367405] [D acc: 0.40 (0.80 real, 0.00 fake)] [G loss: 5.723973] time: 0:52:32.244543\n",
      "(10, 128, 128, 3)\n",
      "0.9177306\n",
      "[Epoch 6/10] [Batch 246/1081] [D loss: 0.331997] [D acc: 0.50 (0.90 real, 0.10 fake)] [G loss: 5.715325] time: 0:52:32.708970\n",
      "(10, 128, 128, 3)\n",
      "0.9774422\n",
      "[Epoch 6/10] [Batch 247/1081] [D loss: 0.308639] [D acc: 0.60 (0.20 real, 1.00 fake)] [G loss: 4.471418] time: 0:52:33.145097\n",
      "(10, 128, 128, 3)\n",
      "0.9424798\n",
      "[Epoch 6/10] [Batch 248/1081] [D loss: 0.190700] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 4.806780] time: 0:52:33.592200\n",
      "(10, 128, 128, 3)\n",
      "0.88393545\n",
      "[Epoch 6/10] [Batch 249/1081] [D loss: 0.127758] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.004164] time: 0:52:34.047339\n",
      "(10, 128, 128, 3)\n",
      "0.91106385\n",
      "[Epoch 6/10] [Batch 250/1081] [D loss: 0.100305] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.713405] time: 0:52:34.487882\n",
      "(10, 128, 128, 3)\n",
      "0.9203518\n",
      "[Epoch 6/10] [Batch 251/1081] [D loss: 0.097073] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.552281] time: 0:52:34.903770\n",
      "(10, 128, 128, 3)\n",
      "0.886386\n",
      "[Epoch 6/10] [Batch 252/1081] [D loss: 0.090920] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.790643] time: 0:52:35.304257\n",
      "(10, 128, 128, 3)\n",
      "0.8960671\n",
      "[Epoch 6/10] [Batch 253/1081] [D loss: 0.093377] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.249560] time: 0:52:35.731666\n",
      "(10, 128, 128, 3)\n",
      "0.9366744\n",
      "[Epoch 6/10] [Batch 254/1081] [D loss: 0.083769] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.232793] time: 0:52:36.216798\n",
      "(10, 128, 128, 3)\n",
      "0.9392485\n",
      "[Epoch 6/10] [Batch 255/1081] [D loss: 0.082937] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.736650] time: 0:52:36.630828\n",
      "(10, 128, 128, 3)\n",
      "0.9005155\n",
      "[Epoch 6/10] [Batch 256/1081] [D loss: 0.081857] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.334670] time: 0:52:37.049822\n",
      "(10, 128, 128, 3)\n",
      "0.9026427\n",
      "[Epoch 6/10] [Batch 257/1081] [D loss: 0.092425] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.143897] time: 0:52:37.449827\n",
      "(10, 128, 128, 3)\n",
      "0.90641993\n",
      "[Epoch 6/10] [Batch 258/1081] [D loss: 0.080987] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.054308] time: 0:52:37.879574\n",
      "(10, 128, 128, 3)\n",
      "0.91863424\n",
      "[Epoch 6/10] [Batch 259/1081] [D loss: 0.079419] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.893985] time: 0:52:38.319410\n",
      "(10, 128, 128, 3)\n",
      "0.9194603\n",
      "[Epoch 6/10] [Batch 260/1081] [D loss: 0.099969] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.478923] time: 0:52:38.744237\n",
      "(10, 128, 128, 3)\n",
      "0.8912237\n",
      "[Epoch 6/10] [Batch 261/1081] [D loss: 0.078920] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.404889] time: 0:52:39.176565\n",
      "(10, 128, 128, 3)\n",
      "0.94535094\n",
      "[Epoch 6/10] [Batch 262/1081] [D loss: 0.078251] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.548388] time: 0:52:39.577625\n",
      "(10, 128, 128, 3)\n",
      "0.92948866\n",
      "[Epoch 6/10] [Batch 263/1081] [D loss: 0.078897] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.254330] time: 0:52:39.980311\n",
      "(10, 128, 128, 3)\n",
      "0.94728965\n",
      "[Epoch 6/10] [Batch 264/1081] [D loss: 0.081874] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.106762] time: 0:52:40.411958\n",
      "(10, 128, 128, 3)\n",
      "0.9491143\n",
      "[Epoch 6/10] [Batch 265/1081] [D loss: 0.078426] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.127688] time: 0:52:40.821427\n",
      "(10, 128, 128, 3)\n",
      "0.99409986\n",
      "[Epoch 6/10] [Batch 266/1081] [D loss: 0.552030] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 4.921407] time: 0:52:41.213635\n",
      "(10, 128, 128, 3)\n",
      "0.97224665\n",
      "[Epoch 6/10] [Batch 267/1081] [D loss: 0.353291] [D acc: 0.45 (0.90 real, 0.00 fake)] [G loss: 5.138703] time: 0:52:41.623757\n",
      "(10, 128, 128, 3)\n",
      "0.96213055\n",
      "[Epoch 6/10] [Batch 268/1081] [D loss: 0.357513] [D acc: 0.45 (0.90 real, 0.00 fake)] [G loss: 5.332695] time: 0:52:42.019773\n",
      "(10, 128, 128, 3)\n",
      "0.935582\n",
      "[Epoch 6/10] [Batch 269/1081] [D loss: 0.212511] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 5.600023] time: 0:52:42.418559\n",
      "(10, 128, 128, 3)\n",
      "0.8960274\n",
      "[Epoch 6/10] [Batch 270/1081] [D loss: 0.190629] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 5.346244] time: 0:52:42.825122\n",
      "(10, 128, 128, 3)\n",
      "0.92651415\n",
      "[Epoch 6/10] [Batch 271/1081] [D loss: 0.260405] [D acc: 0.60 (1.00 real, 0.20 fake)] [G loss: 6.633389] time: 0:52:43.232332\n",
      "(10, 128, 128, 3)\n",
      "0.94095904\n",
      "[Epoch 6/10] [Batch 272/1081] [D loss: 0.195539] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 4.562556] time: 0:52:43.649098\n",
      "(10, 128, 128, 3)\n",
      "0.89153486\n",
      "[Epoch 6/10] [Batch 273/1081] [D loss: 0.115555] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.843765] time: 0:52:44.063890\n",
      "(10, 128, 128, 3)\n",
      "0.902601\n",
      "[Epoch 6/10] [Batch 274/1081] [D loss: 0.086320] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.775053] time: 0:52:44.501944\n",
      "(10, 128, 128, 3)\n",
      "0.93694\n",
      "[Epoch 6/10] [Batch 275/1081] [D loss: 0.087473] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.344809] time: 0:52:44.897222\n",
      "(10, 128, 128, 3)\n",
      "0.9160466\n",
      "[Epoch 6/10] [Batch 276/1081] [D loss: 0.094721] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.741250] time: 0:52:45.304284\n",
      "(10, 128, 128, 3)\n",
      "0.8824026\n",
      "[Epoch 6/10] [Batch 277/1081] [D loss: 0.078523] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.292850] time: 0:52:45.719578\n",
      "(10, 128, 128, 3)\n",
      "0.9187639\n",
      "[Epoch 6/10] [Batch 278/1081] [D loss: 0.092417] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.370008] time: 0:52:46.170728\n",
      "(10, 128, 128, 3)\n",
      "0.8880674\n",
      "[Epoch 6/10] [Batch 279/1081] [D loss: 0.080960] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.116747] time: 0:52:46.576007\n",
      "(10, 128, 128, 3)\n",
      "0.9599518\n",
      "[Epoch 6/10] [Batch 280/1081] [D loss: 0.076727] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.596705] time: 0:52:46.963248\n",
      "(10, 128, 128, 3)\n",
      "0.9264645\n",
      "[Epoch 6/10] [Batch 281/1081] [D loss: 0.077867] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.105053] time: 0:52:47.390395\n",
      "(10, 128, 128, 3)\n",
      "0.92817837\n",
      "[Epoch 6/10] [Batch 282/1081] [D loss: 0.077119] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.542836] time: 0:52:47.809589\n",
      "(10, 128, 128, 3)\n",
      "0.90348476\n",
      "[Epoch 6/10] [Batch 283/1081] [D loss: 0.076048] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.199564] time: 0:52:48.234658\n",
      "(10, 128, 128, 3)\n",
      "0.9422999\n",
      "[Epoch 6/10] [Batch 284/1081] [D loss: 0.076665] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.533130] time: 0:52:48.662625\n",
      "(10, 128, 128, 3)\n",
      "0.9149508\n",
      "[Epoch 6/10] [Batch 285/1081] [D loss: 0.077827] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.535999] time: 0:52:49.113063\n",
      "(10, 128, 128, 3)\n",
      "0.900624\n",
      "[Epoch 6/10] [Batch 286/1081] [D loss: 0.075957] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.490182] time: 0:52:49.537837\n",
      "(10, 128, 128, 3)\n",
      "0.8952241\n",
      "[Epoch 6/10] [Batch 287/1081] [D loss: 0.076099] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.079368] time: 0:52:49.971980\n",
      "(10, 128, 128, 3)\n",
      "0.90761966\n",
      "[Epoch 6/10] [Batch 288/1081] [D loss: 0.076511] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.770246] time: 0:52:50.395943\n",
      "(10, 128, 128, 3)\n",
      "0.85066414\n",
      "[Epoch 6/10] [Batch 289/1081] [D loss: 0.078742] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.997721] time: 0:52:50.799624\n",
      "(10, 128, 128, 3)\n",
      "0.93419224\n",
      "[Epoch 6/10] [Batch 290/1081] [D loss: 0.074093] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.625830] time: 0:52:51.192825\n",
      "(10, 128, 128, 3)\n",
      "0.8707936\n",
      "[Epoch 6/10] [Batch 291/1081] [D loss: 0.077089] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.348852] time: 0:52:51.613180\n",
      "(10, 128, 128, 3)\n",
      "0.9342706\n",
      "[Epoch 6/10] [Batch 292/1081] [D loss: 0.077153] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.796376] time: 0:52:52.043745\n",
      "(10, 128, 128, 3)\n",
      "0.9151549\n",
      "[Epoch 6/10] [Batch 293/1081] [D loss: 0.074260] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.409766] time: 0:52:52.453505\n",
      "(10, 128, 128, 3)\n",
      "0.93274003\n",
      "[Epoch 6/10] [Batch 294/1081] [D loss: 0.075694] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.887661] time: 0:52:52.874352\n",
      "(10, 128, 128, 3)\n",
      "0.89927024\n",
      "[Epoch 6/10] [Batch 295/1081] [D loss: 0.073722] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.490820] time: 0:52:53.311895\n",
      "(10, 128, 128, 3)\n",
      "0.8993992\n",
      "[Epoch 6/10] [Batch 296/1081] [D loss: 0.073686] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.892430] time: 0:52:53.729368\n",
      "(10, 128, 128, 3)\n",
      "0.90311885\n",
      "[Epoch 6/10] [Batch 297/1081] [D loss: 0.073898] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.923646] time: 0:52:54.160529\n",
      "(10, 128, 128, 3)\n",
      "0.9278576\n",
      "[Epoch 6/10] [Batch 298/1081] [D loss: 0.074432] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.146922] time: 0:52:54.584390\n",
      "(10, 128, 128, 3)\n",
      "0.9259608\n",
      "[Epoch 6/10] [Batch 299/1081] [D loss: 0.072678] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.883020] time: 0:52:55.007044\n",
      "(10, 128, 128, 3)\n",
      "0.87553215\n",
      "[Epoch 6/10] [Batch 300/1081] [D loss: 0.078288] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.213385] time: 0:52:55.446430\n",
      "(10, 128, 128, 3)\n",
      "0.8992102\n",
      "[Epoch 6/10] [Batch 301/1081] [D loss: 0.073118] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.883898] time: 0:52:55.883644\n",
      "(10, 128, 128, 3)\n",
      "0.88028306\n",
      "[Epoch 6/10] [Batch 302/1081] [D loss: 0.072762] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.585733] time: 0:52:56.301809\n",
      "(10, 128, 128, 3)\n",
      "0.953729\n",
      "[Epoch 6/10] [Batch 303/1081] [D loss: 0.072156] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.373743] time: 0:52:56.714230\n",
      "(10, 128, 128, 3)\n",
      "0.8796392\n",
      "[Epoch 6/10] [Batch 304/1081] [D loss: 0.080852] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.753284] time: 0:52:57.116070\n",
      "(10, 128, 128, 3)\n",
      "0.93600637\n",
      "[Epoch 6/10] [Batch 305/1081] [D loss: 0.071940] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.707295] time: 0:52:57.540564\n",
      "(10, 128, 128, 3)\n",
      "0.920185\n",
      "[Epoch 6/10] [Batch 306/1081] [D loss: 0.071782] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.480746] time: 0:52:57.966996\n",
      "(10, 128, 128, 3)\n",
      "0.92834014\n",
      "[Epoch 6/10] [Batch 307/1081] [D loss: 0.073689] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.823453] time: 0:52:58.357211\n",
      "(10, 128, 128, 3)\n",
      "0.90208536\n",
      "[Epoch 6/10] [Batch 308/1081] [D loss: 0.071051] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.981832] time: 0:52:58.753636\n",
      "(10, 128, 128, 3)\n",
      "0.8787183\n",
      "[Epoch 6/10] [Batch 309/1081] [D loss: 0.070756] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.336461] time: 0:52:59.155818\n",
      "(10, 128, 128, 3)\n",
      "0.9842331\n",
      "[Epoch 6/10] [Batch 310/1081] [D loss: 0.070587] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.202518] time: 0:52:59.584737\n",
      "(10, 128, 128, 3)\n",
      "0.948512\n",
      "[Epoch 6/10] [Batch 311/1081] [D loss: 0.070340] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.611527] time: 0:53:00.031344\n",
      "(10, 128, 128, 3)\n",
      "0.9318784\n",
      "[Epoch 6/10] [Batch 312/1081] [D loss: 0.070340] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.513202] time: 0:53:00.468061\n",
      "(10, 128, 128, 3)\n",
      "0.9369373\n",
      "[Epoch 6/10] [Batch 313/1081] [D loss: 0.100686] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.020175] time: 0:53:00.887846\n",
      "(10, 128, 128, 3)\n",
      "0.9143405\n",
      "[Epoch 6/10] [Batch 314/1081] [D loss: 0.072003] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.283161] time: 0:53:01.319907\n",
      "(10, 128, 128, 3)\n",
      "0.91879493\n",
      "[Epoch 6/10] [Batch 315/1081] [D loss: 0.226017] [D acc: 0.70 (1.00 real, 0.40 fake)] [G loss: 6.622055] time: 0:53:01.770195\n",
      "(10, 128, 128, 3)\n",
      "0.8851773\n",
      "[Epoch 6/10] [Batch 316/1081] [D loss: 0.084610] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.350750] time: 0:53:02.179599\n",
      "(10, 128, 128, 3)\n",
      "0.92164344\n",
      "[Epoch 6/10] [Batch 317/1081] [D loss: 0.083692] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.546047] time: 0:53:02.606863\n",
      "(10, 128, 128, 3)\n",
      "0.8896734\n",
      "[Epoch 6/10] [Batch 318/1081] [D loss: 0.078971] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.819212] time: 0:53:03.006139\n",
      "(10, 128, 128, 3)\n",
      "0.95156544\n",
      "[Epoch 6/10] [Batch 319/1081] [D loss: 0.085269] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.419273] time: 0:53:03.414608\n",
      "(10, 128, 128, 3)\n",
      "0.87609917\n",
      "[Epoch 6/10] [Batch 320/1081] [D loss: 0.076729] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.180965] time: 0:53:03.805684\n",
      "(10, 128, 128, 3)\n",
      "0.9261629\n",
      "[Epoch 6/10] [Batch 321/1081] [D loss: 0.077302] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.069918] time: 0:53:04.250462\n",
      "(10, 128, 128, 3)\n",
      "0.95327455\n",
      "[Epoch 6/10] [Batch 322/1081] [D loss: 0.077130] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.703049] time: 0:53:04.657585\n",
      "(10, 128, 128, 3)\n",
      "0.93331784\n",
      "[Epoch 6/10] [Batch 323/1081] [D loss: 0.080752] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.786749] time: 0:53:05.094216\n",
      "(10, 128, 128, 3)\n",
      "0.8968671\n",
      "[Epoch 6/10] [Batch 324/1081] [D loss: 0.075753] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.210639] time: 0:53:05.543372\n",
      "(10, 128, 128, 3)\n",
      "0.9176154\n",
      "[Epoch 6/10] [Batch 325/1081] [D loss: 0.075634] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.240159] time: 0:53:05.990446\n",
      "(10, 128, 128, 3)\n",
      "0.91521007\n",
      "[Epoch 6/10] [Batch 326/1081] [D loss: 0.076119] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.343341] time: 0:53:06.427633\n",
      "(10, 128, 128, 3)\n",
      "0.90582305\n",
      "[Epoch 6/10] [Batch 327/1081] [D loss: 0.074196] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.887856] time: 0:53:06.848455\n",
      "(10, 128, 128, 3)\n",
      "0.8862179\n",
      "[Epoch 6/10] [Batch 328/1081] [D loss: 0.076022] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.531500] time: 0:53:07.293012\n",
      "(10, 128, 128, 3)\n",
      "0.9224035\n",
      "[Epoch 6/10] [Batch 329/1081] [D loss: 0.078332] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.044010] time: 0:53:07.735555\n",
      "(10, 128, 128, 3)\n",
      "0.9322028\n",
      "[Epoch 6/10] [Batch 330/1081] [D loss: 0.074192] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.027032] time: 0:53:08.195576\n",
      "(10, 128, 128, 3)\n",
      "0.9362426\n",
      "[Epoch 6/10] [Batch 331/1081] [D loss: 0.073478] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.561686] time: 0:53:08.604260\n",
      "(10, 128, 128, 3)\n",
      "0.8735154\n",
      "[Epoch 6/10] [Batch 332/1081] [D loss: 0.077898] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.548269] time: 0:53:09.002766\n",
      "(10, 128, 128, 3)\n",
      "0.8970595\n",
      "[Epoch 6/10] [Batch 333/1081] [D loss: 0.074802] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.835915] time: 0:53:09.432878\n",
      "(10, 128, 128, 3)\n",
      "0.9501321\n",
      "[Epoch 6/10] [Batch 334/1081] [D loss: 0.087428] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.366964] time: 0:53:09.889345\n",
      "(10, 128, 128, 3)\n",
      "0.9071164\n",
      "[Epoch 6/10] [Batch 335/1081] [D loss: 0.073512] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.121525] time: 0:53:10.347252\n",
      "(10, 128, 128, 3)\n",
      "0.8995362\n",
      "[Epoch 6/10] [Batch 336/1081] [D loss: 0.074790] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.056372] time: 0:53:10.764653\n",
      "(10, 128, 128, 3)\n",
      "0.9308117\n",
      "[Epoch 6/10] [Batch 337/1081] [D loss: 0.074384] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.048080] time: 0:53:11.191418\n",
      "(10, 128, 128, 3)\n",
      "0.90818757\n",
      "[Epoch 6/10] [Batch 338/1081] [D loss: 0.073638] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.976581] time: 0:53:11.617464\n",
      "(10, 128, 128, 3)\n",
      "0.92198616\n",
      "[Epoch 6/10] [Batch 339/1081] [D loss: 0.071883] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.590590] time: 0:53:12.020720\n",
      "(10, 128, 128, 3)\n",
      "0.9362902\n",
      "[Epoch 6/10] [Batch 340/1081] [D loss: 0.073769] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.396806] time: 0:53:12.439191\n",
      "(10, 128, 128, 3)\n",
      "0.90574425\n",
      "[Epoch 6/10] [Batch 341/1081] [D loss: 0.073506] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.360921] time: 0:53:12.889318\n",
      "(10, 128, 128, 3)\n",
      "0.9523921\n",
      "[Epoch 6/10] [Batch 342/1081] [D loss: 0.072070] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.973701] time: 0:53:13.319847\n",
      "(10, 128, 128, 3)\n",
      "0.9132113\n",
      "[Epoch 6/10] [Batch 343/1081] [D loss: 0.071717] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.200311] time: 0:53:13.713465\n",
      "(10, 128, 128, 3)\n",
      "0.92387676\n",
      "[Epoch 6/10] [Batch 344/1081] [D loss: 0.071009] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.307702] time: 0:53:14.136234\n",
      "(10, 128, 128, 3)\n",
      "0.8379679\n",
      "[Epoch 6/10] [Batch 345/1081] [D loss: 0.074311] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.700234] time: 0:53:14.540864\n",
      "(10, 128, 128, 3)\n",
      "0.93356854\n",
      "[Epoch 6/10] [Batch 346/1081] [D loss: 0.070818] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.243198] time: 0:53:14.950450\n",
      "(10, 128, 128, 3)\n",
      "0.9289282\n",
      "[Epoch 6/10] [Batch 347/1081] [D loss: 0.072093] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.474313] time: 0:53:15.367010\n",
      "(10, 128, 128, 3)\n",
      "0.89745945\n",
      "[Epoch 6/10] [Batch 348/1081] [D loss: 0.071541] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.140800] time: 0:53:15.784874\n",
      "(10, 128, 128, 3)\n",
      "0.944232\n",
      "[Epoch 6/10] [Batch 349/1081] [D loss: 0.071884] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.644065] time: 0:53:16.231337\n",
      "(10, 128, 128, 3)\n",
      "0.90579194\n",
      "[Epoch 6/10] [Batch 350/1081] [D loss: 0.072105] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.379059] time: 0:53:16.639432\n",
      "(10, 128, 128, 3)\n",
      "0.87770486\n",
      "[Epoch 6/10] [Batch 351/1081] [D loss: 0.070798] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.879019] time: 0:53:17.058004\n",
      "(10, 128, 128, 3)\n",
      "0.93138975\n",
      "[Epoch 6/10] [Batch 352/1081] [D loss: 0.070483] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.898432] time: 0:53:17.539195\n",
      "(10, 128, 128, 3)\n",
      "0.922642\n",
      "[Epoch 6/10] [Batch 353/1081] [D loss: 0.070107] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.113236] time: 0:53:17.981271\n",
      "(10, 128, 128, 3)\n",
      "0.91108125\n",
      "[Epoch 6/10] [Batch 354/1081] [D loss: 0.070493] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.997270] time: 0:53:18.464605\n",
      "(10, 128, 128, 3)\n",
      "0.9210937\n",
      "[Epoch 6/10] [Batch 355/1081] [D loss: 0.069636] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.765627] time: 0:53:18.911012\n",
      "(10, 128, 128, 3)\n",
      "0.92072135\n",
      "[Epoch 6/10] [Batch 356/1081] [D loss: 0.072772] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.839204] time: 0:53:19.368149\n",
      "(10, 128, 128, 3)\n",
      "0.9196208\n",
      "[Epoch 6/10] [Batch 357/1081] [D loss: 0.071481] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.902913] time: 0:53:19.784664\n",
      "(10, 128, 128, 3)\n",
      "0.9124834\n",
      "[Epoch 6/10] [Batch 358/1081] [D loss: 0.070337] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.379517] time: 0:53:20.213337\n",
      "(10, 128, 128, 3)\n",
      "0.9280439\n",
      "[Epoch 6/10] [Batch 359/1081] [D loss: 0.069189] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.114671] time: 0:53:20.625259\n",
      "(10, 128, 128, 3)\n",
      "0.944124\n",
      "[Epoch 6/10] [Batch 360/1081] [D loss: 0.069116] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.127921] time: 0:53:21.036359\n",
      "(10, 128, 128, 3)\n",
      "0.8920274\n",
      "[Epoch 6/10] [Batch 361/1081] [D loss: 0.284291] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 6.958257] time: 0:53:21.446241\n",
      "(10, 128, 128, 3)\n",
      "0.9171626\n",
      "[Epoch 6/10] [Batch 362/1081] [D loss: 0.089340] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.859975] time: 0:53:21.881902\n",
      "(10, 128, 128, 3)\n",
      "0.9414361\n",
      "[Epoch 6/10] [Batch 363/1081] [D loss: 0.750933] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 4.518674] time: 0:53:22.328671\n",
      "(10, 128, 128, 3)\n",
      "0.9306167\n",
      "[Epoch 6/10] [Batch 364/1081] [D loss: 0.271944] [D acc: 0.70 (0.40 real, 1.00 fake)] [G loss: 4.698187] time: 0:53:22.777344\n",
      "(10, 128, 128, 3)\n",
      "0.9323054\n",
      "[Epoch 6/10] [Batch 365/1081] [D loss: 0.086407] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.557318] time: 0:53:23.226605\n",
      "(10, 128, 128, 3)\n",
      "0.905633\n",
      "[Epoch 6/10] [Batch 366/1081] [D loss: 0.075889] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.458828] time: 0:53:23.637072\n",
      "(10, 128, 128, 3)\n",
      "0.9361097\n",
      "[Epoch 6/10] [Batch 367/1081] [D loss: 0.074164] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.532209] time: 0:53:24.062656\n",
      "(10, 128, 128, 3)\n",
      "0.9123524\n",
      "[Epoch 6/10] [Batch 368/1081] [D loss: 0.077181] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.334229] time: 0:53:24.499472\n",
      "(10, 128, 128, 3)\n",
      "0.9115498\n",
      "[Epoch 6/10] [Batch 369/1081] [D loss: 0.073767] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.586668] time: 0:53:24.934641\n",
      "(10, 128, 128, 3)\n",
      "0.8824596\n",
      "[Epoch 6/10] [Batch 370/1081] [D loss: 0.072689] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.768465] time: 0:53:25.354396\n",
      "(10, 128, 128, 3)\n",
      "0.8725613\n",
      "[Epoch 6/10] [Batch 371/1081] [D loss: 0.072165] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.064376] time: 0:53:25.736255\n",
      "(10, 128, 128, 3)\n",
      "0.9140901\n",
      "[Epoch 6/10] [Batch 372/1081] [D loss: 0.072606] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.248837] time: 0:53:26.170921\n",
      "(10, 128, 128, 3)\n",
      "0.9191323\n",
      "[Epoch 6/10] [Batch 373/1081] [D loss: 0.072298] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.010921] time: 0:53:26.625895\n",
      "(10, 128, 128, 3)\n",
      "0.9506857\n",
      "[Epoch 6/10] [Batch 374/1081] [D loss: 0.071173] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.301137] time: 0:53:27.064936\n",
      "(10, 128, 128, 3)\n",
      "0.92985743\n",
      "[Epoch 6/10] [Batch 375/1081] [D loss: 0.110753] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.968376] time: 0:53:27.462147\n",
      "(10, 128, 128, 3)\n",
      "0.93437463\n",
      "[Epoch 6/10] [Batch 376/1081] [D loss: 0.074998] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.041908] time: 0:53:27.902204\n",
      "(10, 128, 128, 3)\n",
      "0.8971925\n",
      "[Epoch 6/10] [Batch 377/1081] [D loss: 0.071640] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.797827] time: 0:53:28.305071\n",
      "(10, 128, 128, 3)\n",
      "0.8919696\n",
      "[Epoch 6/10] [Batch 378/1081] [D loss: 0.072139] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.167811] time: 0:53:28.713338\n",
      "(10, 128, 128, 3)\n",
      "0.8564809\n",
      "[Epoch 6/10] [Batch 379/1081] [D loss: 0.071604] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.170801] time: 0:53:29.131029\n",
      "(10, 128, 128, 3)\n",
      "0.87008506\n",
      "[Epoch 6/10] [Batch 380/1081] [D loss: 0.073907] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.058558] time: 0:53:29.547986\n",
      "(10, 128, 128, 3)\n",
      "0.9358177\n",
      "[Epoch 6/10] [Batch 381/1081] [D loss: 0.070811] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.601795] time: 0:53:30.008894\n",
      "(10, 128, 128, 3)\n",
      "0.8968563\n",
      "[Epoch 6/10] [Batch 382/1081] [D loss: 0.071022] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.491077] time: 0:53:30.434602\n",
      "(10, 128, 128, 3)\n",
      "0.916027\n",
      "[Epoch 6/10] [Batch 383/1081] [D loss: 0.071114] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.204576] time: 0:53:30.863914\n",
      "(10, 128, 128, 3)\n",
      "0.9249058\n",
      "[Epoch 6/10] [Batch 384/1081] [D loss: 0.075183] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.294568] time: 0:53:31.275948\n",
      "(10, 128, 128, 3)\n",
      "0.91487974\n",
      "[Epoch 6/10] [Batch 385/1081] [D loss: 0.074157] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.957184] time: 0:53:31.713910\n",
      "(10, 128, 128, 3)\n",
      "0.90890676\n",
      "[Epoch 6/10] [Batch 386/1081] [D loss: 0.069800] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.254653] time: 0:53:32.158584\n",
      "(10, 128, 128, 3)\n",
      "0.83335525\n",
      "[Epoch 6/10] [Batch 387/1081] [D loss: 0.071183] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.348133] time: 0:53:32.587824\n",
      "(10, 128, 128, 3)\n",
      "0.90970165\n",
      "[Epoch 6/10] [Batch 388/1081] [D loss: 0.069905] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.147778] time: 0:53:33.048010\n",
      "(10, 128, 128, 3)\n",
      "0.9526866\n",
      "[Epoch 6/10] [Batch 389/1081] [D loss: 0.069740] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.746392] time: 0:53:33.489222\n",
      "(10, 128, 128, 3)\n",
      "0.9193182\n",
      "[Epoch 6/10] [Batch 390/1081] [D loss: 0.069023] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.268580] time: 0:53:33.921302\n",
      "(10, 128, 128, 3)\n",
      "0.8717272\n",
      "[Epoch 6/10] [Batch 391/1081] [D loss: 0.069095] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.383629] time: 0:53:34.388106\n",
      "(10, 128, 128, 3)\n",
      "0.8888081\n",
      "[Epoch 6/10] [Batch 392/1081] [D loss: 0.069384] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.115591] time: 0:53:34.822079\n",
      "(10, 128, 128, 3)\n",
      "0.94937557\n",
      "[Epoch 6/10] [Batch 393/1081] [D loss: 0.069829] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.731341] time: 0:53:35.254349\n",
      "(10, 128, 128, 3)\n",
      "0.8670636\n",
      "[Epoch 6/10] [Batch 394/1081] [D loss: 0.068449] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.008411] time: 0:53:35.655452\n",
      "(10, 128, 128, 3)\n",
      "0.896487\n",
      "[Epoch 6/10] [Batch 395/1081] [D loss: 0.068185] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.464770] time: 0:53:36.104422\n",
      "(10, 128, 128, 3)\n",
      "0.8842697\n",
      "[Epoch 6/10] [Batch 396/1081] [D loss: 0.068498] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.719399] time: 0:53:36.524134\n",
      "(10, 128, 128, 3)\n",
      "0.9040286\n",
      "[Epoch 6/10] [Batch 397/1081] [D loss: 0.070690] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.195704] time: 0:53:36.952283\n",
      "(10, 128, 128, 3)\n",
      "0.8795586\n",
      "[Epoch 6/10] [Batch 398/1081] [D loss: 0.068556] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.326004] time: 0:53:37.381174\n",
      "(10, 128, 128, 3)\n",
      "0.89437604\n",
      "[Epoch 6/10] [Batch 399/1081] [D loss: 0.077172] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.948967] time: 0:53:37.810576\n",
      "(10, 128, 128, 3)\n",
      "0.8962846\n",
      "[Epoch 6/10] [Batch 400/1081] [D loss: 0.069025] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.048302] time: 0:53:38.240064\n",
      "(10, 128, 128, 3)\n",
      "0.8693626\n",
      "[Epoch 6/10] [Batch 401/1081] [D loss: 0.067735] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.842572] time: 0:53:38.656792\n",
      "(10, 128, 128, 3)\n",
      "0.9010434\n",
      "[Epoch 6/10] [Batch 402/1081] [D loss: 0.069864] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.019266] time: 0:53:39.077225\n",
      "(10, 128, 128, 3)\n",
      "0.85790783\n",
      "[Epoch 6/10] [Batch 403/1081] [D loss: 0.067626] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.744720] time: 0:53:39.478059\n",
      "(10, 128, 128, 3)\n",
      "0.8901787\n",
      "[Epoch 6/10] [Batch 404/1081] [D loss: 0.069767] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.486094] time: 0:53:39.902243\n",
      "(10, 128, 128, 3)\n",
      "0.92162937\n",
      "[Epoch 6/10] [Batch 405/1081] [D loss: 0.067547] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.541054] time: 0:53:40.350364\n",
      "(10, 128, 128, 3)\n",
      "0.890866\n",
      "[Epoch 6/10] [Batch 406/1081] [D loss: 0.067958] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.066923] time: 0:53:40.769276\n",
      "(10, 128, 128, 3)\n",
      "0.9367369\n",
      "[Epoch 6/10] [Batch 407/1081] [D loss: 0.067821] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.241590] time: 0:53:41.226017\n",
      "(10, 128, 128, 3)\n",
      "0.86905605\n",
      "[Epoch 6/10] [Batch 408/1081] [D loss: 0.066877] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.411771] time: 0:53:41.661031\n",
      "(10, 128, 128, 3)\n",
      "0.9211674\n",
      "[Epoch 6/10] [Batch 409/1081] [D loss: 0.070230] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.269792] time: 0:53:42.075183\n",
      "(10, 128, 128, 3)\n",
      "0.94823676\n",
      "[Epoch 6/10] [Batch 410/1081] [D loss: 0.067955] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.128446] time: 0:53:42.509359\n",
      "(10, 128, 128, 3)\n",
      "0.8779232\n",
      "[Epoch 6/10] [Batch 411/1081] [D loss: 0.067043] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.824508] time: 0:53:42.936554\n",
      "(10, 128, 128, 3)\n",
      "0.91450197\n",
      "[Epoch 6/10] [Batch 412/1081] [D loss: 0.066043] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.965985] time: 0:53:43.338524\n",
      "(10, 128, 128, 3)\n",
      "0.9324468\n",
      "[Epoch 6/10] [Batch 413/1081] [D loss: 0.065818] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.300035] time: 0:53:43.757393\n",
      "(10, 128, 128, 3)\n",
      "0.9114563\n",
      "[Epoch 6/10] [Batch 414/1081] [D loss: 0.066313] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.304760] time: 0:53:44.188785\n",
      "(10, 128, 128, 3)\n",
      "0.9055117\n",
      "[Epoch 6/10] [Batch 415/1081] [D loss: 0.068178] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.623648] time: 0:53:44.610114\n",
      "(10, 128, 128, 3)\n",
      "0.9117721\n",
      "[Epoch 6/10] [Batch 416/1081] [D loss: 0.065867] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.251842] time: 0:53:45.036974\n",
      "(10, 128, 128, 3)\n",
      "0.9074742\n",
      "[Epoch 6/10] [Batch 417/1081] [D loss: 0.065770] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.202940] time: 0:53:45.436130\n",
      "(10, 128, 128, 3)\n",
      "0.91573924\n",
      "[Epoch 6/10] [Batch 418/1081] [D loss: 0.446313] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 3.705528] time: 0:53:45.845642\n",
      "(10, 128, 128, 3)\n",
      "0.9535627\n",
      "[Epoch 6/10] [Batch 419/1081] [D loss: 0.072002] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.694630] time: 0:53:46.229217\n",
      "(10, 128, 128, 3)\n",
      "0.8684532\n",
      "[Epoch 6/10] [Batch 420/1081] [D loss: 0.086845] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.660730] time: 0:53:46.658080\n",
      "(10, 128, 128, 3)\n",
      "0.89384985\n",
      "[Epoch 6/10] [Batch 421/1081] [D loss: 0.084851] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.818485] time: 0:53:47.085567\n",
      "(10, 128, 128, 3)\n",
      "0.93003756\n",
      "[Epoch 6/10] [Batch 422/1081] [D loss: 0.074135] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.382263] time: 0:53:47.527079\n",
      "(10, 128, 128, 3)\n",
      "0.93393916\n",
      "[Epoch 6/10] [Batch 423/1081] [D loss: 0.070200] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.475233] time: 0:53:47.990669\n",
      "(10, 128, 128, 3)\n",
      "0.8884694\n",
      "[Epoch 6/10] [Batch 424/1081] [D loss: 0.077693] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.362788] time: 0:53:48.417842\n",
      "(10, 128, 128, 3)\n",
      "0.93376595\n",
      "[Epoch 6/10] [Batch 425/1081] [D loss: 0.070103] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.638926] time: 0:53:48.834609\n",
      "(10, 128, 128, 3)\n",
      "0.8638895\n",
      "[Epoch 6/10] [Batch 426/1081] [D loss: 0.072068] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.301538] time: 0:53:49.257105\n",
      "(10, 128, 128, 3)\n",
      "0.94003123\n",
      "[Epoch 6/10] [Batch 427/1081] [D loss: 0.069732] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.773190] time: 0:53:49.666822\n",
      "(10, 128, 128, 3)\n",
      "0.93887633\n",
      "[Epoch 6/10] [Batch 428/1081] [D loss: 0.070888] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.334706] time: 0:53:50.075988\n",
      "(10, 128, 128, 3)\n",
      "0.95454997\n",
      "[Epoch 6/10] [Batch 429/1081] [D loss: 0.071135] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.470260] time: 0:53:50.507074\n",
      "(10, 128, 128, 3)\n",
      "0.8993445\n",
      "[Epoch 6/10] [Batch 430/1081] [D loss: 0.071196] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.307546] time: 0:53:50.904524\n",
      "(10, 128, 128, 3)\n",
      "0.948687\n",
      "[Epoch 6/10] [Batch 431/1081] [D loss: 0.071995] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.336231] time: 0:53:51.331981\n",
      "(10, 128, 128, 3)\n",
      "0.8935342\n",
      "[Epoch 6/10] [Batch 432/1081] [D loss: 0.076797] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.076369] time: 0:53:51.769591\n",
      "(10, 128, 128, 3)\n",
      "0.87156636\n",
      "[Epoch 6/10] [Batch 433/1081] [D loss: 0.068803] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.922659] time: 0:53:52.275046\n",
      "(10, 128, 128, 3)\n",
      "0.8924937\n",
      "[Epoch 6/10] [Batch 434/1081] [D loss: 0.069123] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.015550] time: 0:53:52.762301\n",
      "(10, 128, 128, 3)\n",
      "0.93641025\n",
      "[Epoch 6/10] [Batch 435/1081] [D loss: 0.069063] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.316250] time: 0:53:53.385387\n",
      "(10, 128, 128, 3)\n",
      "0.9370213\n",
      "[Epoch 6/10] [Batch 436/1081] [D loss: 0.070997] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.172258] time: 0:53:53.980062\n",
      "(10, 128, 128, 3)\n",
      "0.9165611\n",
      "[Epoch 6/10] [Batch 437/1081] [D loss: 0.068270] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.421153] time: 0:53:54.911687\n",
      "(10, 128, 128, 3)\n",
      "0.88026315\n",
      "[Epoch 6/10] [Batch 438/1081] [D loss: 0.070092] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.625362] time: 0:53:55.597393\n",
      "(10, 128, 128, 3)\n",
      "0.9107649\n",
      "[Epoch 6/10] [Batch 439/1081] [D loss: 0.068038] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.543126] time: 0:53:56.264856\n",
      "(10, 128, 128, 3)\n",
      "0.89646244\n",
      "[Epoch 6/10] [Batch 440/1081] [D loss: 0.068349] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.948776] time: 0:53:56.930962\n",
      "(10, 128, 128, 3)\n",
      "0.8855882\n",
      "[Epoch 6/10] [Batch 441/1081] [D loss: 0.068743] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.959996] time: 0:53:57.587003\n",
      "(10, 128, 128, 3)\n",
      "0.8789508\n",
      "[Epoch 6/10] [Batch 442/1081] [D loss: 0.069620] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.142201] time: 0:53:58.261737\n",
      "(10, 128, 128, 3)\n",
      "0.9095107\n",
      "[Epoch 6/10] [Batch 443/1081] [D loss: 0.068503] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.974540] time: 0:53:58.853382\n",
      "(10, 128, 128, 3)\n",
      "0.91296434\n",
      "[Epoch 6/10] [Batch 444/1081] [D loss: 0.067543] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.523843] time: 0:53:59.496858\n",
      "(10, 128, 128, 3)\n",
      "0.93421656\n",
      "[Epoch 6/10] [Batch 445/1081] [D loss: 0.071931] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.307613] time: 0:54:00.158247\n",
      "(10, 128, 128, 3)\n",
      "0.8797061\n",
      "[Epoch 6/10] [Batch 446/1081] [D loss: 0.067790] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.733850] time: 0:54:00.815069\n",
      "(10, 128, 128, 3)\n",
      "0.9240214\n",
      "[Epoch 6/10] [Batch 447/1081] [D loss: 0.067832] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.556636] time: 0:54:01.476930\n",
      "(10, 128, 128, 3)\n",
      "0.93515015\n",
      "[Epoch 6/10] [Batch 448/1081] [D loss: 0.067202] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.759358] time: 0:54:02.130473\n",
      "(10, 128, 128, 3)\n",
      "0.8975158\n",
      "[Epoch 6/10] [Batch 449/1081] [D loss: 0.066758] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.298888] time: 0:54:02.765238\n",
      "(10, 128, 128, 3)\n",
      "0.899646\n",
      "[Epoch 6/10] [Batch 450/1081] [D loss: 0.067340] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.186140] time: 0:54:03.429198\n",
      "(10, 128, 128, 3)\n",
      "0.8927265\n",
      "[Epoch 6/10] [Batch 451/1081] [D loss: 0.067451] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.105263] time: 0:54:04.091681\n",
      "(10, 128, 128, 3)\n",
      "0.91759497\n",
      "[Epoch 6/10] [Batch 452/1081] [D loss: 0.067706] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.502601] time: 0:54:04.748702\n",
      "(10, 128, 128, 3)\n",
      "0.9127126\n",
      "[Epoch 6/10] [Batch 453/1081] [D loss: 0.067102] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.624741] time: 0:54:05.412739\n",
      "(10, 128, 128, 3)\n",
      "0.885724\n",
      "[Epoch 6/10] [Batch 454/1081] [D loss: 0.067006] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.211102] time: 0:54:06.016163\n",
      "(10, 128, 128, 3)\n",
      "0.9244981\n",
      "[Epoch 6/10] [Batch 455/1081] [D loss: 0.066616] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.855529] time: 0:54:06.648576\n",
      "(10, 128, 128, 3)\n",
      "0.92955947\n",
      "[Epoch 6/10] [Batch 456/1081] [D loss: 0.065849] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.189302] time: 0:54:07.296599\n",
      "(10, 128, 128, 3)\n",
      "0.95296955\n",
      "[Epoch 6/10] [Batch 457/1081] [D loss: 0.066495] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.420416] time: 0:54:07.926286\n",
      "(10, 128, 128, 3)\n",
      "0.87827635\n",
      "[Epoch 6/10] [Batch 458/1081] [D loss: 0.065743] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.789882] time: 0:54:08.555539\n",
      "(10, 128, 128, 3)\n",
      "0.88665515\n",
      "[Epoch 6/10] [Batch 459/1081] [D loss: 0.066059] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.381951] time: 0:54:09.233478\n",
      "(10, 128, 128, 3)\n",
      "0.94702584\n",
      "[Epoch 6/10] [Batch 460/1081] [D loss: 0.068996] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.993831] time: 0:54:09.891165\n",
      "(10, 128, 128, 3)\n",
      "0.9467507\n",
      "[Epoch 6/10] [Batch 461/1081] [D loss: 0.067177] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.849648] time: 0:54:10.522272\n",
      "(10, 128, 128, 3)\n",
      "0.8848048\n",
      "[Epoch 6/10] [Batch 462/1081] [D loss: 0.065141] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.891542] time: 0:54:11.144173\n",
      "(10, 128, 128, 3)\n",
      "0.9014638\n",
      "[Epoch 6/10] [Batch 463/1081] [D loss: 0.069090] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.257628] time: 0:54:11.794368\n",
      "(10, 128, 128, 3)\n",
      "0.88030314\n",
      "[Epoch 6/10] [Batch 464/1081] [D loss: 0.065407] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.658814] time: 0:54:12.412404\n",
      "(10, 128, 128, 3)\n",
      "0.92140746\n",
      "[Epoch 6/10] [Batch 465/1081] [D loss: 0.065854] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.161595] time: 0:54:13.056551\n",
      "(10, 128, 128, 3)\n",
      "0.9188104\n",
      "[Epoch 6/10] [Batch 466/1081] [D loss: 0.065079] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.093695] time: 0:54:13.714509\n",
      "(10, 128, 128, 3)\n",
      "0.94688636\n",
      "[Epoch 6/10] [Batch 467/1081] [D loss: 0.066182] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.222467] time: 0:54:14.356654\n",
      "(10, 128, 128, 3)\n",
      "0.89536494\n",
      "[Epoch 6/10] [Batch 468/1081] [D loss: 0.065332] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.837802] time: 0:54:15.030469\n",
      "(10, 128, 128, 3)\n",
      "0.8950544\n",
      "[Epoch 6/10] [Batch 469/1081] [D loss: 0.065022] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.806696] time: 0:54:15.695623\n",
      "(10, 128, 128, 3)\n",
      "0.9466009\n",
      "[Epoch 6/10] [Batch 470/1081] [D loss: 0.067263] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.093214] time: 0:54:16.358446\n",
      "(10, 128, 128, 3)\n",
      "0.896161\n",
      "[Epoch 6/10] [Batch 471/1081] [D loss: 0.065674] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.372898] time: 0:54:17.014050\n",
      "(10, 128, 128, 3)\n",
      "0.9373586\n",
      "[Epoch 6/10] [Batch 472/1081] [D loss: 0.066643] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.449815] time: 0:54:17.649214\n",
      "(10, 128, 128, 3)\n",
      "0.92903066\n",
      "[Epoch 6/10] [Batch 473/1081] [D loss: 0.064365] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.883451] time: 0:54:18.312702\n",
      "(10, 128, 128, 3)\n",
      "0.91468734\n",
      "[Epoch 6/10] [Batch 474/1081] [D loss: 0.066676] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.730373] time: 0:54:18.974988\n",
      "(10, 128, 128, 3)\n",
      "0.9701937\n",
      "[Epoch 6/10] [Batch 475/1081] [D loss: 0.064390] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.423784] time: 0:54:19.651556\n",
      "(10, 128, 128, 3)\n",
      "0.8895712\n",
      "[Epoch 6/10] [Batch 476/1081] [D loss: 0.064825] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.990661] time: 0:54:20.313039\n",
      "(10, 128, 128, 3)\n",
      "0.9410159\n",
      "[Epoch 6/10] [Batch 477/1081] [D loss: 0.065026] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.849489] time: 0:54:20.974676\n",
      "(10, 128, 128, 3)\n",
      "0.9341138\n",
      "[Epoch 6/10] [Batch 478/1081] [D loss: 0.064928] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.350999] time: 0:54:21.637174\n",
      "(10, 128, 128, 3)\n",
      "0.9493392\n",
      "[Epoch 6/10] [Batch 479/1081] [D loss: 0.065392] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.317466] time: 0:54:22.280514\n",
      "(10, 128, 128, 3)\n",
      "0.9140269\n",
      "[Epoch 6/10] [Batch 480/1081] [D loss: 0.066849] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.466557] time: 0:54:22.934170\n",
      "(10, 128, 128, 3)\n",
      "0.92610955\n",
      "[Epoch 6/10] [Batch 481/1081] [D loss: 0.064398] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.333170] time: 0:54:23.561809\n",
      "(10, 128, 128, 3)\n",
      "0.8406637\n",
      "[Epoch 6/10] [Batch 482/1081] [D loss: 0.064446] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.505357] time: 0:54:24.218629\n",
      "(10, 128, 128, 3)\n",
      "0.82831603\n",
      "[Epoch 6/10] [Batch 483/1081] [D loss: 0.063966] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.267326] time: 0:54:24.870218\n",
      "(10, 128, 128, 3)\n",
      "0.9395466\n",
      "[Epoch 6/10] [Batch 484/1081] [D loss: 0.064376] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.469313] time: 0:54:25.514224\n",
      "(10, 128, 128, 3)\n",
      "0.9003344\n",
      "[Epoch 6/10] [Batch 485/1081] [D loss: 0.063227] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.840049] time: 0:54:26.195783\n",
      "(10, 128, 128, 3)\n",
      "0.8717821\n",
      "[Epoch 6/10] [Batch 486/1081] [D loss: 0.063168] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.404058] time: 0:54:26.862021\n",
      "(10, 128, 128, 3)\n",
      "0.9044983\n",
      "[Epoch 6/10] [Batch 487/1081] [D loss: 0.062968] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.005385] time: 0:54:27.528131\n",
      "(10, 128, 128, 3)\n",
      "0.94650245\n",
      "[Epoch 6/10] [Batch 488/1081] [D loss: 0.063998] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.622063] time: 0:54:28.178367\n",
      "(10, 128, 128, 3)\n",
      "0.9191547\n",
      "[Epoch 6/10] [Batch 489/1081] [D loss: 0.063441] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.133797] time: 0:54:28.796435\n",
      "(10, 128, 128, 3)\n",
      "0.9341364\n",
      "[Epoch 6/10] [Batch 490/1081] [D loss: 0.063538] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.014042] time: 0:54:29.442676\n",
      "(10, 128, 128, 3)\n",
      "0.93759704\n",
      "[Epoch 6/10] [Batch 491/1081] [D loss: 0.062873] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.953909] time: 0:54:30.097473\n",
      "(10, 128, 128, 3)\n",
      "0.9403355\n",
      "[Epoch 6/10] [Batch 492/1081] [D loss: 0.062478] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.111947] time: 0:54:30.747811\n",
      "(10, 128, 128, 3)\n",
      "0.9510257\n",
      "[Epoch 6/10] [Batch 493/1081] [D loss: 0.063650] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.297303] time: 0:54:31.411653\n",
      "(10, 128, 128, 3)\n",
      "0.9102564\n",
      "[Epoch 6/10] [Batch 494/1081] [D loss: 0.062688] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.960656] time: 0:54:32.033318\n",
      "(10, 128, 128, 3)\n",
      "0.9403634\n",
      "[Epoch 6/10] [Batch 495/1081] [D loss: 0.063595] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.929180] time: 0:54:32.663040\n",
      "(10, 128, 128, 3)\n",
      "0.94244224\n",
      "[Epoch 6/10] [Batch 496/1081] [D loss: 0.062454] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.269668] time: 0:54:33.325162\n",
      "(10, 128, 128, 3)\n",
      "0.8196406\n",
      "[Epoch 6/10] [Batch 497/1081] [D loss: 0.063141] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.179881] time: 0:54:33.984791\n",
      "(10, 128, 128, 3)\n",
      "0.9170584\n",
      "[Epoch 6/10] [Batch 498/1081] [D loss: 0.063584] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.104375] time: 0:54:34.652329\n",
      "(10, 128, 128, 3)\n",
      "0.8881915\n",
      "[Epoch 6/10] [Batch 499/1081] [D loss: 0.063426] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.563021] time: 0:54:35.290287\n",
      "(10, 128, 128, 3)\n",
      "0.9096269\n",
      "[Epoch 6/10] [Batch 500/1081] [D loss: 0.062259] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.556313] time: 0:54:35.946810\n",
      "(10, 128, 128, 3)\n",
      "0.95141315\n",
      "[Epoch 6/10] [Batch 501/1081] [D loss: 0.062309] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.018184] time: 0:54:36.640293\n",
      "(10, 128, 128, 3)\n",
      "0.9212761\n",
      "[Epoch 6/10] [Batch 502/1081] [D loss: 0.062717] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.146773] time: 0:54:37.306332\n",
      "(10, 128, 128, 3)\n",
      "0.91669565\n",
      "[Epoch 6/10] [Batch 503/1081] [D loss: 0.062416] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.056551] time: 0:54:37.990024\n",
      "(10, 128, 128, 3)\n",
      "0.96101874\n",
      "[Epoch 6/10] [Batch 504/1081] [D loss: 0.061774] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.264905] time: 0:54:38.666488\n",
      "(10, 128, 128, 3)\n",
      "0.8923006\n",
      "[Epoch 6/10] [Batch 505/1081] [D loss: 0.061969] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.549907] time: 0:54:39.310506\n",
      "(10, 128, 128, 3)\n",
      "0.91449076\n",
      "[Epoch 6/10] [Batch 506/1081] [D loss: 0.061342] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.390884] time: 0:54:39.963469\n",
      "(10, 128, 128, 3)\n",
      "0.9058047\n",
      "[Epoch 6/10] [Batch 507/1081] [D loss: 0.061318] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.104641] time: 0:54:40.628205\n",
      "(10, 128, 128, 3)\n",
      "0.9158984\n",
      "[Epoch 6/10] [Batch 508/1081] [D loss: 0.061412] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.898447] time: 0:54:41.263365\n",
      "(10, 128, 128, 3)\n",
      "0.94166976\n",
      "[Epoch 6/10] [Batch 509/1081] [D loss: 0.063721] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.994508] time: 0:54:41.901057\n",
      "(10, 128, 128, 3)\n",
      "0.9046805\n",
      "[Epoch 6/10] [Batch 510/1081] [D loss: 0.061802] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.062122] time: 0:54:42.553954\n",
      "(10, 128, 128, 3)\n",
      "0.91765374\n",
      "[Epoch 6/10] [Batch 511/1081] [D loss: 0.062840] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.284187] time: 0:54:43.237691\n",
      "(10, 128, 128, 3)\n",
      "0.91188455\n",
      "[Epoch 6/10] [Batch 512/1081] [D loss: 0.061210] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.075046] time: 0:54:43.895954\n",
      "(10, 128, 128, 3)\n",
      "0.9467824\n",
      "[Epoch 6/10] [Batch 513/1081] [D loss: 0.061020] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.975715] time: 0:54:44.530896\n",
      "(10, 128, 128, 3)\n",
      "0.8472995\n",
      "[Epoch 6/10] [Batch 514/1081] [D loss: 0.060806] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.288393] time: 0:54:45.169276\n",
      "(10, 128, 128, 3)\n",
      "0.8966696\n",
      "[Epoch 6/10] [Batch 515/1081] [D loss: 0.061452] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.251583] time: 0:54:45.840028\n",
      "(10, 128, 128, 3)\n",
      "0.8986366\n",
      "[Epoch 6/10] [Batch 516/1081] [D loss: 0.060831] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.444246] time: 0:54:46.478652\n",
      "(10, 128, 128, 3)\n",
      "0.9221142\n",
      "[Epoch 6/10] [Batch 517/1081] [D loss: 0.060519] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.596254] time: 0:54:47.139574\n",
      "(10, 128, 128, 3)\n",
      "0.9106849\n",
      "[Epoch 6/10] [Batch 518/1081] [D loss: 0.060446] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.332552] time: 0:54:47.769843\n",
      "(10, 128, 128, 3)\n",
      "0.9425977\n",
      "[Epoch 6/10] [Batch 519/1081] [D loss: 0.060720] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.363820] time: 0:54:48.408488\n",
      "(10, 128, 128, 3)\n",
      "0.8989575\n",
      "[Epoch 6/10] [Batch 520/1081] [D loss: 0.060249] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.659856] time: 0:54:49.034899\n",
      "(10, 128, 128, 3)\n",
      "0.9099365\n",
      "[Epoch 6/10] [Batch 521/1081] [D loss: 0.060266] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.841541] time: 0:54:49.712564\n",
      "(10, 128, 128, 3)\n",
      "0.9271714\n",
      "[Epoch 6/10] [Batch 522/1081] [D loss: 0.060339] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.859327] time: 0:54:50.378321\n",
      "(10, 128, 128, 3)\n",
      "0.87457585\n",
      "[Epoch 6/10] [Batch 523/1081] [D loss: 0.060220] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.883410] time: 0:54:51.026723\n",
      "(10, 128, 128, 3)\n",
      "0.91491896\n",
      "[Epoch 6/10] [Batch 524/1081] [D loss: 0.060031] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.213044] time: 0:54:51.684664\n",
      "(10, 128, 128, 3)\n",
      "0.960625\n",
      "[Epoch 6/10] [Batch 525/1081] [D loss: 0.060991] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.554877] time: 0:54:52.341642\n",
      "(10, 128, 128, 3)\n",
      "0.9161139\n",
      "[Epoch 6/10] [Batch 526/1081] [D loss: 0.060193] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.448347] time: 0:54:53.000326\n",
      "(10, 128, 128, 3)\n",
      "0.91441315\n",
      "[Epoch 6/10] [Batch 527/1081] [D loss: 0.060029] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.402697] time: 0:54:53.671038\n",
      "(10, 128, 128, 3)\n",
      "0.91001844\n",
      "[Epoch 6/10] [Batch 528/1081] [D loss: 0.060223] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.485910] time: 0:54:54.327073\n",
      "(10, 128, 128, 3)\n",
      "0.9476476\n",
      "[Epoch 6/10] [Batch 529/1081] [D loss: 0.059659] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.867446] time: 0:54:54.977729\n",
      "(10, 128, 128, 3)\n",
      "0.9497768\n",
      "[Epoch 6/10] [Batch 530/1081] [D loss: 0.060064] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.177694] time: 0:54:55.629174\n",
      "(10, 128, 128, 3)\n",
      "0.92563933\n",
      "[Epoch 6/10] [Batch 531/1081] [D loss: 0.059742] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.752939] time: 0:54:56.288515\n",
      "(10, 128, 128, 3)\n",
      "0.89812946\n",
      "[Epoch 6/10] [Batch 532/1081] [D loss: 0.059637] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.291526] time: 0:54:56.957682\n",
      "(10, 128, 128, 3)\n",
      "0.9374855\n",
      "[Epoch 6/10] [Batch 533/1081] [D loss: 0.059477] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.650525] time: 0:54:57.657918\n",
      "(10, 128, 128, 3)\n",
      "0.9461506\n",
      "[Epoch 6/10] [Batch 534/1081] [D loss: 0.059475] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.200875] time: 0:54:58.315872\n",
      "(10, 128, 128, 3)\n",
      "0.91929847\n",
      "[Epoch 6/10] [Batch 535/1081] [D loss: 0.059289] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.189156] time: 0:54:58.978149\n",
      "(10, 128, 128, 3)\n",
      "0.88957\n",
      "[Epoch 6/10] [Batch 536/1081] [D loss: 0.059168] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.342366] time: 0:54:59.618190\n",
      "(10, 128, 128, 3)\n",
      "0.95296174\n",
      "[Epoch 6/10] [Batch 537/1081] [D loss: 0.059333] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.428346] time: 0:55:00.282502\n",
      "(10, 128, 128, 3)\n",
      "0.89795345\n",
      "[Epoch 6/10] [Batch 538/1081] [D loss: 0.059234] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.793141] time: 0:55:00.943494\n",
      "(10, 128, 128, 3)\n",
      "0.93085116\n",
      "[Epoch 6/10] [Batch 539/1081] [D loss: 0.060781] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.824032] time: 0:55:01.568592\n",
      "(10, 128, 128, 3)\n",
      "0.9379347\n",
      "[Epoch 6/10] [Batch 540/1081] [D loss: 0.060115] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.612570] time: 0:55:02.234513\n",
      "(10, 128, 128, 3)\n",
      "0.9280956\n",
      "[Epoch 6/10] [Batch 541/1081] [D loss: 0.063091] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.337214] time: 0:55:02.904381\n",
      "(10, 128, 128, 3)\n",
      "0.88195753\n",
      "[Epoch 6/10] [Batch 542/1081] [D loss: 0.060920] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.524482] time: 0:55:03.566953\n",
      "(10, 128, 128, 3)\n",
      "0.8974822\n",
      "[Epoch 6/10] [Batch 543/1081] [D loss: 0.059179] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.158033] time: 0:55:04.229772\n",
      "(10, 128, 128, 3)\n",
      "0.8455753\n",
      "[Epoch 6/10] [Batch 544/1081] [D loss: 0.059007] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.629888] time: 0:55:04.922463\n",
      "(10, 128, 128, 3)\n",
      "0.93865967\n",
      "[Epoch 6/10] [Batch 545/1081] [D loss: 0.060075] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.805056] time: 0:55:05.557084\n",
      "(10, 128, 128, 3)\n",
      "0.90239733\n",
      "[Epoch 6/10] [Batch 546/1081] [D loss: 0.061323] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.425298] time: 0:55:06.167074\n",
      "(10, 128, 128, 3)\n",
      "0.94358635\n",
      "[Epoch 6/10] [Batch 547/1081] [D loss: 0.059042] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.013637] time: 0:55:06.830934\n",
      "(10, 128, 128, 3)\n",
      "0.8775608\n",
      "[Epoch 6/10] [Batch 548/1081] [D loss: 0.058805] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.341705] time: 0:55:07.471871\n",
      "(10, 128, 128, 3)\n",
      "0.922525\n",
      "[Epoch 6/10] [Batch 549/1081] [D loss: 0.058698] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.246498] time: 0:55:08.113616\n",
      "(10, 128, 128, 3)\n",
      "0.84764355\n",
      "[Epoch 6/10] [Batch 550/1081] [D loss: 0.059112] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.015771] time: 0:55:08.759351\n",
      "(10, 128, 128, 3)\n",
      "0.9239853\n",
      "[Epoch 6/10] [Batch 551/1081] [D loss: 0.058535] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.720551] time: 0:55:09.427738\n",
      "(10, 128, 128, 3)\n",
      "0.9363821\n",
      "[Epoch 6/10] [Batch 552/1081] [D loss: 0.074038] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.577562] time: 0:55:10.095386\n",
      "(10, 128, 128, 3)\n",
      "0.90078753\n",
      "[Epoch 6/10] [Batch 553/1081] [D loss: 0.063021] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.601799] time: 0:55:10.787425\n",
      "(10, 128, 128, 3)\n",
      "0.9113\n",
      "[Epoch 6/10] [Batch 554/1081] [D loss: 0.061466] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.245241] time: 0:55:11.398947\n",
      "(10, 128, 128, 3)\n",
      "0.94165987\n",
      "[Epoch 6/10] [Batch 555/1081] [D loss: 0.059584] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.496909] time: 0:55:12.047651\n",
      "(10, 128, 128, 3)\n",
      "0.90959334\n",
      "[Epoch 6/10] [Batch 556/1081] [D loss: 0.059559] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.341521] time: 0:55:12.694853\n",
      "(10, 128, 128, 3)\n",
      "0.8905587\n",
      "[Epoch 6/10] [Batch 557/1081] [D loss: 0.059958] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.146522] time: 0:55:13.337061\n",
      "(10, 128, 128, 3)\n",
      "0.96544045\n",
      "[Epoch 6/10] [Batch 558/1081] [D loss: 0.060631] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.243755] time: 0:55:14.017999\n",
      "(10, 128, 128, 3)\n",
      "0.89954907\n",
      "[Epoch 6/10] [Batch 559/1081] [D loss: 0.060411] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.229025] time: 0:55:14.671034\n",
      "(10, 128, 128, 3)\n",
      "0.89072853\n",
      "[Epoch 6/10] [Batch 560/1081] [D loss: 0.059140] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.751198] time: 0:55:15.334861\n",
      "(10, 128, 128, 3)\n",
      "0.90255076\n",
      "[Epoch 6/10] [Batch 561/1081] [D loss: 0.060610] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.671802] time: 0:55:16.012016\n",
      "(10, 128, 128, 3)\n",
      "0.90207404\n",
      "[Epoch 6/10] [Batch 562/1081] [D loss: 0.059097] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.029059] time: 0:55:16.643550\n",
      "(10, 128, 128, 3)\n",
      "0.9191709\n",
      "[Epoch 6/10] [Batch 563/1081] [D loss: 0.060485] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.905418] time: 0:55:17.265893\n",
      "(10, 128, 128, 3)\n",
      "0.95732564\n",
      "[Epoch 6/10] [Batch 564/1081] [D loss: 0.059358] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.708810] time: 0:55:17.928438\n",
      "(10, 128, 128, 3)\n",
      "0.8931053\n",
      "[Epoch 6/10] [Batch 565/1081] [D loss: 0.059069] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.535407] time: 0:55:18.609367\n",
      "(10, 128, 128, 3)\n",
      "0.8574133\n",
      "[Epoch 6/10] [Batch 566/1081] [D loss: 0.061112] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.570897] time: 0:55:19.291796\n",
      "(10, 128, 128, 3)\n",
      "0.9541549\n",
      "[Epoch 6/10] [Batch 567/1081] [D loss: 0.058896] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.823170] time: 0:55:19.934079\n",
      "(10, 128, 128, 3)\n",
      "0.9106565\n",
      "[Epoch 6/10] [Batch 568/1081] [D loss: 0.059978] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.636027] time: 0:55:20.587479\n",
      "(10, 128, 128, 3)\n",
      "0.9288283\n",
      "[Epoch 6/10] [Batch 569/1081] [D loss: 0.059306] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.136806] time: 0:55:21.264653\n",
      "(10, 128, 128, 3)\n",
      "0.92156774\n",
      "[Epoch 6/10] [Batch 570/1081] [D loss: 0.058793] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.366582] time: 0:55:21.971937\n",
      "(10, 128, 128, 3)\n",
      "0.89645916\n",
      "[Epoch 6/10] [Batch 571/1081] [D loss: 0.061392] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.350912] time: 0:55:22.641040\n",
      "(10, 128, 128, 3)\n",
      "0.9288562\n",
      "[Epoch 6/10] [Batch 572/1081] [D loss: 0.058254] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.695320] time: 0:55:23.313853\n",
      "(10, 128, 128, 3)\n",
      "0.87519747\n",
      "[Epoch 6/10] [Batch 573/1081] [D loss: 0.060215] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.046142] time: 0:55:23.962623\n",
      "(10, 128, 128, 3)\n",
      "0.8926994\n",
      "[Epoch 6/10] [Batch 574/1081] [D loss: 0.059303] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.522349] time: 0:55:24.606394\n",
      "(10, 128, 128, 3)\n",
      "0.8820459\n",
      "[Epoch 6/10] [Batch 575/1081] [D loss: 0.058319] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.599143] time: 0:55:25.301382\n",
      "(10, 128, 128, 3)\n",
      "0.92809564\n",
      "[Epoch 6/10] [Batch 576/1081] [D loss: 0.058017] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.775242] time: 0:55:25.950203\n",
      "(10, 128, 128, 3)\n",
      "0.90543526\n",
      "[Epoch 6/10] [Batch 577/1081] [D loss: 0.058379] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.884001] time: 0:55:26.581762\n",
      "(10, 128, 128, 3)\n",
      "0.90448594\n",
      "[Epoch 6/10] [Batch 578/1081] [D loss: 0.058138] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.143232] time: 0:55:27.220399\n",
      "(10, 128, 128, 3)\n",
      "0.9713357\n",
      "[Epoch 6/10] [Batch 579/1081] [D loss: 0.057920] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.956005] time: 0:55:27.866596\n",
      "(10, 128, 128, 3)\n",
      "0.8762996\n",
      "[Epoch 6/10] [Batch 580/1081] [D loss: 0.057776] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.640488] time: 0:55:28.523423\n",
      "(10, 128, 128, 3)\n",
      "0.883998\n",
      "[Epoch 6/10] [Batch 581/1081] [D loss: 0.058184] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.098051] time: 0:55:29.197755\n",
      "(10, 128, 128, 3)\n",
      "0.8723891\n",
      "[Epoch 6/10] [Batch 582/1081] [D loss: 0.057998] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.355433] time: 0:55:29.847636\n",
      "(10, 128, 128, 3)\n",
      "0.8812874\n",
      "[Epoch 6/10] [Batch 583/1081] [D loss: 0.057979] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.959000] time: 0:55:30.513247\n",
      "(10, 128, 128, 3)\n",
      "0.8913343\n",
      "[Epoch 6/10] [Batch 584/1081] [D loss: 0.057514] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.381251] time: 0:55:31.176795\n",
      "(10, 128, 128, 3)\n",
      "0.89535016\n",
      "[Epoch 6/10] [Batch 585/1081] [D loss: 0.058024] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.676775] time: 0:55:31.849113\n",
      "(10, 128, 128, 3)\n",
      "0.97016835\n",
      "[Epoch 6/10] [Batch 586/1081] [D loss: 0.057281] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.685129] time: 0:55:32.500313\n",
      "(10, 128, 128, 3)\n",
      "0.91973966\n",
      "[Epoch 6/10] [Batch 587/1081] [D loss: 0.057373] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.456740] time: 0:55:33.143598\n",
      "(10, 128, 128, 3)\n",
      "0.8628786\n",
      "[Epoch 6/10] [Batch 588/1081] [D loss: 0.057660] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.647030] time: 0:55:33.786720\n",
      "(10, 128, 128, 3)\n",
      "0.92764354\n",
      "[Epoch 6/10] [Batch 589/1081] [D loss: 0.058548] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.904759] time: 0:55:34.473419\n",
      "(10, 128, 128, 3)\n",
      "0.8765338\n",
      "[Epoch 6/10] [Batch 590/1081] [D loss: 0.057681] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.351670] time: 0:55:35.116733\n",
      "(10, 128, 128, 3)\n",
      "0.90577966\n",
      "[Epoch 6/10] [Batch 591/1081] [D loss: 0.059976] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.765317] time: 0:55:35.744177\n",
      "(10, 128, 128, 3)\n",
      "0.92855984\n",
      "[Epoch 6/10] [Batch 592/1081] [D loss: 0.058572] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.905936] time: 0:55:36.386374\n",
      "(10, 128, 128, 3)\n",
      "0.8818391\n",
      "[Epoch 6/10] [Batch 593/1081] [D loss: 0.057399] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.747086] time: 0:55:37.055906\n",
      "(10, 128, 128, 3)\n",
      "0.894705\n",
      "[Epoch 6/10] [Batch 594/1081] [D loss: 0.057084] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.582760] time: 0:55:37.696513\n",
      "(10, 128, 128, 3)\n",
      "0.96978706\n",
      "[Epoch 6/10] [Batch 595/1081] [D loss: 0.057311] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.185991] time: 0:55:38.353057\n",
      "(10, 128, 128, 3)\n",
      "0.93433094\n",
      "[Epoch 6/10] [Batch 596/1081] [D loss: 0.056768] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.971475] time: 0:55:38.960651\n",
      "(10, 128, 128, 3)\n",
      "0.8813675\n",
      "[Epoch 6/10] [Batch 597/1081] [D loss: 0.056817] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.325960] time: 0:55:39.581618\n",
      "(10, 128, 128, 3)\n",
      "0.9313924\n",
      "[Epoch 6/10] [Batch 598/1081] [D loss: 0.057189] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.122531] time: 0:55:40.214071\n",
      "(10, 128, 128, 3)\n",
      "0.90572006\n",
      "[Epoch 6/10] [Batch 599/1081] [D loss: 0.056952] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.741530] time: 0:55:40.892703\n",
      "(10, 128, 128, 3)\n",
      "0.9200258\n",
      "[Epoch 6/10] [Batch 600/1081] [D loss: 0.056695] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.326446] time: 0:55:41.553169\n",
      "(10, 128, 128, 3)\n",
      "0.91422015\n",
      "[Epoch 6/10] [Batch 601/1081] [D loss: 0.056687] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.285426] time: 0:55:42.206793\n",
      "(10, 128, 128, 3)\n",
      "0.93741244\n",
      "[Epoch 6/10] [Batch 602/1081] [D loss: 0.056419] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.549259] time: 0:55:42.841857\n",
      "(10, 128, 128, 3)\n",
      "0.96280724\n",
      "[Epoch 6/10] [Batch 603/1081] [D loss: 0.056320] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.827910] time: 0:55:43.456755\n",
      "(10, 128, 128, 3)\n",
      "0.90199494\n",
      "[Epoch 6/10] [Batch 604/1081] [D loss: 0.057026] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.974435] time: 0:55:44.077472\n",
      "(10, 128, 128, 3)\n",
      "0.92801255\n",
      "[Epoch 6/10] [Batch 605/1081] [D loss: 0.056886] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.468143] time: 0:55:44.760229\n",
      "(10, 128, 128, 3)\n",
      "0.9337999\n",
      "[Epoch 6/10] [Batch 606/1081] [D loss: 0.056458] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.650414] time: 0:55:45.387176\n",
      "(10, 128, 128, 3)\n",
      "0.88849443\n",
      "[Epoch 6/10] [Batch 607/1081] [D loss: 0.056713] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.184796] time: 0:55:46.040208\n",
      "(10, 128, 128, 3)\n",
      "0.92784995\n",
      "[Epoch 6/10] [Batch 608/1081] [D loss: 0.056342] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.908154] time: 0:55:46.716850\n",
      "(10, 128, 128, 3)\n",
      "0.9592112\n",
      "[Epoch 6/10] [Batch 609/1081] [D loss: 0.056989] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.852447] time: 0:55:47.374913\n",
      "(10, 128, 128, 3)\n",
      "0.9420225\n",
      "[Epoch 6/10] [Batch 610/1081] [D loss: 0.057399] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.861658] time: 0:55:48.030614\n",
      "(10, 128, 128, 3)\n",
      "0.8798291\n",
      "[Epoch 6/10] [Batch 611/1081] [D loss: 0.057057] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.520298] time: 0:55:48.658744\n",
      "(10, 128, 128, 3)\n",
      "0.94862396\n",
      "[Epoch 6/10] [Batch 612/1081] [D loss: 0.056802] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.827433] time: 0:55:49.327571\n",
      "(10, 128, 128, 3)\n",
      "0.93626237\n",
      "[Epoch 6/10] [Batch 613/1081] [D loss: 0.055790] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.261274] time: 0:55:50.006121\n",
      "(10, 128, 128, 3)\n",
      "0.9079413\n",
      "[Epoch 6/10] [Batch 614/1081] [D loss: 0.056799] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.049751] time: 0:55:50.661127\n",
      "(10, 128, 128, 3)\n",
      "0.9327777\n",
      "[Epoch 6/10] [Batch 615/1081] [D loss: 0.055985] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.639775] time: 0:55:51.330148\n",
      "(10, 128, 128, 3)\n",
      "0.96265346\n",
      "[Epoch 6/10] [Batch 616/1081] [D loss: 0.056095] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.667321] time: 0:55:51.956071\n",
      "(10, 128, 128, 3)\n",
      "0.92024827\n",
      "[Epoch 6/10] [Batch 617/1081] [D loss: 0.553104] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 4.093315] time: 0:55:52.565881\n",
      "(10, 128, 128, 3)\n",
      "0.9197907\n",
      "[Epoch 6/10] [Batch 618/1081] [D loss: 0.326487] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 4.634244] time: 0:55:53.210970\n",
      "(10, 128, 128, 3)\n",
      "0.95177174\n",
      "[Epoch 6/10] [Batch 619/1081] [D loss: 0.299054] [D acc: 0.45 (0.90 real, 0.00 fake)] [G loss: 4.491938] time: 0:55:53.872671\n",
      "(10, 128, 128, 3)\n",
      "0.9135704\n",
      "[Epoch 6/10] [Batch 620/1081] [D loss: 0.158599] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.174009] time: 0:55:54.500990\n",
      "(10, 128, 128, 3)\n",
      "0.90811795\n",
      "[Epoch 6/10] [Batch 621/1081] [D loss: 0.156638] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 5.320928] time: 0:55:55.152483\n",
      "(10, 128, 128, 3)\n",
      "0.9250254\n",
      "[Epoch 6/10] [Batch 622/1081] [D loss: 0.093634] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.323875] time: 0:55:55.838364\n",
      "(10, 128, 128, 3)\n",
      "0.90535957\n",
      "[Epoch 6/10] [Batch 623/1081] [D loss: 0.086555] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.366212] time: 0:55:56.509488\n",
      "(10, 128, 128, 3)\n",
      "0.9252164\n",
      "[Epoch 6/10] [Batch 624/1081] [D loss: 0.064559] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.467088] time: 0:55:57.125081\n",
      "(10, 128, 128, 3)\n",
      "0.89275384\n",
      "[Epoch 6/10] [Batch 625/1081] [D loss: 0.069098] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.416886] time: 0:55:57.787833\n",
      "(10, 128, 128, 3)\n",
      "0.902286\n",
      "[Epoch 6/10] [Batch 626/1081] [D loss: 0.070162] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.946615] time: 0:55:58.456138\n",
      "(10, 128, 128, 3)\n",
      "0.90525025\n",
      "[Epoch 6/10] [Batch 627/1081] [D loss: 0.065546] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.016407] time: 0:55:59.107334\n",
      "(10, 128, 128, 3)\n",
      "0.930937\n",
      "[Epoch 6/10] [Batch 628/1081] [D loss: 0.062332] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.222588] time: 0:55:59.755523\n",
      "(10, 128, 128, 3)\n",
      "0.8781831\n",
      "[Epoch 6/10] [Batch 629/1081] [D loss: 0.060661] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.518466] time: 0:56:00.425172\n",
      "(10, 128, 128, 3)\n",
      "0.909853\n",
      "[Epoch 6/10] [Batch 630/1081] [D loss: 0.062446] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.185979] time: 0:56:01.084400\n",
      "(10, 128, 128, 3)\n",
      "0.8711899\n",
      "[Epoch 6/10] [Batch 631/1081] [D loss: 0.064179] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.302996] time: 0:56:01.748650\n",
      "(10, 128, 128, 3)\n",
      "0.98030454\n",
      "[Epoch 6/10] [Batch 632/1081] [D loss: 0.060821] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.346280] time: 0:56:02.379132\n",
      "(10, 128, 128, 3)\n",
      "0.8889618\n",
      "[Epoch 6/10] [Batch 633/1081] [D loss: 0.060645] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.346593] time: 0:56:03.034395\n",
      "(10, 128, 128, 3)\n",
      "0.90957266\n",
      "[Epoch 6/10] [Batch 634/1081] [D loss: 0.057783] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.971446] time: 0:56:03.672857\n",
      "(10, 128, 128, 3)\n",
      "0.9140563\n",
      "[Epoch 6/10] [Batch 635/1081] [D loss: 0.057426] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.450144] time: 0:56:04.356131\n",
      "(10, 128, 128, 3)\n",
      "0.9359613\n",
      "[Epoch 6/10] [Batch 636/1081] [D loss: 0.058993] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.173435] time: 0:56:05.024918\n",
      "(10, 128, 128, 3)\n",
      "0.90399224\n",
      "[Epoch 6/10] [Batch 637/1081] [D loss: 0.057585] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.515578] time: 0:56:05.693195\n",
      "(10, 128, 128, 3)\n",
      "0.9391245\n",
      "[Epoch 6/10] [Batch 638/1081] [D loss: 0.065433] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.554392] time: 0:56:06.351819\n",
      "(10, 128, 128, 3)\n",
      "0.909647\n",
      "[Epoch 6/10] [Batch 639/1081] [D loss: 0.061899] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.836497] time: 0:56:07.000485\n",
      "(10, 128, 128, 3)\n",
      "0.92056423\n",
      "[Epoch 6/10] [Batch 640/1081] [D loss: 0.062601] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.857564] time: 0:56:07.654595\n",
      "(10, 128, 128, 3)\n",
      "0.9142437\n",
      "[Epoch 6/10] [Batch 641/1081] [D loss: 0.058346] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.934999] time: 0:56:08.283529\n",
      "(10, 128, 128, 3)\n",
      "0.91246396\n",
      "[Epoch 6/10] [Batch 642/1081] [D loss: 0.058767] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.073471] time: 0:56:08.920505\n",
      "(10, 128, 128, 3)\n",
      "0.8616238\n",
      "[Epoch 6/10] [Batch 643/1081] [D loss: 0.057181] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.229348] time: 0:56:09.526460\n",
      "(10, 128, 128, 3)\n",
      "0.8730264\n",
      "[Epoch 6/10] [Batch 644/1081] [D loss: 0.058360] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.626423] time: 0:56:10.182975\n",
      "(10, 128, 128, 3)\n",
      "0.91115206\n",
      "[Epoch 6/10] [Batch 645/1081] [D loss: 0.058674] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.712042] time: 0:56:10.866962\n",
      "(10, 128, 128, 3)\n",
      "0.8857253\n",
      "[Epoch 6/10] [Batch 646/1081] [D loss: 0.059704] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.877964] time: 0:56:11.535234\n",
      "(10, 128, 128, 3)\n",
      "0.9545699\n",
      "[Epoch 6/10] [Batch 647/1081] [D loss: 0.056948] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.383873] time: 0:56:12.224190\n",
      "(10, 128, 128, 3)\n",
      "0.84639055\n",
      "[Epoch 6/10] [Batch 648/1081] [D loss: 0.058323] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.185462] time: 0:56:12.769190\n",
      "(10, 128, 128, 3)\n",
      "0.8901565\n",
      "[Epoch 6/10] [Batch 649/1081] [D loss: 0.056369] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.989944] time: 0:56:13.194602\n",
      "(10, 128, 128, 3)\n",
      "0.8610664\n",
      "[Epoch 6/10] [Batch 650/1081] [D loss: 0.057845] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.154369] time: 0:56:13.668105\n",
      "(10, 128, 128, 3)\n",
      "0.90139276\n",
      "[Epoch 6/10] [Batch 651/1081] [D loss: 0.059820] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.678109] time: 0:56:14.143480\n",
      "(10, 128, 128, 3)\n",
      "0.9829678\n",
      "[Epoch 6/10] [Batch 652/1081] [D loss: 0.056828] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.082345] time: 0:56:14.591800\n",
      "(10, 128, 128, 3)\n",
      "0.9117129\n",
      "[Epoch 6/10] [Batch 653/1081] [D loss: 0.056230] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.389230] time: 0:56:15.077713\n",
      "(10, 128, 128, 3)\n",
      "0.9368453\n",
      "[Epoch 6/10] [Batch 654/1081] [D loss: 0.058815] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.600537] time: 0:56:15.550274\n",
      "(10, 128, 128, 3)\n",
      "0.8848622\n",
      "[Epoch 6/10] [Batch 655/1081] [D loss: 0.056883] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.682527] time: 0:56:16.024204\n",
      "(10, 128, 128, 3)\n",
      "0.88875335\n",
      "[Epoch 6/10] [Batch 656/1081] [D loss: 0.056453] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.112540] time: 0:56:16.488751\n",
      "(10, 128, 128, 3)\n",
      "0.9172637\n",
      "[Epoch 6/10] [Batch 657/1081] [D loss: 0.056306] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.364411] time: 0:56:16.950246\n",
      "(10, 128, 128, 3)\n",
      "0.89757085\n",
      "[Epoch 6/10] [Batch 658/1081] [D loss: 0.056995] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.499014] time: 0:56:17.412184\n",
      "(10, 128, 128, 3)\n",
      "0.92992115\n",
      "[Epoch 6/10] [Batch 659/1081] [D loss: 0.055849] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.979755] time: 0:56:17.864498\n",
      "(10, 128, 128, 3)\n",
      "0.9501467\n",
      "[Epoch 6/10] [Batch 660/1081] [D loss: 0.055873] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.289121] time: 0:56:18.317810\n",
      "(10, 128, 128, 3)\n",
      "0.9059842\n",
      "[Epoch 6/10] [Batch 661/1081] [D loss: 0.057234] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.280119] time: 0:56:18.774584\n",
      "(10, 128, 128, 3)\n",
      "0.8955123\n",
      "[Epoch 6/10] [Batch 662/1081] [D loss: 0.056053] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.909250] time: 0:56:19.229418\n",
      "(10, 128, 128, 3)\n",
      "0.9143143\n",
      "[Epoch 6/10] [Batch 663/1081] [D loss: 0.055747] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.711366] time: 0:56:19.706776\n",
      "(10, 128, 128, 3)\n",
      "0.9559992\n",
      "[Epoch 6/10] [Batch 664/1081] [D loss: 0.055377] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.918179] time: 0:56:20.170808\n",
      "(10, 128, 128, 3)\n",
      "0.92270947\n",
      "[Epoch 6/10] [Batch 665/1081] [D loss: 0.056088] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.297118] time: 0:56:20.646469\n",
      "(10, 128, 128, 3)\n",
      "0.92665195\n",
      "[Epoch 6/10] [Batch 666/1081] [D loss: 0.055547] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.344627] time: 0:56:21.082943\n",
      "(10, 128, 128, 3)\n",
      "0.95294785\n",
      "[Epoch 6/10] [Batch 667/1081] [D loss: 0.060015] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.711026] time: 0:56:21.542422\n",
      "(10, 128, 128, 3)\n",
      "0.90803295\n",
      "[Epoch 6/10] [Batch 668/1081] [D loss: 0.066804] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.543299] time: 0:56:21.996063\n",
      "(10, 128, 128, 3)\n",
      "0.9520395\n",
      "[Epoch 6/10] [Batch 669/1081] [D loss: 0.055839] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.057084] time: 0:56:22.442320\n",
      "(10, 128, 128, 3)\n",
      "0.932\n",
      "[Epoch 6/10] [Batch 670/1081] [D loss: 0.055384] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.415985] time: 0:56:22.865513\n",
      "(10, 128, 128, 3)\n",
      "0.9449959\n",
      "[Epoch 6/10] [Batch 671/1081] [D loss: 0.055494] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.430689] time: 0:56:23.332746\n",
      "(10, 128, 128, 3)\n",
      "0.8838298\n",
      "[Epoch 6/10] [Batch 672/1081] [D loss: 0.055910] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.374210] time: 0:56:23.801106\n",
      "(10, 128, 128, 3)\n",
      "0.8600252\n",
      "[Epoch 6/10] [Batch 673/1081] [D loss: 0.058068] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.672555] time: 0:56:24.295064\n",
      "(10, 128, 128, 3)\n",
      "0.93542856\n",
      "[Epoch 6/10] [Batch 674/1081] [D loss: 0.055781] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.788043] time: 0:56:24.770111\n",
      "(10, 128, 128, 3)\n",
      "0.928305\n",
      "[Epoch 6/10] [Batch 675/1081] [D loss: 0.055438] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.132288] time: 0:56:25.250435\n",
      "(10, 128, 128, 3)\n",
      "0.8919093\n",
      "[Epoch 6/10] [Batch 676/1081] [D loss: 0.055254] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.845874] time: 0:56:25.723252\n",
      "(10, 128, 128, 3)\n",
      "0.9230102\n",
      "[Epoch 6/10] [Batch 677/1081] [D loss: 0.057815] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.883356] time: 0:56:26.174154\n",
      "(10, 128, 128, 3)\n",
      "0.9675574\n",
      "[Epoch 6/10] [Batch 678/1081] [D loss: 0.056385] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.881474] time: 0:56:26.626049\n",
      "(10, 128, 128, 3)\n",
      "0.9317284\n",
      "[Epoch 6/10] [Batch 679/1081] [D loss: 0.054596] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.177529] time: 0:56:27.073476\n",
      "(10, 128, 128, 3)\n",
      "0.91831285\n",
      "[Epoch 6/10] [Batch 680/1081] [D loss: 0.054424] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.584417] time: 0:56:27.580276\n",
      "(10, 128, 128, 3)\n",
      "0.90462166\n",
      "[Epoch 6/10] [Batch 681/1081] [D loss: 0.055169] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.578403] time: 0:56:28.062747\n",
      "(10, 128, 128, 3)\n",
      "0.9724317\n",
      "[Epoch 6/10] [Batch 682/1081] [D loss: 0.054752] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.450815] time: 0:56:28.543503\n",
      "(10, 128, 128, 3)\n",
      "0.89075106\n",
      "[Epoch 6/10] [Batch 683/1081] [D loss: 0.054323] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.982919] time: 0:56:29.026270\n",
      "(10, 128, 128, 3)\n",
      "0.969454\n",
      "[Epoch 6/10] [Batch 684/1081] [D loss: 0.054881] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.340505] time: 0:56:29.502984\n",
      "(10, 128, 128, 3)\n",
      "0.9493146\n",
      "[Epoch 6/10] [Batch 685/1081] [D loss: 0.057541] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.344742] time: 0:56:29.965288\n",
      "(10, 128, 128, 3)\n",
      "0.9487439\n",
      "[Epoch 6/10] [Batch 686/1081] [D loss: 0.056228] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.148070] time: 0:56:30.511917\n",
      "(10, 128, 128, 3)\n",
      "0.91958404\n",
      "[Epoch 6/10] [Batch 687/1081] [D loss: 0.055375] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.440641] time: 0:56:31.147986\n",
      "(10, 128, 128, 3)\n",
      "0.8771336\n",
      "[Epoch 6/10] [Batch 688/1081] [D loss: 0.054040] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.162069] time: 0:56:31.811041\n",
      "(10, 128, 128, 3)\n",
      "0.9368799\n",
      "[Epoch 6/10] [Batch 689/1081] [D loss: 0.054404] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.339624] time: 0:56:32.477481\n",
      "(10, 128, 128, 3)\n",
      "0.9037184\n",
      "[Epoch 6/10] [Batch 690/1081] [D loss: 0.054643] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.589777] time: 0:56:33.147766\n",
      "(10, 128, 128, 3)\n",
      "0.9093916\n",
      "[Epoch 6/10] [Batch 691/1081] [D loss: 0.057481] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.149162] time: 0:56:33.830351\n",
      "(10, 128, 128, 3)\n",
      "0.8691395\n",
      "[Epoch 6/10] [Batch 692/1081] [D loss: 0.056890] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.540672] time: 0:56:34.453436\n",
      "(10, 128, 128, 3)\n",
      "0.92938185\n",
      "[Epoch 6/10] [Batch 693/1081] [D loss: 0.054499] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.460542] time: 0:56:35.121685\n",
      "(10, 128, 128, 3)\n",
      "0.9399989\n",
      "[Epoch 6/10] [Batch 694/1081] [D loss: 0.054139] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.075624] time: 0:56:35.762981\n",
      "(10, 128, 128, 3)\n",
      "0.87120795\n",
      "[Epoch 6/10] [Batch 695/1081] [D loss: 0.054231] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.952459] time: 0:56:36.412579\n",
      "(10, 128, 128, 3)\n",
      "0.9049272\n",
      "[Epoch 6/10] [Batch 696/1081] [D loss: 0.054253] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.867124] time: 0:56:37.073709\n",
      "(10, 128, 128, 3)\n",
      "0.9200008\n",
      "[Epoch 6/10] [Batch 697/1081] [D loss: 0.053878] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.322655] time: 0:56:37.733901\n",
      "(10, 128, 128, 3)\n",
      "0.8816559\n",
      "[Epoch 6/10] [Batch 698/1081] [D loss: 0.054795] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.373591] time: 0:56:38.371304\n",
      "(10, 128, 128, 3)\n",
      "0.8948989\n",
      "[Epoch 6/10] [Batch 699/1081] [D loss: 0.054893] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.333043] time: 0:56:39.020887\n",
      "(10, 128, 128, 3)\n",
      "0.9616025\n",
      "[Epoch 6/10] [Batch 700/1081] [D loss: 0.054076] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.700299] time: 0:56:39.654083\n",
      "(10, 128, 128, 3)\n",
      "0.95184165\n",
      "[Epoch 6/10] [Batch 701/1081] [D loss: 0.053916] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.074471] time: 0:56:40.309507\n",
      "(10, 128, 128, 3)\n",
      "0.895333\n",
      "[Epoch 6/10] [Batch 702/1081] [D loss: 0.054831] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.150634] time: 0:56:40.945364\n",
      "(10, 128, 128, 3)\n",
      "0.8658538\n",
      "[Epoch 6/10] [Batch 703/1081] [D loss: 0.053917] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.265490] time: 0:56:41.602121\n",
      "(10, 128, 128, 3)\n",
      "0.88361174\n",
      "[Epoch 6/10] [Batch 704/1081] [D loss: 0.053556] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.451485] time: 0:56:42.260044\n",
      "(10, 128, 128, 3)\n",
      "0.9555592\n",
      "[Epoch 6/10] [Batch 705/1081] [D loss: 0.055344] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.025737] time: 0:56:42.914657\n",
      "(10, 128, 128, 3)\n",
      "0.8649897\n",
      "[Epoch 6/10] [Batch 706/1081] [D loss: 0.055146] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.775599] time: 0:56:43.576525\n",
      "(10, 128, 128, 3)\n",
      "0.8634421\n",
      "[Epoch 6/10] [Batch 707/1081] [D loss: 0.053626] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.371166] time: 0:56:44.213169\n",
      "(10, 128, 128, 3)\n",
      "0.89841026\n",
      "[Epoch 6/10] [Batch 708/1081] [D loss: 0.055565] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.069208] time: 0:56:44.827500\n",
      "(10, 128, 128, 3)\n",
      "0.8915029\n",
      "[Epoch 6/10] [Batch 709/1081] [D loss: 0.053925] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.932965] time: 0:56:45.463616\n",
      "(10, 128, 128, 3)\n",
      "0.90540504\n",
      "[Epoch 6/10] [Batch 710/1081] [D loss: 0.053637] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.486386] time: 0:56:46.104401\n",
      "(10, 128, 128, 3)\n",
      "0.9291957\n",
      "[Epoch 6/10] [Batch 711/1081] [D loss: 0.054075] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.306072] time: 0:56:46.731646\n",
      "(10, 128, 128, 3)\n",
      "0.90685445\n",
      "[Epoch 6/10] [Batch 712/1081] [D loss: 0.053069] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.674798] time: 0:56:47.388154\n",
      "(10, 128, 128, 3)\n",
      "0.9560688\n",
      "[Epoch 6/10] [Batch 713/1081] [D loss: 0.055542] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.307165] time: 0:56:48.049358\n",
      "(10, 128, 128, 3)\n",
      "0.9274411\n",
      "[Epoch 6/10] [Batch 714/1081] [D loss: 0.055070] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.326961] time: 0:56:48.719073\n",
      "(10, 128, 128, 3)\n",
      "0.9269786\n",
      "[Epoch 6/10] [Batch 715/1081] [D loss: 0.054568] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.907026] time: 0:56:49.334379\n",
      "(10, 128, 128, 3)\n",
      "0.93412256\n",
      "[Epoch 6/10] [Batch 716/1081] [D loss: 0.053212] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.248789] time: 0:56:49.993961\n",
      "(10, 128, 128, 3)\n",
      "0.916209\n",
      "[Epoch 6/10] [Batch 717/1081] [D loss: 0.052726] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.964092] time: 0:56:50.659082\n",
      "(10, 128, 128, 3)\n",
      "0.9247554\n",
      "[Epoch 6/10] [Batch 718/1081] [D loss: 0.052885] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.568751] time: 0:56:51.316570\n",
      "(10, 128, 128, 3)\n",
      "0.8894696\n",
      "[Epoch 6/10] [Batch 719/1081] [D loss: 0.052821] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.270631] time: 0:56:51.980682\n",
      "(10, 128, 128, 3)\n",
      "0.9243777\n",
      "[Epoch 6/10] [Batch 720/1081] [D loss: 0.053199] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.886367] time: 0:56:52.637172\n",
      "(10, 128, 128, 3)\n",
      "0.92812806\n",
      "[Epoch 6/10] [Batch 721/1081] [D loss: 0.052657] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.743703] time: 0:56:53.274139\n",
      "(10, 128, 128, 3)\n",
      "0.88368803\n",
      "[Epoch 6/10] [Batch 722/1081] [D loss: 0.052928] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.798693] time: 0:56:53.902063\n",
      "(10, 128, 128, 3)\n",
      "0.8642424\n",
      "[Epoch 6/10] [Batch 723/1081] [D loss: 0.052924] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.855079] time: 0:56:54.508023\n",
      "(10, 128, 128, 3)\n",
      "0.88166314\n",
      "[Epoch 6/10] [Batch 724/1081] [D loss: 0.052880] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.366548] time: 0:56:55.154623\n",
      "(10, 128, 128, 3)\n",
      "0.92954844\n",
      "[Epoch 6/10] [Batch 725/1081] [D loss: 0.052530] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.313038] time: 0:56:55.834979\n",
      "(10, 128, 128, 3)\n",
      "0.93015426\n",
      "[Epoch 6/10] [Batch 726/1081] [D loss: 0.053005] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.580109] time: 0:56:56.492314\n",
      "(10, 128, 128, 3)\n",
      "0.8770053\n",
      "[Epoch 6/10] [Batch 727/1081] [D loss: 0.053921] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.713030] time: 0:56:57.140958\n",
      "(10, 128, 128, 3)\n",
      "0.9304753\n",
      "[Epoch 6/10] [Batch 728/1081] [D loss: 0.052924] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.098640] time: 0:56:57.772928\n",
      "(10, 128, 128, 3)\n",
      "0.8966734\n",
      "[Epoch 6/10] [Batch 729/1081] [D loss: 0.053524] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.831663] time: 0:56:58.393897\n",
      "(10, 128, 128, 3)\n",
      "0.92517895\n",
      "[Epoch 6/10] [Batch 730/1081] [D loss: 0.053563] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.582314] time: 0:56:59.049637\n",
      "(10, 128, 128, 3)\n",
      "0.89423734\n",
      "[Epoch 6/10] [Batch 731/1081] [D loss: 0.052772] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.273619] time: 0:56:59.684893\n",
      "(10, 128, 128, 3)\n",
      "0.88301164\n",
      "[Epoch 6/10] [Batch 732/1081] [D loss: 0.052401] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.879304] time: 0:57:00.325570\n",
      "(10, 128, 128, 3)\n",
      "0.98006016\n",
      "[Epoch 6/10] [Batch 733/1081] [D loss: 0.052349] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.330461] time: 0:57:01.011356\n",
      "(10, 128, 128, 3)\n",
      "0.92593664\n",
      "[Epoch 6/10] [Batch 734/1081] [D loss: 0.052618] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.919339] time: 0:57:01.661313\n",
      "(10, 128, 128, 3)\n",
      "0.93726325\n",
      "[Epoch 6/10] [Batch 735/1081] [D loss: 0.052752] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.238732] time: 0:57:02.300065\n",
      "(10, 128, 128, 3)\n",
      "0.9695394\n",
      "[Epoch 6/10] [Batch 736/1081] [D loss: 0.052089] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.847438] time: 0:57:02.970076\n",
      "(10, 128, 128, 3)\n",
      "0.895314\n",
      "[Epoch 6/10] [Batch 737/1081] [D loss: 0.052174] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.899567] time: 0:57:03.669157\n",
      "(10, 128, 128, 3)\n",
      "0.9146018\n",
      "[Epoch 6/10] [Batch 738/1081] [D loss: 0.052208] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.320618] time: 0:57:04.339222\n",
      "(10, 128, 128, 3)\n",
      "0.9260196\n",
      "[Epoch 6/10] [Batch 739/1081] [D loss: 0.052451] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.419062] time: 0:57:04.991381\n",
      "(10, 128, 128, 3)\n",
      "0.8674795\n",
      "[Epoch 6/10] [Batch 740/1081] [D loss: 0.052285] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.587282] time: 0:57:05.638732\n",
      "(10, 128, 128, 3)\n",
      "0.9550759\n",
      "[Epoch 6/10] [Batch 741/1081] [D loss: 0.053287] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.230056] time: 0:57:06.337411\n",
      "(10, 128, 128, 3)\n",
      "0.94157267\n",
      "[Epoch 6/10] [Batch 742/1081] [D loss: 0.052960] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.191736] time: 0:57:06.968085\n",
      "(10, 128, 128, 3)\n",
      "0.9435544\n",
      "[Epoch 6/10] [Batch 743/1081] [D loss: 0.052421] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.102618] time: 0:57:07.637793\n",
      "(10, 128, 128, 3)\n",
      "0.87319374\n",
      "[Epoch 6/10] [Batch 744/1081] [D loss: 0.051861] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.586923] time: 0:57:08.276250\n",
      "(10, 128, 128, 3)\n",
      "0.9255838\n",
      "[Epoch 6/10] [Batch 745/1081] [D loss: 0.052398] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.266521] time: 0:57:08.949216\n",
      "(10, 128, 128, 3)\n",
      "0.9528987\n",
      "[Epoch 6/10] [Batch 746/1081] [D loss: 0.052008] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.342954] time: 0:57:09.593532\n",
      "(10, 128, 128, 3)\n",
      "0.8839361\n",
      "[Epoch 6/10] [Batch 747/1081] [D loss: 0.052509] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.937603] time: 0:57:10.227658\n",
      "(10, 128, 128, 3)\n",
      "0.9141702\n",
      "[Epoch 6/10] [Batch 748/1081] [D loss: 0.051904] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.082036] time: 0:57:10.905548\n",
      "(10, 128, 128, 3)\n",
      "0.9550135\n",
      "[Epoch 6/10] [Batch 749/1081] [D loss: 0.052580] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.711526] time: 0:57:11.565337\n",
      "(10, 128, 128, 3)\n",
      "0.9034095\n",
      "[Epoch 6/10] [Batch 750/1081] [D loss: 0.051543] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.984766] time: 0:57:12.201550\n",
      "(10, 128, 128, 3)\n",
      "0.9357589\n",
      "[Epoch 6/10] [Batch 751/1081] [D loss: 0.051977] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.896111] time: 0:57:12.891467\n",
      "(10, 128, 128, 3)\n",
      "0.87773156\n",
      "[Epoch 6/10] [Batch 752/1081] [D loss: 0.052257] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.472391] time: 0:57:13.525286\n",
      "(10, 128, 128, 3)\n",
      "0.9560361\n",
      "[Epoch 6/10] [Batch 753/1081] [D loss: 0.053205] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.034917] time: 0:57:14.179453\n",
      "(10, 128, 128, 3)\n",
      "0.9332966\n",
      "[Epoch 6/10] [Batch 754/1081] [D loss: 0.051438] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.992847] time: 0:57:14.819965\n",
      "(10, 128, 128, 3)\n",
      "0.88348484\n",
      "[Epoch 6/10] [Batch 755/1081] [D loss: 0.051762] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.848943] time: 0:57:15.483250\n",
      "(10, 128, 128, 3)\n",
      "0.86894816\n",
      "[Epoch 6/10] [Batch 756/1081] [D loss: 0.051404] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.594406] time: 0:57:16.129190\n",
      "(10, 128, 128, 3)\n",
      "0.9354968\n",
      "[Epoch 6/10] [Batch 757/1081] [D loss: 0.051292] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.805926] time: 0:57:16.752267\n",
      "(10, 128, 128, 3)\n",
      "0.84933877\n",
      "[Epoch 6/10] [Batch 758/1081] [D loss: 0.051261] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.809948] time: 0:57:17.417534\n",
      "(10, 128, 128, 3)\n",
      "0.92751724\n",
      "[Epoch 6/10] [Batch 759/1081] [D loss: 0.051235] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.671198] time: 0:57:18.096271\n",
      "(10, 128, 128, 3)\n",
      "0.91763854\n",
      "[Epoch 6/10] [Batch 760/1081] [D loss: 0.051652] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.055838] time: 0:57:18.752026\n",
      "(10, 128, 128, 3)\n",
      "0.91414696\n",
      "[Epoch 6/10] [Batch 761/1081] [D loss: 0.051780] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.938055] time: 0:57:19.401370\n",
      "(10, 128, 128, 3)\n",
      "0.9199281\n",
      "[Epoch 6/10] [Batch 762/1081] [D loss: 0.051201] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.276136] time: 0:57:20.068273\n",
      "(10, 128, 128, 3)\n",
      "0.8915928\n",
      "[Epoch 6/10] [Batch 763/1081] [D loss: 0.054464] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.739367] time: 0:57:20.729895\n",
      "(10, 128, 128, 3)\n",
      "0.9468672\n",
      "[Epoch 6/10] [Batch 764/1081] [D loss: 0.052963] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.835942] time: 0:57:21.404760\n",
      "(10, 128, 128, 3)\n",
      "0.9143634\n",
      "[Epoch 6/10] [Batch 765/1081] [D loss: 0.051589] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.526329] time: 0:57:22.057607\n",
      "(10, 128, 128, 3)\n",
      "0.9291056\n",
      "[Epoch 6/10] [Batch 766/1081] [D loss: 0.051300] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.915840] time: 0:57:22.706933\n",
      "(10, 128, 128, 3)\n",
      "0.9670453\n",
      "[Epoch 6/10] [Batch 767/1081] [D loss: 0.051886] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.207027] time: 0:57:23.363930\n",
      "(10, 128, 128, 3)\n",
      "0.8584051\n",
      "[Epoch 6/10] [Batch 768/1081] [D loss: 0.051079] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.638415] time: 0:57:24.005556\n",
      "(10, 128, 128, 3)\n",
      "0.8822972\n",
      "[Epoch 6/10] [Batch 769/1081] [D loss: 0.051160] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.043645] time: 0:57:24.709982\n",
      "(10, 128, 128, 3)\n",
      "0.9086054\n",
      "[Epoch 6/10] [Batch 770/1081] [D loss: 0.051544] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.598098] time: 0:57:25.353859\n",
      "(10, 128, 128, 3)\n",
      "0.9206365\n",
      "[Epoch 6/10] [Batch 771/1081] [D loss: 0.051545] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.110336] time: 0:57:25.956625\n",
      "(10, 128, 128, 3)\n",
      "0.8466196\n",
      "[Epoch 6/10] [Batch 772/1081] [D loss: 0.051930] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.796535] time: 0:57:26.594540\n",
      "(10, 128, 128, 3)\n",
      "0.87370723\n",
      "[Epoch 6/10] [Batch 773/1081] [D loss: 0.051011] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.284393] time: 0:57:27.269990\n",
      "(10, 128, 128, 3)\n",
      "0.9341404\n",
      "[Epoch 6/10] [Batch 774/1081] [D loss: 0.051846] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.814765] time: 0:57:27.947607\n",
      "(10, 128, 128, 3)\n",
      "0.89831924\n",
      "[Epoch 6/10] [Batch 775/1081] [D loss: 0.051741] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.407604] time: 0:57:28.609168\n",
      "(10, 128, 128, 3)\n",
      "0.89194655\n",
      "[Epoch 6/10] [Batch 776/1081] [D loss: 0.050705] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.055135] time: 0:57:29.300366\n",
      "(10, 128, 128, 3)\n",
      "0.92406225\n",
      "[Epoch 6/10] [Batch 777/1081] [D loss: 0.052023] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.785205] time: 0:57:29.972752\n",
      "(10, 128, 128, 3)\n",
      "0.841152\n",
      "[Epoch 6/10] [Batch 778/1081] [D loss: 0.051104] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.644032] time: 0:57:30.614409\n",
      "(10, 128, 128, 3)\n",
      "0.9190077\n",
      "[Epoch 6/10] [Batch 779/1081] [D loss: 0.051175] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.068048] time: 0:57:31.278314\n",
      "(10, 128, 128, 3)\n",
      "0.8933279\n",
      "[Epoch 6/10] [Batch 780/1081] [D loss: 0.050728] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.047876] time: 0:57:31.947642\n",
      "(10, 128, 128, 3)\n",
      "0.8769281\n",
      "[Epoch 6/10] [Batch 781/1081] [D loss: 0.050952] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.613593] time: 0:57:32.610915\n",
      "(10, 128, 128, 3)\n",
      "0.8732931\n",
      "[Epoch 6/10] [Batch 782/1081] [D loss: 0.050633] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.374103] time: 0:57:33.266163\n",
      "(10, 128, 128, 3)\n",
      "0.900676\n",
      "[Epoch 6/10] [Batch 783/1081] [D loss: 0.052775] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.813686] time: 0:57:33.935086\n",
      "(10, 128, 128, 3)\n",
      "0.89588195\n",
      "[Epoch 6/10] [Batch 784/1081] [D loss: 0.051233] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.031718] time: 0:57:34.579807\n",
      "(10, 128, 128, 3)\n",
      "0.8723719\n",
      "[Epoch 6/10] [Batch 785/1081] [D loss: 0.051337] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.888345] time: 0:57:35.225426\n",
      "(10, 128, 128, 3)\n",
      "0.95748115\n",
      "[Epoch 6/10] [Batch 786/1081] [D loss: 0.074643] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.797189] time: 0:57:35.868414\n",
      "(10, 128, 128, 3)\n",
      "0.9007159\n",
      "[Epoch 6/10] [Batch 787/1081] [D loss: 0.053414] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.842514] time: 0:57:36.512849\n",
      "(10, 128, 128, 3)\n",
      "0.9471721\n",
      "[Epoch 6/10] [Batch 788/1081] [D loss: 0.052545] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.396193] time: 0:57:37.167986\n",
      "(10, 128, 128, 3)\n",
      "0.9502782\n",
      "[Epoch 6/10] [Batch 789/1081] [D loss: 0.055554] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.677146] time: 0:57:37.813108\n",
      "(10, 128, 128, 3)\n",
      "0.95016307\n",
      "[Epoch 6/10] [Batch 790/1081] [D loss: 0.052120] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.199203] time: 0:57:38.454799\n",
      "(10, 128, 128, 3)\n",
      "0.9086948\n",
      "[Epoch 6/10] [Batch 791/1081] [D loss: 0.051982] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.370019] time: 0:57:39.087131\n",
      "(10, 128, 128, 3)\n",
      "0.9077354\n",
      "[Epoch 6/10] [Batch 792/1081] [D loss: 0.052607] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.089663] time: 0:57:39.717557\n",
      "(10, 128, 128, 3)\n",
      "0.9445827\n",
      "[Epoch 6/10] [Batch 793/1081] [D loss: 0.051856] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.583883] time: 0:57:40.345906\n",
      "(10, 128, 128, 3)\n",
      "0.96103096\n",
      "[Epoch 6/10] [Batch 794/1081] [D loss: 0.053786] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.503812] time: 0:57:40.943176\n",
      "(10, 128, 128, 3)\n",
      "0.9420317\n",
      "[Epoch 6/10] [Batch 795/1081] [D loss: 0.055197] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.252645] time: 0:57:41.573227\n",
      "(10, 128, 128, 3)\n",
      "0.9294341\n",
      "[Epoch 6/10] [Batch 796/1081] [D loss: 0.052790] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.855946] time: 0:57:42.236450\n",
      "(10, 128, 128, 3)\n",
      "0.9125586\n",
      "[Epoch 6/10] [Batch 797/1081] [D loss: 0.057621] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.703958] time: 0:57:42.885094\n",
      "(10, 128, 128, 3)\n",
      "0.92904085\n",
      "[Epoch 6/10] [Batch 798/1081] [D loss: 0.053959] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.668168] time: 0:57:43.538570\n",
      "(10, 128, 128, 3)\n",
      "0.920775\n",
      "[Epoch 6/10] [Batch 799/1081] [D loss: 0.052935] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.928638] time: 0:57:44.209341\n",
      "(10, 128, 128, 3)\n",
      "0.8605778\n",
      "[Epoch 6/10] [Batch 800/1081] [D loss: 0.052636] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.103033] time: 0:57:44.853051\n",
      "(10, 128, 128, 3)\n",
      "0.9302915\n",
      "[Epoch 6/10] [Batch 801/1081] [D loss: 0.053670] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.190742] time: 0:57:45.505276\n",
      "(10, 128, 128, 3)\n",
      "0.8977639\n",
      "[Epoch 6/10] [Batch 802/1081] [D loss: 0.052036] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.343725] time: 0:57:46.174406\n",
      "(10, 128, 128, 3)\n",
      "0.9087457\n",
      "[Epoch 6/10] [Batch 803/1081] [D loss: 0.051653] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.775684] time: 0:57:46.848680\n",
      "(10, 128, 128, 3)\n",
      "0.9036816\n",
      "[Epoch 6/10] [Batch 804/1081] [D loss: 0.051849] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.109729] time: 0:57:47.504137\n",
      "(10, 128, 128, 3)\n",
      "0.9417103\n",
      "[Epoch 6/10] [Batch 805/1081] [D loss: 0.052617] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.230577] time: 0:57:48.161062\n",
      "(10, 128, 128, 3)\n",
      "0.91938806\n",
      "[Epoch 6/10] [Batch 806/1081] [D loss: 0.052177] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.039755] time: 0:57:48.815175\n",
      "(10, 128, 128, 3)\n",
      "0.89237565\n",
      "[Epoch 6/10] [Batch 807/1081] [D loss: 0.051525] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.795554] time: 0:57:49.486105\n",
      "(10, 128, 128, 3)\n",
      "0.8828636\n",
      "[Epoch 6/10] [Batch 808/1081] [D loss: 0.051614] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.689854] time: 0:57:50.153852\n",
      "(10, 128, 128, 3)\n",
      "0.87581843\n",
      "[Epoch 6/10] [Batch 809/1081] [D loss: 0.052008] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.979229] time: 0:57:50.805300\n",
      "(10, 128, 128, 3)\n",
      "0.91323096\n",
      "[Epoch 6/10] [Batch 810/1081] [D loss: 0.051866] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.091307] time: 0:57:51.477274\n",
      "(10, 128, 128, 3)\n",
      "0.92815685\n",
      "[Epoch 6/10] [Batch 811/1081] [D loss: 0.051325] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.483802] time: 0:57:52.123290\n",
      "(10, 128, 128, 3)\n",
      "0.8671944\n",
      "[Epoch 6/10] [Batch 812/1081] [D loss: 0.050995] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.809319] time: 0:57:52.775911\n",
      "(10, 128, 128, 3)\n",
      "0.8581497\n",
      "[Epoch 6/10] [Batch 813/1081] [D loss: 0.051631] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.808136] time: 0:57:53.413727\n",
      "(10, 128, 128, 3)\n",
      "0.87352365\n",
      "[Epoch 6/10] [Batch 814/1081] [D loss: 0.051125] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.313859] time: 0:57:54.073965\n",
      "(10, 128, 128, 3)\n",
      "0.9012003\n",
      "[Epoch 6/10] [Batch 815/1081] [D loss: 0.050925] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.330210] time: 0:57:54.698706\n",
      "(10, 128, 128, 3)\n",
      "0.9070323\n",
      "[Epoch 6/10] [Batch 816/1081] [D loss: 0.051160] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.123644] time: 0:57:55.368002\n",
      "(10, 128, 128, 3)\n",
      "0.96595556\n",
      "[Epoch 6/10] [Batch 817/1081] [D loss: 0.050897] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.183909] time: 0:57:56.021576\n",
      "(10, 128, 128, 3)\n",
      "0.9299832\n",
      "[Epoch 6/10] [Batch 818/1081] [D loss: 0.050815] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.029480] time: 0:57:56.671001\n",
      "(10, 128, 128, 3)\n",
      "0.9780908\n",
      "[Epoch 6/10] [Batch 819/1081] [D loss: 0.050726] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.009197] time: 0:57:57.357957\n",
      "(10, 128, 128, 3)\n",
      "0.92395496\n",
      "[Epoch 6/10] [Batch 820/1081] [D loss: 0.051427] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.422862] time: 0:57:58.017850\n",
      "(10, 128, 128, 3)\n",
      "0.907355\n",
      "[Epoch 6/10] [Batch 821/1081] [D loss: 0.050389] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.488766] time: 0:57:58.720837\n",
      "(10, 128, 128, 3)\n",
      "0.9488519\n",
      "[Epoch 6/10] [Batch 822/1081] [D loss: 0.050412] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.236145] time: 0:57:59.357996\n",
      "(10, 128, 128, 3)\n",
      "0.88263005\n",
      "[Epoch 6/10] [Batch 823/1081] [D loss: 0.050866] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.302979] time: 0:57:59.983945\n",
      "(10, 128, 128, 3)\n",
      "0.907747\n",
      "[Epoch 6/10] [Batch 824/1081] [D loss: 0.050607] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.659830] time: 0:58:00.635841\n",
      "(10, 128, 128, 3)\n",
      "0.90932924\n",
      "[Epoch 6/10] [Batch 825/1081] [D loss: 0.050312] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.864485] time: 0:58:01.299700\n",
      "(10, 128, 128, 3)\n",
      "0.95132893\n",
      "[Epoch 6/10] [Batch 826/1081] [D loss: 0.050726] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.801515] time: 0:58:01.942366\n",
      "(10, 128, 128, 3)\n",
      "0.8797493\n",
      "[Epoch 6/10] [Batch 827/1081] [D loss: 0.050884] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.503012] time: 0:58:02.609811\n",
      "(10, 128, 128, 3)\n",
      "0.87464327\n",
      "[Epoch 6/10] [Batch 828/1081] [D loss: 0.050293] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.786190] time: 0:58:03.261141\n",
      "(10, 128, 128, 3)\n",
      "0.8618159\n",
      "[Epoch 6/10] [Batch 829/1081] [D loss: 0.050338] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.719734] time: 0:58:03.912734\n",
      "(10, 128, 128, 3)\n",
      "0.90397614\n",
      "[Epoch 6/10] [Batch 830/1081] [D loss: 0.050141] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.391823] time: 0:58:04.578584\n",
      "(10, 128, 128, 3)\n",
      "0.8960247\n",
      "[Epoch 6/10] [Batch 831/1081] [D loss: 0.050289] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.546566] time: 0:58:05.242861\n",
      "(10, 128, 128, 3)\n",
      "0.94110626\n",
      "[Epoch 6/10] [Batch 832/1081] [D loss: 0.050473] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.630731] time: 0:58:05.912029\n",
      "(10, 128, 128, 3)\n",
      "0.8900163\n",
      "[Epoch 6/10] [Batch 833/1081] [D loss: 0.053793] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.428788] time: 0:58:06.570094\n",
      "(10, 128, 128, 3)\n",
      "0.9252798\n",
      "[Epoch 6/10] [Batch 834/1081] [D loss: 0.051735] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.589471] time: 0:58:07.260930\n",
      "(10, 128, 128, 3)\n",
      "0.97635245\n",
      "[Epoch 6/10] [Batch 835/1081] [D loss: 0.052507] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.559937] time: 0:58:07.939730\n",
      "(10, 128, 128, 3)\n",
      "0.8980949\n",
      "[Epoch 6/10] [Batch 836/1081] [D loss: 0.049909] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.435600] time: 0:58:08.571287\n",
      "(10, 128, 128, 3)\n",
      "0.92650557\n",
      "[Epoch 6/10] [Batch 837/1081] [D loss: 0.050112] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.332048] time: 0:58:09.199411\n",
      "(10, 128, 128, 3)\n",
      "0.8941434\n",
      "[Epoch 6/10] [Batch 838/1081] [D loss: 0.049850] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.724346] time: 0:58:09.887723\n",
      "(10, 128, 128, 3)\n",
      "0.905657\n",
      "[Epoch 6/10] [Batch 839/1081] [D loss: 0.051063] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.205585] time: 0:58:10.586619\n",
      "(10, 128, 128, 3)\n",
      "0.9420388\n",
      "[Epoch 6/10] [Batch 840/1081] [D loss: 0.050215] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.819237] time: 0:58:11.254010\n",
      "(10, 128, 128, 3)\n",
      "0.9148163\n",
      "[Epoch 6/10] [Batch 841/1081] [D loss: 0.049743] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.649720] time: 0:58:11.914153\n",
      "(10, 128, 128, 3)\n",
      "0.88416\n",
      "[Epoch 6/10] [Batch 842/1081] [D loss: 0.050726] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.009502] time: 0:58:12.579768\n",
      "(10, 128, 128, 3)\n",
      "0.945509\n",
      "[Epoch 6/10] [Batch 843/1081] [D loss: 0.050076] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.556294] time: 0:58:13.243773\n",
      "(10, 128, 128, 3)\n",
      "0.9019146\n",
      "[Epoch 6/10] [Batch 844/1081] [D loss: 0.050221] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.247860] time: 0:58:13.893063\n",
      "(10, 128, 128, 3)\n",
      "0.93116504\n",
      "[Epoch 6/10] [Batch 845/1081] [D loss: 0.049661] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.468771] time: 0:58:14.548190\n",
      "(10, 128, 128, 3)\n",
      "0.9204518\n",
      "[Epoch 6/10] [Batch 846/1081] [D loss: 0.050454] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.878388] time: 0:58:15.194088\n",
      "(10, 128, 128, 3)\n",
      "0.9316953\n",
      "[Epoch 6/10] [Batch 847/1081] [D loss: 0.050151] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.529389] time: 0:58:15.866636\n",
      "(10, 128, 128, 3)\n",
      "0.9253199\n",
      "[Epoch 6/10] [Batch 848/1081] [D loss: 0.050492] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.594575] time: 0:58:16.488956\n",
      "(10, 128, 128, 3)\n",
      "0.94373417\n",
      "[Epoch 6/10] [Batch 849/1081] [D loss: 0.049299] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.058335] time: 0:58:17.102277\n",
      "(10, 128, 128, 3)\n",
      "0.94368076\n",
      "[Epoch 6/10] [Batch 850/1081] [D loss: 0.049943] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.883185] time: 0:58:17.766493\n",
      "(10, 128, 128, 3)\n",
      "0.87877375\n",
      "[Epoch 6/10] [Batch 851/1081] [D loss: 0.049467] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.360051] time: 0:58:18.381507\n",
      "(10, 128, 128, 3)\n",
      "0.93559647\n",
      "[Epoch 6/10] [Batch 852/1081] [D loss: 0.049847] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.150094] time: 0:58:19.040716\n",
      "(10, 128, 128, 3)\n",
      "0.8981881\n",
      "[Epoch 6/10] [Batch 853/1081] [D loss: 0.049663] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.827435] time: 0:58:19.707933\n",
      "(10, 128, 128, 3)\n",
      "0.9112374\n",
      "[Epoch 6/10] [Batch 854/1081] [D loss: 0.052560] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.867373] time: 0:58:20.363630\n",
      "(10, 128, 128, 3)\n",
      "0.90932816\n",
      "[Epoch 6/10] [Batch 855/1081] [D loss: 0.049150] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.760214] time: 0:58:21.026257\n",
      "(10, 128, 128, 3)\n",
      "0.9336445\n",
      "[Epoch 6/10] [Batch 856/1081] [D loss: 0.049318] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.273548] time: 0:58:21.697001\n",
      "(10, 128, 128, 3)\n",
      "0.9206012\n",
      "[Epoch 6/10] [Batch 857/1081] [D loss: 0.049686] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.936126] time: 0:58:22.343714\n",
      "(10, 128, 128, 3)\n",
      "0.8705589\n",
      "[Epoch 6/10] [Batch 858/1081] [D loss: 0.050254] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.370979] time: 0:58:22.977877\n",
      "(10, 128, 128, 3)\n",
      "0.9366885\n",
      "[Epoch 6/10] [Batch 859/1081] [D loss: 0.049695] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.371840] time: 0:58:23.644144\n",
      "(10, 128, 128, 3)\n",
      "0.9261441\n",
      "[Epoch 6/10] [Batch 860/1081] [D loss: 0.049354] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.632834] time: 0:58:24.310189\n",
      "(10, 128, 128, 3)\n",
      "0.9168041\n",
      "[Epoch 6/10] [Batch 861/1081] [D loss: 0.049176] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.956794] time: 0:58:24.949086\n",
      "(10, 128, 128, 3)\n",
      "0.90863293\n",
      "[Epoch 6/10] [Batch 862/1081] [D loss: 0.049831] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.785143] time: 0:58:25.597676\n",
      "(10, 128, 128, 3)\n",
      "0.8815029\n",
      "[Epoch 6/10] [Batch 863/1081] [D loss: 0.050148] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.162858] time: 0:58:26.255235\n",
      "(10, 128, 128, 3)\n",
      "0.8934379\n",
      "[Epoch 6/10] [Batch 864/1081] [D loss: 0.050507] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.698298] time: 0:58:26.890921\n",
      "(10, 128, 128, 3)\n",
      "0.9035757\n",
      "[Epoch 6/10] [Batch 865/1081] [D loss: 0.052128] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.125956] time: 0:58:27.524959\n",
      "(10, 128, 128, 3)\n",
      "0.8853952\n",
      "[Epoch 6/10] [Batch 866/1081] [D loss: 0.051170] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.889284] time: 0:58:28.170582\n",
      "(10, 128, 128, 3)\n",
      "0.90476805\n",
      "[Epoch 6/10] [Batch 867/1081] [D loss: 0.051623] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.367347] time: 0:58:28.821962\n",
      "(10, 128, 128, 3)\n",
      "0.89053375\n",
      "[Epoch 6/10] [Batch 868/1081] [D loss: 0.049638] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.807793] time: 0:58:29.480478\n",
      "(10, 128, 128, 3)\n",
      "0.93376255\n",
      "[Epoch 6/10] [Batch 869/1081] [D loss: 0.049338] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.875905] time: 0:58:30.086691\n",
      "(10, 128, 128, 3)\n",
      "0.8798111\n",
      "[Epoch 6/10] [Batch 870/1081] [D loss: 0.050341] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.618030] time: 0:58:30.733997\n",
      "(10, 128, 128, 3)\n",
      "0.9259669\n",
      "[Epoch 6/10] [Batch 871/1081] [D loss: 0.049035] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.323901] time: 0:58:31.367782\n",
      "(10, 128, 128, 3)\n",
      "0.93154985\n",
      "[Epoch 6/10] [Batch 872/1081] [D loss: 0.050272] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.312089] time: 0:58:32.004451\n",
      "(10, 128, 128, 3)\n",
      "0.88323665\n",
      "[Epoch 6/10] [Batch 873/1081] [D loss: 0.049757] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.247540] time: 0:58:32.643081\n",
      "(10, 128, 128, 3)\n",
      "0.8870972\n",
      "[Epoch 6/10] [Batch 874/1081] [D loss: 0.048665] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.213427] time: 0:58:33.288671\n",
      "(10, 128, 128, 3)\n",
      "0.8968455\n",
      "[Epoch 6/10] [Batch 875/1081] [D loss: 0.048821] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.255079] time: 0:58:33.940612\n",
      "(10, 128, 128, 3)\n",
      "0.89257175\n",
      "[Epoch 6/10] [Batch 876/1081] [D loss: 0.049889] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.849298] time: 0:58:34.560753\n",
      "(10, 128, 128, 3)\n",
      "0.9001689\n",
      "[Epoch 6/10] [Batch 877/1081] [D loss: 0.049446] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.689681] time: 0:58:35.252673\n",
      "(10, 128, 128, 3)\n",
      "0.95977026\n",
      "[Epoch 6/10] [Batch 878/1081] [D loss: 0.049049] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.499591] time: 0:58:35.914525\n",
      "(10, 128, 128, 3)\n",
      "0.88464326\n",
      "[Epoch 6/10] [Batch 879/1081] [D loss: 0.048817] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.558571] time: 0:58:36.576252\n",
      "(10, 128, 128, 3)\n",
      "0.9085894\n",
      "[Epoch 6/10] [Batch 880/1081] [D loss: 0.049414] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.945061] time: 0:58:37.220366\n",
      "(10, 128, 128, 3)\n",
      "0.9108406\n",
      "[Epoch 6/10] [Batch 881/1081] [D loss: 0.048404] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.189929] time: 0:58:37.853643\n",
      "(10, 128, 128, 3)\n",
      "0.98236424\n",
      "[Epoch 6/10] [Batch 882/1081] [D loss: 0.048984] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.743778] time: 0:58:38.529040\n",
      "(10, 128, 128, 3)\n",
      "0.94011277\n",
      "[Epoch 6/10] [Batch 883/1081] [D loss: 0.051959] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.024878] time: 0:58:39.170417\n",
      "(10, 128, 128, 3)\n",
      "0.92076796\n",
      "[Epoch 6/10] [Batch 884/1081] [D loss: 0.049881] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.390258] time: 0:58:39.787832\n",
      "(10, 128, 128, 3)\n",
      "0.9570939\n",
      "[Epoch 6/10] [Batch 885/1081] [D loss: 0.048549] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.278993] time: 0:58:40.452643\n",
      "(10, 128, 128, 3)\n",
      "0.92958355\n",
      "[Epoch 6/10] [Batch 886/1081] [D loss: 0.049161] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.204879] time: 0:58:41.117605\n",
      "(10, 128, 128, 3)\n",
      "0.9400093\n",
      "[Epoch 6/10] [Batch 887/1081] [D loss: 0.049438] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.261741] time: 0:58:41.786590\n",
      "(10, 128, 128, 3)\n",
      "0.87720555\n",
      "[Epoch 6/10] [Batch 888/1081] [D loss: 0.048821] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.814229] time: 0:58:42.451656\n",
      "(10, 128, 128, 3)\n",
      "0.8916733\n",
      "[Epoch 6/10] [Batch 889/1081] [D loss: 0.049194] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.230018] time: 0:58:43.125449\n",
      "(10, 128, 128, 3)\n",
      "0.9089635\n",
      "[Epoch 6/10] [Batch 890/1081] [D loss: 0.049344] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.577571] time: 0:58:43.787397\n",
      "(10, 128, 128, 3)\n",
      "0.914869\n",
      "[Epoch 6/10] [Batch 891/1081] [D loss: 0.049838] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.816411] time: 0:58:44.436434\n",
      "(10, 128, 128, 3)\n",
      "0.9299979\n",
      "[Epoch 6/10] [Batch 892/1081] [D loss: 0.048824] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.838149] time: 0:58:45.100965\n",
      "(10, 128, 128, 3)\n",
      "0.9001363\n",
      "[Epoch 6/10] [Batch 893/1081] [D loss: 0.048579] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.838161] time: 0:58:45.756720\n",
      "(10, 128, 128, 3)\n",
      "0.93031293\n",
      "[Epoch 6/10] [Batch 894/1081] [D loss: 0.048868] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.866504] time: 0:58:46.406919\n",
      "(10, 128, 128, 3)\n",
      "0.8941348\n",
      "[Epoch 6/10] [Batch 895/1081] [D loss: 0.049226] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.439319] time: 0:58:47.076943\n",
      "(10, 128, 128, 3)\n",
      "0.9321415\n",
      "[Epoch 6/10] [Batch 896/1081] [D loss: 0.048400] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.006425] time: 0:58:47.743924\n",
      "(10, 128, 128, 3)\n",
      "0.9108717\n",
      "[Epoch 6/10] [Batch 897/1081] [D loss: 0.048537] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.199335] time: 0:58:48.391247\n",
      "(10, 128, 128, 3)\n",
      "0.85690117\n",
      "[Epoch 6/10] [Batch 898/1081] [D loss: 0.049039] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.042119] time: 0:58:49.054012\n",
      "(10, 128, 128, 3)\n",
      "0.92371374\n",
      "[Epoch 6/10] [Batch 899/1081] [D loss: 0.048645] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.727128] time: 0:58:49.714269\n",
      "(10, 128, 128, 3)\n",
      "0.9220257\n",
      "[Epoch 6/10] [Batch 900/1081] [D loss: 0.048561] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.589293] time: 0:58:50.322014\n",
      "(10, 128, 128, 3)\n",
      "0.8872486\n",
      "[Epoch 6/10] [Batch 901/1081] [D loss: 0.048436] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.963964] time: 0:58:50.809045\n",
      "(10, 128, 128, 3)\n",
      "0.96385604\n",
      "[Epoch 6/10] [Batch 902/1081] [D loss: 0.049040] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.546450] time: 0:58:51.299770\n",
      "(10, 128, 128, 3)\n",
      "0.92702514\n",
      "[Epoch 6/10] [Batch 903/1081] [D loss: 0.048152] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.312258] time: 0:58:51.771960\n",
      "(10, 128, 128, 3)\n",
      "0.9056792\n",
      "[Epoch 6/10] [Batch 904/1081] [D loss: 0.048001] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.853937] time: 0:58:52.272537\n",
      "(10, 128, 128, 3)\n",
      "0.9237264\n",
      "[Epoch 6/10] [Batch 905/1081] [D loss: 0.048727] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.497102] time: 0:58:52.759703\n",
      "(10, 128, 128, 3)\n",
      "0.94702506\n",
      "[Epoch 6/10] [Batch 906/1081] [D loss: 0.048009] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.944824] time: 0:58:53.242525\n",
      "(10, 128, 128, 3)\n",
      "0.91248846\n",
      "[Epoch 6/10] [Batch 907/1081] [D loss: 0.048182] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.600574] time: 0:58:53.720219\n",
      "(10, 128, 128, 3)\n",
      "0.90772945\n",
      "[Epoch 6/10] [Batch 908/1081] [D loss: 0.048831] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.733986] time: 0:58:54.179425\n",
      "(10, 128, 128, 3)\n",
      "0.90472585\n",
      "[Epoch 6/10] [Batch 909/1081] [D loss: 0.048236] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.749871] time: 0:58:54.624519\n",
      "(10, 128, 128, 3)\n",
      "0.88817006\n",
      "[Epoch 6/10] [Batch 910/1081] [D loss: 0.048069] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.271867] time: 0:58:55.072957\n",
      "(10, 128, 128, 3)\n",
      "0.8840935\n",
      "[Epoch 6/10] [Batch 911/1081] [D loss: 0.048170] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.985669] time: 0:58:55.533708\n",
      "(10, 128, 128, 3)\n",
      "0.8751562\n",
      "[Epoch 6/10] [Batch 912/1081] [D loss: 0.048104] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.598278] time: 0:58:55.984606\n",
      "(10, 128, 128, 3)\n",
      "0.95249707\n",
      "[Epoch 6/10] [Batch 913/1081] [D loss: 0.048689] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.304147] time: 0:58:56.468096\n",
      "(10, 128, 128, 3)\n",
      "0.8170531\n",
      "[Epoch 6/10] [Batch 914/1081] [D loss: 0.048817] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.816652] time: 0:58:56.958596\n",
      "(10, 128, 128, 3)\n",
      "0.90692395\n",
      "[Epoch 6/10] [Batch 915/1081] [D loss: 0.048008] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.911342] time: 0:58:57.398440\n",
      "(10, 128, 128, 3)\n",
      "0.89543724\n",
      "[Epoch 6/10] [Batch 916/1081] [D loss: 0.048788] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.791384] time: 0:58:57.861971\n",
      "(10, 128, 128, 3)\n",
      "0.8931186\n",
      "[Epoch 6/10] [Batch 917/1081] [D loss: 0.048859] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.918983] time: 0:58:58.337345\n",
      "(10, 128, 128, 3)\n",
      "0.9106664\n",
      "[Epoch 6/10] [Batch 918/1081] [D loss: 0.049341] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.642091] time: 0:58:58.800555\n",
      "(10, 128, 128, 3)\n",
      "0.9161369\n",
      "[Epoch 6/10] [Batch 919/1081] [D loss: 0.063252] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.065148] time: 0:58:59.290852\n",
      "(10, 128, 128, 3)\n",
      "0.9104325\n",
      "[Epoch 6/10] [Batch 920/1081] [D loss: 0.055498] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.275975] time: 0:58:59.801246\n",
      "(10, 128, 128, 3)\n",
      "0.89295167\n",
      "[Epoch 6/10] [Batch 921/1081] [D loss: 0.050132] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.699898] time: 0:59:00.291104\n",
      "(10, 128, 128, 3)\n",
      "0.9233901\n",
      "[Epoch 6/10] [Batch 922/1081] [D loss: 0.054514] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.393016] time: 0:59:00.783656\n",
      "(10, 128, 128, 3)\n",
      "0.89766735\n",
      "[Epoch 6/10] [Batch 923/1081] [D loss: 0.056220] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.411699] time: 0:59:01.241709\n",
      "(10, 128, 128, 3)\n",
      "0.921802\n",
      "[Epoch 6/10] [Batch 924/1081] [D loss: 0.048716] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.070447] time: 0:59:01.700600\n",
      "(10, 128, 128, 3)\n",
      "0.9303761\n",
      "[Epoch 6/10] [Batch 925/1081] [D loss: 0.049987] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.240132] time: 0:59:02.160052\n",
      "(10, 128, 128, 3)\n",
      "0.9064823\n",
      "[Epoch 6/10] [Batch 926/1081] [D loss: 0.050477] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.533662] time: 0:59:02.615939\n",
      "(10, 128, 128, 3)\n",
      "0.9253802\n",
      "[Epoch 6/10] [Batch 927/1081] [D loss: 0.048243] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.021938] time: 0:59:03.105549\n",
      "(10, 128, 128, 3)\n",
      "0.9137991\n",
      "[Epoch 6/10] [Batch 928/1081] [D loss: 0.048415] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.308898] time: 0:59:03.574775\n",
      "(10, 128, 128, 3)\n",
      "0.8993737\n",
      "[Epoch 6/10] [Batch 929/1081] [D loss: 0.050482] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.061306] time: 0:59:04.021585\n",
      "(10, 128, 128, 3)\n",
      "0.86804897\n",
      "[Epoch 6/10] [Batch 930/1081] [D loss: 0.056120] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.865005] time: 0:59:04.477749\n",
      "(10, 128, 128, 3)\n",
      "0.85367507\n",
      "[Epoch 6/10] [Batch 931/1081] [D loss: 0.051678] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.778575] time: 0:59:04.928770\n",
      "(10, 128, 128, 3)\n",
      "0.9514501\n",
      "[Epoch 6/10] [Batch 932/1081] [D loss: 0.048207] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.778329] time: 0:59:05.376400\n",
      "(10, 128, 128, 3)\n",
      "0.9123028\n",
      "[Epoch 6/10] [Batch 933/1081] [D loss: 0.048460] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.666606] time: 0:59:05.837062\n",
      "(10, 128, 128, 3)\n",
      "0.8728252\n",
      "[Epoch 6/10] [Batch 934/1081] [D loss: 0.047838] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.411913] time: 0:59:06.334484\n",
      "(10, 128, 128, 3)\n",
      "0.86181957\n",
      "[Epoch 6/10] [Batch 935/1081] [D loss: 0.048190] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.134579] time: 0:59:06.810405\n",
      "(10, 128, 128, 3)\n",
      "0.9125648\n",
      "[Epoch 6/10] [Batch 936/1081] [D loss: 0.048325] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.094394] time: 0:59:07.272292\n",
      "(10, 128, 128, 3)\n",
      "0.92353964\n",
      "[Epoch 6/10] [Batch 937/1081] [D loss: 0.048343] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.782279] time: 0:59:07.754237\n",
      "(10, 128, 128, 3)\n",
      "0.91000813\n",
      "[Epoch 6/10] [Batch 938/1081] [D loss: 0.049163] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.759413] time: 0:59:08.353565\n",
      "(10, 128, 128, 3)\n",
      "0.8482606\n",
      "[Epoch 6/10] [Batch 939/1081] [D loss: 0.049331] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.484538] time: 0:59:08.971487\n",
      "(10, 128, 128, 3)\n",
      "0.87059516\n",
      "[Epoch 6/10] [Batch 940/1081] [D loss: 0.050230] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.865597] time: 0:59:09.629887\n",
      "(10, 128, 128, 3)\n",
      "0.89383966\n",
      "[Epoch 6/10] [Batch 941/1081] [D loss: 0.047612] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.219033] time: 0:59:10.281053\n",
      "(10, 128, 128, 3)\n",
      "0.9183013\n",
      "[Epoch 6/10] [Batch 942/1081] [D loss: 0.048126] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.524185] time: 0:59:10.938376\n",
      "(10, 128, 128, 3)\n",
      "0.9756868\n",
      "[Epoch 6/10] [Batch 943/1081] [D loss: 0.049567] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.747814] time: 0:59:11.595955\n",
      "(10, 128, 128, 3)\n",
      "0.9685858\n",
      "[Epoch 6/10] [Batch 944/1081] [D loss: 0.048882] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.240472] time: 0:59:12.238309\n",
      "(10, 128, 128, 3)\n",
      "0.9237232\n",
      "[Epoch 6/10] [Batch 945/1081] [D loss: 0.047682] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.200018] time: 0:59:12.873560\n",
      "(10, 128, 128, 3)\n",
      "0.93358755\n",
      "[Epoch 6/10] [Batch 946/1081] [D loss: 0.047615] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.985339] time: 0:59:13.478301\n",
      "(10, 128, 128, 3)\n",
      "0.8818627\n",
      "[Epoch 6/10] [Batch 947/1081] [D loss: 0.048278] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.628627] time: 0:59:14.120477\n",
      "(10, 128, 128, 3)\n",
      "0.93594\n",
      "[Epoch 6/10] [Batch 948/1081] [D loss: 0.049223] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.572917] time: 0:59:14.730704\n",
      "(10, 128, 128, 3)\n",
      "0.91551304\n",
      "[Epoch 6/10] [Batch 949/1081] [D loss: 0.048232] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.577794] time: 0:59:15.345311\n",
      "(10, 128, 128, 3)\n",
      "0.8835814\n",
      "[Epoch 6/10] [Batch 950/1081] [D loss: 0.047453] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.290893] time: 0:59:15.993794\n",
      "(10, 128, 128, 3)\n",
      "0.9289448\n",
      "[Epoch 6/10] [Batch 951/1081] [D loss: 0.047630] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.211918] time: 0:59:16.641438\n",
      "(10, 128, 128, 3)\n",
      "0.8844755\n",
      "[Epoch 6/10] [Batch 952/1081] [D loss: 0.052925] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.439114] time: 0:59:17.288265\n",
      "(10, 128, 128, 3)\n",
      "0.9208915\n",
      "[Epoch 6/10] [Batch 953/1081] [D loss: 0.047723] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.167391] time: 0:59:17.951014\n",
      "(10, 128, 128, 3)\n",
      "0.90824765\n",
      "[Epoch 6/10] [Batch 954/1081] [D loss: 0.047863] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.093575] time: 0:59:18.613150\n",
      "(10, 128, 128, 3)\n",
      "0.9111598\n",
      "[Epoch 6/10] [Batch 955/1081] [D loss: 0.047495] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.246861] time: 0:59:19.209537\n",
      "(10, 128, 128, 3)\n",
      "0.91181844\n",
      "[Epoch 6/10] [Batch 956/1081] [D loss: 0.048365] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.001337] time: 0:59:19.851804\n",
      "(10, 128, 128, 3)\n",
      "0.92800784\n",
      "[Epoch 6/10] [Batch 957/1081] [D loss: 0.047555] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.943864] time: 0:59:20.473354\n",
      "(10, 128, 128, 3)\n",
      "0.9314625\n",
      "[Epoch 6/10] [Batch 958/1081] [D loss: 0.049352] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.760609] time: 0:59:21.144493\n",
      "(10, 128, 128, 3)\n",
      "0.9006074\n",
      "[Epoch 6/10] [Batch 959/1081] [D loss: 0.048202] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.664221] time: 0:59:21.804062\n",
      "(10, 128, 128, 3)\n",
      "0.8904194\n",
      "[Epoch 6/10] [Batch 960/1081] [D loss: 0.048187] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.586781] time: 0:59:22.462377\n",
      "(10, 128, 128, 3)\n",
      "0.92123276\n",
      "[Epoch 6/10] [Batch 961/1081] [D loss: 0.050189] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.226797] time: 0:59:23.093921\n",
      "(10, 128, 128, 3)\n",
      "0.92905325\n",
      "[Epoch 6/10] [Batch 962/1081] [D loss: 0.051221] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.316683] time: 0:59:23.709635\n",
      "(10, 128, 128, 3)\n",
      "0.8768119\n",
      "[Epoch 6/10] [Batch 963/1081] [D loss: 0.048441] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.661650] time: 0:59:24.338263\n",
      "(10, 128, 128, 3)\n",
      "0.97673416\n",
      "[Epoch 6/10] [Batch 964/1081] [D loss: 0.599764] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 1818.270264] time: 0:59:24.979792\n",
      "(10, 128, 128, 3)\n",
      "0.9905192\n",
      "[Epoch 6/10] [Batch 965/1081] [D loss: 0.250310] [D acc: 0.75 (1.00 real, 0.50 fake)] [G loss: 138.242203] time: 0:59:25.640335\n",
      "(10, 128, 128, 3)\n",
      "0.99772024\n",
      "[Epoch 6/10] [Batch 966/1081] [D loss: 0.342543] [D acc: 0.85 (0.90 real, 0.80 fake)] [G loss: 9.713683] time: 0:59:26.304387\n",
      "(10, 128, 128, 3)\n",
      "0.43072367\n",
      "[Epoch 6/10] [Batch 967/1081] [D loss: 0.278298] [D acc: 0.55 (0.20 real, 0.90 fake)] [G loss: 11.593100] time: 0:59:26.960992\n",
      "(10, 128, 128, 3)\n",
      "0.33826113\n",
      "[Epoch 6/10] [Batch 968/1081] [D loss: 0.254191] [D acc: 0.75 (0.90 real, 0.60 fake)] [G loss: 12.029940] time: 0:59:27.637125\n",
      "(10, 128, 128, 3)\n",
      "0.40674654\n",
      "[Epoch 6/10] [Batch 969/1081] [D loss: 0.289453] [D acc: 0.70 (0.70 real, 0.70 fake)] [G loss: 10.273464] time: 0:59:28.288662\n",
      "(10, 128, 128, 3)\n",
      "0.44759664\n",
      "[Epoch 6/10] [Batch 970/1081] [D loss: 0.253163] [D acc: 0.75 (0.50 real, 1.00 fake)] [G loss: 9.874537] time: 0:59:28.931237\n",
      "(10, 128, 128, 3)\n",
      "0.44419813\n",
      "[Epoch 6/10] [Batch 971/1081] [D loss: 0.442579] [D acc: 0.15 (0.20 real, 0.10 fake)] [G loss: 10.018230] time: 0:59:29.598668\n",
      "(10, 128, 128, 3)\n",
      "0.7268904\n",
      "[Epoch 6/10] [Batch 972/1081] [D loss: 0.427358] [D acc: 0.30 (0.60 real, 0.00 fake)] [G loss: 7.889161] time: 0:59:30.246567\n",
      "(10, 128, 128, 3)\n",
      "0.7886961\n",
      "[Epoch 6/10] [Batch 973/1081] [D loss: 0.316341] [D acc: 0.45 (0.40 real, 0.50 fake)] [G loss: 9.073636] time: 0:59:30.886472\n",
      "(10, 128, 128, 3)\n",
      "0.6833458\n",
      "[Epoch 6/10] [Batch 974/1081] [D loss: 0.284500] [D acc: 0.75 (0.90 real, 0.60 fake)] [G loss: 8.800009] time: 0:59:31.575867\n",
      "(10, 128, 128, 3)\n",
      "0.8682513\n",
      "[Epoch 6/10] [Batch 975/1081] [D loss: 0.232105] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.682683] time: 0:59:32.280159\n",
      "(10, 128, 128, 3)\n",
      "0.8582129\n",
      "[Epoch 6/10] [Batch 976/1081] [D loss: 0.299516] [D acc: 0.55 (0.20 real, 0.90 fake)] [G loss: 6.429378] time: 0:59:32.957711\n",
      "(10, 128, 128, 3)\n",
      "0.8657196\n",
      "[Epoch 6/10] [Batch 977/1081] [D loss: 0.162965] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.789201] time: 0:59:33.658020\n",
      "(10, 128, 128, 3)\n",
      "0.8990178\n",
      "[Epoch 6/10] [Batch 978/1081] [D loss: 0.181015] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.853650] time: 0:59:34.322646\n",
      "(10, 128, 128, 3)\n",
      "0.9231755\n",
      "[Epoch 6/10] [Batch 979/1081] [D loss: 0.506206] [D acc: 0.10 (0.00 real, 0.20 fake)] [G loss: 6.152663] time: 0:59:34.934612\n",
      "(10, 128, 128, 3)\n",
      "0.9119111\n",
      "[Epoch 6/10] [Batch 980/1081] [D loss: 0.448822] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 7.555948] time: 0:59:35.580484\n",
      "(10, 128, 128, 3)\n",
      "0.87875026\n",
      "[Epoch 6/10] [Batch 981/1081] [D loss: 0.166974] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.514046] time: 0:59:36.341141\n",
      "(10, 128, 128, 3)\n",
      "0.9234071\n",
      "[Epoch 6/10] [Batch 982/1081] [D loss: 0.343328] [D acc: 0.30 (0.40 real, 0.20 fake)] [G loss: 6.939967] time: 0:59:36.969000\n",
      "(10, 128, 128, 3)\n",
      "0.88574296\n",
      "[Epoch 6/10] [Batch 983/1081] [D loss: 0.359455] [D acc: 0.55 (0.10 real, 1.00 fake)] [G loss: 7.122925] time: 0:59:37.550388\n",
      "(10, 128, 128, 3)\n",
      "0.8791747\n",
      "[Epoch 6/10] [Batch 984/1081] [D loss: 0.685398] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 7.734469] time: 0:59:38.167093\n",
      "(10, 128, 128, 3)\n",
      "0.8646519\n",
      "[Epoch 6/10] [Batch 985/1081] [D loss: 0.325352] [D acc: 0.45 (0.60 real, 0.30 fake)] [G loss: 8.176057] time: 0:59:38.864381\n",
      "(10, 128, 128, 3)\n",
      "0.92289335\n",
      "[Epoch 6/10] [Batch 986/1081] [D loss: 0.278749] [D acc: 0.60 (1.00 real, 0.20 fake)] [G loss: 6.027117] time: 0:59:39.585671\n",
      "(10, 128, 128, 3)\n",
      "0.89476675\n",
      "[Epoch 6/10] [Batch 987/1081] [D loss: 0.282023] [D acc: 0.55 (1.00 real, 0.10 fake)] [G loss: 6.379732] time: 0:59:40.210582\n",
      "(10, 128, 128, 3)\n",
      "0.96132785\n",
      "[Epoch 6/10] [Batch 988/1081] [D loss: 0.355914] [D acc: 0.70 (0.80 real, 0.60 fake)] [G loss: 6.234626] time: 0:59:40.855975\n",
      "(10, 128, 128, 3)\n",
      "0.9243954\n",
      "[Epoch 6/10] [Batch 989/1081] [D loss: 0.402924] [D acc: 0.40 (0.80 real, 0.00 fake)] [G loss: 6.049632] time: 0:59:41.503569\n",
      "(10, 128, 128, 3)\n",
      "0.9159531\n",
      "[Epoch 6/10] [Batch 990/1081] [D loss: 0.383036] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 6.454833] time: 0:59:42.128316\n",
      "(10, 128, 128, 3)\n",
      "0.9080247\n",
      "[Epoch 6/10] [Batch 991/1081] [D loss: 0.269356] [D acc: 0.90 (0.90 real, 0.90 fake)] [G loss: 6.327398] time: 0:59:42.753346\n",
      "(10, 128, 128, 3)\n",
      "0.9278975\n",
      "[Epoch 6/10] [Batch 992/1081] [D loss: 0.567837] [D acc: 0.20 (0.00 real, 0.40 fake)] [G loss: 5.719131] time: 0:59:43.433054\n",
      "(10, 128, 128, 3)\n",
      "0.90794915\n",
      "[Epoch 6/10] [Batch 993/1081] [D loss: 0.235133] [D acc: 0.90 (1.00 real, 0.80 fake)] [G loss: 5.288876] time: 0:59:44.122549\n",
      "(10, 128, 128, 3)\n",
      "0.9058044\n",
      "[Epoch 6/10] [Batch 994/1081] [D loss: 0.329208] [D acc: 0.65 (0.60 real, 0.70 fake)] [G loss: 6.025281] time: 0:59:44.774233\n",
      "(10, 128, 128, 3)\n",
      "0.9442274\n",
      "[Epoch 6/10] [Batch 995/1081] [D loss: 0.269238] [D acc: 0.80 (0.90 real, 0.70 fake)] [G loss: 6.138364] time: 0:59:45.455886\n",
      "(10, 128, 128, 3)\n",
      "0.8046023\n",
      "[Epoch 6/10] [Batch 996/1081] [D loss: 0.188546] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.395534] time: 0:59:46.112316\n",
      "(10, 128, 128, 3)\n",
      "0.9445184\n",
      "[Epoch 6/10] [Batch 997/1081] [D loss: 0.246040] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 6.836421] time: 0:59:46.759487\n",
      "(10, 128, 128, 3)\n",
      "0.92135555\n",
      "[Epoch 6/10] [Batch 998/1081] [D loss: 0.349939] [D acc: 0.50 (0.10 real, 0.90 fake)] [G loss: 7.000607] time: 0:59:47.421001\n",
      "(10, 128, 128, 3)\n",
      "0.92333025\n",
      "[Epoch 6/10] [Batch 999/1081] [D loss: 0.199561] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.575583] time: 0:59:48.071995\n",
      "(10, 128, 128, 3)\n",
      "0.94133264\n",
      "[Epoch 6/10] [Batch 1000/1081] [D loss: 0.202849] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.271314] time: 0:59:48.740111\n",
      "(10, 128, 128, 3)\n",
      "0.8866465\n",
      "[Epoch 6/10] [Batch 1001/1081] [D loss: 0.358345] [D acc: 0.40 (0.00 real, 0.80 fake)] [G loss: 5.932213] time: 0:59:49.370165\n",
      "(10, 128, 128, 3)\n",
      "0.9094892\n",
      "[Epoch 6/10] [Batch 1002/1081] [D loss: 0.298466] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 5.848344] time: 0:59:50.046513\n",
      "(10, 128, 128, 3)\n",
      "0.9164433\n",
      "[Epoch 6/10] [Batch 1003/1081] [D loss: 0.108740] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.610381] time: 0:59:50.694306\n",
      "(10, 128, 128, 3)\n",
      "0.89420146\n",
      "[Epoch 6/10] [Batch 1004/1081] [D loss: 0.132006] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.071128] time: 0:59:51.348495\n",
      "(10, 128, 128, 3)\n",
      "0.94371384\n",
      "[Epoch 6/10] [Batch 1005/1081] [D loss: 0.137632] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.940638] time: 0:59:52.020519\n",
      "(10, 128, 128, 3)\n",
      "0.9310558\n",
      "[Epoch 6/10] [Batch 1006/1081] [D loss: 0.159287] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.969476] time: 0:59:52.715818\n",
      "(10, 128, 128, 3)\n",
      "0.92887205\n",
      "[Epoch 6/10] [Batch 1007/1081] [D loss: 0.157558] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.935086] time: 0:59:53.370932\n",
      "(10, 128, 128, 3)\n",
      "0.85107297\n",
      "[Epoch 6/10] [Batch 1008/1081] [D loss: 0.222555] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 5.408911] time: 0:59:53.990664\n",
      "(10, 128, 128, 3)\n",
      "0.8233107\n",
      "[Epoch 6/10] [Batch 1009/1081] [D loss: 0.239576] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 6.387483] time: 0:59:54.639348\n",
      "(10, 128, 128, 3)\n",
      "0.9318959\n",
      "[Epoch 6/10] [Batch 1010/1081] [D loss: 0.252364] [D acc: 0.75 (1.00 real, 0.50 fake)] [G loss: 5.527120] time: 0:59:55.303650\n",
      "(10, 128, 128, 3)\n",
      "0.8836525\n",
      "[Epoch 6/10] [Batch 1011/1081] [D loss: 0.291503] [D acc: 0.85 (1.00 real, 0.70 fake)] [G loss: 5.318235] time: 0:59:55.954123\n",
      "(10, 128, 128, 3)\n",
      "0.9048385\n",
      "[Epoch 6/10] [Batch 1012/1081] [D loss: 0.295088] [D acc: 0.75 (0.90 real, 0.60 fake)] [G loss: 5.513862] time: 0:59:56.650152\n",
      "(10, 128, 128, 3)\n",
      "0.86574364\n",
      "[Epoch 6/10] [Batch 1013/1081] [D loss: 0.203966] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.240595] time: 0:59:57.302492\n",
      "(10, 128, 128, 3)\n",
      "0.9092078\n",
      "[Epoch 6/10] [Batch 1014/1081] [D loss: 0.190845] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.576320] time: 0:59:57.881176\n",
      "(10, 128, 128, 3)\n",
      "0.876179\n",
      "[Epoch 6/10] [Batch 1015/1081] [D loss: 0.189933] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 6.726600] time: 0:59:58.436710\n",
      "(10, 128, 128, 3)\n",
      "0.91236204\n",
      "[Epoch 6/10] [Batch 1016/1081] [D loss: 0.429912] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 5.900038] time: 0:59:59.046687\n",
      "(10, 128, 128, 3)\n",
      "0.9309426\n",
      "[Epoch 6/10] [Batch 1017/1081] [D loss: 0.151148] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.293102] time: 0:59:59.731733\n",
      "(10, 128, 128, 3)\n",
      "0.9030928\n",
      "[Epoch 6/10] [Batch 1018/1081] [D loss: 0.151671] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.251224] time: 1:00:00.343793\n",
      "(10, 128, 128, 3)\n",
      "0.8985565\n",
      "[Epoch 6/10] [Batch 1019/1081] [D loss: 0.234270] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 6.572116] time: 1:00:00.992411\n",
      "(10, 128, 128, 3)\n",
      "0.9543671\n",
      "[Epoch 6/10] [Batch 1020/1081] [D loss: 0.269337] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 5.605277] time: 1:00:01.643794\n",
      "(10, 128, 128, 3)\n",
      "0.946294\n",
      "[Epoch 6/10] [Batch 1021/1081] [D loss: 0.110209] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.100105] time: 1:00:02.321861\n",
      "(10, 128, 128, 3)\n",
      "0.9310691\n",
      "[Epoch 6/10] [Batch 1022/1081] [D loss: 0.752239] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 4.596969] time: 1:00:02.943212\n",
      "(10, 128, 128, 3)\n",
      "0.91202945\n",
      "[Epoch 6/10] [Batch 1023/1081] [D loss: 0.292502] [D acc: 0.65 (1.00 real, 0.30 fake)] [G loss: 6.121010] time: 1:00:03.598190\n",
      "(10, 128, 128, 3)\n",
      "0.967817\n",
      "[Epoch 6/10] [Batch 1024/1081] [D loss: 0.361120] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 5.451727] time: 1:00:04.225730\n",
      "(10, 128, 128, 3)\n",
      "0.90977454\n",
      "[Epoch 6/10] [Batch 1025/1081] [D loss: 0.284894] [D acc: 0.60 (1.00 real, 0.20 fake)] [G loss: 5.842676] time: 1:00:04.889601\n",
      "(10, 128, 128, 3)\n",
      "0.92602354\n",
      "[Epoch 6/10] [Batch 1026/1081] [D loss: 0.330725] [D acc: 0.45 (0.10 real, 0.80 fake)] [G loss: 5.067663] time: 1:00:05.514757\n",
      "(10, 128, 128, 3)\n",
      "0.9287403\n",
      "[Epoch 6/10] [Batch 1027/1081] [D loss: 0.248378] [D acc: 0.60 (1.00 real, 0.20 fake)] [G loss: 6.021289] time: 1:00:06.159022\n",
      "(10, 128, 128, 3)\n",
      "0.9242286\n",
      "[Epoch 6/10] [Batch 1028/1081] [D loss: 0.317032] [D acc: 0.75 (0.70 real, 0.80 fake)] [G loss: 5.961048] time: 1:00:06.812101\n",
      "(10, 128, 128, 3)\n",
      "0.8982999\n",
      "[Epoch 6/10] [Batch 1029/1081] [D loss: 0.139766] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.889637] time: 1:00:07.446515\n",
      "(10, 128, 128, 3)\n",
      "0.92425203\n",
      "[Epoch 6/10] [Batch 1030/1081] [D loss: 0.285796] [D acc: 0.55 (0.10 real, 1.00 fake)] [G loss: 5.220435] time: 1:00:08.153627\n",
      "(10, 128, 128, 3)\n",
      "0.94330055\n",
      "[Epoch 6/10] [Batch 1031/1081] [D loss: 0.390125] [D acc: 0.45 (0.90 real, 0.00 fake)] [G loss: 5.882303] time: 1:00:08.774518\n",
      "(10, 128, 128, 3)\n",
      "0.9067621\n",
      "[Epoch 6/10] [Batch 1032/1081] [D loss: 0.264719] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 5.851845] time: 1:00:09.410553\n",
      "(10, 128, 128, 3)\n",
      "0.88256884\n",
      "[Epoch 6/10] [Batch 1033/1081] [D loss: 0.188477] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.049492] time: 1:00:10.027439\n",
      "(10, 128, 128, 3)\n",
      "0.921644\n",
      "[Epoch 6/10] [Batch 1034/1081] [D loss: 0.128244] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.973432] time: 1:00:10.660335\n",
      "(10, 128, 128, 3)\n",
      "0.97664887\n",
      "[Epoch 6/10] [Batch 1035/1081] [D loss: 0.251590] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 5.229525] time: 1:00:11.274336\n",
      "(10, 128, 128, 3)\n",
      "0.8958645\n",
      "[Epoch 6/10] [Batch 1036/1081] [D loss: 0.197848] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.719087] time: 1:00:11.959880\n",
      "(10, 128, 128, 3)\n",
      "0.98074913\n",
      "[Epoch 6/10] [Batch 1037/1081] [D loss: 0.716572] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 4.877937] time: 1:00:12.662848\n",
      "(10, 128, 128, 3)\n",
      "0.887897\n",
      "[Epoch 6/10] [Batch 1038/1081] [D loss: 0.535865] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 6.848119] time: 1:00:13.282747\n",
      "(10, 128, 128, 3)\n",
      "0.91864204\n",
      "[Epoch 6/10] [Batch 1039/1081] [D loss: 0.310869] [D acc: 0.55 (0.90 real, 0.20 fake)] [G loss: 5.137596] time: 1:00:13.935003\n",
      "(10, 128, 128, 3)\n",
      "0.92370534\n",
      "[Epoch 6/10] [Batch 1040/1081] [D loss: 0.206449] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 5.580862] time: 1:00:14.601346\n",
      "(10, 128, 128, 3)\n",
      "0.889128\n",
      "[Epoch 6/10] [Batch 1041/1081] [D loss: 0.254541] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 6.469387] time: 1:00:15.251162\n",
      "(10, 128, 128, 3)\n",
      "0.919434\n",
      "[Epoch 6/10] [Batch 1042/1081] [D loss: 0.219161] [D acc: 0.80 (0.60 real, 1.00 fake)] [G loss: 5.172983] time: 1:00:15.884476\n",
      "(10, 128, 128, 3)\n",
      "0.9252031\n",
      "[Epoch 6/10] [Batch 1043/1081] [D loss: 0.704050] [D acc: 0.10 (0.00 real, 0.20 fake)] [G loss: 4.620642] time: 1:00:16.523137\n",
      "(10, 128, 128, 3)\n",
      "0.9346873\n",
      "[Epoch 6/10] [Batch 1044/1081] [D loss: 0.361821] [D acc: 0.30 (0.40 real, 0.20 fake)] [G loss: 7.164025] time: 1:00:17.190475\n",
      "(10, 128, 128, 3)\n",
      "0.8538811\n",
      "[Epoch 6/10] [Batch 1045/1081] [D loss: 0.171911] [D acc: 0.85 (1.00 real, 0.70 fake)] [G loss: 6.027749] time: 1:00:17.810187\n",
      "(10, 128, 128, 3)\n",
      "0.8774337\n",
      "[Epoch 6/10] [Batch 1046/1081] [D loss: 0.147924] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.636646] time: 1:00:18.448102\n",
      "(10, 128, 128, 3)\n",
      "0.9207666\n",
      "[Epoch 6/10] [Batch 1047/1081] [D loss: 0.230418] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 5.093832] time: 1:00:19.101506\n",
      "(10, 128, 128, 3)\n",
      "0.9145656\n",
      "[Epoch 6/10] [Batch 1048/1081] [D loss: 0.208199] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 5.356476] time: 1:00:19.756920\n",
      "(10, 128, 128, 3)\n",
      "0.90339994\n",
      "[Epoch 6/10] [Batch 1049/1081] [D loss: 0.194290] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.384817] time: 1:00:20.396554\n",
      "(10, 128, 128, 3)\n",
      "0.9512534\n",
      "[Epoch 6/10] [Batch 1050/1081] [D loss: 0.394013] [D acc: 0.30 (0.20 real, 0.40 fake)] [G loss: 5.061775] time: 1:00:21.033873\n",
      "(10, 128, 128, 3)\n",
      "0.9658783\n",
      "[Epoch 6/10] [Batch 1051/1081] [D loss: 0.205437] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.123416] time: 1:00:21.665514\n",
      "(10, 128, 128, 3)\n",
      "0.95536375\n",
      "[Epoch 6/10] [Batch 1052/1081] [D loss: 0.114031] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.221339] time: 1:00:22.360741\n",
      "(10, 128, 128, 3)\n",
      "0.8977868\n",
      "[Epoch 6/10] [Batch 1053/1081] [D loss: 0.125900] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.803666] time: 1:00:23.016333\n",
      "(10, 128, 128, 3)\n",
      "0.8798795\n",
      "[Epoch 6/10] [Batch 1054/1081] [D loss: 0.177406] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 5.386000] time: 1:00:23.650958\n",
      "(10, 128, 128, 3)\n",
      "0.8945391\n",
      "[Epoch 6/10] [Batch 1055/1081] [D loss: 0.173685] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 5.075745] time: 1:00:24.300333\n",
      "(10, 128, 128, 3)\n",
      "0.9499722\n",
      "[Epoch 6/10] [Batch 1056/1081] [D loss: 0.201247] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 4.333537] time: 1:00:24.890227\n",
      "(10, 128, 128, 3)\n",
      "0.9480648\n",
      "[Epoch 6/10] [Batch 1057/1081] [D loss: 0.251697] [D acc: 0.70 (0.40 real, 1.00 fake)] [G loss: 4.727096] time: 1:00:25.542512\n",
      "(10, 128, 128, 3)\n",
      "0.92298967\n",
      "[Epoch 6/10] [Batch 1058/1081] [D loss: 0.193754] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.519849] time: 1:00:26.158701\n",
      "(10, 128, 128, 3)\n",
      "0.86806864\n",
      "[Epoch 6/10] [Batch 1059/1081] [D loss: 0.185334] [D acc: 0.90 (1.00 real, 0.80 fake)] [G loss: 4.771807] time: 1:00:26.804493\n",
      "(10, 128, 128, 3)\n",
      "0.8811569\n",
      "[Epoch 6/10] [Batch 1060/1081] [D loss: 0.125860] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.485988] time: 1:00:27.468095\n",
      "(10, 128, 128, 3)\n",
      "0.8414472\n",
      "[Epoch 6/10] [Batch 1061/1081] [D loss: 0.162841] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.551288] time: 1:00:28.121365\n",
      "(10, 128, 128, 3)\n",
      "0.942478\n",
      "[Epoch 6/10] [Batch 1062/1081] [D loss: 0.154653] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.730990] time: 1:00:28.738434\n",
      "(10, 128, 128, 3)\n",
      "0.8543925\n",
      "[Epoch 6/10] [Batch 1063/1081] [D loss: 0.134432] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.862259] time: 1:00:29.417862\n",
      "(10, 128, 128, 3)\n",
      "0.9305758\n",
      "[Epoch 6/10] [Batch 1064/1081] [D loss: 0.462386] [D acc: 0.45 (0.00 real, 0.90 fake)] [G loss: 5.399896] time: 1:00:30.123925\n",
      "(10, 128, 128, 3)\n",
      "0.88918495\n",
      "[Epoch 6/10] [Batch 1065/1081] [D loss: 0.270054] [D acc: 0.65 (1.00 real, 0.30 fake)] [G loss: 5.081358] time: 1:00:30.814189\n",
      "(10, 128, 128, 3)\n",
      "0.8489003\n",
      "[Epoch 6/10] [Batch 1066/1081] [D loss: 0.240713] [D acc: 0.65 (1.00 real, 0.30 fake)] [G loss: 6.498920] time: 1:00:31.476485\n",
      "(10, 128, 128, 3)\n",
      "0.92916393\n",
      "[Epoch 6/10] [Batch 1067/1081] [D loss: 0.276690] [D acc: 0.60 (1.00 real, 0.20 fake)] [G loss: 5.603330] time: 1:00:32.099666\n",
      "(10, 128, 128, 3)\n",
      "0.9362485\n",
      "[Epoch 6/10] [Batch 1068/1081] [D loss: 0.272298] [D acc: 0.65 (0.30 real, 1.00 fake)] [G loss: 4.794643] time: 1:00:32.679825\n",
      "(10, 128, 128, 3)\n",
      "0.93659616\n",
      "[Epoch 6/10] [Batch 1069/1081] [D loss: 0.264781] [D acc: 0.80 (0.80 real, 0.80 fake)] [G loss: 4.838542] time: 1:00:33.373212\n",
      "(10, 128, 128, 3)\n",
      "0.88352615\n",
      "[Epoch 6/10] [Batch 1070/1081] [D loss: 0.169516] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.044344] time: 1:00:34.004710\n",
      "(10, 128, 128, 3)\n",
      "0.86182433\n",
      "[Epoch 6/10] [Batch 1071/1081] [D loss: 0.150480] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 4.373937] time: 1:00:34.652520\n",
      "(10, 128, 128, 3)\n",
      "0.90080506\n",
      "[Epoch 6/10] [Batch 1072/1081] [D loss: 0.112958] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.853698] time: 1:00:35.342920\n",
      "(10, 128, 128, 3)\n",
      "0.9494429\n",
      "[Epoch 6/10] [Batch 1073/1081] [D loss: 0.092633] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.023691] time: 1:00:36.044375\n",
      "(10, 128, 128, 3)\n",
      "0.8726253\n",
      "[Epoch 6/10] [Batch 1074/1081] [D loss: 0.227708] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 5.618962] time: 1:00:36.718017\n",
      "(10, 128, 128, 3)\n",
      "0.88614345\n",
      "[Epoch 6/10] [Batch 1075/1081] [D loss: 0.086807] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.306409] time: 1:00:37.391355\n",
      "(10, 128, 128, 3)\n",
      "0.9291854\n",
      "[Epoch 6/10] [Batch 1076/1081] [D loss: 0.255573] [D acc: 0.55 (0.10 real, 1.00 fake)] [G loss: 6.168437] time: 1:00:37.998853\n",
      "(10, 128, 128, 3)\n",
      "0.90711623\n",
      "[Epoch 6/10] [Batch 1077/1081] [D loss: 0.341359] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 6.481416] time: 1:00:38.723142\n",
      "(10, 128, 128, 3)\n",
      "0.89877015\n",
      "[Epoch 6/10] [Batch 1078/1081] [D loss: 0.098774] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.573340] time: 1:00:39.415830\n",
      "(10, 128, 128, 3)\n",
      "0.95866746\n",
      "[Epoch 6/10] [Batch 1079/1081] [D loss: 0.291094] [D acc: 0.55 (0.10 real, 1.00 fake)] [G loss: 5.122432] time: 1:00:40.023212\n",
      "(10, 128, 128, 3)\n",
      "0.92348164\n",
      "[Epoch 6/10] [Batch 1080/1081] [D loss: 0.310704] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 4.941588] time: 1:00:40.684980\n",
      "############ VALIDATION OF EPOCH 6 ############\n",
      "############ TRAINING OF EPOCH 7 ############\n",
      "(10, 128, 128, 3)\n",
      "0.89820117\n",
      "[Epoch 7/10] [Batch 0/1081] [D loss: 0.145470] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.245227] time: 1:01:50.883434\n",
      "(10, 128, 128, 3)\n",
      "0.9131999\n",
      "[Epoch 7/10] [Batch 1/1081] [D loss: 0.213072] [D acc: 0.75 (1.00 real, 0.50 fake)] [G loss: 6.304352] time: 1:01:51.539252\n",
      "(10, 128, 128, 3)\n",
      "0.9055961\n",
      "[Epoch 7/10] [Batch 2/1081] [D loss: 0.140333] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.496088] time: 1:01:52.178672\n",
      "(10, 128, 128, 3)\n",
      "0.9183361\n",
      "[Epoch 7/10] [Batch 3/1081] [D loss: 0.124111] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.977817] time: 1:01:52.814675\n",
      "(10, 128, 128, 3)\n",
      "0.8995025\n",
      "[Epoch 7/10] [Batch 4/1081] [D loss: 0.132737] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.437993] time: 1:01:53.485525\n",
      "(10, 128, 128, 3)\n",
      "0.85165566\n",
      "[Epoch 7/10] [Batch 6/1081] [D loss: 0.191905] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 4.564719] time: 1:01:54.145098\n",
      "(10, 128, 128, 3)\n",
      "0.91860515\n",
      "[Epoch 7/10] [Batch 7/1081] [D loss: 0.171875] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.442077] time: 1:01:54.764339\n",
      "(10, 128, 128, 3)\n",
      "0.9206206\n",
      "[Epoch 7/10] [Batch 8/1081] [D loss: 0.156561] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.178061] time: 1:01:55.471572\n",
      "(10, 128, 128, 3)\n",
      "0.8681794\n",
      "[Epoch 7/10] [Batch 9/1081] [D loss: 0.110639] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.386822] time: 1:01:56.088329\n",
      "(10, 128, 128, 3)\n",
      "0.910003\n",
      "[Epoch 7/10] [Batch 10/1081] [D loss: 0.186567] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 5.532666] time: 1:01:56.754877\n",
      "(10, 128, 128, 3)\n",
      "0.9500885\n",
      "[Epoch 7/10] [Batch 11/1081] [D loss: 0.077845] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.467036] time: 1:01:57.405446\n",
      "(10, 128, 128, 3)\n",
      "0.90791845\n",
      "[Epoch 7/10] [Batch 12/1081] [D loss: 0.084376] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.657225] time: 1:01:58.022051\n",
      "(10, 128, 128, 3)\n",
      "0.94024205\n",
      "[Epoch 7/10] [Batch 13/1081] [D loss: 0.139619] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.224508] time: 1:01:58.691181\n",
      "(10, 128, 128, 3)\n",
      "0.880723\n",
      "[Epoch 7/10] [Batch 14/1081] [D loss: 0.156242] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.766483] time: 1:01:59.340251\n",
      "(10, 128, 128, 3)\n",
      "0.93282384\n",
      "[Epoch 7/10] [Batch 15/1081] [D loss: 0.226134] [D acc: 0.65 (0.30 real, 1.00 fake)] [G loss: 5.196627] time: 1:02:00.020565\n",
      "(10, 128, 128, 3)\n",
      "0.8635742\n",
      "[Epoch 7/10] [Batch 16/1081] [D loss: 0.076779] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.740239] time: 1:02:00.617230\n",
      "(10, 128, 128, 3)\n",
      "0.91306955\n",
      "[Epoch 7/10] [Batch 17/1081] [D loss: 0.120628] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.906175] time: 1:02:01.272066\n",
      "(10, 128, 128, 3)\n",
      "0.8811569\n",
      "[Epoch 7/10] [Batch 18/1081] [D loss: 0.099608] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.457612] time: 1:02:01.887094\n",
      "(10, 128, 128, 3)\n",
      "0.9294302\n",
      "[Epoch 7/10] [Batch 19/1081] [D loss: 0.221908] [D acc: 0.70 (1.00 real, 0.40 fake)] [G loss: 5.069310] time: 1:02:02.574380\n",
      "(10, 128, 128, 3)\n",
      "0.90812117\n",
      "[Epoch 7/10] [Batch 20/1081] [D loss: 0.115740] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.104016] time: 1:02:03.197151\n",
      "(10, 128, 128, 3)\n",
      "0.9090772\n",
      "[Epoch 7/10] [Batch 21/1081] [D loss: 0.363307] [D acc: 0.45 (0.70 real, 0.20 fake)] [G loss: 5.803222] time: 1:02:03.906543\n",
      "(10, 128, 128, 3)\n",
      "0.9083286\n",
      "[Epoch 7/10] [Batch 22/1081] [D loss: 0.115886] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 6.028813] time: 1:02:04.447258\n",
      "(10, 128, 128, 3)\n",
      "0.8885822\n",
      "[Epoch 7/10] [Batch 23/1081] [D loss: 0.096831] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.654157] time: 1:02:04.999227\n",
      "(10, 128, 128, 3)\n",
      "0.87653214\n",
      "[Epoch 7/10] [Batch 24/1081] [D loss: 0.093284] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.199686] time: 1:02:05.551478\n",
      "(10, 128, 128, 3)\n",
      "0.8904495\n",
      "[Epoch 7/10] [Batch 25/1081] [D loss: 0.116540] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.412559] time: 1:02:06.097596\n",
      "(10, 128, 128, 3)\n",
      "0.88013625\n",
      "[Epoch 7/10] [Batch 26/1081] [D loss: 0.084739] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.614443] time: 1:02:06.664764\n",
      "(10, 128, 128, 3)\n",
      "0.9033161\n",
      "[Epoch 7/10] [Batch 27/1081] [D loss: 0.282267] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 5.604517] time: 1:02:07.206386\n",
      "(10, 128, 128, 3)\n",
      "0.9492919\n",
      "[Epoch 7/10] [Batch 28/1081] [D loss: 0.106658] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.606937] time: 1:02:07.729221\n",
      "(10, 128, 128, 3)\n",
      "0.93323857\n",
      "[Epoch 7/10] [Batch 29/1081] [D loss: 0.201092] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 4.974727] time: 1:02:08.247435\n",
      "(10, 128, 128, 3)\n",
      "0.8606197\n",
      "[Epoch 7/10] [Batch 30/1081] [D loss: 0.125072] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.699470] time: 1:02:08.804821\n",
      "(10, 128, 128, 3)\n",
      "0.90978783\n",
      "[Epoch 7/10] [Batch 31/1081] [D loss: 0.514629] [D acc: 0.40 (0.00 real, 0.80 fake)] [G loss: 4.414313] time: 1:02:09.356108\n",
      "(10, 128, 128, 3)\n",
      "0.9309232\n",
      "[Epoch 7/10] [Batch 32/1081] [D loss: 0.177196] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 4.874917] time: 1:02:09.928790\n",
      "(10, 128, 128, 3)\n",
      "0.9249801\n",
      "[Epoch 7/10] [Batch 33/1081] [D loss: 0.221274] [D acc: 0.70 (1.00 real, 0.40 fake)] [G loss: 3.709464] time: 1:02:10.511131\n",
      "(10, 128, 128, 3)\n",
      "0.9074917\n",
      "[Epoch 7/10] [Batch 34/1081] [D loss: 0.101288] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.912884] time: 1:02:11.038339\n",
      "(10, 128, 128, 3)\n",
      "0.94210654\n",
      "[Epoch 7/10] [Batch 35/1081] [D loss: 0.183560] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 5.142725] time: 1:02:11.572909\n",
      "(10, 128, 128, 3)\n",
      "0.9166207\n",
      "[Epoch 7/10] [Batch 36/1081] [D loss: 0.102200] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.128458] time: 1:02:12.107046\n",
      "(10, 128, 128, 3)\n",
      "0.87396735\n",
      "[Epoch 7/10] [Batch 37/1081] [D loss: 0.237503] [D acc: 0.55 (0.10 real, 1.00 fake)] [G loss: 6.240004] time: 1:02:12.683192\n",
      "(10, 128, 128, 3)\n",
      "0.8944518\n",
      "[Epoch 7/10] [Batch 38/1081] [D loss: 0.088660] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.260260] time: 1:02:13.227202\n",
      "(10, 128, 128, 3)\n",
      "0.92854613\n",
      "[Epoch 7/10] [Batch 39/1081] [D loss: 0.145346] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.123758] time: 1:02:13.789268\n",
      "(10, 128, 128, 3)\n",
      "0.92263365\n",
      "[Epoch 7/10] [Batch 40/1081] [D loss: 0.086918] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.829906] time: 1:02:14.358103\n",
      "(10, 128, 128, 3)\n",
      "0.9076324\n",
      "[Epoch 7/10] [Batch 41/1081] [D loss: 0.244602] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 4.933219] time: 1:02:14.926391\n",
      "(10, 128, 128, 3)\n",
      "0.87836003\n",
      "[Epoch 7/10] [Batch 42/1081] [D loss: 0.267914] [D acc: 0.80 (0.60 real, 1.00 fake)] [G loss: 5.295875] time: 1:02:15.485380\n",
      "(10, 128, 128, 3)\n",
      "0.89065295\n",
      "[Epoch 7/10] [Batch 43/1081] [D loss: 0.194578] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 4.640440] time: 1:02:16.011022\n",
      "(10, 128, 128, 3)\n",
      "0.91454524\n",
      "[Epoch 7/10] [Batch 44/1081] [D loss: 0.133153] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.824874] time: 1:02:16.550519\n",
      "(10, 128, 128, 3)\n",
      "0.89681125\n",
      "[Epoch 7/10] [Batch 45/1081] [D loss: 0.132092] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.373943] time: 1:02:17.117666\n",
      "(10, 128, 128, 3)\n",
      "0.92668766\n",
      "[Epoch 7/10] [Batch 46/1081] [D loss: 0.113336] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.102304] time: 1:02:17.679201\n",
      "(10, 128, 128, 3)\n",
      "0.88383174\n",
      "[Epoch 7/10] [Batch 47/1081] [D loss: 0.093977] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.182801] time: 1:02:18.247101\n",
      "(10, 128, 128, 3)\n",
      "0.9150524\n",
      "[Epoch 7/10] [Batch 48/1081] [D loss: 0.138686] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.267830] time: 1:02:18.782555\n",
      "(10, 128, 128, 3)\n",
      "0.9350898\n",
      "[Epoch 7/10] [Batch 49/1081] [D loss: 0.156783] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.516116] time: 1:02:19.334559\n",
      "(10, 128, 128, 3)\n",
      "0.9249508\n",
      "[Epoch 7/10] [Batch 50/1081] [D loss: 0.145159] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.161547] time: 1:02:19.869589\n",
      "(10, 128, 128, 3)\n",
      "0.9156909\n",
      "[Epoch 7/10] [Batch 51/1081] [D loss: 0.177622] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 4.634070] time: 1:02:20.421687\n",
      "(10, 128, 128, 3)\n",
      "0.8906669\n",
      "[Epoch 7/10] [Batch 52/1081] [D loss: 0.191737] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.642173] time: 1:02:20.982360\n",
      "(10, 128, 128, 3)\n",
      "0.8722095\n",
      "[Epoch 7/10] [Batch 53/1081] [D loss: 0.086331] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.005771] time: 1:02:21.544066\n",
      "(10, 128, 128, 3)\n",
      "0.8583996\n",
      "[Epoch 7/10] [Batch 54/1081] [D loss: 0.208378] [D acc: 0.75 (1.00 real, 0.50 fake)] [G loss: 6.561912] time: 1:02:22.101632\n",
      "(10, 128, 128, 3)\n",
      "0.9334987\n",
      "[Epoch 7/10] [Batch 55/1081] [D loss: 0.156724] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 6.150365] time: 1:02:22.634888\n",
      "(10, 128, 128, 3)\n",
      "0.9089787\n",
      "[Epoch 7/10] [Batch 56/1081] [D loss: 0.092112] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.666036] time: 1:02:23.172340\n",
      "(10, 128, 128, 3)\n",
      "0.9086059\n",
      "[Epoch 7/10] [Batch 57/1081] [D loss: 0.203248] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 5.801026] time: 1:02:23.767096\n",
      "(10, 128, 128, 3)\n",
      "0.90013456\n",
      "[Epoch 7/10] [Batch 58/1081] [D loss: 0.080284] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.509673] time: 1:02:24.386511\n",
      "(10, 128, 128, 3)\n",
      "0.89080864\n",
      "[Epoch 7/10] [Batch 59/1081] [D loss: 0.137420] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.149630] time: 1:02:25.064857\n",
      "(10, 128, 128, 3)\n",
      "0.92671496\n",
      "[Epoch 7/10] [Batch 60/1081] [D loss: 0.158191] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.563453] time: 1:02:25.817325\n",
      "(10, 128, 128, 3)\n",
      "0.9342734\n",
      "[Epoch 7/10] [Batch 61/1081] [D loss: 0.197842] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 5.977818] time: 1:02:26.467080\n",
      "(10, 128, 128, 3)\n",
      "0.9180638\n",
      "[Epoch 7/10] [Batch 62/1081] [D loss: 0.138936] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.704444] time: 1:02:27.129373\n",
      "(10, 128, 128, 3)\n",
      "0.89923424\n",
      "[Epoch 7/10] [Batch 63/1081] [D loss: 0.195980] [D acc: 0.80 (1.00 real, 0.60 fake)] [G loss: 4.645200] time: 1:02:27.809427\n",
      "(10, 128, 128, 3)\n",
      "0.85965246\n",
      "[Epoch 7/10] [Batch 64/1081] [D loss: 0.165842] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 5.458297] time: 1:02:28.448839\n",
      "(10, 128, 128, 3)\n",
      "0.9241573\n",
      "[Epoch 7/10] [Batch 65/1081] [D loss: 0.236078] [D acc: 0.65 (0.30 real, 1.00 fake)] [G loss: 4.584571] time: 1:02:29.122338\n",
      "(10, 128, 128, 3)\n",
      "0.94288045\n",
      "[Epoch 7/10] [Batch 66/1081] [D loss: 0.258617] [D acc: 0.55 (1.00 real, 0.10 fake)] [G loss: 4.780378] time: 1:02:29.746507\n",
      "(10, 128, 128, 3)\n",
      "0.94694227\n",
      "[Epoch 7/10] [Batch 67/1081] [D loss: 0.123875] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.057818] time: 1:02:30.402428\n",
      "(10, 128, 128, 3)\n",
      "0.9068176\n",
      "[Epoch 7/10] [Batch 68/1081] [D loss: 0.154093] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.611536] time: 1:02:31.069564\n",
      "(10, 128, 128, 3)\n",
      "0.91272086\n",
      "[Epoch 7/10] [Batch 69/1081] [D loss: 0.272309] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 5.770687] time: 1:02:31.747290\n",
      "(10, 128, 128, 3)\n",
      "0.9562266\n",
      "[Epoch 7/10] [Batch 70/1081] [D loss: 0.157195] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 4.656208] time: 1:02:32.415399\n",
      "(10, 128, 128, 3)\n",
      "0.9252909\n",
      "[Epoch 7/10] [Batch 71/1081] [D loss: 0.381731] [D acc: 0.45 (0.00 real, 0.90 fake)] [G loss: 5.682246] time: 1:02:33.013688\n",
      "(10, 128, 128, 3)\n",
      "0.9104884\n",
      "[Epoch 7/10] [Batch 72/1081] [D loss: 0.132479] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.394221] time: 1:02:33.674241\n",
      "(10, 128, 128, 3)\n",
      "0.8950763\n",
      "[Epoch 7/10] [Batch 73/1081] [D loss: 0.174976] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.536277] time: 1:02:34.297778\n",
      "(10, 128, 128, 3)\n",
      "0.94509625\n",
      "[Epoch 7/10] [Batch 74/1081] [D loss: 0.112893] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.031279] time: 1:02:34.959079\n",
      "(10, 128, 128, 3)\n",
      "0.92750865\n",
      "[Epoch 7/10] [Batch 75/1081] [D loss: 0.143507] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.970419] time: 1:02:35.581599\n",
      "(10, 128, 128, 3)\n",
      "0.96574473\n",
      "[Epoch 7/10] [Batch 76/1081] [D loss: 0.164896] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.092250] time: 1:02:36.221048\n",
      "(10, 128, 128, 3)\n",
      "0.949079\n",
      "[Epoch 7/10] [Batch 77/1081] [D loss: 0.489955] [D acc: 0.30 (0.60 real, 0.00 fake)] [G loss: 4.584532] time: 1:02:36.909271\n",
      "(10, 128, 128, 3)\n",
      "0.8870987\n",
      "[Epoch 7/10] [Batch 78/1081] [D loss: 0.310411] [D acc: 0.55 (1.00 real, 0.10 fake)] [G loss: 6.179277] time: 1:02:37.571822\n",
      "(10, 128, 128, 3)\n",
      "0.93802136\n",
      "[Epoch 7/10] [Batch 79/1081] [D loss: 0.158246] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.981913] time: 1:02:38.188510\n",
      "(10, 128, 128, 3)\n",
      "0.9197121\n",
      "[Epoch 7/10] [Batch 80/1081] [D loss: 0.102449] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.171875] time: 1:02:38.803276\n",
      "(10, 128, 128, 3)\n",
      "0.88694435\n",
      "[Epoch 7/10] [Batch 81/1081] [D loss: 0.334242] [D acc: 0.45 (0.50 real, 0.40 fake)] [G loss: 6.631988] time: 1:02:39.531834\n",
      "(10, 128, 128, 3)\n",
      "0.9384822\n",
      "[Epoch 7/10] [Batch 82/1081] [D loss: 0.258683] [D acc: 0.60 (1.00 real, 0.20 fake)] [G loss: 5.341524] time: 1:02:40.147757\n",
      "(10, 128, 128, 3)\n",
      "0.9310104\n",
      "[Epoch 7/10] [Batch 83/1081] [D loss: 0.231512] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.935130] time: 1:02:40.729553\n",
      "(10, 128, 128, 3)\n",
      "0.9204771\n",
      "[Epoch 7/10] [Batch 84/1081] [D loss: 0.154716] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.611018] time: 1:02:41.366496\n",
      "(10, 128, 128, 3)\n",
      "0.94638854\n",
      "[Epoch 7/10] [Batch 85/1081] [D loss: 0.101099] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.681219] time: 1:02:41.969266\n",
      "(10, 128, 128, 3)\n",
      "0.8441461\n",
      "[Epoch 7/10] [Batch 86/1081] [D loss: 0.081104] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.163837] time: 1:02:42.578585\n",
      "(10, 128, 128, 3)\n",
      "0.9188404\n",
      "[Epoch 7/10] [Batch 87/1081] [D loss: 0.150567] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.695313] time: 1:02:43.227384\n",
      "(10, 128, 128, 3)\n",
      "0.9775905\n",
      "[Epoch 7/10] [Batch 88/1081] [D loss: 0.353977] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 4.437450] time: 1:02:43.931583\n",
      "(10, 128, 128, 3)\n",
      "0.90540314\n",
      "[Epoch 7/10] [Batch 89/1081] [D loss: 0.122846] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.196480] time: 1:02:44.568766\n",
      "(10, 128, 128, 3)\n",
      "0.9642146\n",
      "[Epoch 7/10] [Batch 90/1081] [D loss: 0.097169] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.854922] time: 1:02:45.199343\n",
      "(10, 128, 128, 3)\n",
      "0.9465292\n",
      "[Epoch 7/10] [Batch 91/1081] [D loss: 0.213162] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.875742] time: 1:02:45.748045\n",
      "(10, 128, 128, 3)\n",
      "0.917602\n",
      "[Epoch 7/10] [Batch 92/1081] [D loss: 0.130801] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.762351] time: 1:02:46.355507\n",
      "(10, 128, 128, 3)\n",
      "0.9212983\n",
      "[Epoch 7/10] [Batch 93/1081] [D loss: 0.086231] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.031156] time: 1:02:46.994055\n",
      "(10, 128, 128, 3)\n",
      "0.9297908\n",
      "[Epoch 7/10] [Batch 94/1081] [D loss: 0.187669] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 5.445709] time: 1:02:47.629871\n",
      "(10, 128, 128, 3)\n",
      "0.9095292\n",
      "[Epoch 7/10] [Batch 95/1081] [D loss: 0.184505] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 5.289311] time: 1:02:48.297657\n",
      "(10, 128, 128, 3)\n",
      "0.9284048\n",
      "[Epoch 7/10] [Batch 96/1081] [D loss: 0.085833] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.510047] time: 1:02:48.941209\n",
      "(10, 128, 128, 3)\n",
      "0.89907867\n",
      "[Epoch 7/10] [Batch 97/1081] [D loss: 0.225266] [D acc: 0.75 (1.00 real, 0.50 fake)] [G loss: 4.390403] time: 1:02:49.619423\n",
      "(10, 128, 128, 3)\n",
      "0.9106429\n",
      "[Epoch 7/10] [Batch 98/1081] [D loss: 0.096651] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.172475] time: 1:02:50.240348\n",
      "(10, 128, 128, 3)\n",
      "0.9033814\n",
      "[Epoch 7/10] [Batch 99/1081] [D loss: 0.086218] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.307632] time: 1:02:50.835088\n",
      "(10, 128, 128, 3)\n",
      "0.933628\n",
      "[Epoch 7/10] [Batch 100/1081] [D loss: 0.114803] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.713422] time: 1:02:51.508420\n",
      "(10, 128, 128, 3)\n",
      "0.94548804\n",
      "[Epoch 7/10] [Batch 101/1081] [D loss: 0.095239] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.114024] time: 1:02:52.215018\n",
      "(10, 128, 128, 3)\n",
      "0.910471\n",
      "[Epoch 7/10] [Batch 102/1081] [D loss: 0.129782] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.573439] time: 1:02:52.910505\n",
      "(10, 128, 128, 3)\n",
      "0.9188259\n",
      "[Epoch 7/10] [Batch 103/1081] [D loss: 0.128160] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.159753] time: 1:02:53.533432\n",
      "(10, 128, 128, 3)\n",
      "0.9235036\n",
      "[Epoch 7/10] [Batch 104/1081] [D loss: 0.121821] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.857451] time: 1:02:54.180373\n",
      "(10, 128, 128, 3)\n",
      "0.9529001\n",
      "[Epoch 7/10] [Batch 105/1081] [D loss: 0.111637] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.226571] time: 1:02:54.880542\n",
      "(10, 128, 128, 3)\n",
      "0.8727909\n",
      "[Epoch 7/10] [Batch 106/1081] [D loss: 0.084646] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.731695] time: 1:02:55.545914\n",
      "(10, 128, 128, 3)\n",
      "0.93318915\n",
      "[Epoch 7/10] [Batch 107/1081] [D loss: 0.130340] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.336086] time: 1:02:56.167767\n",
      "(10, 128, 128, 3)\n",
      "0.9103963\n",
      "[Epoch 7/10] [Batch 108/1081] [D loss: 0.411878] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 4.956255] time: 1:02:56.827856\n",
      "(10, 128, 128, 3)\n",
      "0.9096821\n",
      "[Epoch 7/10] [Batch 109/1081] [D loss: 0.117796] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.321096] time: 1:02:57.522385\n",
      "(10, 128, 128, 3)\n",
      "0.90210205\n",
      "[Epoch 7/10] [Batch 110/1081] [D loss: 0.098728] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.349586] time: 1:02:58.213030\n",
      "(10, 128, 128, 3)\n",
      "0.95901316\n",
      "[Epoch 7/10] [Batch 111/1081] [D loss: 0.111858] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.635884] time: 1:02:58.874576\n",
      "(10, 128, 128, 3)\n",
      "0.9327666\n",
      "[Epoch 7/10] [Batch 112/1081] [D loss: 0.149338] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.083008] time: 1:02:59.510840\n",
      "(10, 128, 128, 3)\n",
      "0.89147717\n",
      "[Epoch 7/10] [Batch 113/1081] [D loss: 0.210221] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 6.057734] time: 1:03:00.174782\n",
      "(10, 128, 128, 3)\n",
      "0.91738635\n",
      "[Epoch 7/10] [Batch 114/1081] [D loss: 0.083440] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.945981] time: 1:03:00.827716\n",
      "(10, 128, 128, 3)\n",
      "0.9458928\n",
      "[Epoch 7/10] [Batch 115/1081] [D loss: 0.093337] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.206101] time: 1:03:01.503159\n",
      "(10, 128, 128, 3)\n",
      "0.93176895\n",
      "[Epoch 7/10] [Batch 116/1081] [D loss: 0.176115] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 6.426103] time: 1:03:02.176914\n",
      "(10, 128, 128, 3)\n",
      "0.8833929\n",
      "[Epoch 7/10] [Batch 117/1081] [D loss: 0.084797] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.739109] time: 1:03:02.821292\n",
      "(10, 128, 128, 3)\n",
      "0.9241218\n",
      "[Epoch 7/10] [Batch 118/1081] [D loss: 0.086682] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.616760] time: 1:03:03.496413\n",
      "(10, 128, 128, 3)\n",
      "0.9112837\n",
      "[Epoch 7/10] [Batch 119/1081] [D loss: 0.080095] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.516262] time: 1:03:04.099988\n",
      "(10, 128, 128, 3)\n",
      "0.89469594\n",
      "[Epoch 7/10] [Batch 120/1081] [D loss: 0.086108] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.248290] time: 1:03:04.772647\n",
      "(10, 128, 128, 3)\n",
      "0.8946278\n",
      "[Epoch 7/10] [Batch 121/1081] [D loss: 0.103304] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.112917] time: 1:03:05.432017\n",
      "(10, 128, 128, 3)\n",
      "0.9353158\n",
      "[Epoch 7/10] [Batch 122/1081] [D loss: 0.084794] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.426797] time: 1:03:06.100853\n",
      "(10, 128, 128, 3)\n",
      "0.8631994\n",
      "[Epoch 7/10] [Batch 123/1081] [D loss: 0.090661] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.586688] time: 1:03:06.764655\n",
      "(10, 128, 128, 3)\n",
      "0.9356007\n",
      "[Epoch 7/10] [Batch 124/1081] [D loss: 0.178669] [D acc: 0.90 (1.00 real, 0.80 fake)] [G loss: 5.082635] time: 1:03:07.363556\n",
      "(10, 128, 128, 3)\n",
      "0.89101976\n",
      "[Epoch 7/10] [Batch 125/1081] [D loss: 0.084176] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.842712] time: 1:03:08.081749\n",
      "(10, 128, 128, 3)\n",
      "0.8827575\n",
      "[Epoch 7/10] [Batch 126/1081] [D loss: 0.126546] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.365736] time: 1:03:08.702061\n",
      "(10, 128, 128, 3)\n",
      "0.8638439\n",
      "[Epoch 7/10] [Batch 127/1081] [D loss: 0.295377] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 5.436871] time: 1:03:09.373318\n",
      "(10, 128, 128, 3)\n",
      "0.9130519\n",
      "[Epoch 7/10] [Batch 128/1081] [D loss: 0.265090] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 5.643141] time: 1:03:10.072707\n",
      "(10, 128, 128, 3)\n",
      "0.915406\n",
      "[Epoch 7/10] [Batch 129/1081] [D loss: 0.112558] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.320175] time: 1:03:10.768169\n",
      "(10, 128, 128, 3)\n",
      "0.92773914\n",
      "[Epoch 7/10] [Batch 130/1081] [D loss: 0.175329] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 5.769871] time: 1:03:11.421655\n",
      "(10, 128, 128, 3)\n",
      "0.89182585\n",
      "[Epoch 7/10] [Batch 131/1081] [D loss: 0.102713] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.593029] time: 1:03:12.046117\n",
      "(10, 128, 128, 3)\n",
      "0.9464676\n",
      "[Epoch 7/10] [Batch 132/1081] [D loss: 0.207488] [D acc: 0.70 (0.40 real, 1.00 fake)] [G loss: 4.652785] time: 1:03:12.665221\n",
      "(10, 128, 128, 3)\n",
      "0.9360523\n",
      "[Epoch 7/10] [Batch 133/1081] [D loss: 0.141312] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.938338] time: 1:03:13.343657\n",
      "(10, 128, 128, 3)\n",
      "0.9008023\n",
      "[Epoch 7/10] [Batch 134/1081] [D loss: 0.121456] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.493107] time: 1:03:14.008928\n",
      "(10, 128, 128, 3)\n",
      "0.92956066\n",
      "[Epoch 7/10] [Batch 135/1081] [D loss: 0.118116] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.617085] time: 1:03:14.687824\n",
      "(10, 128, 128, 3)\n",
      "0.9091539\n",
      "[Epoch 7/10] [Batch 136/1081] [D loss: 0.124342] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.185584] time: 1:03:15.310711\n",
      "(10, 128, 128, 3)\n",
      "0.9103627\n",
      "[Epoch 7/10] [Batch 137/1081] [D loss: 0.080853] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.291088] time: 1:03:15.981809\n",
      "(10, 128, 128, 3)\n",
      "0.9176143\n",
      "[Epoch 7/10] [Batch 138/1081] [D loss: 0.091858] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.173295] time: 1:03:16.595239\n",
      "(10, 128, 128, 3)\n",
      "0.8942621\n",
      "[Epoch 7/10] [Batch 139/1081] [D loss: 0.083971] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.421447] time: 1:03:17.224896\n",
      "(10, 128, 128, 3)\n",
      "0.9082188\n",
      "[Epoch 7/10] [Batch 140/1081] [D loss: 0.127498] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.910981] time: 1:03:17.897541\n",
      "(10, 128, 128, 3)\n",
      "0.897388\n",
      "[Epoch 7/10] [Batch 141/1081] [D loss: 0.090473] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.726070] time: 1:03:18.609628\n",
      "(10, 128, 128, 3)\n",
      "0.8785753\n",
      "[Epoch 7/10] [Batch 142/1081] [D loss: 0.751164] [D acc: 0.05 (0.10 real, 0.00 fake)] [G loss: 5.949960] time: 1:03:19.291784\n",
      "(10, 128, 128, 3)\n",
      "0.91092306\n",
      "[Epoch 7/10] [Batch 143/1081] [D loss: 0.088125] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.333426] time: 1:03:19.946542\n",
      "(10, 128, 128, 3)\n",
      "0.92054564\n",
      "[Epoch 7/10] [Batch 144/1081] [D loss: 0.082859] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.636734] time: 1:03:20.630278\n",
      "(10, 128, 128, 3)\n",
      "0.8561422\n",
      "[Epoch 7/10] [Batch 145/1081] [D loss: 0.100515] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.555454] time: 1:03:21.310758\n",
      "(10, 128, 128, 3)\n",
      "0.90486103\n",
      "[Epoch 7/10] [Batch 146/1081] [D loss: 0.098911] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.970982] time: 1:03:22.005740\n",
      "(10, 128, 128, 3)\n",
      "0.8748706\n",
      "[Epoch 7/10] [Batch 147/1081] [D loss: 0.109970] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.628604] time: 1:03:22.628946\n",
      "(10, 128, 128, 3)\n",
      "0.9073527\n",
      "[Epoch 7/10] [Batch 148/1081] [D loss: 0.140562] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.956687] time: 1:03:23.290563\n",
      "(10, 128, 128, 3)\n",
      "0.91286516\n",
      "[Epoch 7/10] [Batch 149/1081] [D loss: 0.222009] [D acc: 0.80 (0.60 real, 1.00 fake)] [G loss: 5.046429] time: 1:03:23.953150\n",
      "(10, 128, 128, 3)\n",
      "0.914432\n",
      "[Epoch 7/10] [Batch 150/1081] [D loss: 0.095378] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.069089] time: 1:03:24.592289\n",
      "(10, 128, 128, 3)\n",
      "0.8683057\n",
      "[Epoch 7/10] [Batch 151/1081] [D loss: 0.172334] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.519610] time: 1:03:25.255716\n",
      "(10, 128, 128, 3)\n",
      "0.95445997\n",
      "[Epoch 7/10] [Batch 152/1081] [D loss: 0.211659] [D acc: 0.65 (1.00 real, 0.30 fake)] [G loss: 5.499125] time: 1:03:25.877486\n",
      "(10, 128, 128, 3)\n",
      "0.8777612\n",
      "[Epoch 7/10] [Batch 153/1081] [D loss: 0.078368] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.558596] time: 1:03:26.568796\n",
      "(10, 128, 128, 3)\n",
      "0.9179909\n",
      "[Epoch 7/10] [Batch 154/1081] [D loss: 0.125523] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.589975] time: 1:03:27.226332\n",
      "(10, 128, 128, 3)\n",
      "0.9092085\n",
      "[Epoch 7/10] [Batch 155/1081] [D loss: 0.109998] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.497888] time: 1:03:27.834695\n",
      "(10, 128, 128, 3)\n",
      "0.94652057\n",
      "[Epoch 7/10] [Batch 156/1081] [D loss: 0.155701] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.066933] time: 1:03:28.479130\n",
      "(10, 128, 128, 3)\n",
      "0.9333485\n",
      "[Epoch 7/10] [Batch 157/1081] [D loss: 0.085472] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.108937] time: 1:03:29.170823\n",
      "(10, 128, 128, 3)\n",
      "0.8780424\n",
      "[Epoch 7/10] [Batch 158/1081] [D loss: 0.133249] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.899590] time: 1:03:29.789819\n",
      "(10, 128, 128, 3)\n",
      "0.8914024\n",
      "[Epoch 7/10] [Batch 159/1081] [D loss: 0.093630] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.214888] time: 1:03:30.456567\n",
      "(10, 128, 128, 3)\n",
      "0.89862806\n",
      "[Epoch 7/10] [Batch 160/1081] [D loss: 0.077823] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.920217] time: 1:03:31.134670\n",
      "(10, 128, 128, 3)\n",
      "0.88395435\n",
      "[Epoch 7/10] [Batch 161/1081] [D loss: 0.137074] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.051085] time: 1:03:31.767485\n",
      "(10, 128, 128, 3)\n",
      "0.83030605\n",
      "[Epoch 7/10] [Batch 162/1081] [D loss: 0.120300] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.407393] time: 1:03:32.424778\n",
      "(10, 128, 128, 3)\n",
      "0.90509397\n",
      "[Epoch 7/10] [Batch 163/1081] [D loss: 0.090553] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.625906] time: 1:03:33.089049\n",
      "(10, 128, 128, 3)\n",
      "0.9209412\n",
      "[Epoch 7/10] [Batch 164/1081] [D loss: 0.113378] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.668001] time: 1:03:33.760624\n",
      "(10, 128, 128, 3)\n",
      "0.948847\n",
      "[Epoch 7/10] [Batch 165/1081] [D loss: 0.123226] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.156440] time: 1:03:34.443564\n",
      "(10, 128, 128, 3)\n",
      "0.92581016\n",
      "[Epoch 7/10] [Batch 166/1081] [D loss: 0.075884] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.785336] time: 1:03:35.085582\n",
      "(10, 128, 128, 3)\n",
      "0.8749633\n",
      "[Epoch 7/10] [Batch 167/1081] [D loss: 0.109988] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.768551] time: 1:03:35.738504\n",
      "(10, 128, 128, 3)\n",
      "0.9225547\n",
      "[Epoch 7/10] [Batch 168/1081] [D loss: 0.113482] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.467305] time: 1:03:36.353498\n",
      "(10, 128, 128, 3)\n",
      "0.9579959\n",
      "[Epoch 7/10] [Batch 169/1081] [D loss: 0.277948] [D acc: 0.55 (1.00 real, 0.10 fake)] [G loss: 5.783277] time: 1:03:37.046813\n",
      "(10, 128, 128, 3)\n",
      "0.928756\n",
      "[Epoch 7/10] [Batch 170/1081] [D loss: 0.210936] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 5.672917] time: 1:03:37.719760\n",
      "(10, 128, 128, 3)\n",
      "0.8949432\n",
      "[Epoch 7/10] [Batch 171/1081] [D loss: 0.078379] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.816512] time: 1:03:38.350519\n",
      "(10, 128, 128, 3)\n",
      "0.938966\n",
      "[Epoch 7/10] [Batch 172/1081] [D loss: 0.147147] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.149173] time: 1:03:39.007659\n",
      "(10, 128, 128, 3)\n",
      "0.9424908\n",
      "[Epoch 7/10] [Batch 173/1081] [D loss: 0.296322] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 4.797206] time: 1:03:39.666356\n",
      "(10, 128, 128, 3)\n",
      "0.8593641\n",
      "[Epoch 7/10] [Batch 174/1081] [D loss: 0.146561] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.682237] time: 1:03:40.306160\n",
      "(10, 128, 128, 3)\n",
      "0.9425164\n",
      "[Epoch 7/10] [Batch 175/1081] [D loss: 0.091463] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.016546] time: 1:03:40.921013\n",
      "(10, 128, 128, 3)\n",
      "0.91032076\n",
      "[Epoch 7/10] [Batch 176/1081] [D loss: 0.101580] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.137816] time: 1:03:41.614503\n",
      "(10, 128, 128, 3)\n",
      "0.9228428\n",
      "[Epoch 7/10] [Batch 177/1081] [D loss: 0.137242] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.449135] time: 1:03:42.261534\n",
      "(10, 128, 128, 3)\n",
      "0.8714635\n",
      "[Epoch 7/10] [Batch 178/1081] [D loss: 0.089332] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.405195] time: 1:03:42.898285\n",
      "(10, 128, 128, 3)\n",
      "0.9094437\n",
      "[Epoch 7/10] [Batch 179/1081] [D loss: 0.098787] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.592813] time: 1:03:43.525451\n",
      "(10, 128, 128, 3)\n",
      "0.9604265\n",
      "[Epoch 7/10] [Batch 180/1081] [D loss: 0.082135] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.050433] time: 1:03:44.159167\n",
      "(10, 128, 128, 3)\n",
      "0.91549325\n",
      "[Epoch 7/10] [Batch 181/1081] [D loss: 0.080967] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.713614] time: 1:03:44.834435\n",
      "(10, 128, 128, 3)\n",
      "0.9349225\n",
      "[Epoch 7/10] [Batch 182/1081] [D loss: 0.112094] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.628916] time: 1:03:45.530233\n",
      "(10, 128, 128, 3)\n",
      "0.9031522\n",
      "[Epoch 7/10] [Batch 183/1081] [D loss: 0.129673] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.935393] time: 1:03:46.226479\n",
      "(10, 128, 128, 3)\n",
      "0.9574265\n",
      "[Epoch 7/10] [Batch 184/1081] [D loss: 0.082386] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.840128] time: 1:03:46.865469\n",
      "(10, 128, 128, 3)\n",
      "0.9135892\n",
      "[Epoch 7/10] [Batch 185/1081] [D loss: 0.087643] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.303466] time: 1:03:47.513784\n",
      "(10, 128, 128, 3)\n",
      "0.93254834\n",
      "[Epoch 7/10] [Batch 186/1081] [D loss: 0.098890] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.969033] time: 1:03:48.142516\n",
      "(10, 128, 128, 3)\n",
      "0.9402279\n",
      "[Epoch 7/10] [Batch 187/1081] [D loss: 0.087915] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.819714] time: 1:03:48.793063\n",
      "(10, 128, 128, 3)\n",
      "0.9477775\n",
      "[Epoch 7/10] [Batch 188/1081] [D loss: 0.075081] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.527444] time: 1:03:49.478553\n",
      "(10, 128, 128, 3)\n",
      "0.91872436\n",
      "[Epoch 7/10] [Batch 189/1081] [D loss: 0.079598] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.683270] time: 1:03:50.158975\n",
      "(10, 128, 128, 3)\n",
      "0.9358976\n",
      "[Epoch 7/10] [Batch 190/1081] [D loss: 0.085781] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.511281] time: 1:03:50.793604\n",
      "(10, 128, 128, 3)\n",
      "0.9394939\n",
      "[Epoch 7/10] [Batch 191/1081] [D loss: 0.090431] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.833802] time: 1:03:51.462202\n",
      "(10, 128, 128, 3)\n",
      "0.8708494\n",
      "[Epoch 7/10] [Batch 192/1081] [D loss: 0.094951] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.757864] time: 1:03:52.090430\n",
      "(10, 128, 128, 3)\n",
      "0.9233677\n",
      "[Epoch 7/10] [Batch 193/1081] [D loss: 0.189892] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 5.105668] time: 1:03:52.728916\n",
      "(10, 128, 128, 3)\n",
      "0.91746205\n",
      "[Epoch 7/10] [Batch 194/1081] [D loss: 0.081474] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.653327] time: 1:03:53.409015\n",
      "(10, 128, 128, 3)\n",
      "0.9056354\n",
      "[Epoch 7/10] [Batch 195/1081] [D loss: 0.290345] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 4.591478] time: 1:03:54.058482\n",
      "(10, 128, 128, 3)\n",
      "0.9081392\n",
      "[Epoch 7/10] [Batch 196/1081] [D loss: 0.088139] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.315647] time: 1:03:54.721588\n",
      "(10, 128, 128, 3)\n",
      "0.8829689\n",
      "[Epoch 7/10] [Batch 197/1081] [D loss: 0.130419] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.795452] time: 1:03:55.438415\n",
      "(10, 128, 128, 3)\n",
      "0.9199629\n",
      "[Epoch 7/10] [Batch 198/1081] [D loss: 0.111254] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.013785] time: 1:03:56.091356\n",
      "(10, 128, 128, 3)\n",
      "0.9456925\n",
      "[Epoch 7/10] [Batch 199/1081] [D loss: 0.079028] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.046363] time: 1:03:56.704283\n",
      "(10, 128, 128, 3)\n",
      "0.9416501\n",
      "[Epoch 7/10] [Batch 200/1081] [D loss: 0.073288] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.527283] time: 1:03:57.316697\n",
      "(10, 128, 128, 3)\n",
      "0.92290777\n",
      "[Epoch 7/10] [Batch 201/1081] [D loss: 0.073609] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.141492] time: 1:03:58.061426\n",
      "(10, 128, 128, 3)\n",
      "0.91665107\n",
      "[Epoch 7/10] [Batch 202/1081] [D loss: 0.095536] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.784501] time: 1:03:58.676584\n",
      "(10, 128, 128, 3)\n",
      "0.8091894\n",
      "[Epoch 7/10] [Batch 203/1081] [D loss: 0.082484] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.056243] time: 1:03:59.376713\n",
      "(10, 128, 128, 3)\n",
      "0.9155151\n",
      "[Epoch 7/10] [Batch 204/1081] [D loss: 0.075437] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.785859] time: 1:04:00.079234\n",
      "(10, 128, 128, 3)\n",
      "0.8625216\n",
      "[Epoch 7/10] [Batch 205/1081] [D loss: 0.075714] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.975413] time: 1:04:00.763571\n",
      "(10, 128, 128, 3)\n",
      "0.92131966\n",
      "[Epoch 7/10] [Batch 206/1081] [D loss: 0.080251] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.350021] time: 1:04:01.385681\n",
      "(10, 128, 128, 3)\n",
      "0.9105616\n",
      "[Epoch 7/10] [Batch 207/1081] [D loss: 0.076207] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.185345] time: 1:04:02.058356\n",
      "(10, 128, 128, 3)\n",
      "0.93396837\n",
      "[Epoch 7/10] [Batch 208/1081] [D loss: 0.086127] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.812625] time: 1:04:02.706552\n",
      "(10, 128, 128, 3)\n",
      "0.9046821\n",
      "[Epoch 7/10] [Batch 209/1081] [D loss: 0.101238] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.684459] time: 1:04:03.412081\n",
      "(10, 128, 128, 3)\n",
      "0.816765\n",
      "[Epoch 7/10] [Batch 210/1081] [D loss: 0.073966] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.513186] time: 1:04:04.035955\n",
      "(10, 128, 128, 3)\n",
      "0.8652732\n",
      "[Epoch 7/10] [Batch 211/1081] [D loss: 0.121152] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.858222] time: 1:04:04.652020\n",
      "(10, 128, 128, 3)\n",
      "0.9247238\n",
      "[Epoch 7/10] [Batch 212/1081] [D loss: 0.078266] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.751360] time: 1:04:05.339569\n",
      "(10, 128, 128, 3)\n",
      "0.9544968\n",
      "[Epoch 7/10] [Batch 213/1081] [D loss: 0.079409] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.860752] time: 1:04:05.983152\n",
      "(10, 128, 128, 3)\n",
      "0.9127349\n",
      "[Epoch 7/10] [Batch 214/1081] [D loss: 0.094100] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.695765] time: 1:04:06.643394\n",
      "(10, 128, 128, 3)\n",
      "0.9053512\n",
      "[Epoch 7/10] [Batch 215/1081] [D loss: 0.119637] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.884673] time: 1:04:07.228560\n",
      "(10, 128, 128, 3)\n",
      "0.81539816\n",
      "[Epoch 7/10] [Batch 216/1081] [D loss: 0.106052] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.886109] time: 1:04:07.842093\n",
      "(10, 128, 128, 3)\n",
      "0.8487682\n",
      "[Epoch 7/10] [Batch 217/1081] [D loss: 0.087460] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.885499] time: 1:04:08.494524\n",
      "(10, 128, 128, 3)\n",
      "0.9021838\n",
      "[Epoch 7/10] [Batch 218/1081] [D loss: 0.089789] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.254073] time: 1:04:09.125574\n",
      "(10, 128, 128, 3)\n",
      "0.9021094\n",
      "[Epoch 7/10] [Batch 219/1081] [D loss: 0.111673] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.488641] time: 1:04:09.772182\n",
      "(10, 128, 128, 3)\n",
      "0.9311139\n",
      "[Epoch 7/10] [Batch 220/1081] [D loss: 0.173810] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.826066] time: 1:04:10.428866\n",
      "(10, 128, 128, 3)\n",
      "0.89105815\n",
      "[Epoch 7/10] [Batch 221/1081] [D loss: 0.083823] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.480171] time: 1:04:11.068192\n",
      "(10, 128, 128, 3)\n",
      "0.90947014\n",
      "[Epoch 7/10] [Batch 222/1081] [D loss: 0.083197] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.387606] time: 1:04:11.764270\n",
      "(10, 128, 128, 3)\n",
      "0.9209619\n",
      "[Epoch 7/10] [Batch 223/1081] [D loss: 0.386338] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 6.095300] time: 1:04:12.393937\n",
      "(10, 128, 128, 3)\n",
      "0.89278084\n",
      "[Epoch 7/10] [Batch 224/1081] [D loss: 0.096177] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.874591] time: 1:04:13.022151\n",
      "(10, 128, 128, 3)\n",
      "0.90195304\n",
      "[Epoch 7/10] [Batch 225/1081] [D loss: 0.109900] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.609070] time: 1:04:13.703437\n",
      "(10, 128, 128, 3)\n",
      "0.849087\n",
      "[Epoch 7/10] [Batch 226/1081] [D loss: 0.092637] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.562040] time: 1:04:14.307725\n",
      "(10, 128, 128, 3)\n",
      "0.95012814\n",
      "[Epoch 7/10] [Batch 227/1081] [D loss: 0.103197] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.661157] time: 1:04:14.971864\n",
      "(10, 128, 128, 3)\n",
      "0.90037996\n",
      "[Epoch 7/10] [Batch 228/1081] [D loss: 0.072747] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.564364] time: 1:04:15.565519\n",
      "(10, 128, 128, 3)\n",
      "0.9151056\n",
      "[Epoch 7/10] [Batch 229/1081] [D loss: 0.127537] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.135551] time: 1:04:16.207035\n",
      "(10, 128, 128, 3)\n",
      "0.9134167\n",
      "[Epoch 7/10] [Batch 230/1081] [D loss: 0.174903] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 4.375937] time: 1:04:16.820601\n",
      "(10, 128, 128, 3)\n",
      "0.9064699\n",
      "[Epoch 7/10] [Batch 231/1081] [D loss: 0.096370] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.564607] time: 1:04:17.519226\n",
      "(10, 128, 128, 3)\n",
      "0.8315897\n",
      "[Epoch 7/10] [Batch 232/1081] [D loss: 0.070966] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.848785] time: 1:04:18.208230\n",
      "(10, 128, 128, 3)\n",
      "0.96275026\n",
      "[Epoch 7/10] [Batch 233/1081] [D loss: 0.077274] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.639106] time: 1:04:18.873140\n",
      "(10, 128, 128, 3)\n",
      "0.94694585\n",
      "[Epoch 7/10] [Batch 234/1081] [D loss: 0.118703] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.934607] time: 1:04:19.515007\n",
      "(10, 128, 128, 3)\n",
      "0.9136521\n",
      "[Epoch 7/10] [Batch 235/1081] [D loss: 0.589296] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 5.898746] time: 1:04:20.247995\n",
      "(10, 128, 128, 3)\n",
      "0.83975554\n",
      "[Epoch 7/10] [Batch 236/1081] [D loss: 0.074099] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.341523] time: 1:04:20.876671\n",
      "(10, 128, 128, 3)\n",
      "0.9511842\n",
      "[Epoch 7/10] [Batch 237/1081] [D loss: 0.072547] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.229544] time: 1:04:21.531679\n",
      "(10, 128, 128, 3)\n",
      "0.89195967\n",
      "[Epoch 7/10] [Batch 238/1081] [D loss: 0.114628] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.518950] time: 1:04:22.192730\n",
      "(10, 128, 128, 3)\n",
      "0.9470573\n",
      "[Epoch 7/10] [Batch 239/1081] [D loss: 0.694201] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 4.358767] time: 1:04:22.853827\n",
      "(10, 128, 128, 3)\n",
      "0.9234225\n",
      "[Epoch 7/10] [Batch 240/1081] [D loss: 0.156110] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.547318] time: 1:04:23.494347\n",
      "(10, 128, 128, 3)\n",
      "0.8935414\n",
      "[Epoch 7/10] [Batch 241/1081] [D loss: 0.117339] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.467277] time: 1:04:24.165578\n",
      "(10, 128, 128, 3)\n",
      "0.883941\n",
      "[Epoch 7/10] [Batch 242/1081] [D loss: 0.119956] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.583919] time: 1:04:24.770465\n",
      "(10, 128, 128, 3)\n",
      "0.9170623\n",
      "[Epoch 7/10] [Batch 243/1081] [D loss: 0.164477] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.013671] time: 1:04:25.396796\n",
      "(10, 128, 128, 3)\n",
      "0.90777117\n",
      "[Epoch 7/10] [Batch 244/1081] [D loss: 0.099404] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.842461] time: 1:04:26.020834\n",
      "(10, 128, 128, 3)\n",
      "0.90376425\n",
      "[Epoch 7/10] [Batch 245/1081] [D loss: 0.163046] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.039505] time: 1:04:26.745536\n",
      "(10, 128, 128, 3)\n",
      "0.9017263\n",
      "[Epoch 7/10] [Batch 246/1081] [D loss: 0.305439] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 5.332694] time: 1:04:27.355480\n",
      "(10, 128, 128, 3)\n",
      "0.89691305\n",
      "[Epoch 7/10] [Batch 247/1081] [D loss: 0.114201] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.817368] time: 1:04:28.050009\n",
      "(10, 128, 128, 3)\n",
      "0.8787381\n",
      "[Epoch 7/10] [Batch 248/1081] [D loss: 0.386221] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 5.391629] time: 1:04:28.714684\n",
      "(10, 128, 128, 3)\n",
      "0.86123484\n",
      "[Epoch 7/10] [Batch 249/1081] [D loss: 0.106330] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.433517] time: 1:04:29.344240\n",
      "(10, 128, 128, 3)\n",
      "0.9010022\n",
      "[Epoch 7/10] [Batch 250/1081] [D loss: 0.081709] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.033136] time: 1:04:30.055283\n",
      "(10, 128, 128, 3)\n",
      "0.9047641\n",
      "[Epoch 7/10] [Batch 251/1081] [D loss: 0.164603] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 5.762256] time: 1:04:30.701526\n",
      "(10, 128, 128, 3)\n",
      "0.92662746\n",
      "[Epoch 7/10] [Batch 252/1081] [D loss: 0.107747] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.012076] time: 1:04:31.332629\n",
      "(10, 128, 128, 3)\n",
      "0.91160315\n",
      "[Epoch 7/10] [Batch 253/1081] [D loss: 0.085365] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.536045] time: 1:04:31.982599\n",
      "(10, 128, 128, 3)\n",
      "0.88913727\n",
      "[Epoch 7/10] [Batch 254/1081] [D loss: 0.241110] [D acc: 0.60 (0.20 real, 1.00 fake)] [G loss: 5.479855] time: 1:04:32.631033\n",
      "(10, 128, 128, 3)\n",
      "0.91769713\n",
      "[Epoch 7/10] [Batch 255/1081] [D loss: 0.099790] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.287191] time: 1:04:33.257883\n",
      "(10, 128, 128, 3)\n",
      "0.9223425\n",
      "[Epoch 7/10] [Batch 256/1081] [D loss: 0.122230] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.446932] time: 1:04:33.929960\n",
      "(10, 128, 128, 3)\n",
      "0.9435094\n",
      "[Epoch 7/10] [Batch 257/1081] [D loss: 0.154125] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.954960] time: 1:04:34.565324\n",
      "(10, 128, 128, 3)\n",
      "0.9112074\n",
      "[Epoch 7/10] [Batch 258/1081] [D loss: 0.201551] [D acc: 0.90 (0.90 real, 0.90 fake)] [G loss: 4.428661] time: 1:04:35.195779\n",
      "(10, 128, 128, 3)\n",
      "0.9196749\n",
      "[Epoch 7/10] [Batch 259/1081] [D loss: 0.127092] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 5.833667] time: 1:04:35.927768\n",
      "(10, 128, 128, 3)\n",
      "0.93862516\n",
      "[Epoch 7/10] [Batch 260/1081] [D loss: 0.096818] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.479049] time: 1:04:36.603936\n",
      "(10, 128, 128, 3)\n",
      "0.9103131\n",
      "[Epoch 7/10] [Batch 261/1081] [D loss: 0.121835] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.056828] time: 1:04:37.258427\n",
      "(10, 128, 128, 3)\n",
      "0.8584772\n",
      "[Epoch 7/10] [Batch 262/1081] [D loss: 0.080863] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.274000] time: 1:04:37.930499\n",
      "(10, 128, 128, 3)\n",
      "0.88064694\n",
      "[Epoch 7/10] [Batch 263/1081] [D loss: 0.098040] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.287068] time: 1:04:38.581967\n",
      "(10, 128, 128, 3)\n",
      "0.89536357\n",
      "[Epoch 7/10] [Batch 264/1081] [D loss: 0.080893] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.043545] time: 1:04:39.234326\n",
      "(10, 128, 128, 3)\n",
      "0.94391245\n",
      "[Epoch 7/10] [Batch 265/1081] [D loss: 0.094171] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.402106] time: 1:04:39.912415\n",
      "(10, 128, 128, 3)\n",
      "0.80915755\n",
      "[Epoch 7/10] [Batch 266/1081] [D loss: 0.110280] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.432419] time: 1:04:40.573735\n",
      "(10, 128, 128, 3)\n",
      "0.9037471\n",
      "[Epoch 7/10] [Batch 267/1081] [D loss: 0.135663] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.694943] time: 1:04:41.210371\n",
      "(10, 128, 128, 3)\n",
      "0.87206817\n",
      "[Epoch 7/10] [Batch 268/1081] [D loss: 0.134783] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.016723] time: 1:04:41.821057\n",
      "(10, 128, 128, 3)\n",
      "0.919491\n",
      "[Epoch 7/10] [Batch 269/1081] [D loss: 0.123969] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.815456] time: 1:04:42.515913\n",
      "(10, 128, 128, 3)\n",
      "0.91629356\n",
      "[Epoch 7/10] [Batch 270/1081] [D loss: 0.132876] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.120155] time: 1:04:43.149858\n",
      "(10, 128, 128, 3)\n",
      "0.96244335\n",
      "[Epoch 7/10] [Batch 271/1081] [D loss: 0.091611] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.453658] time: 1:04:43.811088\n",
      "(10, 128, 128, 3)\n",
      "0.9217436\n",
      "[Epoch 7/10] [Batch 272/1081] [D loss: 0.092581] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.607525] time: 1:04:44.470763\n",
      "(10, 128, 128, 3)\n",
      "0.8874232\n",
      "[Epoch 7/10] [Batch 273/1081] [D loss: 0.149852] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.420175] time: 1:04:45.141375\n",
      "(10, 128, 128, 3)\n",
      "0.8625578\n",
      "[Epoch 7/10] [Batch 274/1081] [D loss: 0.191446] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 4.093287] time: 1:04:45.785063\n",
      "(10, 128, 128, 3)\n",
      "0.8581223\n",
      "[Epoch 7/10] [Batch 275/1081] [D loss: 0.086767] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.957003] time: 1:04:46.442647\n",
      "(10, 128, 128, 3)\n",
      "0.91755104\n",
      "[Epoch 7/10] [Batch 276/1081] [D loss: 0.120138] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.485930] time: 1:04:47.097241\n",
      "(10, 128, 128, 3)\n",
      "0.92290133\n",
      "[Epoch 7/10] [Batch 277/1081] [D loss: 0.177972] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.656899] time: 1:04:47.755424\n",
      "(10, 128, 128, 3)\n",
      "0.88575506\n",
      "[Epoch 7/10] [Batch 278/1081] [D loss: 0.079001] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.629136] time: 1:04:48.433255\n",
      "(10, 128, 128, 3)\n",
      "0.9637992\n",
      "[Epoch 7/10] [Batch 279/1081] [D loss: 0.090784] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.900282] time: 1:04:49.090941\n",
      "(10, 128, 128, 3)\n",
      "0.8648579\n",
      "[Epoch 7/10] [Batch 280/1081] [D loss: 0.080297] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.377205] time: 1:04:49.735521\n",
      "(10, 128, 128, 3)\n",
      "0.9447705\n",
      "[Epoch 7/10] [Batch 281/1081] [D loss: 0.351396] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 7.158580] time: 1:04:50.451322\n",
      "(10, 128, 128, 3)\n",
      "0.88060075\n",
      "[Epoch 7/10] [Batch 282/1081] [D loss: 0.115338] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.601589] time: 1:04:51.064315\n",
      "(10, 128, 128, 3)\n",
      "0.92709213\n",
      "[Epoch 7/10] [Batch 283/1081] [D loss: 0.095308] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.302503] time: 1:04:51.717039\n",
      "(10, 128, 128, 3)\n",
      "0.9123955\n",
      "[Epoch 7/10] [Batch 284/1081] [D loss: 0.107057] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.152386] time: 1:04:52.338898\n",
      "(10, 128, 128, 3)\n",
      "0.92015165\n",
      "[Epoch 7/10] [Batch 285/1081] [D loss: 0.117685] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.205816] time: 1:04:52.978347\n",
      "(10, 128, 128, 3)\n",
      "0.8950255\n",
      "[Epoch 7/10] [Batch 286/1081] [D loss: 0.113411] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.052083] time: 1:04:53.617601\n",
      "(10, 128, 128, 3)\n",
      "0.96704125\n",
      "[Epoch 7/10] [Batch 287/1081] [D loss: 0.087827] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.552418] time: 1:04:54.265779\n",
      "(10, 128, 128, 3)\n",
      "0.9213434\n",
      "[Epoch 7/10] [Batch 288/1081] [D loss: 0.094370] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.652507] time: 1:04:54.887953\n",
      "(10, 128, 128, 3)\n",
      "0.8835408\n",
      "[Epoch 7/10] [Batch 289/1081] [D loss: 0.142301] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.516105] time: 1:04:55.524369\n",
      "(10, 128, 128, 3)\n",
      "0.9584122\n",
      "[Epoch 7/10] [Batch 290/1081] [D loss: 0.184848] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.676297] time: 1:04:56.158451\n",
      "(10, 128, 128, 3)\n",
      "0.9540763\n",
      "[Epoch 7/10] [Batch 291/1081] [D loss: 0.266783] [D acc: 0.65 (1.00 real, 0.30 fake)] [G loss: 5.603174] time: 1:04:56.833595\n",
      "(10, 128, 128, 3)\n",
      "0.9103914\n",
      "[Epoch 7/10] [Batch 292/1081] [D loss: 0.090197] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.360864] time: 1:04:57.445627\n",
      "(10, 128, 128, 3)\n",
      "0.85519916\n",
      "[Epoch 7/10] [Batch 293/1081] [D loss: 0.302059] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 5.897607] time: 1:04:58.149791\n",
      "(10, 128, 128, 3)\n",
      "0.9100372\n",
      "[Epoch 7/10] [Batch 294/1081] [D loss: 0.110559] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.404983] time: 1:04:58.804358\n",
      "(10, 128, 128, 3)\n",
      "0.91970223\n",
      "[Epoch 7/10] [Batch 295/1081] [D loss: 0.090012] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.947740] time: 1:04:59.450853\n",
      "(10, 128, 128, 3)\n",
      "0.9197707\n",
      "[Epoch 7/10] [Batch 296/1081] [D loss: 0.232478] [D acc: 0.55 (0.10 real, 1.00 fake)] [G loss: 5.196514] time: 1:05:00.153109\n",
      "(10, 128, 128, 3)\n",
      "0.9078917\n",
      "[Epoch 7/10] [Batch 297/1081] [D loss: 0.158045] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.704238] time: 1:05:00.809375\n",
      "(10, 128, 128, 3)\n",
      "0.93076915\n",
      "[Epoch 7/10] [Batch 298/1081] [D loss: 0.083036] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.567790] time: 1:05:01.472843\n",
      "(10, 128, 128, 3)\n",
      "0.947931\n",
      "[Epoch 7/10] [Batch 299/1081] [D loss: 0.171636] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 4.997687] time: 1:05:02.109974\n",
      "(10, 128, 128, 3)\n",
      "0.97450763\n",
      "[Epoch 7/10] [Batch 300/1081] [D loss: 0.112762] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.676869] time: 1:05:02.748176\n",
      "(10, 128, 128, 3)\n",
      "0.91109085\n",
      "[Epoch 7/10] [Batch 301/1081] [D loss: 0.080682] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.586689] time: 1:05:03.382425\n",
      "(10, 128, 128, 3)\n",
      "0.96564573\n",
      "[Epoch 7/10] [Batch 302/1081] [D loss: 0.081749] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.772154] time: 1:05:04.024378\n",
      "(10, 128, 128, 3)\n",
      "0.901797\n",
      "[Epoch 7/10] [Batch 303/1081] [D loss: 0.113573] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.039808] time: 1:05:04.665024\n",
      "(10, 128, 128, 3)\n",
      "0.9017747\n",
      "[Epoch 7/10] [Batch 304/1081] [D loss: 0.076354] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.600226] time: 1:05:05.307093\n",
      "(10, 128, 128, 3)\n",
      "0.90852064\n",
      "[Epoch 7/10] [Batch 305/1081] [D loss: 0.508425] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 6.922978] time: 1:05:06.034626\n",
      "(10, 128, 128, 3)\n",
      "0.9097325\n",
      "[Epoch 7/10] [Batch 306/1081] [D loss: 0.109836] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.887160] time: 1:05:06.663993\n",
      "(10, 128, 128, 3)\n",
      "0.93293905\n",
      "[Epoch 7/10] [Batch 307/1081] [D loss: 0.098186] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.952308] time: 1:05:07.297404\n",
      "(10, 128, 128, 3)\n",
      "0.87888736\n",
      "[Epoch 7/10] [Batch 308/1081] [D loss: 0.077484] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.426844] time: 1:05:07.911380\n",
      "(10, 128, 128, 3)\n",
      "0.9756412\n",
      "[Epoch 7/10] [Batch 309/1081] [D loss: 0.197323] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 4.624925] time: 1:05:08.555954\n",
      "(10, 128, 128, 3)\n",
      "0.9192343\n",
      "[Epoch 7/10] [Batch 310/1081] [D loss: 0.271394] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 4.648355] time: 1:05:09.177069\n",
      "(10, 128, 128, 3)\n",
      "0.910209\n",
      "[Epoch 7/10] [Batch 311/1081] [D loss: 0.086008] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.608594] time: 1:05:09.797065\n",
      "(10, 128, 128, 3)\n",
      "0.9418009\n",
      "[Epoch 7/10] [Batch 312/1081] [D loss: 0.081355] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.821547] time: 1:05:10.461653\n",
      "(10, 128, 128, 3)\n",
      "0.93028516\n",
      "[Epoch 7/10] [Batch 313/1081] [D loss: 0.094612] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.335483] time: 1:05:11.165021\n",
      "(10, 128, 128, 3)\n",
      "0.9373242\n",
      "[Epoch 7/10] [Batch 314/1081] [D loss: 0.082714] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.264970] time: 1:05:11.820194\n",
      "(10, 128, 128, 3)\n",
      "0.9229092\n",
      "[Epoch 7/10] [Batch 315/1081] [D loss: 0.092041] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.658610] time: 1:05:12.468283\n",
      "(10, 128, 128, 3)\n",
      "0.91481686\n",
      "[Epoch 7/10] [Batch 316/1081] [D loss: 0.094633] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.126565] time: 1:05:13.102105\n",
      "(10, 128, 128, 3)\n",
      "0.91008884\n",
      "[Epoch 7/10] [Batch 317/1081] [D loss: 0.161410] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 4.511802] time: 1:05:13.743294\n",
      "(10, 128, 128, 3)\n",
      "0.90699095\n",
      "[Epoch 7/10] [Batch 318/1081] [D loss: 0.134775] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 4.659445] time: 1:05:14.426188\n",
      "(10, 128, 128, 3)\n",
      "0.92638654\n",
      "[Epoch 7/10] [Batch 319/1081] [D loss: 0.083017] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.232227] time: 1:05:15.069388\n",
      "(10, 128, 128, 3)\n",
      "0.916064\n",
      "[Epoch 7/10] [Batch 320/1081] [D loss: 0.101011] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.787292] time: 1:05:15.707245\n",
      "(10, 128, 128, 3)\n",
      "0.9481862\n",
      "[Epoch 7/10] [Batch 321/1081] [D loss: 0.091650] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.577085] time: 1:05:16.399891\n",
      "(10, 128, 128, 3)\n",
      "0.95413786\n",
      "[Epoch 7/10] [Batch 322/1081] [D loss: 0.076257] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.858046] time: 1:05:17.015653\n",
      "(10, 128, 128, 3)\n",
      "0.92914367\n",
      "[Epoch 7/10] [Batch 323/1081] [D loss: 0.086163] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.842879] time: 1:05:17.612350\n",
      "(10, 128, 128, 3)\n",
      "0.8905025\n",
      "[Epoch 7/10] [Batch 324/1081] [D loss: 0.083409] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.487542] time: 1:05:18.300900\n",
      "(10, 128, 128, 3)\n",
      "0.92387086\n",
      "[Epoch 7/10] [Batch 325/1081] [D loss: 0.142948] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 5.575416] time: 1:05:18.970891\n",
      "(10, 128, 128, 3)\n",
      "0.9475622\n",
      "[Epoch 7/10] [Batch 326/1081] [D loss: 0.133162] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.158543] time: 1:05:19.645800\n",
      "(10, 128, 128, 3)\n",
      "0.90202075\n",
      "[Epoch 7/10] [Batch 327/1081] [D loss: 0.076780] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.038622] time: 1:05:20.282295\n",
      "(10, 128, 128, 3)\n",
      "0.92338306\n",
      "[Epoch 7/10] [Batch 328/1081] [D loss: 0.142392] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.162781] time: 1:05:20.900032\n",
      "(10, 128, 128, 3)\n",
      "0.89437014\n",
      "[Epoch 7/10] [Batch 329/1081] [D loss: 0.103973] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.851192] time: 1:05:21.581035\n",
      "(10, 128, 128, 3)\n",
      "0.91025144\n",
      "[Epoch 7/10] [Batch 330/1081] [D loss: 0.104488] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.257471] time: 1:05:22.166610\n",
      "(10, 128, 128, 3)\n",
      "0.94614536\n",
      "[Epoch 7/10] [Batch 331/1081] [D loss: 0.079942] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.771761] time: 1:05:22.881434\n",
      "(10, 128, 128, 3)\n",
      "0.8843608\n",
      "[Epoch 7/10] [Batch 332/1081] [D loss: 0.088790] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.759935] time: 1:05:23.509700\n",
      "(10, 128, 128, 3)\n",
      "0.8975778\n",
      "[Epoch 7/10] [Batch 333/1081] [D loss: 0.079487] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.262379] time: 1:05:24.159343\n",
      "(10, 128, 128, 3)\n",
      "0.9274449\n",
      "[Epoch 7/10] [Batch 334/1081] [D loss: 0.093844] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.489364] time: 1:05:24.790418\n",
      "(10, 128, 128, 3)\n",
      "0.86636287\n",
      "[Epoch 7/10] [Batch 335/1081] [D loss: 0.080096] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.702749] time: 1:05:25.451201\n",
      "(10, 128, 128, 3)\n",
      "0.9296248\n",
      "[Epoch 7/10] [Batch 336/1081] [D loss: 0.159294] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.224876] time: 1:05:26.104634\n",
      "(10, 128, 128, 3)\n",
      "0.92441136\n",
      "[Epoch 7/10] [Batch 337/1081] [D loss: 0.099017] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.436819] time: 1:05:26.790369\n",
      "(10, 128, 128, 3)\n",
      "0.8838989\n",
      "[Epoch 7/10] [Batch 338/1081] [D loss: 0.075966] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.000414] time: 1:05:27.410054\n",
      "(10, 128, 128, 3)\n",
      "0.9416941\n",
      "[Epoch 7/10] [Batch 339/1081] [D loss: 0.172816] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 4.972164] time: 1:05:28.050249\n",
      "(10, 128, 128, 3)\n",
      "0.91120225\n",
      "[Epoch 7/10] [Batch 340/1081] [D loss: 0.254231] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.386043] time: 1:05:28.728952\n",
      "(10, 128, 128, 3)\n",
      "0.91170424\n",
      "[Epoch 7/10] [Batch 341/1081] [D loss: 0.151277] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.062939] time: 1:05:29.370799\n",
      "(10, 128, 128, 3)\n",
      "0.9229694\n",
      "[Epoch 7/10] [Batch 342/1081] [D loss: 0.134864] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 5.168066] time: 1:05:30.030693\n",
      "(10, 128, 128, 3)\n",
      "0.9186918\n",
      "[Epoch 7/10] [Batch 343/1081] [D loss: 0.089446] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.929779] time: 1:05:30.598234\n",
      "(10, 128, 128, 3)\n",
      "0.93068916\n",
      "[Epoch 7/10] [Batch 344/1081] [D loss: 0.137982] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.125606] time: 1:05:31.178567\n",
      "(10, 128, 128, 3)\n",
      "0.9275856\n",
      "[Epoch 7/10] [Batch 345/1081] [D loss: 0.074676] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.709425] time: 1:05:31.753847\n",
      "(10, 128, 128, 3)\n",
      "0.8868094\n",
      "[Epoch 7/10] [Batch 346/1081] [D loss: 0.080185] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.140013] time: 1:05:32.320681\n",
      "(10, 128, 128, 3)\n",
      "0.9118983\n",
      "[Epoch 7/10] [Batch 347/1081] [D loss: 0.293366] [D acc: 0.55 (0.10 real, 1.00 fake)] [G loss: 4.154120] time: 1:05:32.855736\n",
      "(10, 128, 128, 3)\n",
      "0.8445304\n",
      "[Epoch 7/10] [Batch 348/1081] [D loss: 0.088027] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.282140] time: 1:05:33.393735\n",
      "(10, 128, 128, 3)\n",
      "0.90740913\n",
      "[Epoch 7/10] [Batch 349/1081] [D loss: 0.371070] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 5.122913] time: 1:05:33.997240\n",
      "(10, 128, 128, 3)\n",
      "0.88682866\n",
      "[Epoch 7/10] [Batch 350/1081] [D loss: 0.091552] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.156811] time: 1:05:34.565978\n",
      "(10, 128, 128, 3)\n",
      "0.9055249\n",
      "[Epoch 7/10] [Batch 351/1081] [D loss: 0.127295] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.158434] time: 1:05:35.072510\n",
      "(10, 128, 128, 3)\n",
      "0.92281383\n",
      "[Epoch 7/10] [Batch 352/1081] [D loss: 0.358916] [D acc: 0.35 (0.50 real, 0.20 fake)] [G loss: 5.020196] time: 1:05:35.616277\n",
      "(10, 128, 128, 3)\n",
      "0.93211144\n",
      "[Epoch 7/10] [Batch 353/1081] [D loss: 0.129099] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.132308] time: 1:05:36.204965\n",
      "(10, 128, 128, 3)\n",
      "0.8757517\n",
      "[Epoch 7/10] [Batch 354/1081] [D loss: 0.084519] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.779105] time: 1:05:36.746467\n",
      "(10, 128, 128, 3)\n",
      "0.8353463\n",
      "[Epoch 7/10] [Batch 355/1081] [D loss: 0.156332] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.189959] time: 1:05:37.291390\n",
      "(10, 128, 128, 3)\n",
      "0.89612967\n",
      "[Epoch 7/10] [Batch 356/1081] [D loss: 0.171114] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.638526] time: 1:05:37.838496\n",
      "(10, 128, 128, 3)\n",
      "0.89143246\n",
      "[Epoch 7/10] [Batch 357/1081] [D loss: 0.215730] [D acc: 0.80 (1.00 real, 0.60 fake)] [G loss: 5.389423] time: 1:05:38.393294\n",
      "(10, 128, 128, 3)\n",
      "0.9829843\n",
      "[Epoch 7/10] [Batch 358/1081] [D loss: 0.093656] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.618993] time: 1:05:38.961920\n",
      "(10, 128, 128, 3)\n",
      "0.8946454\n",
      "[Epoch 7/10] [Batch 359/1081] [D loss: 0.086209] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.176960] time: 1:05:39.498534\n",
      "(10, 128, 128, 3)\n",
      "0.9035859\n",
      "[Epoch 7/10] [Batch 360/1081] [D loss: 0.107369] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.715985] time: 1:05:40.044908\n",
      "(10, 128, 128, 3)\n",
      "0.9403064\n",
      "[Epoch 7/10] [Batch 361/1081] [D loss: 0.152578] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.370185] time: 1:05:40.588612\n",
      "(10, 128, 128, 3)\n",
      "0.9155697\n",
      "[Epoch 7/10] [Batch 362/1081] [D loss: 0.128868] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.979748] time: 1:05:41.154008\n",
      "(10, 128, 128, 3)\n",
      "0.9182051\n",
      "[Epoch 7/10] [Batch 363/1081] [D loss: 0.145401] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.425061] time: 1:05:41.685713\n",
      "(10, 128, 128, 3)\n",
      "0.9239357\n",
      "[Epoch 7/10] [Batch 364/1081] [D loss: 0.084813] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.806853] time: 1:05:42.246527\n",
      "(10, 128, 128, 3)\n",
      "0.9120579\n",
      "[Epoch 7/10] [Batch 365/1081] [D loss: 0.076811] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.742541] time: 1:05:42.823633\n",
      "(10, 128, 128, 3)\n",
      "0.8487632\n",
      "[Epoch 7/10] [Batch 366/1081] [D loss: 0.127709] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 5.555785] time: 1:05:43.373210\n",
      "(10, 128, 128, 3)\n",
      "0.88430214\n",
      "[Epoch 7/10] [Batch 367/1081] [D loss: 0.084664] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.107056] time: 1:05:43.919242\n",
      "(10, 128, 128, 3)\n",
      "0.90620375\n",
      "[Epoch 7/10] [Batch 368/1081] [D loss: 0.081148] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.618936] time: 1:05:44.494705\n",
      "(10, 128, 128, 3)\n",
      "0.91269904\n",
      "[Epoch 7/10] [Batch 369/1081] [D loss: 0.082539] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.082129] time: 1:05:45.097154\n",
      "(10, 128, 128, 3)\n",
      "0.9411585\n",
      "[Epoch 7/10] [Batch 370/1081] [D loss: 0.657246] [D acc: 0.15 (0.30 real, 0.00 fake)] [G loss: 6.554915] time: 1:05:45.690135\n",
      "(10, 128, 128, 3)\n",
      "0.9196665\n",
      "[Epoch 7/10] [Batch 371/1081] [D loss: 0.205255] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 5.687777] time: 1:05:46.231838\n",
      "(10, 128, 128, 3)\n",
      "0.9576962\n",
      "[Epoch 7/10] [Batch 372/1081] [D loss: 0.224975] [D acc: 0.80 (1.00 real, 0.60 fake)] [G loss: 5.003116] time: 1:05:46.784622\n",
      "(10, 128, 128, 3)\n",
      "0.9005392\n",
      "[Epoch 7/10] [Batch 373/1081] [D loss: 0.114063] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.400512] time: 1:05:47.347918\n",
      "(10, 128, 128, 3)\n",
      "0.8968239\n",
      "[Epoch 7/10] [Batch 374/1081] [D loss: 0.275839] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 4.341185] time: 1:05:47.917755\n",
      "(10, 128, 128, 3)\n",
      "0.8979853\n",
      "[Epoch 7/10] [Batch 375/1081] [D loss: 0.110984] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.192447] time: 1:05:48.486871\n",
      "(10, 128, 128, 3)\n",
      "0.8462265\n",
      "[Epoch 7/10] [Batch 376/1081] [D loss: 0.092013] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.559328] time: 1:05:49.074897\n",
      "(10, 128, 128, 3)\n",
      "0.9392988\n",
      "[Epoch 7/10] [Batch 377/1081] [D loss: 0.182879] [D acc: 0.90 (1.00 real, 0.80 fake)] [G loss: 6.231057] time: 1:05:49.677348\n",
      "(10, 128, 128, 3)\n",
      "0.9158482\n",
      "[Epoch 7/10] [Batch 378/1081] [D loss: 0.184676] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.016685] time: 1:05:50.285151\n",
      "(10, 128, 128, 3)\n",
      "0.91424537\n",
      "[Epoch 7/10] [Batch 379/1081] [D loss: 0.223087] [D acc: 0.60 (1.00 real, 0.20 fake)] [G loss: 6.402648] time: 1:05:50.970520\n",
      "(10, 128, 128, 3)\n",
      "0.9042141\n",
      "[Epoch 7/10] [Batch 380/1081] [D loss: 0.091530] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.337250] time: 1:05:51.638844\n",
      "(10, 128, 128, 3)\n",
      "0.90393066\n",
      "[Epoch 7/10] [Batch 381/1081] [D loss: 0.082504] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.829892] time: 1:05:52.301396\n",
      "(10, 128, 128, 3)\n",
      "0.8951077\n",
      "[Epoch 7/10] [Batch 382/1081] [D loss: 0.078419] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.222654] time: 1:05:52.943821\n",
      "(10, 128, 128, 3)\n",
      "0.9260672\n",
      "[Epoch 7/10] [Batch 383/1081] [D loss: 0.245277] [D acc: 0.65 (0.30 real, 1.00 fake)] [G loss: 5.653673] time: 1:05:53.640854\n",
      "(10, 128, 128, 3)\n",
      "0.90019196\n",
      "[Epoch 7/10] [Batch 384/1081] [D loss: 0.102750] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.734454] time: 1:05:54.309528\n",
      "(10, 128, 128, 3)\n",
      "0.9144508\n",
      "[Epoch 7/10] [Batch 385/1081] [D loss: 0.109765] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.883079] time: 1:05:54.965680\n",
      "(10, 128, 128, 3)\n",
      "0.87555486\n",
      "[Epoch 7/10] [Batch 386/1081] [D loss: 0.132848] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.039443] time: 1:05:55.648328\n",
      "(10, 128, 128, 3)\n",
      "0.8990152\n",
      "[Epoch 7/10] [Batch 387/1081] [D loss: 0.214406] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.257139] time: 1:05:56.295925\n",
      "(10, 128, 128, 3)\n",
      "0.8396197\n",
      "[Epoch 7/10] [Batch 388/1081] [D loss: 0.096566] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.824597] time: 1:05:57.006359\n",
      "(10, 128, 128, 3)\n",
      "0.9494652\n",
      "[Epoch 7/10] [Batch 389/1081] [D loss: 0.076159] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.028666] time: 1:05:57.661536\n",
      "(10, 128, 128, 3)\n",
      "0.88855594\n",
      "[Epoch 7/10] [Batch 390/1081] [D loss: 0.119561] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.724281] time: 1:05:58.287596\n",
      "(10, 128, 128, 3)\n",
      "0.9160865\n",
      "[Epoch 7/10] [Batch 391/1081] [D loss: 0.082779] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.756571] time: 1:05:58.935086\n",
      "(10, 128, 128, 3)\n",
      "0.8557396\n",
      "[Epoch 7/10] [Batch 392/1081] [D loss: 0.078535] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.480630] time: 1:05:59.614180\n",
      "(10, 128, 128, 3)\n",
      "0.9054351\n",
      "[Epoch 7/10] [Batch 393/1081] [D loss: 0.140580] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 4.571942] time: 1:06:00.298353\n",
      "(10, 128, 128, 3)\n",
      "0.9117155\n",
      "[Epoch 7/10] [Batch 394/1081] [D loss: 0.121479] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.251042] time: 1:06:00.977138\n",
      "(10, 128, 128, 3)\n",
      "0.89634037\n",
      "[Epoch 7/10] [Batch 395/1081] [D loss: 0.288424] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 3.925058] time: 1:06:01.612597\n",
      "(10, 128, 128, 3)\n",
      "0.9466832\n",
      "[Epoch 7/10] [Batch 396/1081] [D loss: 0.120568] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.677709] time: 1:06:02.283749\n",
      "(10, 128, 128, 3)\n",
      "0.9211752\n",
      "[Epoch 7/10] [Batch 397/1081] [D loss: 0.080078] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.243552] time: 1:06:02.959848\n",
      "(10, 128, 128, 3)\n",
      "0.9305201\n",
      "[Epoch 7/10] [Batch 398/1081] [D loss: 0.081392] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.701878] time: 1:06:03.598013\n",
      "(10, 128, 128, 3)\n",
      "0.903271\n",
      "[Epoch 7/10] [Batch 399/1081] [D loss: 0.077588] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.547377] time: 1:06:04.247792\n",
      "(10, 128, 128, 3)\n",
      "0.8781236\n",
      "[Epoch 7/10] [Batch 400/1081] [D loss: 0.155281] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.552161] time: 1:06:04.816779\n",
      "(10, 128, 128, 3)\n",
      "0.91089743\n",
      "[Epoch 7/10] [Batch 401/1081] [D loss: 0.074522] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.300429] time: 1:06:05.438297\n",
      "(10, 128, 128, 3)\n",
      "0.9180321\n",
      "[Epoch 7/10] [Batch 402/1081] [D loss: 0.094109] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.595836] time: 1:06:06.139445\n",
      "(10, 128, 128, 3)\n",
      "0.8829617\n",
      "[Epoch 7/10] [Batch 403/1081] [D loss: 0.086384] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.554416] time: 1:06:06.726491\n",
      "(10, 128, 128, 3)\n",
      "0.88599426\n",
      "[Epoch 7/10] [Batch 404/1081] [D loss: 0.084513] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.493287] time: 1:06:07.410484\n",
      "(10, 128, 128, 3)\n",
      "0.91584134\n",
      "[Epoch 7/10] [Batch 405/1081] [D loss: 0.111615] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.240973] time: 1:06:08.071330\n",
      "(10, 128, 128, 3)\n",
      "0.90915346\n",
      "[Epoch 7/10] [Batch 406/1081] [D loss: 0.115569] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.181334] time: 1:06:08.711738\n",
      "(10, 128, 128, 3)\n",
      "0.9004197\n",
      "[Epoch 7/10] [Batch 407/1081] [D loss: 0.106227] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.092318] time: 1:06:09.344782\n",
      "(10, 128, 128, 3)\n",
      "0.9167293\n",
      "[Epoch 7/10] [Batch 408/1081] [D loss: 0.104407] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.204381] time: 1:06:09.979498\n",
      "(10, 128, 128, 3)\n",
      "0.9254825\n",
      "[Epoch 7/10] [Batch 409/1081] [D loss: 0.108847] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.554813] time: 1:06:10.669046\n",
      "(10, 128, 128, 3)\n",
      "0.91308576\n",
      "[Epoch 7/10] [Batch 410/1081] [D loss: 0.154549] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.764153] time: 1:06:11.303162\n",
      "(10, 128, 128, 3)\n",
      "0.9411082\n",
      "[Epoch 7/10] [Batch 411/1081] [D loss: 0.091925] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.213036] time: 1:06:11.940945\n",
      "(10, 128, 128, 3)\n",
      "0.9308049\n",
      "[Epoch 7/10] [Batch 412/1081] [D loss: 0.185072] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.137531] time: 1:06:12.547941\n",
      "(10, 128, 128, 3)\n",
      "0.92321366\n",
      "[Epoch 7/10] [Batch 413/1081] [D loss: 0.154129] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.421983] time: 1:06:13.149331\n",
      "(10, 128, 128, 3)\n",
      "0.9158914\n",
      "[Epoch 7/10] [Batch 414/1081] [D loss: 0.078655] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.427627] time: 1:06:13.805154\n",
      "(10, 128, 128, 3)\n",
      "0.94483685\n",
      "[Epoch 7/10] [Batch 415/1081] [D loss: 0.078113] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.648987] time: 1:06:14.432138\n",
      "(10, 128, 128, 3)\n",
      "0.92967963\n",
      "[Epoch 7/10] [Batch 416/1081] [D loss: 0.088959] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.983804] time: 1:06:15.124260\n",
      "(10, 128, 128, 3)\n",
      "0.9033568\n",
      "[Epoch 7/10] [Batch 417/1081] [D loss: 0.088415] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.988709] time: 1:06:15.747159\n",
      "(10, 128, 128, 3)\n",
      "0.9464081\n",
      "[Epoch 7/10] [Batch 418/1081] [D loss: 0.084709] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.237512] time: 1:06:16.406932\n",
      "(10, 128, 128, 3)\n",
      "0.9107003\n",
      "[Epoch 7/10] [Batch 419/1081] [D loss: 0.082020] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.137152] time: 1:06:17.077972\n",
      "(10, 128, 128, 3)\n",
      "0.8971538\n",
      "[Epoch 7/10] [Batch 420/1081] [D loss: 0.073524] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.955046] time: 1:06:17.792908\n",
      "(10, 128, 128, 3)\n",
      "0.92660123\n",
      "[Epoch 7/10] [Batch 421/1081] [D loss: 0.078954] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.432171] time: 1:06:18.489027\n",
      "(10, 128, 128, 3)\n",
      "0.8870631\n",
      "[Epoch 7/10] [Batch 422/1081] [D loss: 0.164256] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.937932] time: 1:06:19.112977\n",
      "(10, 128, 128, 3)\n",
      "0.9168248\n",
      "[Epoch 7/10] [Batch 423/1081] [D loss: 0.107287] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.469851] time: 1:06:19.754232\n",
      "(10, 128, 128, 3)\n",
      "0.8921952\n",
      "[Epoch 7/10] [Batch 424/1081] [D loss: 0.138329] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.298103] time: 1:06:20.454496\n",
      "(10, 128, 128, 3)\n",
      "0.88635564\n",
      "[Epoch 7/10] [Batch 425/1081] [D loss: 0.090225] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.688552] time: 1:06:21.108078\n",
      "(10, 128, 128, 3)\n",
      "0.92561436\n",
      "[Epoch 7/10] [Batch 426/1081] [D loss: 0.181407] [D acc: 0.90 (1.00 real, 0.80 fake)] [G loss: 5.719427] time: 1:06:21.730315\n",
      "(10, 128, 128, 3)\n",
      "0.9182958\n",
      "[Epoch 7/10] [Batch 427/1081] [D loss: 0.089304] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.486640] time: 1:06:22.426455\n",
      "(10, 128, 128, 3)\n",
      "0.91424036\n",
      "[Epoch 7/10] [Batch 428/1081] [D loss: 0.086067] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.857301] time: 1:06:23.043206\n",
      "(10, 128, 128, 3)\n",
      "0.8615832\n",
      "[Epoch 7/10] [Batch 429/1081] [D loss: 0.076453] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.143816] time: 1:06:23.670792\n",
      "(10, 128, 128, 3)\n",
      "0.9419494\n",
      "[Epoch 7/10] [Batch 430/1081] [D loss: 0.157495] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.411244] time: 1:06:24.348002\n",
      "(10, 128, 128, 3)\n",
      "0.874027\n",
      "[Epoch 7/10] [Batch 431/1081] [D loss: 0.108611] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.375864] time: 1:06:24.978551\n",
      "(10, 128, 128, 3)\n",
      "0.91303873\n",
      "[Epoch 7/10] [Batch 432/1081] [D loss: 0.126021] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.156342] time: 1:06:25.615317\n",
      "(10, 128, 128, 3)\n",
      "0.8333192\n",
      "[Epoch 7/10] [Batch 433/1081] [D loss: 0.126074] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.400173] time: 1:06:26.254501\n",
      "(10, 128, 128, 3)\n",
      "0.87517613\n",
      "[Epoch 7/10] [Batch 434/1081] [D loss: 0.090748] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.413005] time: 1:06:26.932594\n",
      "(10, 128, 128, 3)\n",
      "0.9107949\n",
      "[Epoch 7/10] [Batch 435/1081] [D loss: 0.147741] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.414067] time: 1:06:27.562160\n",
      "(10, 128, 128, 3)\n",
      "0.9075448\n",
      "[Epoch 7/10] [Batch 436/1081] [D loss: 0.356756] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 4.872959] time: 1:06:28.166936\n",
      "(10, 128, 128, 3)\n",
      "0.8914399\n",
      "[Epoch 7/10] [Batch 437/1081] [D loss: 0.102464] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.036021] time: 1:06:28.875621\n",
      "(10, 128, 128, 3)\n",
      "0.9036334\n",
      "[Epoch 7/10] [Batch 438/1081] [D loss: 0.113950] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.927104] time: 1:06:29.504997\n",
      "(10, 128, 128, 3)\n",
      "0.9479487\n",
      "[Epoch 7/10] [Batch 439/1081] [D loss: 0.124367] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.686901] time: 1:06:30.131306\n",
      "(10, 128, 128, 3)\n",
      "0.8944433\n",
      "[Epoch 7/10] [Batch 440/1081] [D loss: 0.076440] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.525267] time: 1:06:30.771862\n",
      "(10, 128, 128, 3)\n",
      "0.8435817\n",
      "[Epoch 7/10] [Batch 441/1081] [D loss: 0.102716] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.783397] time: 1:06:31.465364\n",
      "(10, 128, 128, 3)\n",
      "0.9704893\n",
      "[Epoch 7/10] [Batch 442/1081] [D loss: 0.078294] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.461854] time: 1:06:32.090444\n",
      "(10, 128, 128, 3)\n",
      "0.926815\n",
      "[Epoch 7/10] [Batch 443/1081] [D loss: 0.080406] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.352181] time: 1:06:32.726465\n",
      "(10, 128, 128, 3)\n",
      "0.9587818\n",
      "[Epoch 7/10] [Batch 444/1081] [D loss: 0.096140] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.342780] time: 1:06:33.406252\n",
      "(10, 128, 128, 3)\n",
      "0.9523639\n",
      "[Epoch 7/10] [Batch 445/1081] [D loss: 0.094580] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.090110] time: 1:06:34.065986\n",
      "(10, 128, 128, 3)\n",
      "0.8805534\n",
      "[Epoch 7/10] [Batch 446/1081] [D loss: 0.091226] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.512180] time: 1:06:34.754393\n",
      "(10, 128, 128, 3)\n",
      "0.9428285\n",
      "[Epoch 7/10] [Batch 447/1081] [D loss: 0.147296] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.783281] time: 1:06:35.419598\n",
      "(10, 128, 128, 3)\n",
      "0.9296549\n",
      "[Epoch 7/10] [Batch 448/1081] [D loss: 0.086450] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.984247] time: 1:06:36.054497\n",
      "(10, 128, 128, 3)\n",
      "0.89742094\n",
      "[Epoch 7/10] [Batch 449/1081] [D loss: 0.078742] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.233497] time: 1:06:36.680459\n",
      "(10, 128, 128, 3)\n",
      "0.89722246\n",
      "[Epoch 7/10] [Batch 450/1081] [D loss: 0.156490] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.391700] time: 1:06:37.297925\n",
      "(10, 128, 128, 3)\n",
      "0.8824644\n",
      "[Epoch 7/10] [Batch 451/1081] [D loss: 0.086061] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.074427] time: 1:06:37.916553\n",
      "(10, 128, 128, 3)\n",
      "0.88254184\n",
      "[Epoch 7/10] [Batch 452/1081] [D loss: 0.075076] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.484519] time: 1:06:38.536847\n",
      "(10, 128, 128, 3)\n",
      "0.8839321\n",
      "[Epoch 7/10] [Batch 453/1081] [D loss: 0.235307] [D acc: 0.55 (1.00 real, 0.10 fake)] [G loss: 5.223279] time: 1:06:39.263171\n",
      "(10, 128, 128, 3)\n",
      "0.92221147\n",
      "[Epoch 7/10] [Batch 454/1081] [D loss: 0.080661] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.061942] time: 1:06:39.903110\n",
      "(10, 128, 128, 3)\n",
      "0.87665224\n",
      "[Epoch 7/10] [Batch 455/1081] [D loss: 0.080197] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.507764] time: 1:06:40.534004\n",
      "(10, 128, 128, 3)\n",
      "0.92053646\n",
      "[Epoch 7/10] [Batch 456/1081] [D loss: 0.218897] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 5.338521] time: 1:06:41.142546\n",
      "(10, 128, 128, 3)\n",
      "0.8942763\n",
      "[Epoch 7/10] [Batch 457/1081] [D loss: 0.120491] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.949693] time: 1:06:41.885536\n",
      "(10, 128, 128, 3)\n",
      "0.8827698\n",
      "[Epoch 7/10] [Batch 458/1081] [D loss: 0.077468] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.901053] time: 1:06:42.550874\n",
      "(10, 128, 128, 3)\n",
      "0.91880035\n",
      "[Epoch 7/10] [Batch 459/1081] [D loss: 0.086598] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.731029] time: 1:06:43.171402\n",
      "(10, 128, 128, 3)\n",
      "0.92792296\n",
      "[Epoch 7/10] [Batch 460/1081] [D loss: 0.072041] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.947623] time: 1:06:43.800951\n",
      "(10, 128, 128, 3)\n",
      "0.944573\n",
      "[Epoch 7/10] [Batch 461/1081] [D loss: 0.095988] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.819089] time: 1:06:44.488336\n",
      "(10, 128, 128, 3)\n",
      "0.94714737\n",
      "[Epoch 7/10] [Batch 462/1081] [D loss: 0.077130] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.019046] time: 1:06:45.129526\n",
      "(10, 128, 128, 3)\n",
      "0.9087092\n",
      "[Epoch 7/10] [Batch 463/1081] [D loss: 0.091598] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.047385] time: 1:06:45.768002\n",
      "(10, 128, 128, 3)\n",
      "0.8906215\n",
      "[Epoch 7/10] [Batch 464/1081] [D loss: 0.072213] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.564737] time: 1:06:46.424082\n",
      "(10, 128, 128, 3)\n",
      "0.90919477\n",
      "[Epoch 7/10] [Batch 465/1081] [D loss: 0.072479] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.627920] time: 1:06:47.058547\n",
      "(10, 128, 128, 3)\n",
      "0.90826637\n",
      "[Epoch 7/10] [Batch 466/1081] [D loss: 0.081694] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.300013] time: 1:06:47.697040\n",
      "(10, 128, 128, 3)\n",
      "0.9093849\n",
      "[Epoch 7/10] [Batch 467/1081] [D loss: 0.078223] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.991559] time: 1:06:48.300886\n",
      "(10, 128, 128, 3)\n",
      "0.9446619\n",
      "[Epoch 7/10] [Batch 468/1081] [D loss: 0.086698] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.303484] time: 1:06:48.941501\n",
      "(10, 128, 128, 3)\n",
      "0.9213949\n",
      "[Epoch 7/10] [Batch 469/1081] [D loss: 0.070320] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.591297] time: 1:06:49.566153\n",
      "(10, 128, 128, 3)\n",
      "0.9020965\n",
      "[Epoch 7/10] [Batch 470/1081] [D loss: 0.082839] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.108172] time: 1:06:50.210142\n",
      "(10, 128, 128, 3)\n",
      "0.9147358\n",
      "[Epoch 7/10] [Batch 471/1081] [D loss: 0.264179] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 3.813002] time: 1:06:50.868326\n",
      "(10, 128, 128, 3)\n",
      "0.9393614\n",
      "[Epoch 7/10] [Batch 472/1081] [D loss: 0.108282] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.084694] time: 1:06:51.523199\n",
      "(10, 128, 128, 3)\n",
      "0.8986063\n",
      "[Epoch 7/10] [Batch 473/1081] [D loss: 0.125898] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.258379] time: 1:06:52.222991\n",
      "(10, 128, 128, 3)\n",
      "0.9697881\n",
      "[Epoch 7/10] [Batch 474/1081] [D loss: 0.080993] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.547530] time: 1:06:52.855270\n",
      "(10, 128, 128, 3)\n",
      "0.8971891\n",
      "[Epoch 7/10] [Batch 475/1081] [D loss: 0.073625] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.140267] time: 1:06:53.441970\n",
      "(10, 128, 128, 3)\n",
      "0.9154062\n",
      "[Epoch 7/10] [Batch 476/1081] [D loss: 0.076074] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.681496] time: 1:06:54.137777\n",
      "(10, 128, 128, 3)\n",
      "0.93715596\n",
      "[Epoch 7/10] [Batch 477/1081] [D loss: 0.254894] [D acc: 0.55 (1.00 real, 0.10 fake)] [G loss: 6.142101] time: 1:06:54.775240\n",
      "(10, 128, 128, 3)\n",
      "0.96227264\n",
      "[Epoch 7/10] [Batch 478/1081] [D loss: 0.188978] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 4.733181] time: 1:06:55.405314\n",
      "(10, 128, 128, 3)\n",
      "0.8698511\n",
      "[Epoch 7/10] [Batch 479/1081] [D loss: 0.095969] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.970948] time: 1:06:56.047802\n",
      "(10, 128, 128, 3)\n",
      "0.92954427\n",
      "[Epoch 7/10] [Batch 480/1081] [D loss: 0.072753] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.850071] time: 1:06:56.679146\n",
      "(10, 128, 128, 3)\n",
      "0.9373913\n",
      "[Epoch 7/10] [Batch 481/1081] [D loss: 0.080528] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.873873] time: 1:06:57.352378\n",
      "(10, 128, 128, 3)\n",
      "0.9062116\n",
      "[Epoch 7/10] [Batch 482/1081] [D loss: 0.153184] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.068530] time: 1:06:58.029457\n",
      "(10, 128, 128, 3)\n",
      "0.87835807\n",
      "[Epoch 7/10] [Batch 483/1081] [D loss: 0.228855] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 5.256779] time: 1:06:58.676918\n",
      "(10, 128, 128, 3)\n",
      "0.9040818\n",
      "[Epoch 7/10] [Batch 484/1081] [D loss: 0.074204] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.228766] time: 1:06:59.282917\n",
      "(10, 128, 128, 3)\n",
      "0.92508\n",
      "[Epoch 7/10] [Batch 485/1081] [D loss: 0.074287] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.110399] time: 1:06:59.971896\n",
      "(10, 128, 128, 3)\n",
      "0.89211863\n",
      "[Epoch 7/10] [Batch 486/1081] [D loss: 0.079457] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.419239] time: 1:07:00.683177\n",
      "(10, 128, 128, 3)\n",
      "0.93581957\n",
      "[Epoch 7/10] [Batch 487/1081] [D loss: 0.073116] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.634231] time: 1:07:01.329040\n",
      "(10, 128, 128, 3)\n",
      "0.9158993\n",
      "[Epoch 7/10] [Batch 488/1081] [D loss: 0.097520] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.151824] time: 1:07:01.959101\n",
      "(10, 128, 128, 3)\n",
      "0.9141465\n",
      "[Epoch 7/10] [Batch 489/1081] [D loss: 0.074616] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.190307] time: 1:07:02.573635\n",
      "(10, 128, 128, 3)\n",
      "0.94775623\n",
      "[Epoch 7/10] [Batch 490/1081] [D loss: 0.087354] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.475732] time: 1:07:03.309227\n",
      "(10, 128, 128, 3)\n",
      "0.9493456\n",
      "[Epoch 7/10] [Batch 491/1081] [D loss: 0.070253] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.284434] time: 1:07:03.958275\n",
      "(10, 128, 128, 3)\n",
      "0.90644455\n",
      "[Epoch 7/10] [Batch 492/1081] [D loss: 0.075244] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.816237] time: 1:07:04.638415\n",
      "(10, 128, 128, 3)\n",
      "0.9391977\n",
      "[Epoch 7/10] [Batch 493/1081] [D loss: 0.078968] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.486329] time: 1:07:05.299811\n",
      "(10, 128, 128, 3)\n",
      "0.9051404\n",
      "[Epoch 7/10] [Batch 494/1081] [D loss: 0.072789] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.194609] time: 1:07:05.939650\n",
      "(10, 128, 128, 3)\n",
      "0.9256337\n",
      "[Epoch 7/10] [Batch 495/1081] [D loss: 0.690095] [D acc: 0.25 (0.00 real, 0.50 fake)] [G loss: 4.297455] time: 1:07:06.596638\n",
      "(10, 128, 128, 3)\n",
      "0.8781901\n",
      "[Epoch 7/10] [Batch 496/1081] [D loss: 0.110551] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.465749] time: 1:07:07.232640\n",
      "(10, 128, 128, 3)\n",
      "0.9531007\n",
      "[Epoch 7/10] [Batch 497/1081] [D loss: 0.104997] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.943204] time: 1:07:07.902000\n",
      "(10, 128, 128, 3)\n",
      "0.8848731\n",
      "[Epoch 7/10] [Batch 498/1081] [D loss: 0.128825] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.283366] time: 1:07:08.554941\n",
      "(10, 128, 128, 3)\n",
      "0.90442115\n",
      "[Epoch 7/10] [Batch 499/1081] [D loss: 0.079272] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.011734] time: 1:07:09.201397\n",
      "(10, 128, 128, 3)\n",
      "0.9464391\n",
      "[Epoch 7/10] [Batch 500/1081] [D loss: 0.071056] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.193342] time: 1:07:09.824667\n",
      "(10, 128, 128, 3)\n",
      "0.8989615\n",
      "[Epoch 7/10] [Batch 501/1081] [D loss: 0.069430] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.815482] time: 1:07:10.462724\n",
      "(10, 128, 128, 3)\n",
      "0.9480668\n",
      "[Epoch 7/10] [Batch 502/1081] [D loss: 0.075711] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.212781] time: 1:07:11.079136\n",
      "(10, 128, 128, 3)\n",
      "0.98190135\n",
      "[Epoch 7/10] [Batch 503/1081] [D loss: 0.068102] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.257465] time: 1:07:11.736142\n",
      "(10, 128, 128, 3)\n",
      "0.93315\n",
      "[Epoch 7/10] [Batch 504/1081] [D loss: 0.079797] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.180572] time: 1:07:12.346118\n",
      "(10, 128, 128, 3)\n",
      "0.8767147\n",
      "[Epoch 7/10] [Batch 505/1081] [D loss: 0.075165] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.588650] time: 1:07:12.978031\n",
      "(10, 128, 128, 3)\n",
      "0.9048775\n",
      "[Epoch 7/10] [Batch 506/1081] [D loss: 0.078540] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.655951] time: 1:07:13.626501\n",
      "(10, 128, 128, 3)\n",
      "0.8938313\n",
      "[Epoch 7/10] [Batch 507/1081] [D loss: 0.093454] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.842652] time: 1:07:14.235153\n",
      "(10, 128, 128, 3)\n",
      "0.87504584\n",
      "[Epoch 7/10] [Batch 508/1081] [D loss: 0.099759] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.292902] time: 1:07:14.882106\n",
      "(10, 128, 128, 3)\n",
      "0.9451361\n",
      "[Epoch 7/10] [Batch 509/1081] [D loss: 0.184472] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 3.894789] time: 1:07:15.562603\n",
      "(10, 128, 128, 3)\n",
      "0.8853151\n",
      "[Epoch 7/10] [Batch 510/1081] [D loss: 0.074904] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.151295] time: 1:07:16.182472\n",
      "(10, 128, 128, 3)\n",
      "0.92168754\n",
      "[Epoch 7/10] [Batch 511/1081] [D loss: 0.089465] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.235592] time: 1:07:16.846082\n",
      "(10, 128, 128, 3)\n",
      "0.93431824\n",
      "[Epoch 7/10] [Batch 512/1081] [D loss: 0.075160] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.498569] time: 1:07:17.440002\n",
      "(10, 128, 128, 3)\n",
      "0.9199069\n",
      "[Epoch 7/10] [Batch 513/1081] [D loss: 0.068421] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.685043] time: 1:07:18.089099\n",
      "(10, 128, 128, 3)\n",
      "0.89198476\n",
      "[Epoch 7/10] [Batch 514/1081] [D loss: 0.068808] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.841988] time: 1:07:18.702215\n",
      "(10, 128, 128, 3)\n",
      "0.95524216\n",
      "[Epoch 7/10] [Batch 515/1081] [D loss: 0.084767] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.727593] time: 1:07:19.348640\n",
      "(10, 128, 128, 3)\n",
      "0.92119765\n",
      "[Epoch 7/10] [Batch 516/1081] [D loss: 0.066876] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.182554] time: 1:07:19.982255\n",
      "(10, 128, 128, 3)\n",
      "0.9670078\n",
      "[Epoch 7/10] [Batch 517/1081] [D loss: 0.068357] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.368509] time: 1:07:20.661268\n",
      "(10, 128, 128, 3)\n",
      "0.91313887\n",
      "[Epoch 7/10] [Batch 518/1081] [D loss: 0.067344] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.181532] time: 1:07:21.311092\n",
      "(10, 128, 128, 3)\n",
      "0.9318242\n",
      "[Epoch 7/10] [Batch 519/1081] [D loss: 0.067456] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.574057] time: 1:07:21.920709\n",
      "(10, 128, 128, 3)\n",
      "0.9466276\n",
      "[Epoch 7/10] [Batch 520/1081] [D loss: 0.069793] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.419097] time: 1:07:22.541977\n",
      "(10, 128, 128, 3)\n",
      "0.87593704\n",
      "[Epoch 7/10] [Batch 521/1081] [D loss: 0.102950] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.175459] time: 1:07:23.196876\n",
      "(10, 128, 128, 3)\n",
      "0.8875901\n",
      "[Epoch 7/10] [Batch 522/1081] [D loss: 0.071364] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.578665] time: 1:07:23.844977\n",
      "(10, 128, 128, 3)\n",
      "0.8434582\n",
      "[Epoch 7/10] [Batch 523/1081] [D loss: 0.069407] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.056774] time: 1:07:24.511713\n",
      "(10, 128, 128, 3)\n",
      "0.88319165\n",
      "[Epoch 7/10] [Batch 524/1081] [D loss: 0.210429] [D acc: 0.75 (0.50 real, 1.00 fake)] [G loss: 5.154955] time: 1:07:25.195836\n",
      "(10, 128, 128, 3)\n",
      "0.9117921\n",
      "[Epoch 7/10] [Batch 525/1081] [D loss: 0.079122] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.852768] time: 1:07:25.901535\n",
      "(10, 128, 128, 3)\n",
      "0.89005965\n",
      "[Epoch 7/10] [Batch 526/1081] [D loss: 0.073832] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.854594] time: 1:07:26.599799\n",
      "(10, 128, 128, 3)\n",
      "0.95180655\n",
      "[Epoch 7/10] [Batch 527/1081] [D loss: 0.076856] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.896208] time: 1:07:27.207331\n",
      "(10, 128, 128, 3)\n",
      "0.8584878\n",
      "[Epoch 7/10] [Batch 528/1081] [D loss: 0.073200] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.652765] time: 1:07:27.882124\n",
      "(10, 128, 128, 3)\n",
      "0.87788033\n",
      "[Epoch 7/10] [Batch 529/1081] [D loss: 0.065883] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.260547] time: 1:07:28.574381\n",
      "(10, 128, 128, 3)\n",
      "0.90373826\n",
      "[Epoch 7/10] [Batch 530/1081] [D loss: 0.069244] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.926211] time: 1:07:29.274749\n",
      "(10, 128, 128, 3)\n",
      "0.8529529\n",
      "[Epoch 7/10] [Batch 531/1081] [D loss: 0.086146] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.289150] time: 1:07:29.960266\n",
      "(10, 128, 128, 3)\n",
      "0.84333867\n",
      "[Epoch 7/10] [Batch 532/1081] [D loss: 0.158853] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.115746] time: 1:07:30.611980\n",
      "(10, 128, 128, 3)\n",
      "0.94163495\n",
      "[Epoch 7/10] [Batch 533/1081] [D loss: 0.073890] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.852466] time: 1:07:31.273077\n",
      "(10, 128, 128, 3)\n",
      "0.944941\n",
      "[Epoch 7/10] [Batch 534/1081] [D loss: 0.105235] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.508404] time: 1:07:31.927293\n",
      "(10, 128, 128, 3)\n",
      "0.9023153\n",
      "[Epoch 7/10] [Batch 535/1081] [D loss: 0.069603] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.626687] time: 1:07:32.531691\n",
      "(10, 128, 128, 3)\n",
      "0.9305895\n",
      "[Epoch 7/10] [Batch 536/1081] [D loss: 0.071689] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.278206] time: 1:07:33.222840\n",
      "(10, 128, 128, 3)\n",
      "0.9002623\n",
      "[Epoch 7/10] [Batch 537/1081] [D loss: 0.069806] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.677124] time: 1:07:33.880556\n",
      "(10, 128, 128, 3)\n",
      "0.91523427\n",
      "[Epoch 7/10] [Batch 538/1081] [D loss: 0.068550] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.176567] time: 1:07:34.481308\n",
      "(10, 128, 128, 3)\n",
      "0.9299601\n",
      "[Epoch 7/10] [Batch 539/1081] [D loss: 0.065341] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.685410] time: 1:07:35.165395\n",
      "(10, 128, 128, 3)\n",
      "0.8749549\n",
      "[Epoch 7/10] [Batch 540/1081] [D loss: 0.118601] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.602800] time: 1:07:35.805103\n",
      "(10, 128, 128, 3)\n",
      "0.90782374\n",
      "[Epoch 7/10] [Batch 541/1081] [D loss: 0.112663] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.391440] time: 1:07:36.437715\n",
      "(10, 128, 128, 3)\n",
      "0.97457385\n",
      "[Epoch 7/10] [Batch 542/1081] [D loss: 0.068415] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.475133] time: 1:07:37.123740\n",
      "(10, 128, 128, 3)\n",
      "0.9117897\n",
      "[Epoch 7/10] [Batch 543/1081] [D loss: 0.124238] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.127656] time: 1:07:37.797945\n",
      "(10, 128, 128, 3)\n",
      "0.9497268\n",
      "[Epoch 7/10] [Batch 544/1081] [D loss: 0.067005] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.081474] time: 1:07:38.434104\n",
      "(10, 128, 128, 3)\n",
      "0.8935089\n",
      "[Epoch 7/10] [Batch 545/1081] [D loss: 0.068316] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.036017] time: 1:07:39.133635\n",
      "(10, 128, 128, 3)\n",
      "0.864742\n",
      "[Epoch 7/10] [Batch 546/1081] [D loss: 0.096707] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.034549] time: 1:07:39.781109\n",
      "(10, 128, 128, 3)\n",
      "0.8969547\n",
      "[Epoch 7/10] [Batch 547/1081] [D loss: 0.073405] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.466416] time: 1:07:40.421652\n",
      "(10, 128, 128, 3)\n",
      "0.924239\n",
      "[Epoch 7/10] [Batch 548/1081] [D loss: 0.064617] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.317158] time: 1:07:41.061289\n",
      "(10, 128, 128, 3)\n",
      "0.9295397\n",
      "[Epoch 7/10] [Batch 549/1081] [D loss: 0.079688] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.100697] time: 1:07:41.759363\n",
      "(10, 128, 128, 3)\n",
      "0.92721725\n",
      "[Epoch 7/10] [Batch 550/1081] [D loss: 0.065868] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.907332] time: 1:07:42.419854\n",
      "(10, 128, 128, 3)\n",
      "0.9259291\n",
      "[Epoch 7/10] [Batch 551/1081] [D loss: 0.209377] [D acc: 0.90 (1.00 real, 0.80 fake)] [G loss: 5.003608] time: 1:07:43.112219\n",
      "(10, 128, 128, 3)\n",
      "0.9142464\n",
      "[Epoch 7/10] [Batch 552/1081] [D loss: 0.068930] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.540507] time: 1:07:43.746546\n",
      "(10, 128, 128, 3)\n",
      "0.88266665\n",
      "[Epoch 7/10] [Batch 553/1081] [D loss: 0.068152] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.489458] time: 1:07:44.380716\n",
      "(10, 128, 128, 3)\n",
      "0.88219833\n",
      "[Epoch 7/10] [Batch 554/1081] [D loss: 0.065484] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.166358] time: 1:07:45.010348\n",
      "(10, 128, 128, 3)\n",
      "0.88411075\n",
      "[Epoch 7/10] [Batch 555/1081] [D loss: 0.081696] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.172558] time: 1:07:45.670818\n",
      "(10, 128, 128, 3)\n",
      "0.89711094\n",
      "[Epoch 7/10] [Batch 556/1081] [D loss: 0.074210] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.052986] time: 1:07:46.296017\n",
      "(10, 128, 128, 3)\n",
      "0.91927284\n",
      "[Epoch 7/10] [Batch 557/1081] [D loss: 0.067690] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.122094] time: 1:07:46.929572\n",
      "(10, 128, 128, 3)\n",
      "0.9053898\n",
      "[Epoch 7/10] [Batch 558/1081] [D loss: 0.363381] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 4.128438] time: 1:07:47.547218\n",
      "(10, 128, 128, 3)\n",
      "0.9588863\n",
      "[Epoch 7/10] [Batch 559/1081] [D loss: 0.226892] [D acc: 0.85 (1.00 real, 0.70 fake)] [G loss: 4.323473] time: 1:07:48.184573\n",
      "(10, 128, 128, 3)\n",
      "0.9230561\n",
      "[Epoch 7/10] [Batch 560/1081] [D loss: 0.070726] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.151124] time: 1:07:48.780900\n",
      "(10, 128, 128, 3)\n",
      "0.918194\n",
      "[Epoch 7/10] [Batch 561/1081] [D loss: 0.106017] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.872839] time: 1:07:49.456315\n",
      "(10, 128, 128, 3)\n",
      "0.9233554\n",
      "[Epoch 7/10] [Batch 562/1081] [D loss: 0.100514] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.790098] time: 1:07:50.096287\n",
      "(10, 128, 128, 3)\n",
      "0.93738395\n",
      "[Epoch 7/10] [Batch 563/1081] [D loss: 0.125162] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 3.775668] time: 1:07:50.685159\n",
      "(10, 128, 128, 3)\n",
      "0.84412575\n",
      "[Epoch 7/10] [Batch 564/1081] [D loss: 0.078549] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.085504] time: 1:07:51.299655\n",
      "(10, 128, 128, 3)\n",
      "0.88558435\n",
      "[Epoch 7/10] [Batch 565/1081] [D loss: 0.099112] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.796988] time: 1:07:51.910165\n",
      "(10, 128, 128, 3)\n",
      "0.91571563\n",
      "[Epoch 7/10] [Batch 566/1081] [D loss: 0.071382] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.637873] time: 1:07:52.543889\n",
      "(10, 128, 128, 3)\n",
      "0.89246625\n",
      "[Epoch 7/10] [Batch 567/1081] [D loss: 0.068729] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.250153] time: 1:07:53.139619\n",
      "(10, 128, 128, 3)\n",
      "0.8843922\n",
      "[Epoch 7/10] [Batch 568/1081] [D loss: 0.083211] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.751534] time: 1:07:53.809945\n",
      "(10, 128, 128, 3)\n",
      "0.9112313\n",
      "[Epoch 7/10] [Batch 569/1081] [D loss: 0.091245] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.739966] time: 1:07:54.514480\n",
      "(10, 128, 128, 3)\n",
      "0.8842068\n",
      "[Epoch 7/10] [Batch 570/1081] [D loss: 0.111376] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.856966] time: 1:07:55.152284\n",
      "(10, 128, 128, 3)\n",
      "0.96290153\n",
      "[Epoch 7/10] [Batch 571/1081] [D loss: 0.084882] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.404143] time: 1:07:55.777761\n",
      "(10, 128, 128, 3)\n",
      "0.9012584\n",
      "[Epoch 7/10] [Batch 572/1081] [D loss: 0.067201] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.093516] time: 1:07:56.353981\n",
      "(10, 128, 128, 3)\n",
      "0.9082463\n",
      "[Epoch 7/10] [Batch 573/1081] [D loss: 0.072194] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.960116] time: 1:07:56.988834\n",
      "(10, 128, 128, 3)\n",
      "0.8871133\n",
      "[Epoch 7/10] [Batch 574/1081] [D loss: 0.104094] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.112144] time: 1:07:57.580792\n",
      "(10, 128, 128, 3)\n",
      "0.9296026\n",
      "[Epoch 7/10] [Batch 575/1081] [D loss: 0.067122] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.181119] time: 1:07:58.209337\n",
      "(10, 128, 128, 3)\n",
      "0.9015911\n",
      "[Epoch 7/10] [Batch 576/1081] [D loss: 0.074664] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.932807] time: 1:07:58.866411\n",
      "(10, 128, 128, 3)\n",
      "0.93556076\n",
      "[Epoch 7/10] [Batch 577/1081] [D loss: 0.093957] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.757670] time: 1:07:59.505709\n",
      "(10, 128, 128, 3)\n",
      "0.8761019\n",
      "[Epoch 7/10] [Batch 578/1081] [D loss: 0.074672] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.718155] time: 1:08:00.159000\n",
      "(10, 128, 128, 3)\n",
      "0.8706152\n",
      "[Epoch 7/10] [Batch 579/1081] [D loss: 0.074675] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.880077] time: 1:08:00.810784\n",
      "(10, 128, 128, 3)\n",
      "0.9148998\n",
      "[Epoch 7/10] [Batch 580/1081] [D loss: 0.070709] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.272097] time: 1:08:01.453484\n",
      "(10, 128, 128, 3)\n",
      "0.8834543\n",
      "[Epoch 7/10] [Batch 581/1081] [D loss: 0.075888] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.174939] time: 1:08:02.109741\n",
      "(10, 128, 128, 3)\n",
      "0.9241709\n",
      "[Epoch 7/10] [Batch 582/1081] [D loss: 0.361924] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 3.962965] time: 1:08:02.739255\n",
      "(10, 128, 128, 3)\n",
      "0.91084224\n",
      "[Epoch 7/10] [Batch 583/1081] [D loss: 0.161331] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 4.214400] time: 1:08:03.382761\n",
      "(10, 128, 128, 3)\n",
      "0.9398644\n",
      "[Epoch 7/10] [Batch 584/1081] [D loss: 0.205802] [D acc: 0.60 (1.00 real, 0.20 fake)] [G loss: 4.362544] time: 1:08:03.981166\n",
      "(10, 128, 128, 3)\n",
      "0.8926173\n",
      "[Epoch 7/10] [Batch 585/1081] [D loss: 0.106044] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.542667] time: 1:08:04.620382\n",
      "(10, 128, 128, 3)\n",
      "0.9043396\n",
      "[Epoch 7/10] [Batch 586/1081] [D loss: 0.520702] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 4.448087] time: 1:08:05.252015\n",
      "(10, 128, 128, 3)\n",
      "0.9029591\n",
      "[Epoch 7/10] [Batch 587/1081] [D loss: 0.294393] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 4.702139] time: 1:08:05.837911\n",
      "(10, 128, 128, 3)\n",
      "0.91755635\n",
      "[Epoch 7/10] [Batch 588/1081] [D loss: 0.170498] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.596457] time: 1:08:06.455401\n",
      "(10, 128, 128, 3)\n",
      "0.93257636\n",
      "[Epoch 7/10] [Batch 589/1081] [D loss: 0.083011] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.337296] time: 1:08:07.151170\n",
      "(10, 128, 128, 3)\n",
      "0.86275244\n",
      "[Epoch 7/10] [Batch 590/1081] [D loss: 0.139711] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.716615] time: 1:08:07.850169\n",
      "(10, 128, 128, 3)\n",
      "0.90883064\n",
      "[Epoch 7/10] [Batch 591/1081] [D loss: 0.083908] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.367980] time: 1:08:08.508897\n",
      "(10, 128, 128, 3)\n",
      "0.87648296\n",
      "[Epoch 7/10] [Batch 592/1081] [D loss: 0.110519] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.062831] time: 1:08:09.180679\n",
      "(10, 128, 128, 3)\n",
      "0.8704695\n",
      "[Epoch 7/10] [Batch 593/1081] [D loss: 0.072153] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.844303] time: 1:08:09.891905\n",
      "(10, 128, 128, 3)\n",
      "0.88588756\n",
      "[Epoch 7/10] [Batch 594/1081] [D loss: 0.080769] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.844762] time: 1:08:10.539115\n",
      "(10, 128, 128, 3)\n",
      "0.9098592\n",
      "[Epoch 7/10] [Batch 595/1081] [D loss: 0.071514] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.609834] time: 1:08:11.223294\n",
      "(10, 128, 128, 3)\n",
      "0.87852335\n",
      "[Epoch 7/10] [Batch 596/1081] [D loss: 0.072391] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.430385] time: 1:08:11.880609\n",
      "(10, 128, 128, 3)\n",
      "0.91199404\n",
      "[Epoch 7/10] [Batch 597/1081] [D loss: 0.074616] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.933726] time: 1:08:12.549747\n",
      "(10, 128, 128, 3)\n",
      "0.9107576\n",
      "[Epoch 7/10] [Batch 598/1081] [D loss: 0.070709] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.481153] time: 1:08:13.257678\n",
      "(10, 128, 128, 3)\n",
      "0.9131177\n",
      "[Epoch 7/10] [Batch 599/1081] [D loss: 0.075766] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.827361] time: 1:08:13.903287\n",
      "(10, 128, 128, 3)\n",
      "0.8348654\n",
      "[Epoch 7/10] [Batch 600/1081] [D loss: 0.079363] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.066709] time: 1:08:14.533171\n",
      "(10, 128, 128, 3)\n",
      "0.8465124\n",
      "[Epoch 7/10] [Batch 601/1081] [D loss: 0.177514] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 4.498023] time: 1:08:15.169358\n",
      "(10, 128, 128, 3)\n",
      "0.921035\n",
      "[Epoch 7/10] [Batch 602/1081] [D loss: 0.077232] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.699416] time: 1:08:15.775813\n",
      "(10, 128, 128, 3)\n",
      "0.87709355\n",
      "[Epoch 7/10] [Batch 603/1081] [D loss: 0.079734] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.142019] time: 1:08:16.496045\n",
      "(10, 128, 128, 3)\n",
      "0.9091132\n",
      "[Epoch 7/10] [Batch 604/1081] [D loss: 0.069859] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.204262] time: 1:08:17.105467\n",
      "(10, 128, 128, 3)\n",
      "0.88428545\n",
      "[Epoch 7/10] [Batch 605/1081] [D loss: 0.069871] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.594104] time: 1:08:17.769144\n",
      "(10, 128, 128, 3)\n",
      "0.95015764\n",
      "[Epoch 7/10] [Batch 606/1081] [D loss: 0.107554] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.432975] time: 1:08:18.417973\n",
      "(10, 128, 128, 3)\n",
      "0.94217587\n",
      "[Epoch 7/10] [Batch 607/1081] [D loss: 0.078993] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.499934] time: 1:08:19.066295\n",
      "(10, 128, 128, 3)\n",
      "0.88639396\n",
      "[Epoch 7/10] [Batch 608/1081] [D loss: 0.074926] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.926309] time: 1:08:19.706369\n",
      "(10, 128, 128, 3)\n",
      "0.89287716\n",
      "[Epoch 7/10] [Batch 609/1081] [D loss: 0.093852] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.306361] time: 1:08:20.362364\n",
      "(10, 128, 128, 3)\n",
      "0.8762005\n",
      "[Epoch 7/10] [Batch 610/1081] [D loss: 0.078262] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.236273] time: 1:08:20.998387\n",
      "(10, 128, 128, 3)\n",
      "0.9359632\n",
      "[Epoch 7/10] [Batch 611/1081] [D loss: 0.137386] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.615805] time: 1:08:21.682791\n",
      "(10, 128, 128, 3)\n",
      "0.9772069\n",
      "[Epoch 7/10] [Batch 612/1081] [D loss: 0.071331] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.895109] time: 1:08:22.335669\n",
      "(10, 128, 128, 3)\n",
      "0.9654078\n",
      "[Epoch 7/10] [Batch 613/1081] [D loss: 0.068309] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.589543] time: 1:08:23.028347\n",
      "(10, 128, 128, 3)\n",
      "0.89998084\n",
      "[Epoch 7/10] [Batch 614/1081] [D loss: 0.070418] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.312849] time: 1:08:23.697054\n",
      "(10, 128, 128, 3)\n",
      "0.90717196\n",
      "[Epoch 7/10] [Batch 615/1081] [D loss: 0.085172] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.170415] time: 1:08:24.317136\n",
      "(10, 128, 128, 3)\n",
      "0.9282303\n",
      "[Epoch 7/10] [Batch 616/1081] [D loss: 0.073169] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.211859] time: 1:08:24.945277\n",
      "(10, 128, 128, 3)\n",
      "0.9125115\n",
      "[Epoch 7/10] [Batch 617/1081] [D loss: 0.071475] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.607386] time: 1:08:25.679579\n",
      "(10, 128, 128, 3)\n",
      "0.93672746\n",
      "[Epoch 7/10] [Batch 618/1081] [D loss: 0.069150] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.583892] time: 1:08:26.312385\n",
      "(10, 128, 128, 3)\n",
      "0.94781256\n",
      "[Epoch 7/10] [Batch 619/1081] [D loss: 0.072209] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.494739] time: 1:08:26.966726\n",
      "(10, 128, 128, 3)\n",
      "0.8982189\n",
      "[Epoch 7/10] [Batch 620/1081] [D loss: 0.106382] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.780301] time: 1:08:27.600848\n",
      "(10, 128, 128, 3)\n",
      "0.89619416\n",
      "[Epoch 7/10] [Batch 621/1081] [D loss: 0.136573] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 4.744768] time: 1:08:28.241145\n",
      "(10, 128, 128, 3)\n",
      "0.8798397\n",
      "[Epoch 7/10] [Batch 622/1081] [D loss: 0.081722] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.371156] time: 1:08:28.875023\n",
      "(10, 128, 128, 3)\n",
      "0.974565\n",
      "[Epoch 7/10] [Batch 623/1081] [D loss: 0.090486] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.690378] time: 1:08:29.560998\n",
      "(10, 128, 128, 3)\n",
      "0.9159696\n",
      "[Epoch 7/10] [Batch 624/1081] [D loss: 0.070133] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.270136] time: 1:08:30.208269\n",
      "(10, 128, 128, 3)\n",
      "0.9463141\n",
      "[Epoch 7/10] [Batch 625/1081] [D loss: 0.069747] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.050499] time: 1:08:30.840336\n",
      "(10, 128, 128, 3)\n",
      "0.91541576\n",
      "[Epoch 7/10] [Batch 626/1081] [D loss: 0.072038] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.689660] time: 1:08:31.510134\n",
      "(10, 128, 128, 3)\n",
      "0.92983025\n",
      "[Epoch 7/10] [Batch 627/1081] [D loss: 0.070996] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.848972] time: 1:08:32.100398\n",
      "(10, 128, 128, 3)\n",
      "0.9317959\n",
      "[Epoch 7/10] [Batch 628/1081] [D loss: 0.070105] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.640731] time: 1:08:32.728630\n",
      "(10, 128, 128, 3)\n",
      "0.914686\n",
      "[Epoch 7/10] [Batch 629/1081] [D loss: 0.066831] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.346791] time: 1:08:33.385392\n",
      "(10, 128, 128, 3)\n",
      "0.8974121\n",
      "[Epoch 7/10] [Batch 630/1081] [D loss: 0.073964] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.644440] time: 1:08:34.082514\n",
      "(10, 128, 128, 3)\n",
      "0.94374627\n",
      "[Epoch 7/10] [Batch 631/1081] [D loss: 0.088853] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.164256] time: 1:08:34.716613\n",
      "(10, 128, 128, 3)\n",
      "0.9009221\n",
      "[Epoch 7/10] [Batch 632/1081] [D loss: 0.067891] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.756515] time: 1:08:35.360409\n",
      "(10, 128, 128, 3)\n",
      "0.85262966\n",
      "[Epoch 7/10] [Batch 633/1081] [D loss: 0.075411] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.996901] time: 1:08:36.021844\n",
      "(10, 128, 128, 3)\n",
      "0.872279\n",
      "[Epoch 7/10] [Batch 634/1081] [D loss: 0.083873] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.608044] time: 1:08:36.679173\n",
      "(10, 128, 128, 3)\n",
      "0.9141297\n",
      "[Epoch 7/10] [Batch 635/1081] [D loss: 0.083934] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.332611] time: 1:08:37.361173\n",
      "(10, 128, 128, 3)\n",
      "0.90651244\n",
      "[Epoch 7/10] [Batch 636/1081] [D loss: 0.075912] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.338024] time: 1:08:38.010130\n",
      "(10, 128, 128, 3)\n",
      "0.90316135\n",
      "[Epoch 7/10] [Batch 637/1081] [D loss: 0.070729] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.289261] time: 1:08:38.619948\n",
      "(10, 128, 128, 3)\n",
      "0.90950006\n",
      "[Epoch 7/10] [Batch 638/1081] [D loss: 0.069459] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.632978] time: 1:08:39.314579\n",
      "(10, 128, 128, 3)\n",
      "0.9305551\n",
      "[Epoch 7/10] [Batch 639/1081] [D loss: 0.068177] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.360087] time: 1:08:39.980046\n",
      "(10, 128, 128, 3)\n",
      "0.93135923\n",
      "[Epoch 7/10] [Batch 640/1081] [D loss: 0.071068] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.035698] time: 1:08:40.618507\n",
      "(10, 128, 128, 3)\n",
      "0.92855185\n",
      "[Epoch 7/10] [Batch 641/1081] [D loss: 0.069435] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.370525] time: 1:08:41.255017\n",
      "(10, 128, 128, 3)\n",
      "0.91653687\n",
      "[Epoch 7/10] [Batch 642/1081] [D loss: 0.069576] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.928056] time: 1:08:41.926539\n",
      "(10, 128, 128, 3)\n",
      "0.89832526\n",
      "[Epoch 7/10] [Batch 643/1081] [D loss: 0.065682] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.555926] time: 1:08:42.635990\n",
      "(10, 128, 128, 3)\n",
      "0.9591237\n",
      "[Epoch 7/10] [Batch 644/1081] [D loss: 0.067322] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.000924] time: 1:08:43.264613\n",
      "(10, 128, 128, 3)\n",
      "0.9120245\n",
      "[Epoch 7/10] [Batch 645/1081] [D loss: 0.070319] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.855757] time: 1:08:43.942002\n",
      "(10, 128, 128, 3)\n",
      "0.9184784\n",
      "[Epoch 7/10] [Batch 646/1081] [D loss: 0.064349] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.809603] time: 1:08:44.561235\n",
      "(10, 128, 128, 3)\n",
      "0.89871526\n",
      "[Epoch 7/10] [Batch 647/1081] [D loss: 0.064387] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.762431] time: 1:08:45.241267\n",
      "(10, 128, 128, 3)\n",
      "0.88947845\n",
      "[Epoch 7/10] [Batch 648/1081] [D loss: 0.066243] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.852844] time: 1:08:45.819045\n",
      "(10, 128, 128, 3)\n",
      "0.9323161\n",
      "[Epoch 7/10] [Batch 649/1081] [D loss: 0.064247] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.346117] time: 1:08:46.476087\n",
      "(10, 128, 128, 3)\n",
      "0.8659398\n",
      "[Epoch 7/10] [Batch 650/1081] [D loss: 0.071324] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.270180] time: 1:08:47.090484\n",
      "(10, 128, 128, 3)\n",
      "0.8800771\n",
      "[Epoch 7/10] [Batch 651/1081] [D loss: 0.065196] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.320561] time: 1:08:47.808259\n",
      "(10, 128, 128, 3)\n",
      "0.9817957\n",
      "[Epoch 7/10] [Batch 652/1081] [D loss: 0.072181] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.043122] time: 1:08:48.400670\n",
      "(10, 128, 128, 3)\n",
      "0.89432746\n",
      "[Epoch 7/10] [Batch 653/1081] [D loss: 0.066840] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.827126] time: 1:08:49.014030\n",
      "(10, 128, 128, 3)\n",
      "0.9539005\n",
      "[Epoch 7/10] [Batch 654/1081] [D loss: 0.075571] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.422064] time: 1:08:49.638234\n",
      "(10, 128, 128, 3)\n",
      "0.93366027\n",
      "[Epoch 7/10] [Batch 655/1081] [D loss: 0.082747] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.202775] time: 1:08:50.266535\n",
      "(10, 128, 128, 3)\n",
      "0.9482431\n",
      "[Epoch 7/10] [Batch 656/1081] [D loss: 0.069841] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.535195] time: 1:08:50.977065\n",
      "(10, 128, 128, 3)\n",
      "0.9086311\n",
      "[Epoch 7/10] [Batch 657/1081] [D loss: 0.073507] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.686476] time: 1:08:51.639388\n",
      "(10, 128, 128, 3)\n",
      "0.85995847\n",
      "[Epoch 7/10] [Batch 658/1081] [D loss: 0.068494] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.275723] time: 1:08:52.304202\n",
      "(10, 128, 128, 3)\n",
      "0.9189232\n",
      "[Epoch 7/10] [Batch 659/1081] [D loss: 0.070161] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.628830] time: 1:08:52.957706\n",
      "(10, 128, 128, 3)\n",
      "0.92762566\n",
      "[Epoch 7/10] [Batch 660/1081] [D loss: 0.068027] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.685063] time: 1:08:53.566953\n",
      "(10, 128, 128, 3)\n",
      "0.871484\n",
      "[Epoch 7/10] [Batch 661/1081] [D loss: 0.065395] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.496291] time: 1:08:54.220649\n",
      "(10, 128, 128, 3)\n",
      "0.9174635\n",
      "[Epoch 7/10] [Batch 662/1081] [D loss: 0.063875] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.702091] time: 1:08:54.875812\n",
      "(10, 128, 128, 3)\n",
      "0.88302994\n",
      "[Epoch 7/10] [Batch 663/1081] [D loss: 0.062557] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.590455] time: 1:08:55.484223\n",
      "(10, 128, 128, 3)\n",
      "0.9047644\n",
      "[Epoch 7/10] [Batch 664/1081] [D loss: 0.075100] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.842181] time: 1:08:56.049594\n",
      "(10, 128, 128, 3)\n",
      "0.91459495\n",
      "[Epoch 7/10] [Batch 665/1081] [D loss: 0.062021] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.121015] time: 1:08:56.629976\n",
      "(10, 128, 128, 3)\n",
      "0.91176194\n",
      "[Epoch 7/10] [Batch 666/1081] [D loss: 0.062683] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.252075] time: 1:08:57.176068\n",
      "(10, 128, 128, 3)\n",
      "0.9237216\n",
      "[Epoch 7/10] [Batch 667/1081] [D loss: 0.066042] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.691802] time: 1:08:57.721931\n",
      "(10, 128, 128, 3)\n",
      "0.95667124\n",
      "[Epoch 7/10] [Batch 668/1081] [D loss: 0.066119] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.709776] time: 1:08:58.316937\n",
      "(10, 128, 128, 3)\n",
      "0.95009565\n",
      "[Epoch 7/10] [Batch 669/1081] [D loss: 0.064253] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.265473] time: 1:08:58.902684\n",
      "(10, 128, 128, 3)\n",
      "0.87894434\n",
      "[Epoch 7/10] [Batch 670/1081] [D loss: 0.064340] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.331611] time: 1:08:59.453366\n",
      "(10, 128, 128, 3)\n",
      "0.92668414\n",
      "[Epoch 7/10] [Batch 671/1081] [D loss: 0.061090] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.658645] time: 1:09:00.015684\n",
      "(10, 128, 128, 3)\n",
      "0.9171283\n",
      "[Epoch 7/10] [Batch 672/1081] [D loss: 0.064258] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.323568] time: 1:09:00.544556\n",
      "(10, 128, 128, 3)\n",
      "0.8925001\n",
      "[Epoch 7/10] [Batch 673/1081] [D loss: 0.065066] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.819015] time: 1:09:01.133597\n",
      "(10, 128, 128, 3)\n",
      "0.8734036\n",
      "[Epoch 7/10] [Batch 674/1081] [D loss: 0.062066] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.318033] time: 1:09:01.713718\n",
      "(10, 128, 128, 3)\n",
      "0.87840396\n",
      "[Epoch 7/10] [Batch 675/1081] [D loss: 0.060445] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.574980] time: 1:09:02.263532\n",
      "(10, 128, 128, 3)\n",
      "0.8642285\n",
      "[Epoch 7/10] [Batch 676/1081] [D loss: 0.061243] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.237473] time: 1:09:02.784002\n",
      "(10, 128, 128, 3)\n",
      "0.91139895\n",
      "[Epoch 7/10] [Batch 677/1081] [D loss: 0.060107] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.853923] time: 1:09:03.339628\n",
      "(10, 128, 128, 3)\n",
      "0.96614385\n",
      "[Epoch 7/10] [Batch 678/1081] [D loss: 0.061757] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.891393] time: 1:09:03.878517\n",
      "(10, 128, 128, 3)\n",
      "0.8417186\n",
      "[Epoch 7/10] [Batch 679/1081] [D loss: 0.060001] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.844414] time: 1:09:04.430987\n",
      "(10, 128, 128, 3)\n",
      "0.921428\n",
      "[Epoch 7/10] [Batch 680/1081] [D loss: 0.073817] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.923842] time: 1:09:04.978285\n",
      "(10, 128, 128, 3)\n",
      "0.9377208\n",
      "[Epoch 7/10] [Batch 681/1081] [D loss: 0.071979] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.221983] time: 1:09:05.544584\n",
      "(10, 128, 128, 3)\n",
      "0.9487293\n",
      "[Epoch 7/10] [Batch 682/1081] [D loss: 0.062136] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.392036] time: 1:09:06.074432\n",
      "(10, 128, 128, 3)\n",
      "0.89135414\n",
      "[Epoch 7/10] [Batch 683/1081] [D loss: 0.068859] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.089036] time: 1:09:06.622509\n",
      "(10, 128, 128, 3)\n",
      "0.89207846\n",
      "[Epoch 7/10] [Batch 684/1081] [D loss: 0.067412] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.197065] time: 1:09:07.150632\n",
      "(10, 128, 128, 3)\n",
      "0.9380699\n",
      "[Epoch 7/10] [Batch 685/1081] [D loss: 0.065937] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.593459] time: 1:09:07.734599\n",
      "(10, 128, 128, 3)\n",
      "0.93046784\n",
      "[Epoch 7/10] [Batch 686/1081] [D loss: 0.059567] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.519386] time: 1:09:08.267232\n",
      "(10, 128, 128, 3)\n",
      "0.9131394\n",
      "[Epoch 7/10] [Batch 687/1081] [D loss: 0.059431] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.400773] time: 1:09:08.817992\n",
      "(10, 128, 128, 3)\n",
      "0.87288636\n",
      "[Epoch 7/10] [Batch 688/1081] [D loss: 0.375131] [D acc: 0.35 (0.10 real, 0.60 fake)] [G loss: 3.464958] time: 1:09:09.370769\n",
      "(10, 128, 128, 3)\n",
      "0.9256709\n",
      "[Epoch 7/10] [Batch 689/1081] [D loss: 0.260031] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 4.050647] time: 1:09:09.942144\n",
      "(10, 128, 128, 3)\n",
      "0.945822\n",
      "[Epoch 7/10] [Batch 690/1081] [D loss: 0.071780] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.001693] time: 1:09:10.534244\n",
      "(10, 128, 128, 3)\n",
      "0.88215464\n",
      "[Epoch 7/10] [Batch 691/1081] [D loss: 0.077233] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.129697] time: 1:09:11.101300\n",
      "(10, 128, 128, 3)\n",
      "0.95109385\n",
      "[Epoch 7/10] [Batch 692/1081] [D loss: 0.190782] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.782967] time: 1:09:11.667215\n",
      "(10, 128, 128, 3)\n",
      "0.89901763\n",
      "[Epoch 7/10] [Batch 693/1081] [D loss: 0.362222] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 4.038774] time: 1:09:12.252308\n",
      "(10, 128, 128, 3)\n",
      "0.91633314\n",
      "[Epoch 7/10] [Batch 694/1081] [D loss: 0.198450] [D acc: 0.75 (1.00 real, 0.50 fake)] [G loss: 4.071582] time: 1:09:12.795989\n",
      "(10, 128, 128, 3)\n",
      "0.9225512\n",
      "[Epoch 7/10] [Batch 695/1081] [D loss: 0.219397] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 4.744807] time: 1:09:13.360314\n",
      "(10, 128, 128, 3)\n",
      "0.9405732\n",
      "[Epoch 7/10] [Batch 696/1081] [D loss: 0.271142] [D acc: 0.60 (0.20 real, 1.00 fake)] [G loss: 4.402124] time: 1:09:13.928587\n",
      "(10, 128, 128, 3)\n",
      "0.92452174\n",
      "[Epoch 7/10] [Batch 697/1081] [D loss: 0.101005] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.522755] time: 1:09:14.495490\n",
      "(10, 128, 128, 3)\n",
      "0.87529373\n",
      "[Epoch 7/10] [Batch 698/1081] [D loss: 0.116909] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.694059] time: 1:09:15.074669\n",
      "(10, 128, 128, 3)\n",
      "0.9078672\n",
      "[Epoch 7/10] [Batch 699/1081] [D loss: 0.075105] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.187650] time: 1:09:15.685710\n",
      "(10, 128, 128, 3)\n",
      "0.9196151\n",
      "[Epoch 7/10] [Batch 700/1081] [D loss: 0.125019] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.674973] time: 1:09:16.294051\n",
      "(10, 128, 128, 3)\n",
      "0.90956694\n",
      "[Epoch 7/10] [Batch 701/1081] [D loss: 0.083580] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.603847] time: 1:09:16.989257\n",
      "(10, 128, 128, 3)\n",
      "0.9612673\n",
      "[Epoch 7/10] [Batch 702/1081] [D loss: 0.068653] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.081735] time: 1:09:17.638341\n",
      "(10, 128, 128, 3)\n",
      "0.92200774\n",
      "[Epoch 7/10] [Batch 703/1081] [D loss: 0.072512] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.489812] time: 1:09:18.255274\n",
      "(10, 128, 128, 3)\n",
      "0.94896287\n",
      "[Epoch 7/10] [Batch 704/1081] [D loss: 0.140142] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.279572] time: 1:09:18.924337\n",
      "(10, 128, 128, 3)\n",
      "0.9202296\n",
      "[Epoch 7/10] [Batch 705/1081] [D loss: 0.153607] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 3.562180] time: 1:09:19.595854\n",
      "(10, 128, 128, 3)\n",
      "0.95256215\n",
      "[Epoch 7/10] [Batch 706/1081] [D loss: 0.095329] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.037204] time: 1:09:20.258204\n",
      "(10, 128, 128, 3)\n",
      "0.9302203\n",
      "[Epoch 7/10] [Batch 707/1081] [D loss: 0.070534] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.578419] time: 1:09:20.873557\n",
      "(10, 128, 128, 3)\n",
      "0.9556348\n",
      "[Epoch 7/10] [Batch 708/1081] [D loss: 0.069138] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.999838] time: 1:09:21.528046\n",
      "(10, 128, 128, 3)\n",
      "0.9000619\n",
      "[Epoch 7/10] [Batch 709/1081] [D loss: 0.080850] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.709289] time: 1:09:22.159022\n",
      "(10, 128, 128, 3)\n",
      "0.9081111\n",
      "[Epoch 7/10] [Batch 710/1081] [D loss: 0.129185] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.688940] time: 1:09:22.789065\n",
      "(10, 128, 128, 3)\n",
      "0.8653641\n",
      "[Epoch 7/10] [Batch 711/1081] [D loss: 0.068688] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.209670] time: 1:09:23.445602\n",
      "(10, 128, 128, 3)\n",
      "0.9184236\n",
      "[Epoch 7/10] [Batch 712/1081] [D loss: 0.074179] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.992104] time: 1:09:24.051983\n",
      "(10, 128, 128, 3)\n",
      "0.9108766\n",
      "[Epoch 7/10] [Batch 713/1081] [D loss: 0.070309] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.469449] time: 1:09:24.716080\n",
      "(10, 128, 128, 3)\n",
      "0.88434726\n",
      "[Epoch 7/10] [Batch 714/1081] [D loss: 0.134438] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.792087] time: 1:09:25.324678\n",
      "(10, 128, 128, 3)\n",
      "0.9403665\n",
      "[Epoch 7/10] [Batch 715/1081] [D loss: 0.072059] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.841259] time: 1:09:25.994497\n",
      "(10, 128, 128, 3)\n",
      "0.9419891\n",
      "[Epoch 7/10] [Batch 716/1081] [D loss: 0.088827] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.380825] time: 1:09:26.631600\n",
      "(10, 128, 128, 3)\n",
      "0.9342885\n",
      "[Epoch 7/10] [Batch 717/1081] [D loss: 0.078554] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.500425] time: 1:09:27.268109\n",
      "(10, 128, 128, 3)\n",
      "0.92024493\n",
      "[Epoch 7/10] [Batch 718/1081] [D loss: 0.066119] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.140231] time: 1:09:27.914160\n",
      "(10, 128, 128, 3)\n",
      "0.89913034\n",
      "[Epoch 7/10] [Batch 719/1081] [D loss: 0.088433] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.371412] time: 1:09:28.546225\n",
      "(10, 128, 128, 3)\n",
      "0.93269366\n",
      "[Epoch 7/10] [Batch 720/1081] [D loss: 0.079646] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.882251] time: 1:09:29.173701\n",
      "(10, 128, 128, 3)\n",
      "0.9684112\n",
      "[Epoch 7/10] [Batch 721/1081] [D loss: 0.069160] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.604106] time: 1:09:29.805893\n",
      "(10, 128, 128, 3)\n",
      "0.8800575\n",
      "[Epoch 7/10] [Batch 722/1081] [D loss: 0.069513] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.045597] time: 1:09:30.459507\n",
      "(10, 128, 128, 3)\n",
      "0.878839\n",
      "[Epoch 7/10] [Batch 723/1081] [D loss: 0.074306] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.699641] time: 1:09:31.111198\n",
      "(10, 128, 128, 3)\n",
      "0.9208649\n",
      "[Epoch 7/10] [Batch 724/1081] [D loss: 0.086447] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.820772] time: 1:09:31.776879\n",
      "(10, 128, 128, 3)\n",
      "0.8758254\n",
      "[Epoch 7/10] [Batch 725/1081] [D loss: 0.074025] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.102896] time: 1:09:32.355417\n",
      "(10, 128, 128, 3)\n",
      "0.9686063\n",
      "[Epoch 7/10] [Batch 726/1081] [D loss: 0.105285] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.136531] time: 1:09:32.984701\n",
      "(10, 128, 128, 3)\n",
      "0.8961393\n",
      "[Epoch 7/10] [Batch 727/1081] [D loss: 0.083446] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.906402] time: 1:09:33.635565\n",
      "(10, 128, 128, 3)\n",
      "0.91116834\n",
      "[Epoch 7/10] [Batch 728/1081] [D loss: 0.069979] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.268954] time: 1:09:34.245764\n",
      "(10, 128, 128, 3)\n",
      "0.9086279\n",
      "[Epoch 7/10] [Batch 729/1081] [D loss: 0.075461] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.796970] time: 1:09:34.902955\n",
      "(10, 128, 128, 3)\n",
      "0.92439127\n",
      "[Epoch 7/10] [Batch 730/1081] [D loss: 0.078857] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.945732] time: 1:09:35.504163\n",
      "(10, 128, 128, 3)\n",
      "0.88795096\n",
      "[Epoch 7/10] [Batch 731/1081] [D loss: 0.086470] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.776484] time: 1:09:36.147832\n",
      "(10, 128, 128, 3)\n",
      "0.87856984\n",
      "[Epoch 7/10] [Batch 732/1081] [D loss: 0.066975] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.314240] time: 1:09:36.815916\n",
      "(10, 128, 128, 3)\n",
      "0.8683803\n",
      "[Epoch 7/10] [Batch 733/1081] [D loss: 0.176859] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 5.197875] time: 1:09:37.453795\n",
      "(10, 128, 128, 3)\n",
      "0.92012095\n",
      "[Epoch 7/10] [Batch 734/1081] [D loss: 0.065720] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.517951] time: 1:09:38.086482\n",
      "(10, 128, 128, 3)\n",
      "0.92981833\n",
      "[Epoch 7/10] [Batch 735/1081] [D loss: 0.083567] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.117594] time: 1:09:38.722194\n",
      "(10, 128, 128, 3)\n",
      "0.92320466\n",
      "[Epoch 7/10] [Batch 736/1081] [D loss: 0.090685] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.681358] time: 1:09:39.350431\n",
      "(10, 128, 128, 3)\n",
      "0.95570755\n",
      "[Epoch 7/10] [Batch 737/1081] [D loss: 0.222764] [D acc: 0.60 (1.00 real, 0.20 fake)] [G loss: 3.893638] time: 1:09:39.989234\n",
      "(10, 128, 128, 3)\n",
      "0.8960156\n",
      "[Epoch 7/10] [Batch 738/1081] [D loss: 0.102204] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.499944] time: 1:09:40.630470\n",
      "(10, 128, 128, 3)\n",
      "0.92120886\n",
      "[Epoch 7/10] [Batch 739/1081] [D loss: 0.074927] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.403791] time: 1:09:41.227270\n",
      "(10, 128, 128, 3)\n",
      "0.8755099\n",
      "[Epoch 7/10] [Batch 740/1081] [D loss: 0.124914] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.233279] time: 1:09:41.844096\n",
      "(10, 128, 128, 3)\n",
      "0.9356899\n",
      "[Epoch 7/10] [Batch 741/1081] [D loss: 0.126801] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.560594] time: 1:09:42.517662\n",
      "(10, 128, 128, 3)\n",
      "0.9052536\n",
      "[Epoch 7/10] [Batch 742/1081] [D loss: 0.117663] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.525344] time: 1:09:43.172800\n",
      "(10, 128, 128, 3)\n",
      "0.87379473\n",
      "[Epoch 7/10] [Batch 743/1081] [D loss: 0.082738] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.660646] time: 1:09:43.842011\n",
      "(10, 128, 128, 3)\n",
      "0.8835779\n",
      "[Epoch 7/10] [Batch 744/1081] [D loss: 0.078386] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.157537] time: 1:09:44.541224\n",
      "(10, 128, 128, 3)\n",
      "0.9404238\n",
      "[Epoch 7/10] [Batch 745/1081] [D loss: 0.065948] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.103273] time: 1:09:45.225658\n",
      "(10, 128, 128, 3)\n",
      "0.8816667\n",
      "[Epoch 7/10] [Batch 746/1081] [D loss: 0.067689] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.313274] time: 1:09:45.869640\n",
      "(10, 128, 128, 3)\n",
      "0.88553405\n",
      "[Epoch 7/10] [Batch 747/1081] [D loss: 0.146461] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 5.211229] time: 1:09:46.458082\n",
      "(10, 128, 128, 3)\n",
      "0.9433165\n",
      "[Epoch 7/10] [Batch 748/1081] [D loss: 0.067549] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.989231] time: 1:09:47.071216\n",
      "(10, 128, 128, 3)\n",
      "0.929982\n",
      "[Epoch 7/10] [Batch 749/1081] [D loss: 0.071211] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.513543] time: 1:09:47.731661\n",
      "(10, 128, 128, 3)\n",
      "0.9456486\n",
      "[Epoch 7/10] [Batch 750/1081] [D loss: 0.082241] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.027095] time: 1:09:48.346254\n",
      "(10, 128, 128, 3)\n",
      "0.9009512\n",
      "[Epoch 7/10] [Batch 751/1081] [D loss: 0.067701] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.142656] time: 1:09:48.962953\n",
      "(10, 128, 128, 3)\n",
      "0.93045896\n",
      "[Epoch 7/10] [Batch 752/1081] [D loss: 0.201887] [D acc: 0.75 (1.00 real, 0.50 fake)] [G loss: 4.481729] time: 1:09:49.586469\n",
      "(10, 128, 128, 3)\n",
      "0.9037135\n",
      "[Epoch 7/10] [Batch 753/1081] [D loss: 0.066967] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.891192] time: 1:09:50.251656\n",
      "(10, 128, 128, 3)\n",
      "0.88667005\n",
      "[Epoch 7/10] [Batch 754/1081] [D loss: 0.080689] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.102978] time: 1:09:50.922744\n",
      "(10, 128, 128, 3)\n",
      "0.8688956\n",
      "[Epoch 7/10] [Batch 755/1081] [D loss: 0.077123] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.360555] time: 1:09:51.571400\n",
      "(10, 128, 128, 3)\n",
      "0.91402435\n",
      "[Epoch 7/10] [Batch 756/1081] [D loss: 0.066399] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.601450] time: 1:09:52.194415\n",
      "(10, 128, 128, 3)\n",
      "0.91410667\n",
      "[Epoch 7/10] [Batch 757/1081] [D loss: 0.065358] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.598664] time: 1:09:52.857755\n",
      "(10, 128, 128, 3)\n",
      "0.92085123\n",
      "[Epoch 7/10] [Batch 758/1081] [D loss: 0.068112] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.133043] time: 1:09:53.492761\n",
      "(10, 128, 128, 3)\n",
      "0.86229205\n",
      "[Epoch 7/10] [Batch 759/1081] [D loss: 0.071517] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.544625] time: 1:09:54.122077\n",
      "(10, 128, 128, 3)\n",
      "0.86859125\n",
      "[Epoch 7/10] [Batch 760/1081] [D loss: 0.108570] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.432260] time: 1:09:54.796234\n",
      "(10, 128, 128, 3)\n",
      "0.8994143\n",
      "[Epoch 7/10] [Batch 761/1081] [D loss: 0.070818] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.611043] time: 1:09:55.445924\n",
      "(10, 128, 128, 3)\n",
      "0.9197059\n",
      "[Epoch 7/10] [Batch 762/1081] [D loss: 0.070539] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.011095] time: 1:09:56.144002\n",
      "(10, 128, 128, 3)\n",
      "0.9105156\n",
      "[Epoch 7/10] [Batch 763/1081] [D loss: 0.076438] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.524566] time: 1:09:56.834353\n",
      "(10, 128, 128, 3)\n",
      "0.8628399\n",
      "[Epoch 7/10] [Batch 764/1081] [D loss: 0.063872] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.626703] time: 1:09:57.542747\n",
      "(10, 128, 128, 3)\n",
      "0.92811066\n",
      "[Epoch 7/10] [Batch 765/1081] [D loss: 0.065893] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.834510] time: 1:09:58.164247\n",
      "(10, 128, 128, 3)\n",
      "0.92737174\n",
      "[Epoch 7/10] [Batch 766/1081] [D loss: 0.072910] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.243773] time: 1:09:58.811695\n",
      "(10, 128, 128, 3)\n",
      "0.9024708\n",
      "[Epoch 7/10] [Batch 767/1081] [D loss: 0.081610] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.282729] time: 1:09:59.485979\n",
      "(10, 128, 128, 3)\n",
      "0.87945414\n",
      "[Epoch 7/10] [Batch 768/1081] [D loss: 0.065673] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.570007] time: 1:10:00.140080\n",
      "(10, 128, 128, 3)\n",
      "0.8898096\n",
      "[Epoch 7/10] [Batch 769/1081] [D loss: 0.064575] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.973102] time: 1:10:00.833503\n",
      "(10, 128, 128, 3)\n",
      "0.8531622\n",
      "[Epoch 7/10] [Batch 770/1081] [D loss: 0.116138] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.615197] time: 1:10:01.472986\n",
      "(10, 128, 128, 3)\n",
      "0.8930345\n",
      "[Epoch 7/10] [Batch 771/1081] [D loss: 0.069708] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.432326] time: 1:10:02.154497\n",
      "(10, 128, 128, 3)\n",
      "0.9216699\n",
      "[Epoch 7/10] [Batch 772/1081] [D loss: 0.062440] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.847481] time: 1:10:02.833922\n",
      "(10, 128, 128, 3)\n",
      "0.88568115\n",
      "[Epoch 7/10] [Batch 773/1081] [D loss: 0.064411] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.930546] time: 1:10:03.483213\n",
      "(10, 128, 128, 3)\n",
      "0.912517\n",
      "[Epoch 7/10] [Batch 774/1081] [D loss: 0.063719] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.567599] time: 1:10:04.167755\n",
      "(10, 128, 128, 3)\n",
      "0.9338487\n",
      "[Epoch 7/10] [Batch 775/1081] [D loss: 0.062146] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.327661] time: 1:10:04.799141\n",
      "(10, 128, 128, 3)\n",
      "0.9327511\n",
      "[Epoch 7/10] [Batch 776/1081] [D loss: 0.063567] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.005809] time: 1:10:05.421467\n",
      "(10, 128, 128, 3)\n",
      "0.88721734\n",
      "[Epoch 7/10] [Batch 777/1081] [D loss: 0.135034] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.633563] time: 1:10:06.079268\n",
      "(10, 128, 128, 3)\n",
      "0.9395456\n",
      "[Epoch 7/10] [Batch 778/1081] [D loss: 0.067676] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.435334] time: 1:10:06.751876\n",
      "(10, 128, 128, 3)\n",
      "0.8833928\n",
      "[Epoch 7/10] [Batch 779/1081] [D loss: 0.239845] [D acc: 0.60 (1.00 real, 0.20 fake)] [G loss: 3.889966] time: 1:10:07.419934\n",
      "(10, 128, 128, 3)\n",
      "0.91599196\n",
      "[Epoch 7/10] [Batch 780/1081] [D loss: 0.220264] [D acc: 0.65 (1.00 real, 0.30 fake)] [G loss: 6.047143] time: 1:10:08.104234\n",
      "(10, 128, 128, 3)\n",
      "0.88222796\n",
      "[Epoch 7/10] [Batch 781/1081] [D loss: 0.099811] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.038339] time: 1:10:08.775975\n",
      "(10, 128, 128, 3)\n",
      "0.9532562\n",
      "[Epoch 7/10] [Batch 782/1081] [D loss: 0.250313] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 4.558211] time: 1:10:09.431818\n",
      "(10, 128, 128, 3)\n",
      "0.9107871\n",
      "[Epoch 7/10] [Batch 783/1081] [D loss: 0.108580] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.941436] time: 1:10:10.134408\n",
      "(10, 128, 128, 3)\n",
      "0.90752864\n",
      "[Epoch 7/10] [Batch 784/1081] [D loss: 0.095855] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.171370] time: 1:10:10.847180\n",
      "(10, 128, 128, 3)\n",
      "0.93186325\n",
      "[Epoch 7/10] [Batch 785/1081] [D loss: 0.115697] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.390727] time: 1:10:11.540580\n",
      "(10, 128, 128, 3)\n",
      "0.93065864\n",
      "[Epoch 7/10] [Batch 786/1081] [D loss: 0.070175] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.736157] time: 1:10:12.168930\n",
      "(10, 128, 128, 3)\n",
      "0.95827705\n",
      "[Epoch 7/10] [Batch 787/1081] [D loss: 0.071971] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.050464] time: 1:10:12.814836\n",
      "(10, 128, 128, 3)\n",
      "0.910384\n",
      "[Epoch 7/10] [Batch 788/1081] [D loss: 0.069102] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.588737] time: 1:10:13.495114\n",
      "(10, 128, 128, 3)\n",
      "0.8746595\n",
      "[Epoch 7/10] [Batch 789/1081] [D loss: 0.069411] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.930101] time: 1:10:14.140609\n",
      "(10, 128, 128, 3)\n",
      "0.9319682\n",
      "[Epoch 7/10] [Batch 790/1081] [D loss: 0.070130] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.290790] time: 1:10:14.771738\n",
      "(10, 128, 128, 3)\n",
      "0.94858456\n",
      "[Epoch 7/10] [Batch 791/1081] [D loss: 0.068351] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.440459] time: 1:10:15.423240\n",
      "(10, 128, 128, 3)\n",
      "0.9337282\n",
      "[Epoch 7/10] [Batch 792/1081] [D loss: 0.071355] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.519355] time: 1:10:16.062657\n",
      "(10, 128, 128, 3)\n",
      "0.88102984\n",
      "[Epoch 7/10] [Batch 793/1081] [D loss: 0.068576] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.256673] time: 1:10:16.741251\n",
      "(10, 128, 128, 3)\n",
      "0.85270333\n",
      "[Epoch 7/10] [Batch 794/1081] [D loss: 0.073926] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.089870] time: 1:10:17.415074\n",
      "(10, 128, 128, 3)\n",
      "0.84701234\n",
      "[Epoch 7/10] [Batch 795/1081] [D loss: 0.066571] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.562212] time: 1:10:18.029788\n",
      "(10, 128, 128, 3)\n",
      "0.9845807\n",
      "[Epoch 7/10] [Batch 796/1081] [D loss: 0.090911] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.016714] time: 1:10:18.668872\n",
      "(10, 128, 128, 3)\n",
      "0.88256246\n",
      "[Epoch 7/10] [Batch 797/1081] [D loss: 0.084625] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.899941] time: 1:10:19.288118\n",
      "(10, 128, 128, 3)\n",
      "0.9148212\n",
      "[Epoch 7/10] [Batch 798/1081] [D loss: 0.067230] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.482576] time: 1:10:19.910193\n",
      "(10, 128, 128, 3)\n",
      "0.9154199\n",
      "[Epoch 7/10] [Batch 799/1081] [D loss: 0.066261] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.005623] time: 1:10:20.533557\n",
      "(10, 128, 128, 3)\n",
      "0.9332178\n",
      "[Epoch 7/10] [Batch 800/1081] [D loss: 0.065247] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.311384] time: 1:10:21.156085\n",
      "(10, 128, 128, 3)\n",
      "0.907011\n",
      "[Epoch 7/10] [Batch 801/1081] [D loss: 0.079359] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.909268] time: 1:10:21.850592\n",
      "(10, 128, 128, 3)\n",
      "0.9492743\n",
      "[Epoch 7/10] [Batch 802/1081] [D loss: 0.067338] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.112916] time: 1:10:22.521482\n",
      "(10, 128, 128, 3)\n",
      "0.9162629\n",
      "[Epoch 7/10] [Batch 803/1081] [D loss: 0.065388] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.377232] time: 1:10:23.150051\n",
      "(10, 128, 128, 3)\n",
      "0.85464287\n",
      "[Epoch 7/10] [Batch 804/1081] [D loss: 0.070590] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.420467] time: 1:10:23.814919\n",
      "(10, 128, 128, 3)\n",
      "0.89792365\n",
      "[Epoch 7/10] [Batch 805/1081] [D loss: 0.067682] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.060062] time: 1:10:24.538945\n",
      "(10, 128, 128, 3)\n",
      "0.9250057\n",
      "[Epoch 7/10] [Batch 806/1081] [D loss: 0.066530] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.504011] time: 1:10:25.187297\n",
      "(10, 128, 128, 3)\n",
      "0.9226468\n",
      "[Epoch 7/10] [Batch 807/1081] [D loss: 0.072864] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.670596] time: 1:10:25.834055\n",
      "(10, 128, 128, 3)\n",
      "0.8574846\n",
      "[Epoch 7/10] [Batch 808/1081] [D loss: 0.064998] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.181270] time: 1:10:26.453160\n",
      "(10, 128, 128, 3)\n",
      "0.9121282\n",
      "[Epoch 7/10] [Batch 809/1081] [D loss: 0.066545] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.792031] time: 1:10:27.121923\n",
      "(10, 128, 128, 3)\n",
      "0.90691966\n",
      "[Epoch 7/10] [Batch 810/1081] [D loss: 0.064548] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.762360] time: 1:10:27.776446\n",
      "(10, 128, 128, 3)\n",
      "0.8452228\n",
      "[Epoch 7/10] [Batch 811/1081] [D loss: 0.065573] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.560940] time: 1:10:28.407243\n",
      "(10, 128, 128, 3)\n",
      "0.8943181\n",
      "[Epoch 7/10] [Batch 812/1081] [D loss: 0.083867] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.444237] time: 1:10:29.055949\n",
      "(10, 128, 128, 3)\n",
      "0.9253134\n",
      "[Epoch 7/10] [Batch 813/1081] [D loss: 0.079565] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.012838] time: 1:10:29.708720\n",
      "(10, 128, 128, 3)\n",
      "0.97256184\n",
      "[Epoch 7/10] [Batch 814/1081] [D loss: 0.063117] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.781368] time: 1:10:30.334626\n",
      "(10, 128, 128, 3)\n",
      "0.9184223\n",
      "[Epoch 7/10] [Batch 815/1081] [D loss: 0.072369] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.778392] time: 1:10:30.981105\n",
      "(10, 128, 128, 3)\n",
      "0.90624404\n",
      "[Epoch 7/10] [Batch 816/1081] [D loss: 0.068755] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.009761] time: 1:10:31.593988\n",
      "(10, 128, 128, 3)\n",
      "0.94055367\n",
      "[Epoch 7/10] [Batch 817/1081] [D loss: 0.063105] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.085392] time: 1:10:32.243303\n",
      "(10, 128, 128, 3)\n",
      "0.88502353\n",
      "[Epoch 7/10] [Batch 818/1081] [D loss: 0.065063] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.183187] time: 1:10:32.884406\n",
      "(10, 128, 128, 3)\n",
      "0.9275318\n",
      "[Epoch 7/10] [Batch 819/1081] [D loss: 0.062972] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.495523] time: 1:10:33.525000\n",
      "(10, 128, 128, 3)\n",
      "0.8881643\n",
      "[Epoch 7/10] [Batch 820/1081] [D loss: 0.081341] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.233003] time: 1:10:34.130200\n",
      "(10, 128, 128, 3)\n",
      "0.9400855\n",
      "[Epoch 7/10] [Batch 821/1081] [D loss: 0.065425] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.680232] time: 1:10:34.804862\n",
      "(10, 128, 128, 3)\n",
      "0.8816816\n",
      "[Epoch 7/10] [Batch 822/1081] [D loss: 0.077900] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.789687] time: 1:10:35.480134\n",
      "(10, 128, 128, 3)\n",
      "0.8707793\n",
      "[Epoch 7/10] [Batch 823/1081] [D loss: 0.067930] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.160655] time: 1:10:36.099795\n",
      "(10, 128, 128, 3)\n",
      "0.94303435\n",
      "[Epoch 7/10] [Batch 824/1081] [D loss: 0.066428] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.955724] time: 1:10:36.770781\n",
      "(10, 128, 128, 3)\n",
      "0.920988\n",
      "[Epoch 7/10] [Batch 825/1081] [D loss: 0.102704] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.186137] time: 1:10:37.413206\n",
      "(10, 128, 128, 3)\n",
      "0.908714\n",
      "[Epoch 7/10] [Batch 826/1081] [D loss: 0.066479] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.566923] time: 1:10:38.068736\n",
      "(10, 128, 128, 3)\n",
      "0.9111037\n",
      "[Epoch 7/10] [Batch 827/1081] [D loss: 0.091884] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.865821] time: 1:10:38.692239\n",
      "(10, 128, 128, 3)\n",
      "0.9361947\n",
      "[Epoch 7/10] [Batch 828/1081] [D loss: 0.078263] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.758770] time: 1:10:39.366480\n",
      "(10, 128, 128, 3)\n",
      "0.9117462\n",
      "[Epoch 7/10] [Batch 829/1081] [D loss: 0.063377] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.814388] time: 1:10:40.030496\n",
      "(10, 128, 128, 3)\n",
      "0.8871193\n",
      "[Epoch 7/10] [Batch 830/1081] [D loss: 0.064743] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.888726] time: 1:10:40.683245\n",
      "(10, 128, 128, 3)\n",
      "0.89076954\n",
      "[Epoch 7/10] [Batch 831/1081] [D loss: 0.082829] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.468884] time: 1:10:41.310764\n",
      "(10, 128, 128, 3)\n",
      "0.8795781\n",
      "[Epoch 7/10] [Batch 832/1081] [D loss: 0.067642] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.921311] time: 1:10:41.944309\n",
      "(10, 128, 128, 3)\n",
      "0.83884186\n",
      "[Epoch 7/10] [Batch 833/1081] [D loss: 0.064970] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.658609] time: 1:10:42.625619\n",
      "(10, 128, 128, 3)\n",
      "0.8942402\n",
      "[Epoch 7/10] [Batch 834/1081] [D loss: 0.064073] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.013958] time: 1:10:43.299727\n",
      "(10, 128, 128, 3)\n",
      "0.94257474\n",
      "[Epoch 7/10] [Batch 835/1081] [D loss: 0.064994] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.010951] time: 1:10:43.884430\n",
      "(10, 128, 128, 3)\n",
      "0.9166465\n",
      "[Epoch 7/10] [Batch 836/1081] [D loss: 0.065178] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.212860] time: 1:10:44.547975\n",
      "(10, 128, 128, 3)\n",
      "0.900719\n",
      "[Epoch 7/10] [Batch 837/1081] [D loss: 0.071057] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.515394] time: 1:10:45.212659\n",
      "(10, 128, 128, 3)\n",
      "0.9003787\n",
      "[Epoch 7/10] [Batch 838/1081] [D loss: 0.063993] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.144403] time: 1:10:45.876218\n",
      "(10, 128, 128, 3)\n",
      "0.86595756\n",
      "[Epoch 7/10] [Batch 839/1081] [D loss: 0.175591] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 5.173010] time: 1:10:46.529698\n",
      "(10, 128, 128, 3)\n",
      "0.90519744\n",
      "[Epoch 7/10] [Batch 840/1081] [D loss: 0.063497] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.541454] time: 1:10:47.152216\n",
      "(10, 128, 128, 3)\n",
      "0.9174393\n",
      "[Epoch 7/10] [Batch 841/1081] [D loss: 0.063497] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.886577] time: 1:10:47.801456\n",
      "(10, 128, 128, 3)\n",
      "0.90537286\n",
      "[Epoch 7/10] [Batch 842/1081] [D loss: 0.067361] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.555322] time: 1:10:48.427086\n",
      "(10, 128, 128, 3)\n",
      "0.9108865\n",
      "[Epoch 7/10] [Batch 843/1081] [D loss: 0.065015] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.268377] time: 1:10:49.146983\n",
      "(10, 128, 128, 3)\n",
      "0.91407037\n",
      "[Epoch 7/10] [Batch 844/1081] [D loss: 0.073034] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.468135] time: 1:10:49.755359\n",
      "(10, 128, 128, 3)\n",
      "0.88965493\n",
      "[Epoch 7/10] [Batch 845/1081] [D loss: 0.099825] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.879616] time: 1:10:50.447323\n",
      "(10, 128, 128, 3)\n",
      "0.91528314\n",
      "[Epoch 7/10] [Batch 846/1081] [D loss: 0.065290] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.708591] time: 1:10:51.078574\n",
      "(10, 128, 128, 3)\n",
      "0.9136626\n",
      "[Epoch 7/10] [Batch 847/1081] [D loss: 0.063476] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.975667] time: 1:10:51.718549\n",
      "(10, 128, 128, 3)\n",
      "0.88882256\n",
      "[Epoch 7/10] [Batch 848/1081] [D loss: 0.063472] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.856834] time: 1:10:52.330357\n",
      "(10, 128, 128, 3)\n",
      "0.88030416\n",
      "[Epoch 7/10] [Batch 849/1081] [D loss: 0.062943] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.691689] time: 1:10:53.010361\n",
      "(10, 128, 128, 3)\n",
      "0.9159228\n",
      "[Epoch 7/10] [Batch 850/1081] [D loss: 0.064018] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.277481] time: 1:10:53.710104\n",
      "(10, 128, 128, 3)\n",
      "0.9345276\n",
      "[Epoch 7/10] [Batch 851/1081] [D loss: 0.060041] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.545022] time: 1:10:54.355821\n",
      "(10, 128, 128, 3)\n",
      "0.9074481\n",
      "[Epoch 7/10] [Batch 852/1081] [D loss: 0.061028] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.707356] time: 1:10:54.967579\n",
      "(10, 128, 128, 3)\n",
      "0.9277751\n",
      "[Epoch 7/10] [Batch 853/1081] [D loss: 0.073685] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.896359] time: 1:10:55.606619\n",
      "(10, 128, 128, 3)\n",
      "0.91433567\n",
      "[Epoch 7/10] [Batch 854/1081] [D loss: 0.061805] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.474526] time: 1:10:56.246274\n",
      "(10, 128, 128, 3)\n",
      "0.8954442\n",
      "[Epoch 7/10] [Batch 855/1081] [D loss: 0.064136] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.730010] time: 1:10:56.926323\n",
      "(10, 128, 128, 3)\n",
      "0.8956492\n",
      "[Epoch 7/10] [Batch 856/1081] [D loss: 0.064510] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.063158] time: 1:10:57.597829\n",
      "(10, 128, 128, 3)\n",
      "0.9235348\n",
      "[Epoch 7/10] [Batch 857/1081] [D loss: 0.061160] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.262398] time: 1:10:58.238478\n",
      "(10, 128, 128, 3)\n",
      "0.8988102\n",
      "[Epoch 7/10] [Batch 858/1081] [D loss: 0.059634] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.706126] time: 1:10:58.840317\n",
      "(10, 128, 128, 3)\n",
      "0.8945713\n",
      "[Epoch 7/10] [Batch 859/1081] [D loss: 0.060715] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.318875] time: 1:10:59.465133\n",
      "(10, 128, 128, 3)\n",
      "0.85948324\n",
      "[Epoch 7/10] [Batch 860/1081] [D loss: 0.067009] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.716752] time: 1:11:00.114863\n",
      "(10, 128, 128, 3)\n",
      "0.9261406\n",
      "[Epoch 7/10] [Batch 861/1081] [D loss: 0.100594] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.490078] time: 1:11:00.828476\n",
      "(10, 128, 128, 3)\n",
      "0.965525\n",
      "[Epoch 7/10] [Batch 862/1081] [D loss: 0.100183] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.674469] time: 1:11:01.503867\n",
      "(10, 128, 128, 3)\n",
      "0.9170058\n",
      "[Epoch 7/10] [Batch 863/1081] [D loss: 0.061443] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.822075] time: 1:11:02.077002\n",
      "(10, 128, 128, 3)\n",
      "0.9102805\n",
      "[Epoch 7/10] [Batch 864/1081] [D loss: 0.059921] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.557653] time: 1:11:02.770584\n",
      "(10, 128, 128, 3)\n",
      "0.86318517\n",
      "[Epoch 7/10] [Batch 865/1081] [D loss: 0.063074] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.409592] time: 1:11:03.407475\n",
      "(10, 128, 128, 3)\n",
      "0.90486\n",
      "[Epoch 7/10] [Batch 866/1081] [D loss: 0.066223] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.521996] time: 1:11:04.078643\n",
      "(10, 128, 128, 3)\n",
      "0.81627625\n",
      "[Epoch 7/10] [Batch 867/1081] [D loss: 0.072789] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.860652] time: 1:11:04.697865\n",
      "(10, 128, 128, 3)\n",
      "0.9588532\n",
      "[Epoch 7/10] [Batch 868/1081] [D loss: 0.062420] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.829479] time: 1:11:05.368751\n",
      "(10, 128, 128, 3)\n",
      "0.89895123\n",
      "[Epoch 7/10] [Batch 869/1081] [D loss: 0.058944] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.104667] time: 1:11:05.981013\n",
      "(10, 128, 128, 3)\n",
      "0.91540956\n",
      "[Epoch 7/10] [Batch 870/1081] [D loss: 0.064645] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.383064] time: 1:11:06.634943\n",
      "(10, 128, 128, 3)\n",
      "0.91887885\n",
      "[Epoch 7/10] [Batch 871/1081] [D loss: 0.061591] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.099318] time: 1:11:07.293479\n",
      "(10, 128, 128, 3)\n",
      "0.888922\n",
      "[Epoch 7/10] [Batch 872/1081] [D loss: 0.058774] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.146090] time: 1:11:07.943746\n",
      "(10, 128, 128, 3)\n",
      "0.9050495\n",
      "[Epoch 7/10] [Batch 873/1081] [D loss: 0.058452] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.886911] time: 1:11:08.624159\n",
      "(10, 128, 128, 3)\n",
      "0.8991661\n",
      "[Epoch 7/10] [Batch 874/1081] [D loss: 0.060408] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.118273] time: 1:11:09.258012\n",
      "(10, 128, 128, 3)\n",
      "0.88976806\n",
      "[Epoch 7/10] [Batch 875/1081] [D loss: 0.057804] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.992480] time: 1:11:09.890490\n",
      "(10, 128, 128, 3)\n",
      "0.9674368\n",
      "[Epoch 7/10] [Batch 876/1081] [D loss: 0.058579] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.809286] time: 1:11:10.474648\n",
      "(10, 128, 128, 3)\n",
      "0.9001951\n",
      "[Epoch 7/10] [Batch 877/1081] [D loss: 0.059695] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.336739] time: 1:11:11.092520\n",
      "(10, 128, 128, 3)\n",
      "0.91917086\n",
      "[Epoch 7/10] [Batch 878/1081] [D loss: 0.059982] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.588709] time: 1:11:11.709692\n",
      "(10, 128, 128, 3)\n",
      "0.94130975\n",
      "[Epoch 7/10] [Batch 879/1081] [D loss: 0.058096] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.637287] time: 1:11:12.410370\n",
      "(10, 128, 128, 3)\n",
      "0.9132538\n",
      "[Epoch 7/10] [Batch 880/1081] [D loss: 0.057702] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.853151] time: 1:11:13.049101\n",
      "(10, 128, 128, 3)\n",
      "0.90019417\n",
      "[Epoch 7/10] [Batch 881/1081] [D loss: 0.057370] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.714419] time: 1:11:13.692544\n",
      "(10, 128, 128, 3)\n",
      "0.9552539\n",
      "[Epoch 7/10] [Batch 882/1081] [D loss: 0.078014] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.843297] time: 1:11:14.326855\n",
      "(10, 128, 128, 3)\n",
      "0.9098044\n",
      "[Epoch 7/10] [Batch 883/1081] [D loss: 0.058013] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.036389] time: 1:11:14.952527\n",
      "(10, 128, 128, 3)\n",
      "0.8653209\n",
      "[Epoch 7/10] [Batch 884/1081] [D loss: 0.057518] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.932503] time: 1:11:15.594259\n",
      "(10, 128, 128, 3)\n",
      "0.9104543\n",
      "[Epoch 7/10] [Batch 885/1081] [D loss: 0.061226] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.935472] time: 1:11:16.294501\n",
      "(10, 128, 128, 3)\n",
      "0.94648415\n",
      "[Epoch 7/10] [Batch 886/1081] [D loss: 0.057225] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.382054] time: 1:11:16.961532\n",
      "(10, 128, 128, 3)\n",
      "0.91973925\n",
      "[Epoch 7/10] [Batch 887/1081] [D loss: 0.071272] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.231459] time: 1:11:17.618498\n",
      "(10, 128, 128, 3)\n",
      "0.93806237\n",
      "[Epoch 7/10] [Batch 888/1081] [D loss: 0.149488] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.026443] time: 1:11:18.250250\n",
      "(10, 128, 128, 3)\n",
      "0.8926355\n",
      "[Epoch 7/10] [Batch 889/1081] [D loss: 0.129174] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.634807] time: 1:11:18.894795\n",
      "(10, 128, 128, 3)\n",
      "0.8920372\n",
      "[Epoch 7/10] [Batch 890/1081] [D loss: 0.116046] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.722063] time: 1:11:19.535180\n",
      "(10, 128, 128, 3)\n",
      "0.9141903\n",
      "[Epoch 7/10] [Batch 891/1081] [D loss: 0.071233] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.865090] time: 1:11:20.215806\n",
      "(10, 128, 128, 3)\n",
      "0.9286277\n",
      "[Epoch 7/10] [Batch 892/1081] [D loss: 0.073292] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.629259] time: 1:11:20.831574\n",
      "(10, 128, 128, 3)\n",
      "0.9373987\n",
      "[Epoch 7/10] [Batch 893/1081] [D loss: 0.100151] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.895129] time: 1:11:21.494122\n",
      "(10, 128, 128, 3)\n",
      "0.8778536\n",
      "[Epoch 7/10] [Batch 894/1081] [D loss: 0.068809] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.611679] time: 1:11:22.120273\n",
      "(10, 128, 128, 3)\n",
      "0.9146807\n",
      "[Epoch 7/10] [Batch 895/1081] [D loss: 0.063273] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.040484] time: 1:11:22.781749\n",
      "(10, 128, 128, 3)\n",
      "0.92091304\n",
      "[Epoch 7/10] [Batch 896/1081] [D loss: 0.064835] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.954847] time: 1:11:23.411897\n",
      "(10, 128, 128, 3)\n",
      "0.9310391\n",
      "[Epoch 7/10] [Batch 897/1081] [D loss: 0.065006] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.502802] time: 1:11:24.066607\n",
      "(10, 128, 128, 3)\n",
      "0.95063066\n",
      "[Epoch 7/10] [Batch 898/1081] [D loss: 0.078041] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.568869] time: 1:11:24.736395\n",
      "(10, 128, 128, 3)\n",
      "0.8759323\n",
      "[Epoch 7/10] [Batch 899/1081] [D loss: 0.062541] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.520357] time: 1:11:25.376355\n",
      "(10, 128, 128, 3)\n",
      "0.9102435\n",
      "[Epoch 7/10] [Batch 900/1081] [D loss: 0.102542] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.135668] time: 1:11:26.084195\n",
      "(10, 128, 128, 3)\n",
      "0.9085199\n",
      "[Epoch 7/10] [Batch 901/1081] [D loss: 0.075223] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.709122] time: 1:11:26.729615\n",
      "(10, 128, 128, 3)\n",
      "0.9249756\n",
      "[Epoch 7/10] [Batch 902/1081] [D loss: 0.082293] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.186586] time: 1:11:27.344220\n",
      "(10, 128, 128, 3)\n",
      "0.8562483\n",
      "[Epoch 7/10] [Batch 903/1081] [D loss: 0.104979] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.720571] time: 1:11:27.968858\n",
      "(10, 128, 128, 3)\n",
      "0.9083639\n",
      "[Epoch 7/10] [Batch 904/1081] [D loss: 0.060699] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.877073] time: 1:11:28.613067\n",
      "(10, 128, 128, 3)\n",
      "0.9226386\n",
      "[Epoch 7/10] [Batch 905/1081] [D loss: 0.122443] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.226315] time: 1:11:29.346087\n",
      "(10, 128, 128, 3)\n",
      "0.88546354\n",
      "[Epoch 7/10] [Batch 906/1081] [D loss: 0.079697] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.132645] time: 1:11:29.962487\n",
      "(10, 128, 128, 3)\n",
      "0.9468265\n",
      "[Epoch 7/10] [Batch 907/1081] [D loss: 0.072111] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.971329] time: 1:11:30.652933\n",
      "(10, 128, 128, 3)\n",
      "0.90631706\n",
      "[Epoch 7/10] [Batch 908/1081] [D loss: 0.066727] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.848863] time: 1:11:31.285454\n",
      "(10, 128, 128, 3)\n",
      "0.9113893\n",
      "[Epoch 7/10] [Batch 909/1081] [D loss: 0.065454] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.546497] time: 1:11:31.924006\n",
      "(10, 128, 128, 3)\n",
      "0.892281\n",
      "[Epoch 7/10] [Batch 910/1081] [D loss: 0.070897] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.112631] time: 1:11:32.585399\n",
      "(10, 128, 128, 3)\n",
      "0.866477\n",
      "[Epoch 7/10] [Batch 911/1081] [D loss: 0.069314] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.675610] time: 1:11:33.243961\n",
      "(10, 128, 128, 3)\n",
      "0.9217511\n",
      "[Epoch 7/10] [Batch 912/1081] [D loss: 0.077085] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.398989] time: 1:11:33.895330\n",
      "(10, 128, 128, 3)\n",
      "0.9278433\n",
      "[Epoch 7/10] [Batch 913/1081] [D loss: 0.070692] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.941434] time: 1:11:34.565478\n",
      "(10, 128, 128, 3)\n",
      "0.9160134\n",
      "[Epoch 7/10] [Batch 914/1081] [D loss: 0.069724] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.837811] time: 1:11:35.278462\n",
      "(10, 128, 128, 3)\n",
      "0.90071326\n",
      "[Epoch 7/10] [Batch 915/1081] [D loss: 0.105868] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.698607] time: 1:11:35.947651\n",
      "(10, 128, 128, 3)\n",
      "0.90338606\n",
      "[Epoch 7/10] [Batch 916/1081] [D loss: 0.113278] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.908217] time: 1:11:36.580071\n",
      "(10, 128, 128, 3)\n",
      "0.906475\n",
      "[Epoch 7/10] [Batch 917/1081] [D loss: 0.067001] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.798072] time: 1:11:37.276045\n",
      "(10, 128, 128, 3)\n",
      "0.9293285\n",
      "[Epoch 7/10] [Batch 918/1081] [D loss: 0.073737] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.025258] time: 1:11:37.931043\n",
      "(10, 128, 128, 3)\n",
      "0.94926786\n",
      "[Epoch 7/10] [Batch 919/1081] [D loss: 0.072489] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.752828] time: 1:11:38.571822\n",
      "(10, 128, 128, 3)\n",
      "0.9198467\n",
      "[Epoch 7/10] [Batch 920/1081] [D loss: 0.110931] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.727799] time: 1:11:39.215094\n",
      "(10, 128, 128, 3)\n",
      "0.8736906\n",
      "[Epoch 7/10] [Batch 921/1081] [D loss: 0.072262] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.860868] time: 1:11:39.823350\n",
      "(10, 128, 128, 3)\n",
      "0.8912947\n",
      "[Epoch 7/10] [Batch 922/1081] [D loss: 0.069059] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.926468] time: 1:11:40.494570\n",
      "(10, 128, 128, 3)\n",
      "0.9298561\n",
      "[Epoch 7/10] [Batch 923/1081] [D loss: 0.062117] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.504050] time: 1:11:41.098540\n",
      "(10, 128, 128, 3)\n",
      "0.9011402\n",
      "[Epoch 7/10] [Batch 924/1081] [D loss: 0.065281] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.347172] time: 1:11:41.706544\n",
      "(10, 128, 128, 3)\n",
      "0.9106664\n",
      "[Epoch 7/10] [Batch 925/1081] [D loss: 0.061603] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.443075] time: 1:11:42.396236\n",
      "(10, 128, 128, 3)\n",
      "0.9159858\n",
      "[Epoch 7/10] [Batch 926/1081] [D loss: 0.061634] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.655212] time: 1:11:43.119049\n",
      "(10, 128, 128, 3)\n",
      "0.8933794\n",
      "[Epoch 7/10] [Batch 927/1081] [D loss: 0.062769] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.101652] time: 1:11:43.709339\n",
      "(10, 128, 128, 3)\n",
      "0.88535786\n",
      "[Epoch 7/10] [Batch 928/1081] [D loss: 0.067381] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.833188] time: 1:11:44.370540\n",
      "(10, 128, 128, 3)\n",
      "0.9267705\n",
      "[Epoch 7/10] [Batch 929/1081] [D loss: 0.061939] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.934553] time: 1:11:45.028897\n",
      "(10, 128, 128, 3)\n",
      "0.9208862\n",
      "[Epoch 7/10] [Batch 930/1081] [D loss: 0.077598] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.138530] time: 1:11:45.600563\n",
      "(10, 128, 128, 3)\n",
      "0.88846046\n",
      "[Epoch 7/10] [Batch 931/1081] [D loss: 0.071247] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.309713] time: 1:11:46.280559\n",
      "(10, 128, 128, 3)\n",
      "0.894715\n",
      "[Epoch 7/10] [Batch 932/1081] [D loss: 0.068123] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.430877] time: 1:11:46.982517\n",
      "(10, 128, 128, 3)\n",
      "0.8638018\n",
      "[Epoch 7/10] [Batch 933/1081] [D loss: 0.084360] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.537329] time: 1:11:47.677051\n",
      "(10, 128, 128, 3)\n",
      "0.91365814\n",
      "[Epoch 7/10] [Batch 934/1081] [D loss: 0.066560] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.084165] time: 1:11:48.294490\n",
      "(10, 128, 128, 3)\n",
      "0.9396818\n",
      "[Epoch 7/10] [Batch 935/1081] [D loss: 0.071498] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.415734] time: 1:11:49.002177\n",
      "(10, 128, 128, 3)\n",
      "0.91670877\n",
      "[Epoch 7/10] [Batch 936/1081] [D loss: 0.065741] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.930654] time: 1:11:49.622501\n",
      "(10, 128, 128, 3)\n",
      "0.947855\n",
      "[Epoch 7/10] [Batch 937/1081] [D loss: 0.092615] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.822057] time: 1:11:50.256175\n",
      "(10, 128, 128, 3)\n",
      "0.8957862\n",
      "[Epoch 7/10] [Batch 938/1081] [D loss: 0.065364] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.223801] time: 1:11:50.894483\n",
      "(10, 128, 128, 3)\n",
      "0.87701386\n",
      "[Epoch 7/10] [Batch 939/1081] [D loss: 0.068622] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.426822] time: 1:11:51.538053\n",
      "(10, 128, 128, 3)\n",
      "0.9430177\n",
      "[Epoch 7/10] [Batch 940/1081] [D loss: 0.061252] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.182090] time: 1:11:52.179674\n",
      "(10, 128, 128, 3)\n",
      "0.9373267\n",
      "[Epoch 7/10] [Batch 941/1081] [D loss: 0.061213] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.958512] time: 1:11:52.810443\n",
      "(10, 128, 128, 3)\n",
      "0.8727555\n",
      "[Epoch 7/10] [Batch 942/1081] [D loss: 0.065181] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.097250] time: 1:11:53.482478\n",
      "(10, 128, 128, 3)\n",
      "0.92191666\n",
      "[Epoch 7/10] [Batch 943/1081] [D loss: 0.063563] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.163235] time: 1:11:54.116133\n",
      "(10, 128, 128, 3)\n",
      "0.9346188\n",
      "[Epoch 7/10] [Batch 944/1081] [D loss: 0.060825] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.322204] time: 1:11:54.818480\n",
      "(10, 128, 128, 3)\n",
      "0.89016587\n",
      "[Epoch 7/10] [Batch 945/1081] [D loss: 0.061943] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.474706] time: 1:11:55.451452\n",
      "(10, 128, 128, 3)\n",
      "0.86297774\n",
      "[Epoch 7/10] [Batch 946/1081] [D loss: 0.061119] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.244868] time: 1:11:56.688319\n",
      "(10, 128, 128, 3)\n",
      "0.9343075\n",
      "[Epoch 7/10] [Batch 947/1081] [D loss: 0.063136] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.008538] time: 1:11:57.392860\n",
      "(10, 128, 128, 3)\n",
      "0.95874566\n",
      "[Epoch 7/10] [Batch 948/1081] [D loss: 0.060095] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.981057] time: 1:11:58.062008\n",
      "(10, 128, 128, 3)\n",
      "0.87248087\n",
      "[Epoch 7/10] [Batch 949/1081] [D loss: 0.060662] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.215333] time: 1:11:58.699311\n",
      "(10, 128, 128, 3)\n",
      "0.9194257\n",
      "[Epoch 7/10] [Batch 950/1081] [D loss: 0.061888] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.624659] time: 1:11:59.387939\n",
      "(10, 128, 128, 3)\n",
      "0.935335\n",
      "[Epoch 7/10] [Batch 951/1081] [D loss: 0.059410] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.123973] time: 1:12:00.019933\n",
      "(10, 128, 128, 3)\n",
      "0.93565124\n",
      "[Epoch 7/10] [Batch 952/1081] [D loss: 0.058978] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.064589] time: 1:12:00.656343\n",
      "(10, 128, 128, 3)\n",
      "0.87701803\n",
      "[Epoch 7/10] [Batch 953/1081] [D loss: 0.060278] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.358987] time: 1:12:01.321892\n",
      "(10, 128, 128, 3)\n",
      "0.9559388\n",
      "[Epoch 7/10] [Batch 954/1081] [D loss: 0.058610] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.140059] time: 1:12:01.980916\n",
      "(10, 128, 128, 3)\n",
      "0.913974\n",
      "[Epoch 7/10] [Batch 955/1081] [D loss: 0.057537] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.611732] time: 1:12:02.648753\n",
      "(10, 128, 128, 3)\n",
      "0.93546295\n",
      "[Epoch 7/10] [Batch 956/1081] [D loss: 0.062571] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.429997] time: 1:12:03.279500\n",
      "(10, 128, 128, 3)\n",
      "0.84936374\n",
      "[Epoch 7/10] [Batch 957/1081] [D loss: 0.065347] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.236853] time: 1:12:03.928712\n",
      "(10, 128, 128, 3)\n",
      "0.9481916\n",
      "[Epoch 7/10] [Batch 958/1081] [D loss: 0.059059] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.643976] time: 1:12:04.648496\n",
      "(10, 128, 128, 3)\n",
      "0.9140397\n",
      "[Epoch 7/10] [Batch 959/1081] [D loss: 0.064805] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.097803] time: 1:12:05.326422\n",
      "(10, 128, 128, 3)\n",
      "0.94641954\n",
      "[Epoch 7/10] [Batch 960/1081] [D loss: 0.060632] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.936912] time: 1:12:05.950621\n",
      "(10, 128, 128, 3)\n",
      "0.9362505\n",
      "[Epoch 7/10] [Batch 961/1081] [D loss: 0.067268] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.471411] time: 1:12:06.541045\n",
      "(10, 128, 128, 3)\n",
      "0.909971\n",
      "[Epoch 7/10] [Batch 962/1081] [D loss: 0.059689] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.127739] time: 1:12:07.206425\n",
      "(10, 128, 128, 3)\n",
      "0.8996795\n",
      "[Epoch 7/10] [Batch 963/1081] [D loss: 0.060459] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.428532] time: 1:12:07.871010\n",
      "(10, 128, 128, 3)\n",
      "0.91123456\n",
      "[Epoch 7/10] [Batch 964/1081] [D loss: 0.056841] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.614745] time: 1:12:08.550612\n",
      "(10, 128, 128, 3)\n",
      "0.91595554\n",
      "[Epoch 7/10] [Batch 965/1081] [D loss: 0.057278] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.787482] time: 1:12:09.252681\n",
      "(10, 128, 128, 3)\n",
      "0.91981083\n",
      "[Epoch 7/10] [Batch 966/1081] [D loss: 0.059576] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.010626] time: 1:12:09.951007\n",
      "(10, 128, 128, 3)\n",
      "0.8854301\n",
      "[Epoch 7/10] [Batch 967/1081] [D loss: 0.058497] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.483031] time: 1:12:10.598544\n",
      "(10, 128, 128, 3)\n",
      "0.9302225\n",
      "[Epoch 7/10] [Batch 968/1081] [D loss: 0.059722] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.047604] time: 1:12:11.255178\n",
      "(10, 128, 128, 3)\n",
      "0.8680889\n",
      "[Epoch 7/10] [Batch 969/1081] [D loss: 0.058570] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.047565] time: 1:12:11.879201\n",
      "(10, 128, 128, 3)\n",
      "0.9488123\n",
      "[Epoch 7/10] [Batch 970/1081] [D loss: 0.056819] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.034412] time: 1:12:12.557564\n",
      "(10, 128, 128, 3)\n",
      "0.9252344\n",
      "[Epoch 7/10] [Batch 971/1081] [D loss: 0.055964] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.563292] time: 1:12:13.192466\n",
      "(10, 128, 128, 3)\n",
      "0.91955686\n",
      "[Epoch 7/10] [Batch 972/1081] [D loss: 0.060242] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.743274] time: 1:12:13.830920\n",
      "(10, 128, 128, 3)\n",
      "0.9420666\n",
      "[Epoch 7/10] [Batch 973/1081] [D loss: 0.057449] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.975936] time: 1:12:14.475491\n",
      "(10, 128, 128, 3)\n",
      "0.8775657\n",
      "[Epoch 7/10] [Batch 974/1081] [D loss: 0.060701] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.441148] time: 1:12:15.141864\n",
      "(10, 128, 128, 3)\n",
      "0.87147325\n",
      "[Epoch 7/10] [Batch 975/1081] [D loss: 0.058154] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.597523] time: 1:12:15.759169\n",
      "(10, 128, 128, 3)\n",
      "0.907533\n",
      "[Epoch 7/10] [Batch 976/1081] [D loss: 0.058484] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.730237] time: 1:12:16.442448\n",
      "(10, 128, 128, 3)\n",
      "0.9220321\n",
      "[Epoch 7/10] [Batch 977/1081] [D loss: 0.059244] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.593049] time: 1:12:17.022505\n",
      "(10, 128, 128, 3)\n",
      "0.97337383\n",
      "[Epoch 7/10] [Batch 978/1081] [D loss: 0.056585] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.897319] time: 1:12:17.614468\n",
      "(10, 128, 128, 3)\n",
      "0.93542844\n",
      "[Epoch 7/10] [Batch 979/1081] [D loss: 0.136909] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.239908] time: 1:12:18.200876\n",
      "(10, 128, 128, 3)\n",
      "0.9280286\n",
      "[Epoch 7/10] [Batch 980/1081] [D loss: 0.071497] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.357702] time: 1:12:18.787996\n",
      "(10, 128, 128, 3)\n",
      "0.8878009\n",
      "[Epoch 7/10] [Batch 981/1081] [D loss: 0.060558] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.902372] time: 1:12:19.352416\n",
      "(10, 128, 128, 3)\n",
      "0.9440469\n",
      "[Epoch 7/10] [Batch 982/1081] [D loss: 0.062770] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.890595] time: 1:12:19.913206\n",
      "(10, 128, 128, 3)\n",
      "0.9232592\n",
      "[Epoch 7/10] [Batch 983/1081] [D loss: 0.058500] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.231674] time: 1:12:20.471484\n",
      "(10, 128, 128, 3)\n",
      "0.90704703\n",
      "[Epoch 7/10] [Batch 984/1081] [D loss: 0.057208] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.373544] time: 1:12:21.051178\n",
      "(10, 128, 128, 3)\n",
      "0.87076783\n",
      "[Epoch 7/10] [Batch 985/1081] [D loss: 0.058446] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.629037] time: 1:12:21.606717\n",
      "(10, 128, 128, 3)\n",
      "0.94483787\n",
      "[Epoch 7/10] [Batch 986/1081] [D loss: 0.059761] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.830208] time: 1:12:22.182822\n",
      "(10, 128, 128, 3)\n",
      "0.9067261\n",
      "[Epoch 7/10] [Batch 987/1081] [D loss: 0.059015] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.104098] time: 1:12:22.772148\n",
      "(10, 128, 128, 3)\n",
      "0.93264836\n",
      "[Epoch 7/10] [Batch 988/1081] [D loss: 0.057679] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.345061] time: 1:12:23.339234\n",
      "(10, 128, 128, 3)\n",
      "0.90969115\n",
      "[Epoch 7/10] [Batch 989/1081] [D loss: 0.056769] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.806509] time: 1:12:23.905777\n",
      "(10, 128, 128, 3)\n",
      "0.8789666\n",
      "[Epoch 7/10] [Batch 990/1081] [D loss: 0.058079] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.735079] time: 1:12:24.482450\n",
      "(10, 128, 128, 3)\n",
      "0.9609399\n",
      "[Epoch 7/10] [Batch 991/1081] [D loss: 0.056592] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.421576] time: 1:12:25.022563\n",
      "(10, 128, 128, 3)\n",
      "0.942126\n",
      "[Epoch 7/10] [Batch 992/1081] [D loss: 0.055929] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.368560] time: 1:12:25.541474\n",
      "(10, 128, 128, 3)\n",
      "0.9133174\n",
      "[Epoch 7/10] [Batch 993/1081] [D loss: 0.057550] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.594688] time: 1:12:26.075201\n",
      "(10, 128, 128, 3)\n",
      "0.94648117\n",
      "[Epoch 7/10] [Batch 994/1081] [D loss: 0.057054] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.801672] time: 1:12:26.626515\n",
      "(10, 128, 128, 3)\n",
      "0.89281815\n",
      "[Epoch 7/10] [Batch 995/1081] [D loss: 0.055876] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.411535] time: 1:12:27.161130\n",
      "(10, 128, 128, 3)\n",
      "0.9039871\n",
      "[Epoch 7/10] [Batch 996/1081] [D loss: 0.056898] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.614675] time: 1:12:27.700009\n",
      "(10, 128, 128, 3)\n",
      "0.8993044\n",
      "[Epoch 7/10] [Batch 997/1081] [D loss: 0.056000] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.987413] time: 1:12:28.270161\n",
      "(10, 128, 128, 3)\n",
      "0.8757441\n",
      "[Epoch 7/10] [Batch 998/1081] [D loss: 0.057227] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.364332] time: 1:12:28.851930\n",
      "(10, 128, 128, 3)\n",
      "0.9177861\n",
      "[Epoch 7/10] [Batch 999/1081] [D loss: 0.578769] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 4.344599] time: 1:12:29.425597\n",
      "(10, 128, 128, 3)\n",
      "0.90544486\n",
      "[Epoch 7/10] [Batch 1000/1081] [D loss: 0.402438] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 4.680627] time: 1:12:29.972299\n",
      "(10, 128, 128, 3)\n",
      "0.8895152\n",
      "[Epoch 7/10] [Batch 1001/1081] [D loss: 0.324078] [D acc: 0.45 (0.90 real, 0.00 fake)] [G loss: 5.264941] time: 1:12:30.488690\n",
      "(10, 128, 128, 3)\n",
      "0.9276592\n",
      "[Epoch 7/10] [Batch 1002/1081] [D loss: 0.403592] [D acc: 0.15 (0.20 real, 0.10 fake)] [G loss: 5.126565] time: 1:12:31.070578\n",
      "(10, 128, 128, 3)\n",
      "0.9420163\n",
      "[Epoch 7/10] [Batch 1003/1081] [D loss: 0.307159] [D acc: 0.45 (0.10 real, 0.80 fake)] [G loss: 4.089951] time: 1:12:31.675395\n",
      "(10, 128, 128, 3)\n",
      "0.9384224\n",
      "[Epoch 7/10] [Batch 1004/1081] [D loss: 0.200616] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 3.808649] time: 1:12:32.230834\n",
      "(10, 128, 128, 3)\n",
      "0.8855663\n",
      "[Epoch 7/10] [Batch 1005/1081] [D loss: 0.134555] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.086957] time: 1:12:32.769704\n",
      "(10, 128, 128, 3)\n",
      "0.894396\n",
      "[Epoch 7/10] [Batch 1006/1081] [D loss: 0.101757] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.349709] time: 1:12:33.367914\n",
      "(10, 128, 128, 3)\n",
      "0.90963507\n",
      "[Epoch 7/10] [Batch 1007/1081] [D loss: 0.078089] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.867866] time: 1:12:33.931660\n",
      "(10, 128, 128, 3)\n",
      "0.88806325\n",
      "[Epoch 7/10] [Batch 1008/1081] [D loss: 0.069181] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.544442] time: 1:12:34.481390\n",
      "(10, 128, 128, 3)\n",
      "0.9375286\n",
      "[Epoch 7/10] [Batch 1009/1081] [D loss: 0.063962] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.171468] time: 1:12:35.045319\n",
      "(10, 128, 128, 3)\n",
      "0.96036416\n",
      "[Epoch 7/10] [Batch 1010/1081] [D loss: 0.066467] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.897933] time: 1:12:35.622946\n",
      "(10, 128, 128, 3)\n",
      "0.94147426\n",
      "[Epoch 7/10] [Batch 1011/1081] [D loss: 0.057920] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.077403] time: 1:12:36.205900\n",
      "(10, 128, 128, 3)\n",
      "0.87581825\n",
      "[Epoch 7/10] [Batch 1012/1081] [D loss: 0.062738] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.861691] time: 1:12:36.791831\n",
      "(10, 128, 128, 3)\n",
      "0.91319185\n",
      "[Epoch 7/10] [Batch 1013/1081] [D loss: 0.059458] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.346039] time: 1:12:37.460670\n",
      "(10, 128, 128, 3)\n",
      "0.8967367\n",
      "[Epoch 7/10] [Batch 1014/1081] [D loss: 0.059474] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.844178] time: 1:12:38.175936\n",
      "(10, 128, 128, 3)\n",
      "0.95966506\n",
      "[Epoch 7/10] [Batch 1015/1081] [D loss: 0.056602] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.861299] time: 1:12:38.861832\n",
      "(10, 128, 128, 3)\n",
      "0.9195352\n",
      "[Epoch 7/10] [Batch 1016/1081] [D loss: 0.058241] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.472009] time: 1:12:39.481395\n",
      "(10, 128, 128, 3)\n",
      "0.90460664\n",
      "[Epoch 7/10] [Batch 1017/1081] [D loss: 0.071683] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.309302] time: 1:12:40.160211\n",
      "(10, 128, 128, 3)\n",
      "0.92530555\n",
      "[Epoch 7/10] [Batch 1018/1081] [D loss: 0.058794] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.237510] time: 1:12:40.864357\n",
      "(10, 128, 128, 3)\n",
      "0.91731954\n",
      "[Epoch 7/10] [Batch 1019/1081] [D loss: 0.057721] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.414634] time: 1:12:41.537808\n",
      "(10, 128, 128, 3)\n",
      "0.90609986\n",
      "[Epoch 7/10] [Batch 1020/1081] [D loss: 0.055999] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.559729] time: 1:12:42.187801\n",
      "(10, 128, 128, 3)\n",
      "0.89387745\n",
      "[Epoch 7/10] [Batch 1021/1081] [D loss: 0.056368] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.780000] time: 1:12:42.773858\n",
      "(10, 128, 128, 3)\n",
      "0.92984587\n",
      "[Epoch 7/10] [Batch 1022/1081] [D loss: 0.058043] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.445118] time: 1:12:43.414773\n",
      "(10, 128, 128, 3)\n",
      "0.90236014\n",
      "[Epoch 7/10] [Batch 1023/1081] [D loss: 0.055640] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.340334] time: 1:12:44.095418\n",
      "(10, 128, 128, 3)\n",
      "0.84903115\n",
      "[Epoch 7/10] [Batch 1024/1081] [D loss: 0.055776] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.419630] time: 1:12:44.810187\n",
      "(10, 128, 128, 3)\n",
      "0.9360743\n",
      "[Epoch 7/10] [Batch 1025/1081] [D loss: 0.056686] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.432137] time: 1:12:45.436608\n",
      "(10, 128, 128, 3)\n",
      "0.93433696\n",
      "[Epoch 7/10] [Batch 1026/1081] [D loss: 0.054807] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.467185] time: 1:12:46.138932\n",
      "(10, 128, 128, 3)\n",
      "0.9135595\n",
      "[Epoch 7/10] [Batch 1027/1081] [D loss: 0.056034] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.793605] time: 1:12:46.811682\n",
      "(10, 128, 128, 3)\n",
      "0.9027856\n",
      "[Epoch 7/10] [Batch 1028/1081] [D loss: 0.055759] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.170559] time: 1:12:47.473549\n",
      "(10, 128, 128, 3)\n",
      "0.9398921\n",
      "[Epoch 7/10] [Batch 1029/1081] [D loss: 0.054685] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.534698] time: 1:12:48.096610\n",
      "(10, 128, 128, 3)\n",
      "0.90126085\n",
      "[Epoch 7/10] [Batch 1030/1081] [D loss: 0.054736] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.982004] time: 1:12:48.719461\n",
      "(10, 128, 128, 3)\n",
      "0.8738727\n",
      "[Epoch 7/10] [Batch 1031/1081] [D loss: 0.055727] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.528707] time: 1:12:49.377315\n",
      "(10, 128, 128, 3)\n",
      "0.96722984\n",
      "[Epoch 7/10] [Batch 1032/1081] [D loss: 0.054585] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.860959] time: 1:12:50.004699\n",
      "(10, 128, 128, 3)\n",
      "0.96371406\n",
      "[Epoch 7/10] [Batch 1033/1081] [D loss: 0.054325] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.296713] time: 1:12:50.675098\n",
      "(10, 128, 128, 3)\n",
      "0.93197674\n",
      "[Epoch 7/10] [Batch 1034/1081] [D loss: 0.054668] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.291902] time: 1:12:51.358348\n",
      "(10, 128, 128, 3)\n",
      "0.91170853\n",
      "[Epoch 7/10] [Batch 1035/1081] [D loss: 0.054794] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.385185] time: 1:12:51.969127\n",
      "(10, 128, 128, 3)\n",
      "0.9463928\n",
      "[Epoch 7/10] [Batch 1036/1081] [D loss: 0.056654] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.605473] time: 1:12:52.653282\n",
      "(10, 128, 128, 3)\n",
      "0.918992\n",
      "[Epoch 7/10] [Batch 1037/1081] [D loss: 0.053507] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.681854] time: 1:12:53.345824\n",
      "(10, 128, 128, 3)\n",
      "0.8706754\n",
      "[Epoch 7/10] [Batch 1038/1081] [D loss: 0.055144] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.375629] time: 1:12:53.996878\n",
      "(10, 128, 128, 3)\n",
      "0.93458575\n",
      "[Epoch 7/10] [Batch 1039/1081] [D loss: 0.055258] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.039708] time: 1:12:54.622482\n",
      "(10, 128, 128, 3)\n",
      "0.9451558\n",
      "[Epoch 7/10] [Batch 1040/1081] [D loss: 0.054513] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.722263] time: 1:12:55.254648\n",
      "(10, 128, 128, 3)\n",
      "0.92658263\n",
      "[Epoch 7/10] [Batch 1041/1081] [D loss: 0.055432] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.485107] time: 1:12:55.891120\n",
      "(10, 128, 128, 3)\n",
      "0.91367775\n",
      "[Epoch 7/10] [Batch 1042/1081] [D loss: 0.054809] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.591161] time: 1:12:56.503621\n",
      "(10, 128, 128, 3)\n",
      "0.8999613\n",
      "[Epoch 7/10] [Batch 1043/1081] [D loss: 0.054005] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.413052] time: 1:12:57.202356\n",
      "(10, 128, 128, 3)\n",
      "0.89434505\n",
      "[Epoch 7/10] [Batch 1044/1081] [D loss: 0.053042] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.086812] time: 1:12:57.814782\n",
      "(10, 128, 128, 3)\n",
      "0.8627551\n",
      "[Epoch 7/10] [Batch 1045/1081] [D loss: 0.056654] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.853388] time: 1:12:58.429259\n",
      "(10, 128, 128, 3)\n",
      "0.88673323\n",
      "[Epoch 7/10] [Batch 1046/1081] [D loss: 0.055760] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.376516] time: 1:12:59.154598\n",
      "(10, 128, 128, 3)\n",
      "0.9100814\n",
      "[Epoch 7/10] [Batch 1047/1081] [D loss: 0.053937] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.751305] time: 1:12:59.787058\n",
      "(10, 128, 128, 3)\n",
      "0.896033\n",
      "[Epoch 7/10] [Batch 1048/1081] [D loss: 0.054209] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.698398] time: 1:13:00.439126\n",
      "(10, 128, 128, 3)\n",
      "0.9048719\n",
      "[Epoch 7/10] [Batch 1049/1081] [D loss: 0.053819] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.281426] time: 1:13:01.063493\n",
      "(10, 128, 128, 3)\n",
      "0.8261528\n",
      "[Epoch 7/10] [Batch 1050/1081] [D loss: 0.055048] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.234862] time: 1:13:01.766721\n",
      "(10, 128, 128, 3)\n",
      "0.95023394\n",
      "[Epoch 7/10] [Batch 1051/1081] [D loss: 0.052376] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.898417] time: 1:13:02.401376\n",
      "(10, 128, 128, 3)\n",
      "0.91585135\n",
      "[Epoch 7/10] [Batch 1052/1081] [D loss: 0.053527] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.413863] time: 1:13:03.056233\n",
      "(10, 128, 128, 3)\n",
      "0.94156104\n",
      "[Epoch 7/10] [Batch 1053/1081] [D loss: 0.052554] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.736130] time: 1:13:03.754049\n",
      "(10, 128, 128, 3)\n",
      "0.86111706\n",
      "[Epoch 7/10] [Batch 1054/1081] [D loss: 0.053788] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.357240] time: 1:13:04.465337\n",
      "(10, 128, 128, 3)\n",
      "0.9182491\n",
      "[Epoch 7/10] [Batch 1055/1081] [D loss: 0.053621] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.308524] time: 1:13:05.149953\n",
      "(10, 128, 128, 3)\n",
      "0.88878006\n",
      "[Epoch 7/10] [Batch 1056/1081] [D loss: 0.055462] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.783020] time: 1:13:05.750480\n",
      "(10, 128, 128, 3)\n",
      "0.93107563\n",
      "[Epoch 7/10] [Batch 1057/1081] [D loss: 0.052630] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.704686] time: 1:13:06.358482\n",
      "(10, 128, 128, 3)\n",
      "0.9153808\n",
      "[Epoch 7/10] [Batch 1058/1081] [D loss: 0.052305] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.103326] time: 1:13:07.006181\n",
      "(10, 128, 128, 3)\n",
      "0.91795516\n",
      "[Epoch 7/10] [Batch 1059/1081] [D loss: 0.052402] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.029540] time: 1:13:07.672910\n",
      "(10, 128, 128, 3)\n",
      "0.9029085\n",
      "[Epoch 7/10] [Batch 1060/1081] [D loss: 0.052588] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.431524] time: 1:13:08.319984\n",
      "(10, 128, 128, 3)\n",
      "0.9415564\n",
      "[Epoch 7/10] [Batch 1061/1081] [D loss: 0.052737] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.907765] time: 1:13:08.991992\n",
      "(10, 128, 128, 3)\n",
      "0.90377825\n",
      "[Epoch 7/10] [Batch 1062/1081] [D loss: 0.051602] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.051115] time: 1:13:09.661953\n",
      "(10, 128, 128, 3)\n",
      "0.8968621\n",
      "[Epoch 7/10] [Batch 1063/1081] [D loss: 0.052100] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.592351] time: 1:13:10.302369\n",
      "(10, 128, 128, 3)\n",
      "0.8952372\n",
      "[Epoch 7/10] [Batch 1064/1081] [D loss: 0.053398] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.970198] time: 1:13:11.002478\n",
      "(10, 128, 128, 3)\n",
      "0.84449893\n",
      "[Epoch 7/10] [Batch 1065/1081] [D loss: 0.056584] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.363059] time: 1:13:11.642409\n",
      "(10, 128, 128, 3)\n",
      "0.89111215\n",
      "[Epoch 7/10] [Batch 1066/1081] [D loss: 0.051968] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.569490] time: 1:13:12.347338\n",
      "(10, 128, 128, 3)\n",
      "0.9130911\n",
      "[Epoch 7/10] [Batch 1067/1081] [D loss: 0.054043] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.991363] time: 1:13:12.990803\n",
      "(10, 128, 128, 3)\n",
      "0.93303394\n",
      "[Epoch 7/10] [Batch 1068/1081] [D loss: 0.052415] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.846943] time: 1:13:13.657105\n",
      "(10, 128, 128, 3)\n",
      "0.91774577\n",
      "[Epoch 7/10] [Batch 1069/1081] [D loss: 0.051984] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.106774] time: 1:13:14.322007\n",
      "(10, 128, 128, 3)\n",
      "0.8816802\n",
      "[Epoch 7/10] [Batch 1070/1081] [D loss: 0.051616] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.763361] time: 1:13:14.945621\n",
      "(10, 128, 128, 3)\n",
      "0.903477\n",
      "[Epoch 7/10] [Batch 1071/1081] [D loss: 0.052591] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.078427] time: 1:13:15.588439\n",
      "(10, 128, 128, 3)\n",
      "0.89732605\n",
      "[Epoch 7/10] [Batch 1072/1081] [D loss: 0.051637] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.450593] time: 1:13:16.167860\n",
      "(10, 128, 128, 3)\n",
      "0.90443\n",
      "[Epoch 7/10] [Batch 1073/1081] [D loss: 0.052911] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.998761] time: 1:13:16.826943\n",
      "(10, 128, 128, 3)\n",
      "0.9324681\n",
      "[Epoch 7/10] [Batch 1074/1081] [D loss: 0.050942] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.261241] time: 1:13:17.477205\n",
      "(10, 128, 128, 3)\n",
      "0.92003155\n",
      "[Epoch 7/10] [Batch 1075/1081] [D loss: 0.051393] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.535934] time: 1:13:18.078931\n",
      "(10, 128, 128, 3)\n",
      "0.8915658\n",
      "[Epoch 7/10] [Batch 1076/1081] [D loss: 0.050959] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.572311] time: 1:13:18.715762\n",
      "(10, 128, 128, 3)\n",
      "0.93679285\n",
      "[Epoch 7/10] [Batch 1077/1081] [D loss: 0.050588] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.382659] time: 1:13:19.349551\n",
      "(10, 128, 128, 3)\n",
      "0.8668341\n",
      "[Epoch 7/10] [Batch 1078/1081] [D loss: 0.052351] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.951049] time: 1:13:19.994196\n",
      "(10, 128, 128, 3)\n",
      "0.89899445\n",
      "[Epoch 7/10] [Batch 1079/1081] [D loss: 0.050941] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.188163] time: 1:13:20.623472\n",
      "(10, 128, 128, 3)\n",
      "0.9044399\n",
      "[Epoch 7/10] [Batch 1080/1081] [D loss: 0.050411] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.908941] time: 1:13:21.256675\n",
      "############ VALIDATION OF EPOCH 7 ############\n",
      "############ TRAINING OF EPOCH 8 ############\n",
      "(10, 128, 128, 3)\n",
      "0.9098322\n",
      "[Epoch 8/10] [Batch 0/1081] [D loss: 0.050584] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.531630] time: 1:14:30.942975\n",
      "(10, 128, 128, 3)\n",
      "0.94275546\n",
      "[Epoch 8/10] [Batch 1/1081] [D loss: 0.050935] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.142168] time: 1:14:31.539456\n",
      "(10, 128, 128, 3)\n",
      "0.907767\n",
      "[Epoch 8/10] [Batch 2/1081] [D loss: 0.050100] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.670184] time: 1:14:32.163944\n",
      "(10, 128, 128, 3)\n",
      "0.8982806\n",
      "[Epoch 8/10] [Batch 3/1081] [D loss: 0.050526] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.462175] time: 1:14:32.803886\n",
      "(10, 128, 128, 3)\n",
      "0.91848755\n",
      "[Epoch 8/10] [Batch 4/1081] [D loss: 0.051239] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.015133] time: 1:14:33.425045\n",
      "(10, 128, 128, 3)\n",
      "0.8839333\n",
      "[Epoch 8/10] [Batch 5/1081] [D loss: 0.049927] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.557983] time: 1:14:34.081075\n",
      "(10, 128, 128, 3)\n",
      "0.9054032\n",
      "[Epoch 8/10] [Batch 7/1081] [D loss: 0.049958] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.753158] time: 1:14:34.730873\n",
      "(10, 128, 128, 3)\n",
      "0.93665266\n",
      "[Epoch 8/10] [Batch 8/1081] [D loss: 0.050232] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.660006] time: 1:14:35.371201\n",
      "(10, 128, 128, 3)\n",
      "0.8666904\n",
      "[Epoch 8/10] [Batch 9/1081] [D loss: 0.051445] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.595710] time: 1:14:36.013000\n",
      "(10, 128, 128, 3)\n",
      "0.9402818\n",
      "[Epoch 8/10] [Batch 10/1081] [D loss: 0.050454] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.776768] time: 1:14:36.672283\n",
      "(10, 128, 128, 3)\n",
      "0.9124996\n",
      "[Epoch 8/10] [Batch 11/1081] [D loss: 0.050756] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.095258] time: 1:14:37.268859\n",
      "(10, 128, 128, 3)\n",
      "0.8727927\n",
      "[Epoch 8/10] [Batch 12/1081] [D loss: 0.050532] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.450727] time: 1:14:37.936988\n",
      "(10, 128, 128, 3)\n",
      "0.8900426\n",
      "[Epoch 8/10] [Batch 13/1081] [D loss: 0.050438] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.989997] time: 1:14:38.574551\n",
      "(10, 128, 128, 3)\n",
      "0.87005764\n",
      "[Epoch 8/10] [Batch 14/1081] [D loss: 0.050815] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.426311] time: 1:14:39.196345\n",
      "(10, 128, 128, 3)\n",
      "0.90875524\n",
      "[Epoch 8/10] [Batch 15/1081] [D loss: 0.049946] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.493856] time: 1:14:39.874848\n",
      "(10, 128, 128, 3)\n",
      "0.899688\n",
      "[Epoch 8/10] [Batch 16/1081] [D loss: 0.049328] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.145467] time: 1:14:40.473136\n",
      "(10, 128, 128, 3)\n",
      "0.93901294\n",
      "[Epoch 8/10] [Batch 17/1081] [D loss: 0.050219] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.540635] time: 1:14:41.125605\n",
      "(10, 128, 128, 3)\n",
      "0.9232199\n",
      "[Epoch 8/10] [Batch 18/1081] [D loss: 0.050864] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.386835] time: 1:14:41.844194\n",
      "(10, 128, 128, 3)\n",
      "0.9323564\n",
      "[Epoch 8/10] [Batch 19/1081] [D loss: 0.050075] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.417155] time: 1:14:42.485132\n",
      "(10, 128, 128, 3)\n",
      "0.9375885\n",
      "[Epoch 8/10] [Batch 20/1081] [D loss: 0.049413] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.879928] time: 1:14:43.150463\n",
      "(10, 128, 128, 3)\n",
      "0.89779633\n",
      "[Epoch 8/10] [Batch 21/1081] [D loss: 0.049519] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.415099] time: 1:14:43.811857\n",
      "(10, 128, 128, 3)\n",
      "0.8828481\n",
      "[Epoch 8/10] [Batch 22/1081] [D loss: 0.048907] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.732693] time: 1:14:44.457402\n",
      "(10, 128, 128, 3)\n",
      "0.9088824\n",
      "[Epoch 8/10] [Batch 23/1081] [D loss: 0.049014] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.643181] time: 1:14:45.133676\n",
      "(10, 128, 128, 3)\n",
      "0.89159936\n",
      "[Epoch 8/10] [Batch 24/1081] [D loss: 0.049297] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.046916] time: 1:14:45.851386\n",
      "(10, 128, 128, 3)\n",
      "0.9221299\n",
      "[Epoch 8/10] [Batch 25/1081] [D loss: 0.048764] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.121265] time: 1:14:46.450487\n",
      "(10, 128, 128, 3)\n",
      "0.9040449\n",
      "[Epoch 8/10] [Batch 26/1081] [D loss: 0.050423] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.878350] time: 1:14:47.095564\n",
      "(10, 128, 128, 3)\n",
      "0.9105503\n",
      "[Epoch 8/10] [Batch 27/1081] [D loss: 0.049577] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.704554] time: 1:14:47.728333\n",
      "(10, 128, 128, 3)\n",
      "0.905399\n",
      "[Epoch 8/10] [Batch 28/1081] [D loss: 0.048488] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.092345] time: 1:14:48.340179\n",
      "(10, 128, 128, 3)\n",
      "0.94321275\n",
      "[Epoch 8/10] [Batch 29/1081] [D loss: 0.049731] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.963093] time: 1:14:49.036112\n",
      "(10, 128, 128, 3)\n",
      "0.90788895\n",
      "[Epoch 8/10] [Batch 30/1081] [D loss: 0.050418] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.871710] time: 1:14:49.702687\n",
      "(10, 128, 128, 3)\n",
      "0.9349334\n",
      "[Epoch 8/10] [Batch 31/1081] [D loss: 0.048938] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.560293] time: 1:14:50.364961\n",
      "(10, 128, 128, 3)\n",
      "0.92233443\n",
      "[Epoch 8/10] [Batch 32/1081] [D loss: 0.048882] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.149071] time: 1:14:51.028154\n",
      "(10, 128, 128, 3)\n",
      "0.9717954\n",
      "[Epoch 8/10] [Batch 33/1081] [D loss: 0.049125] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.287242] time: 1:14:51.695167\n",
      "(10, 128, 128, 3)\n",
      "0.8999472\n",
      "[Epoch 8/10] [Batch 34/1081] [D loss: 0.048179] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.375750] time: 1:14:52.385898\n",
      "(10, 128, 128, 3)\n",
      "0.87609315\n",
      "[Epoch 8/10] [Batch 35/1081] [D loss: 0.049549] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.993793] time: 1:14:52.994725\n",
      "(10, 128, 128, 3)\n",
      "0.9465985\n",
      "[Epoch 8/10] [Batch 36/1081] [D loss: 0.048482] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.998038] time: 1:14:53.675462\n",
      "(10, 128, 128, 3)\n",
      "0.8988597\n",
      "[Epoch 8/10] [Batch 37/1081] [D loss: 0.048524] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.977012] time: 1:14:54.320966\n",
      "(10, 128, 128, 3)\n",
      "0.9166825\n",
      "[Epoch 8/10] [Batch 38/1081] [D loss: 0.048799] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.757439] time: 1:14:54.995783\n",
      "(10, 128, 128, 3)\n",
      "0.914557\n",
      "[Epoch 8/10] [Batch 39/1081] [D loss: 0.048617] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.805226] time: 1:14:55.621888\n",
      "(10, 128, 128, 3)\n",
      "0.8666973\n",
      "[Epoch 8/10] [Batch 40/1081] [D loss: 0.048477] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.053756] time: 1:14:56.278675\n",
      "(10, 128, 128, 3)\n",
      "0.89932674\n",
      "[Epoch 8/10] [Batch 41/1081] [D loss: 0.047992] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.256979] time: 1:14:56.874632\n",
      "(10, 128, 128, 3)\n",
      "0.96488315\n",
      "[Epoch 8/10] [Batch 42/1081] [D loss: 0.048986] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.428648] time: 1:14:57.562179\n",
      "(10, 128, 128, 3)\n",
      "0.8953716\n",
      "[Epoch 8/10] [Batch 43/1081] [D loss: 0.048401] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.132241] time: 1:14:58.208288\n",
      "(10, 128, 128, 3)\n",
      "0.93309927\n",
      "[Epoch 8/10] [Batch 44/1081] [D loss: 0.048157] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.062955] time: 1:14:58.872849\n",
      "(10, 128, 128, 3)\n",
      "0.884758\n",
      "[Epoch 8/10] [Batch 45/1081] [D loss: 0.049926] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.276540] time: 1:14:59.477466\n",
      "(10, 128, 128, 3)\n",
      "0.8670122\n",
      "[Epoch 8/10] [Batch 46/1081] [D loss: 0.050117] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.794504] time: 1:15:00.166918\n",
      "(10, 128, 128, 3)\n",
      "0.8969736\n",
      "[Epoch 8/10] [Batch 47/1081] [D loss: 0.047917] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.142880] time: 1:15:00.825227\n",
      "(10, 128, 128, 3)\n",
      "0.9442844\n",
      "[Epoch 8/10] [Batch 48/1081] [D loss: 0.048366] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.045011] time: 1:15:01.466492\n",
      "(10, 128, 128, 3)\n",
      "0.9545124\n",
      "[Epoch 8/10] [Batch 49/1081] [D loss: 0.048362] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.554617] time: 1:15:02.091971\n",
      "(10, 128, 128, 3)\n",
      "0.9387195\n",
      "[Epoch 8/10] [Batch 50/1081] [D loss: 0.047820] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.169765] time: 1:15:02.754547\n",
      "(10, 128, 128, 3)\n",
      "0.92949265\n",
      "[Epoch 8/10] [Batch 51/1081] [D loss: 0.048281] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.983001] time: 1:15:03.406887\n",
      "(10, 128, 128, 3)\n",
      "0.9289697\n",
      "[Epoch 8/10] [Batch 52/1081] [D loss: 0.047625] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.619260] time: 1:15:03.996945\n",
      "(10, 128, 128, 3)\n",
      "0.93712837\n",
      "[Epoch 8/10] [Batch 53/1081] [D loss: 0.047753] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.789409] time: 1:15:04.661600\n",
      "(10, 128, 128, 3)\n",
      "0.92789024\n",
      "[Epoch 8/10] [Batch 54/1081] [D loss: 0.048112] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.434737] time: 1:15:05.347969\n",
      "(10, 128, 128, 3)\n",
      "0.9165895\n",
      "[Epoch 8/10] [Batch 55/1081] [D loss: 0.047622] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.700166] time: 1:15:06.027096\n",
      "(10, 128, 128, 3)\n",
      "0.95577574\n",
      "[Epoch 8/10] [Batch 56/1081] [D loss: 0.047350] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.041226] time: 1:15:06.708698\n",
      "(10, 128, 128, 3)\n",
      "0.94278836\n",
      "[Epoch 8/10] [Batch 57/1081] [D loss: 0.047414] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.590138] time: 1:15:07.318556\n",
      "(10, 128, 128, 3)\n",
      "0.9403436\n",
      "[Epoch 8/10] [Batch 58/1081] [D loss: 0.047896] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.807320] time: 1:15:08.032215\n",
      "(10, 128, 128, 3)\n",
      "0.9371721\n",
      "[Epoch 8/10] [Batch 59/1081] [D loss: 0.047130] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.839793] time: 1:15:08.681281\n",
      "(10, 128, 128, 3)\n",
      "0.933093\n",
      "[Epoch 8/10] [Batch 60/1081] [D loss: 0.049573] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.719473] time: 1:15:09.304556\n",
      "(10, 128, 128, 3)\n",
      "0.9438365\n",
      "[Epoch 8/10] [Batch 61/1081] [D loss: 0.054084] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.371631] time: 1:15:09.946554\n",
      "(10, 128, 128, 3)\n",
      "0.9178181\n",
      "[Epoch 8/10] [Batch 62/1081] [D loss: 0.050803] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.059200] time: 1:15:10.601664\n",
      "(10, 128, 128, 3)\n",
      "0.93543094\n",
      "[Epoch 8/10] [Batch 63/1081] [D loss: 0.050511] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.476918] time: 1:15:11.263641\n",
      "(10, 128, 128, 3)\n",
      "0.90491885\n",
      "[Epoch 8/10] [Batch 64/1081] [D loss: 0.048255] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.028663] time: 1:15:11.935285\n",
      "(10, 128, 128, 3)\n",
      "0.9027427\n",
      "[Epoch 8/10] [Batch 65/1081] [D loss: 0.049054] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.543231] time: 1:15:12.594473\n",
      "(10, 128, 128, 3)\n",
      "0.9336539\n",
      "[Epoch 8/10] [Batch 66/1081] [D loss: 0.048133] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.590728] time: 1:15:13.246610\n",
      "(10, 128, 128, 3)\n",
      "0.8954577\n",
      "[Epoch 8/10] [Batch 67/1081] [D loss: 0.047268] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.318421] time: 1:15:13.830361\n",
      "(10, 128, 128, 3)\n",
      "0.91620207\n",
      "[Epoch 8/10] [Batch 68/1081] [D loss: 0.047416] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.444096] time: 1:15:14.468943\n",
      "(10, 128, 128, 3)\n",
      "0.90239185\n",
      "[Epoch 8/10] [Batch 69/1081] [D loss: 0.047284] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.389327] time: 1:15:15.113114\n",
      "(10, 128, 128, 3)\n",
      "0.9346719\n",
      "[Epoch 8/10] [Batch 70/1081] [D loss: 0.047760] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.996062] time: 1:15:15.776460\n",
      "(10, 128, 128, 3)\n",
      "0.8870508\n",
      "[Epoch 8/10] [Batch 71/1081] [D loss: 0.047983] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.105980] time: 1:15:16.394862\n",
      "(10, 128, 128, 3)\n",
      "0.9578016\n",
      "[Epoch 8/10] [Batch 72/1081] [D loss: 0.047203] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.910479] time: 1:15:17.051730\n",
      "(10, 128, 128, 3)\n",
      "0.90057445\n",
      "[Epoch 8/10] [Batch 73/1081] [D loss: 0.046984] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.866228] time: 1:15:17.695535\n",
      "(10, 128, 128, 3)\n",
      "0.87445927\n",
      "[Epoch 8/10] [Batch 74/1081] [D loss: 0.047014] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.991654] time: 1:15:18.318950\n",
      "(10, 128, 128, 3)\n",
      "0.91993994\n",
      "[Epoch 8/10] [Batch 75/1081] [D loss: 0.046745] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.423041] time: 1:15:18.950315\n",
      "(10, 128, 128, 3)\n",
      "0.93858355\n",
      "[Epoch 8/10] [Batch 76/1081] [D loss: 0.046499] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.651756] time: 1:15:19.573035\n",
      "(10, 128, 128, 3)\n",
      "0.9112614\n",
      "[Epoch 8/10] [Batch 77/1081] [D loss: 0.046404] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.256013] time: 1:15:20.223592\n",
      "(10, 128, 128, 3)\n",
      "0.87697715\n",
      "[Epoch 8/10] [Batch 78/1081] [D loss: 0.046562] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.996710] time: 1:15:20.910938\n",
      "(10, 128, 128, 3)\n",
      "0.92963475\n",
      "[Epoch 8/10] [Batch 79/1081] [D loss: 0.047322] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.004951] time: 1:15:21.618101\n",
      "(10, 128, 128, 3)\n",
      "0.94880366\n",
      "[Epoch 8/10] [Batch 80/1081] [D loss: 0.046678] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.897267] time: 1:15:22.265029\n",
      "(10, 128, 128, 3)\n",
      "0.9695558\n",
      "[Epoch 8/10] [Batch 81/1081] [D loss: 0.046946] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.824570] time: 1:15:22.857344\n",
      "(10, 128, 128, 3)\n",
      "0.8986135\n",
      "[Epoch 8/10] [Batch 82/1081] [D loss: 0.046924] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.153946] time: 1:15:23.488490\n",
      "(10, 128, 128, 3)\n",
      "0.9442646\n",
      "[Epoch 8/10] [Batch 83/1081] [D loss: 0.046207] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.171221] time: 1:15:24.133202\n",
      "(10, 128, 128, 3)\n",
      "0.87107563\n",
      "[Epoch 8/10] [Batch 84/1081] [D loss: 0.046777] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.132612] time: 1:15:24.760993\n",
      "(10, 128, 128, 3)\n",
      "0.88268155\n",
      "[Epoch 8/10] [Batch 85/1081] [D loss: 0.046248] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.993047] time: 1:15:25.396930\n",
      "(10, 128, 128, 3)\n",
      "0.88066095\n",
      "[Epoch 8/10] [Batch 86/1081] [D loss: 0.047799] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.860349] time: 1:15:26.039044\n",
      "(10, 128, 128, 3)\n",
      "0.91059095\n",
      "[Epoch 8/10] [Batch 87/1081] [D loss: 0.046679] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.256577] time: 1:15:26.741307\n",
      "(10, 128, 128, 3)\n",
      "0.9171366\n",
      "[Epoch 8/10] [Batch 88/1081] [D loss: 0.045847] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.235152] time: 1:15:27.422741\n",
      "(10, 128, 128, 3)\n",
      "0.9075963\n",
      "[Epoch 8/10] [Batch 89/1081] [D loss: 0.046810] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.189567] time: 1:15:28.049940\n",
      "(10, 128, 128, 3)\n",
      "0.908379\n",
      "[Epoch 8/10] [Batch 90/1081] [D loss: 0.046159] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.898058] time: 1:15:28.705461\n",
      "(10, 128, 128, 3)\n",
      "0.8444786\n",
      "[Epoch 8/10] [Batch 91/1081] [D loss: 0.046248] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.011536] time: 1:15:29.303630\n",
      "(10, 128, 128, 3)\n",
      "0.9124818\n",
      "[Epoch 8/10] [Batch 92/1081] [D loss: 0.046271] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.112702] time: 1:15:29.928068\n",
      "(10, 128, 128, 3)\n",
      "0.91287166\n",
      "[Epoch 8/10] [Batch 93/1081] [D loss: 0.046542] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.085571] time: 1:15:30.620790\n",
      "(10, 128, 128, 3)\n",
      "0.8461984\n",
      "[Epoch 8/10] [Batch 94/1081] [D loss: 0.046224] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.935526] time: 1:15:31.289668\n",
      "(10, 128, 128, 3)\n",
      "0.8785514\n",
      "[Epoch 8/10] [Batch 95/1081] [D loss: 0.046058] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.179912] time: 1:15:31.984595\n",
      "(10, 128, 128, 3)\n",
      "0.94268245\n",
      "[Epoch 8/10] [Batch 96/1081] [D loss: 0.046512] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.107129] time: 1:15:32.660082\n",
      "(10, 128, 128, 3)\n",
      "0.89223164\n",
      "[Epoch 8/10] [Batch 97/1081] [D loss: 0.045660] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.601728] time: 1:15:33.314238\n",
      "(10, 128, 128, 3)\n",
      "0.89297634\n",
      "[Epoch 8/10] [Batch 98/1081] [D loss: 0.045704] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.718207] time: 1:15:33.989662\n",
      "(10, 128, 128, 3)\n",
      "0.9232277\n",
      "[Epoch 8/10] [Batch 99/1081] [D loss: 0.049069] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.806150] time: 1:15:34.679962\n",
      "(10, 128, 128, 3)\n",
      "0.86918086\n",
      "[Epoch 8/10] [Batch 100/1081] [D loss: 0.046554] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.308521] time: 1:15:35.348062\n",
      "(10, 128, 128, 3)\n",
      "0.9252014\n",
      "[Epoch 8/10] [Batch 101/1081] [D loss: 0.047770] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.855237] time: 1:15:36.016052\n",
      "(10, 128, 128, 3)\n",
      "0.97291183\n",
      "[Epoch 8/10] [Batch 102/1081] [D loss: 0.046566] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.654014] time: 1:15:36.699097\n",
      "(10, 128, 128, 3)\n",
      "0.88801533\n",
      "[Epoch 8/10] [Batch 103/1081] [D loss: 0.046476] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.320852] time: 1:15:37.377532\n",
      "(10, 128, 128, 3)\n",
      "0.9017914\n",
      "[Epoch 8/10] [Batch 104/1081] [D loss: 0.047034] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.035296] time: 1:15:38.047125\n",
      "(10, 128, 128, 3)\n",
      "0.902184\n",
      "[Epoch 8/10] [Batch 105/1081] [D loss: 0.047152] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.776795] time: 1:15:38.709622\n",
      "(10, 128, 128, 3)\n",
      "0.84405375\n",
      "[Epoch 8/10] [Batch 106/1081] [D loss: 0.045708] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.084160] time: 1:15:39.284582\n",
      "(10, 128, 128, 3)\n",
      "0.90128756\n",
      "[Epoch 8/10] [Batch 107/1081] [D loss: 0.045360] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.632787] time: 1:15:39.847439\n",
      "(10, 128, 128, 3)\n",
      "0.8937447\n",
      "[Epoch 8/10] [Batch 108/1081] [D loss: 0.046260] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.370595] time: 1:15:40.390501\n",
      "(10, 128, 128, 3)\n",
      "0.910803\n",
      "[Epoch 8/10] [Batch 109/1081] [D loss: 0.045865] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.083312] time: 1:15:40.929113\n",
      "(10, 128, 128, 3)\n",
      "0.9014926\n",
      "[Epoch 8/10] [Batch 110/1081] [D loss: 0.046382] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.404442] time: 1:15:41.493664\n",
      "(10, 128, 128, 3)\n",
      "0.89139533\n",
      "[Epoch 8/10] [Batch 111/1081] [D loss: 0.046676] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.482363] time: 1:15:42.078290\n",
      "(10, 128, 128, 3)\n",
      "0.97403145\n",
      "[Epoch 8/10] [Batch 112/1081] [D loss: 0.045756] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.668170] time: 1:15:42.619569\n",
      "(10, 128, 128, 3)\n",
      "0.97032446\n",
      "[Epoch 8/10] [Batch 113/1081] [D loss: 0.046012] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.885216] time: 1:15:43.165231\n",
      "(10, 128, 128, 3)\n",
      "0.9317331\n",
      "[Epoch 8/10] [Batch 114/1081] [D loss: 0.046190] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.337802] time: 1:15:43.733736\n",
      "(10, 128, 128, 3)\n",
      "0.9255621\n",
      "[Epoch 8/10] [Batch 115/1081] [D loss: 0.045474] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.558809] time: 1:15:44.269567\n",
      "(10, 128, 128, 3)\n",
      "0.8555984\n",
      "[Epoch 8/10] [Batch 116/1081] [D loss: 0.045172] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.769708] time: 1:15:44.827419\n",
      "(10, 128, 128, 3)\n",
      "0.9004589\n",
      "[Epoch 8/10] [Batch 117/1081] [D loss: 0.046074] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.954362] time: 1:15:45.387672\n",
      "(10, 128, 128, 3)\n",
      "0.9324467\n",
      "[Epoch 8/10] [Batch 118/1081] [D loss: 0.046795] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.737762] time: 1:15:45.967966\n",
      "(10, 128, 128, 3)\n",
      "0.920368\n",
      "[Epoch 8/10] [Batch 119/1081] [D loss: 0.045286] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.758358] time: 1:15:46.513751\n",
      "(10, 128, 128, 3)\n",
      "0.9242113\n",
      "[Epoch 8/10] [Batch 120/1081] [D loss: 0.045777] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.269174] time: 1:15:47.075238\n",
      "(10, 128, 128, 3)\n",
      "0.8711824\n",
      "[Epoch 8/10] [Batch 121/1081] [D loss: 0.044884] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.331174] time: 1:15:47.608660\n",
      "(10, 128, 128, 3)\n",
      "0.9228344\n",
      "[Epoch 8/10] [Batch 122/1081] [D loss: 0.045963] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.202659] time: 1:15:48.152273\n",
      "(10, 128, 128, 3)\n",
      "0.8915079\n",
      "[Epoch 8/10] [Batch 123/1081] [D loss: 0.045499] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.311340] time: 1:15:48.734918\n",
      "(10, 128, 128, 3)\n",
      "0.8986327\n",
      "[Epoch 8/10] [Batch 124/1081] [D loss: 0.045398] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.979496] time: 1:15:49.309887\n",
      "(10, 128, 128, 3)\n",
      "0.92999816\n",
      "[Epoch 8/10] [Batch 125/1081] [D loss: 0.045412] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.160769] time: 1:15:49.845811\n",
      "(10, 128, 128, 3)\n",
      "0.92107505\n",
      "[Epoch 8/10] [Batch 126/1081] [D loss: 0.044971] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.847276] time: 1:15:50.434341\n",
      "(10, 128, 128, 3)\n",
      "0.94745415\n",
      "[Epoch 8/10] [Batch 127/1081] [D loss: 0.044853] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.013321] time: 1:15:50.970160\n",
      "(10, 128, 128, 3)\n",
      "0.87797743\n",
      "[Epoch 8/10] [Batch 128/1081] [D loss: 0.044502] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.489529] time: 1:15:51.528731\n",
      "(10, 128, 128, 3)\n",
      "0.92068547\n",
      "[Epoch 8/10] [Batch 129/1081] [D loss: 0.044461] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.553637] time: 1:15:52.118966\n",
      "(10, 128, 128, 3)\n",
      "0.9536974\n",
      "[Epoch 8/10] [Batch 130/1081] [D loss: 0.045313] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.564094] time: 1:15:52.695791\n",
      "(10, 128, 128, 3)\n",
      "0.934112\n",
      "[Epoch 8/10] [Batch 131/1081] [D loss: 0.046059] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.020469] time: 1:15:53.264911\n",
      "(10, 128, 128, 3)\n",
      "0.88363916\n",
      "[Epoch 8/10] [Batch 132/1081] [D loss: 0.044576] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.723402] time: 1:15:53.823854\n",
      "(10, 128, 128, 3)\n",
      "0.9748316\n",
      "[Epoch 8/10] [Batch 133/1081] [D loss: 0.044643] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.642916] time: 1:15:54.394830\n",
      "(10, 128, 128, 3)\n",
      "0.90535194\n",
      "[Epoch 8/10] [Batch 134/1081] [D loss: 0.045303] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.942407] time: 1:15:54.966601\n",
      "(10, 128, 128, 3)\n",
      "0.9297509\n",
      "[Epoch 8/10] [Batch 135/1081] [D loss: 0.045800] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.396458] time: 1:15:55.519396\n",
      "(10, 128, 128, 3)\n",
      "0.8868883\n",
      "[Epoch 8/10] [Batch 136/1081] [D loss: 0.044880] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.642136] time: 1:15:56.075378\n",
      "(10, 128, 128, 3)\n",
      "0.9171939\n",
      "[Epoch 8/10] [Batch 137/1081] [D loss: 0.044918] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.617013] time: 1:15:56.632902\n",
      "(10, 128, 128, 3)\n",
      "0.8831196\n",
      "[Epoch 8/10] [Batch 138/1081] [D loss: 0.044679] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.415485] time: 1:15:57.227946\n",
      "(10, 128, 128, 3)\n",
      "0.8918726\n",
      "[Epoch 8/10] [Batch 139/1081] [D loss: 0.044524] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.074425] time: 1:15:57.790416\n",
      "(10, 128, 128, 3)\n",
      "0.87784433\n",
      "[Epoch 8/10] [Batch 140/1081] [D loss: 0.045800] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.350245] time: 1:15:58.382233\n",
      "(10, 128, 128, 3)\n",
      "0.953959\n",
      "[Epoch 8/10] [Batch 141/1081] [D loss: 0.044369] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.414254] time: 1:15:59.008446\n",
      "(10, 128, 128, 3)\n",
      "0.91881496\n",
      "[Epoch 8/10] [Batch 142/1081] [D loss: 0.044445] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.709417] time: 1:15:59.626790\n",
      "(10, 128, 128, 3)\n",
      "0.8974121\n",
      "[Epoch 8/10] [Batch 143/1081] [D loss: 0.044484] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.666176] time: 1:16:00.260943\n",
      "(10, 128, 128, 3)\n",
      "0.94446254\n",
      "[Epoch 8/10] [Batch 144/1081] [D loss: 0.044533] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.849997] time: 1:16:00.898955\n",
      "(10, 128, 128, 3)\n",
      "0.8978495\n",
      "[Epoch 8/10] [Batch 145/1081] [D loss: 0.045167] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.767132] time: 1:16:01.565325\n",
      "(10, 128, 128, 3)\n",
      "0.9342277\n",
      "[Epoch 8/10] [Batch 146/1081] [D loss: 0.044916] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.373086] time: 1:16:02.230828\n",
      "(10, 128, 128, 3)\n",
      "0.88545126\n",
      "[Epoch 8/10] [Batch 147/1081] [D loss: 0.044675] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.126836] time: 1:16:02.916317\n",
      "(10, 128, 128, 3)\n",
      "0.893413\n",
      "[Epoch 8/10] [Batch 148/1081] [D loss: 0.044200] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.911592] time: 1:16:03.565389\n",
      "(10, 128, 128, 3)\n",
      "0.94041634\n",
      "[Epoch 8/10] [Batch 149/1081] [D loss: 0.043984] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.287181] time: 1:16:04.193992\n",
      "(10, 128, 128, 3)\n",
      "0.9218456\n",
      "[Epoch 8/10] [Batch 150/1081] [D loss: 0.043675] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.135928] time: 1:16:04.817350\n",
      "(10, 128, 128, 3)\n",
      "0.9391257\n",
      "[Epoch 8/10] [Batch 151/1081] [D loss: 0.044316] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.856256] time: 1:16:05.433637\n",
      "(10, 128, 128, 3)\n",
      "0.9036282\n",
      "[Epoch 8/10] [Batch 152/1081] [D loss: 0.044035] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.807283] time: 1:16:06.107925\n",
      "(10, 128, 128, 3)\n",
      "0.88483614\n",
      "[Epoch 8/10] [Batch 153/1081] [D loss: 0.044581] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.421174] time: 1:16:06.764163\n",
      "(10, 128, 128, 3)\n",
      "0.938777\n",
      "[Epoch 8/10] [Batch 154/1081] [D loss: 0.043837] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.525513] time: 1:16:07.451179\n",
      "(10, 128, 128, 3)\n",
      "0.9048152\n",
      "[Epoch 8/10] [Batch 155/1081] [D loss: 0.044107] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.810575] time: 1:16:08.106836\n",
      "(10, 128, 128, 3)\n",
      "0.9174268\n",
      "[Epoch 8/10] [Batch 156/1081] [D loss: 0.062930] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.863455] time: 1:16:08.772770\n",
      "(10, 128, 128, 3)\n",
      "0.92183423\n",
      "[Epoch 8/10] [Batch 157/1081] [D loss: 0.062324] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.341054] time: 1:16:09.463029\n",
      "(10, 128, 128, 3)\n",
      "0.87780064\n",
      "[Epoch 8/10] [Batch 158/1081] [D loss: 0.050475] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.074888] time: 1:16:10.169288\n",
      "(10, 128, 128, 3)\n",
      "0.9608101\n",
      "[Epoch 8/10] [Batch 159/1081] [D loss: 0.051641] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.544147] time: 1:16:10.851413\n",
      "(10, 128, 128, 3)\n",
      "0.86466473\n",
      "[Epoch 8/10] [Batch 160/1081] [D loss: 0.054137] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.305087] time: 1:16:11.485306\n",
      "(10, 128, 128, 3)\n",
      "0.8953951\n",
      "[Epoch 8/10] [Batch 161/1081] [D loss: 0.052330] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.558105] time: 1:16:12.118588\n",
      "(10, 128, 128, 3)\n",
      "0.92374295\n",
      "[Epoch 8/10] [Batch 162/1081] [D loss: 0.052381] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.338082] time: 1:16:12.755414\n",
      "(10, 128, 128, 3)\n",
      "0.90456915\n",
      "[Epoch 8/10] [Batch 163/1081] [D loss: 0.052120] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.645669] time: 1:16:13.378993\n",
      "(10, 128, 128, 3)\n",
      "0.94752973\n",
      "[Epoch 8/10] [Batch 164/1081] [D loss: 0.052362] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.919293] time: 1:16:14.032253\n",
      "(10, 128, 128, 3)\n",
      "0.90891844\n",
      "[Epoch 8/10] [Batch 165/1081] [D loss: 0.113037] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.691664] time: 1:16:14.640039\n",
      "(10, 128, 128, 3)\n",
      "0.903378\n",
      "[Epoch 8/10] [Batch 166/1081] [D loss: 0.060666] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.824497] time: 1:16:15.338445\n",
      "(10, 128, 128, 3)\n",
      "0.91131496\n",
      "[Epoch 8/10] [Batch 167/1081] [D loss: 0.068515] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.647358] time: 1:16:15.978497\n",
      "(10, 128, 128, 3)\n",
      "0.89416665\n",
      "[Epoch 8/10] [Batch 168/1081] [D loss: 0.095671] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.967918] time: 1:16:16.677204\n",
      "(10, 128, 128, 3)\n",
      "0.97173303\n",
      "[Epoch 8/10] [Batch 169/1081] [D loss: 0.064307] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.091194] time: 1:16:17.332924\n",
      "(10, 128, 128, 3)\n",
      "0.93191767\n",
      "[Epoch 8/10] [Batch 170/1081] [D loss: 0.060818] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.938169] time: 1:16:17.991887\n",
      "(10, 128, 128, 3)\n",
      "0.9142774\n",
      "[Epoch 8/10] [Batch 171/1081] [D loss: 0.070663] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.151441] time: 1:16:18.667725\n",
      "(10, 128, 128, 3)\n",
      "0.94137746\n",
      "[Epoch 8/10] [Batch 172/1081] [D loss: 0.053283] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.660552] time: 1:16:19.373471\n",
      "(10, 128, 128, 3)\n",
      "0.9105184\n",
      "[Epoch 8/10] [Batch 173/1081] [D loss: 0.082696] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.858179] time: 1:16:20.072689\n",
      "(10, 128, 128, 3)\n",
      "0.9379456\n",
      "[Epoch 8/10] [Batch 174/1081] [D loss: 0.057499] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.484882] time: 1:16:20.775244\n",
      "(10, 128, 128, 3)\n",
      "0.948472\n",
      "[Epoch 8/10] [Batch 175/1081] [D loss: 0.054810] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.035860] time: 1:16:21.438064\n",
      "(10, 128, 128, 3)\n",
      "0.92161065\n",
      "[Epoch 8/10] [Batch 176/1081] [D loss: 0.052303] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.614044] time: 1:16:22.105332\n",
      "(10, 128, 128, 3)\n",
      "0.87785083\n",
      "[Epoch 8/10] [Batch 177/1081] [D loss: 0.054547] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.984547] time: 1:16:22.792493\n",
      "(10, 128, 128, 3)\n",
      "0.87407756\n",
      "[Epoch 8/10] [Batch 178/1081] [D loss: 0.053131] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.613033] time: 1:16:23.462665\n",
      "(10, 128, 128, 3)\n",
      "0.9174848\n",
      "[Epoch 8/10] [Batch 179/1081] [D loss: 0.352694] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 3.048974] time: 1:16:24.100462\n",
      "(10, 128, 128, 3)\n",
      "0.92008406\n",
      "[Epoch 8/10] [Batch 180/1081] [D loss: 0.066387] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.126968] time: 1:16:24.743834\n",
      "(10, 128, 128, 3)\n",
      "0.8529776\n",
      "[Epoch 8/10] [Batch 181/1081] [D loss: 0.079402] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.546549] time: 1:16:25.361609\n",
      "(10, 128, 128, 3)\n",
      "0.92909855\n",
      "[Epoch 8/10] [Batch 182/1081] [D loss: 0.069111] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.814986] time: 1:16:26.002164\n",
      "(10, 128, 128, 3)\n",
      "0.93972015\n",
      "[Epoch 8/10] [Batch 183/1081] [D loss: 0.066254] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.768009] time: 1:16:26.601321\n",
      "(10, 128, 128, 3)\n",
      "0.9302197\n",
      "[Epoch 8/10] [Batch 184/1081] [D loss: 0.072156] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.492100] time: 1:16:27.307359\n",
      "(10, 128, 128, 3)\n",
      "0.9469189\n",
      "[Epoch 8/10] [Batch 185/1081] [D loss: 0.083870] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.963059] time: 1:16:27.990590\n",
      "(10, 128, 128, 3)\n",
      "0.92878246\n",
      "[Epoch 8/10] [Batch 186/1081] [D loss: 0.077094] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.342945] time: 1:16:28.718444\n",
      "(10, 128, 128, 3)\n",
      "0.9119738\n",
      "[Epoch 8/10] [Batch 187/1081] [D loss: 0.081963] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.382910] time: 1:16:29.424635\n",
      "(10, 128, 128, 3)\n",
      "0.85020375\n",
      "[Epoch 8/10] [Batch 188/1081] [D loss: 0.066428] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.158242] time: 1:16:30.122993\n",
      "(10, 128, 128, 3)\n",
      "0.92494726\n",
      "[Epoch 8/10] [Batch 189/1081] [D loss: 0.063466] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.783669] time: 1:16:30.776793\n",
      "(10, 128, 128, 3)\n",
      "0.93383217\n",
      "[Epoch 8/10] [Batch 190/1081] [D loss: 0.060607] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.401541] time: 1:16:31.466351\n",
      "(10, 128, 128, 3)\n",
      "0.88193464\n",
      "[Epoch 8/10] [Batch 191/1081] [D loss: 0.063173] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.525155] time: 1:16:32.099108\n",
      "(10, 128, 128, 3)\n",
      "0.9489572\n",
      "[Epoch 8/10] [Batch 192/1081] [D loss: 0.064466] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.046999] time: 1:16:32.768118\n",
      "(10, 128, 128, 3)\n",
      "0.9066244\n",
      "[Epoch 8/10] [Batch 193/1081] [D loss: 0.068304] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.023815] time: 1:16:33.454309\n",
      "(10, 128, 128, 3)\n",
      "0.97664255\n",
      "[Epoch 8/10] [Batch 194/1081] [D loss: 0.062417] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.547526] time: 1:16:34.168546\n",
      "(10, 128, 128, 3)\n",
      "0.9398734\n",
      "[Epoch 8/10] [Batch 195/1081] [D loss: 0.057387] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.172431] time: 1:16:34.822599\n",
      "(10, 128, 128, 3)\n",
      "0.89774984\n",
      "[Epoch 8/10] [Batch 196/1081] [D loss: 0.061461] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.078053] time: 1:16:35.465212\n",
      "(10, 128, 128, 3)\n",
      "0.9386664\n",
      "[Epoch 8/10] [Batch 197/1081] [D loss: 0.058388] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.468630] time: 1:16:36.113894\n",
      "(10, 128, 128, 3)\n",
      "0.9353129\n",
      "[Epoch 8/10] [Batch 198/1081] [D loss: 0.061085] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.967639] time: 1:16:36.814124\n",
      "(10, 128, 128, 3)\n",
      "0.93322134\n",
      "[Epoch 8/10] [Batch 199/1081] [D loss: 0.061650] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.165230] time: 1:16:37.427659\n",
      "(10, 128, 128, 3)\n",
      "0.9083274\n",
      "[Epoch 8/10] [Batch 200/1081] [D loss: 0.087899] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 4.061908] time: 1:16:38.041051\n",
      "(10, 128, 128, 3)\n",
      "0.8818615\n",
      "[Epoch 8/10] [Batch 201/1081] [D loss: 0.072435] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.115364] time: 1:16:38.642878\n",
      "(10, 128, 128, 3)\n",
      "0.90964144\n",
      "[Epoch 8/10] [Batch 202/1081] [D loss: 0.804658] [D acc: 0.15 (0.00 real, 0.30 fake)] [G loss: 6.444404] time: 1:16:39.316213\n",
      "(10, 128, 128, 3)\n",
      "0.9754208\n",
      "[Epoch 8/10] [Batch 203/1081] [D loss: 0.121859] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.286237] time: 1:16:39.963852\n",
      "(10, 128, 128, 3)\n",
      "0.92552155\n",
      "[Epoch 8/10] [Batch 204/1081] [D loss: 0.091305] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.373841] time: 1:16:40.630419\n",
      "(10, 128, 128, 3)\n",
      "0.9183044\n",
      "[Epoch 8/10] [Batch 205/1081] [D loss: 0.088516] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.372544] time: 1:16:41.336969\n",
      "(10, 128, 128, 3)\n",
      "0.92687935\n",
      "[Epoch 8/10] [Batch 206/1081] [D loss: 0.797962] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 4.609452] time: 1:16:41.991030\n",
      "(10, 128, 128, 3)\n",
      "0.8981932\n",
      "[Epoch 8/10] [Batch 207/1081] [D loss: 0.119367] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.357779] time: 1:16:42.677189\n",
      "(10, 128, 128, 3)\n",
      "0.9307399\n",
      "[Epoch 8/10] [Batch 208/1081] [D loss: 0.073628] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.959374] time: 1:16:43.300184\n",
      "(10, 128, 128, 3)\n",
      "0.8597687\n",
      "[Epoch 8/10] [Batch 209/1081] [D loss: 0.062376] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.321662] time: 1:16:43.945672\n",
      "(10, 128, 128, 3)\n",
      "0.92683077\n",
      "[Epoch 8/10] [Batch 210/1081] [D loss: 0.058339] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.293055] time: 1:16:44.597361\n",
      "(10, 128, 128, 3)\n",
      "0.8964684\n",
      "[Epoch 8/10] [Batch 211/1081] [D loss: 0.057379] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.950176] time: 1:16:45.237332\n",
      "(10, 128, 128, 3)\n",
      "0.913029\n",
      "[Epoch 8/10] [Batch 212/1081] [D loss: 0.058882] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.964071] time: 1:16:45.840963\n",
      "(10, 128, 128, 3)\n",
      "0.9270399\n",
      "[Epoch 8/10] [Batch 213/1081] [D loss: 0.057334] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.774551] time: 1:16:46.441046\n",
      "(10, 128, 128, 3)\n",
      "0.8821704\n",
      "[Epoch 8/10] [Batch 214/1081] [D loss: 0.056825] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.404339] time: 1:16:47.109609\n",
      "(10, 128, 128, 3)\n",
      "0.9097298\n",
      "[Epoch 8/10] [Batch 215/1081] [D loss: 0.056034] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.512951] time: 1:16:47.749244\n",
      "(10, 128, 128, 3)\n",
      "0.9056019\n",
      "[Epoch 8/10] [Batch 216/1081] [D loss: 0.056376] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.236759] time: 1:16:48.426562\n",
      "(10, 128, 128, 3)\n",
      "0.8962328\n",
      "[Epoch 8/10] [Batch 217/1081] [D loss: 0.055449] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.959490] time: 1:16:49.071755\n",
      "(10, 128, 128, 3)\n",
      "0.9390764\n",
      "[Epoch 8/10] [Batch 218/1081] [D loss: 0.055763] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.028872] time: 1:16:49.722522\n",
      "(10, 128, 128, 3)\n",
      "0.91424984\n",
      "[Epoch 8/10] [Batch 219/1081] [D loss: 0.055631] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.950564] time: 1:16:50.322917\n",
      "(10, 128, 128, 3)\n",
      "0.9407508\n",
      "[Epoch 8/10] [Batch 220/1081] [D loss: 0.055613] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.369544] time: 1:16:51.009259\n",
      "(10, 128, 128, 3)\n",
      "0.814019\n",
      "[Epoch 8/10] [Batch 221/1081] [D loss: 0.054093] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.293810] time: 1:16:51.649237\n",
      "(10, 128, 128, 3)\n",
      "0.9211884\n",
      "[Epoch 8/10] [Batch 222/1081] [D loss: 0.054612] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.592142] time: 1:16:52.359111\n",
      "(10, 128, 128, 3)\n",
      "0.88722354\n",
      "[Epoch 8/10] [Batch 223/1081] [D loss: 0.053638] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.203072] time: 1:16:53.020750\n",
      "(10, 128, 128, 3)\n",
      "0.9557071\n",
      "[Epoch 8/10] [Batch 224/1081] [D loss: 0.055447] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.672766] time: 1:16:53.658287\n",
      "(10, 128, 128, 3)\n",
      "0.91822845\n",
      "[Epoch 8/10] [Batch 225/1081] [D loss: 0.055080] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.849026] time: 1:16:54.260602\n",
      "(10, 128, 128, 3)\n",
      "0.90367454\n",
      "[Epoch 8/10] [Batch 226/1081] [D loss: 0.056504] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.617869] time: 1:16:54.964022\n",
      "(10, 128, 128, 3)\n",
      "0.9286041\n",
      "[Epoch 8/10] [Batch 227/1081] [D loss: 0.054206] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.908191] time: 1:16:55.601862\n",
      "(10, 128, 128, 3)\n",
      "0.93645996\n",
      "[Epoch 8/10] [Batch 228/1081] [D loss: 0.055244] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.909324] time: 1:16:56.244809\n",
      "(10, 128, 128, 3)\n",
      "0.8504359\n",
      "[Epoch 8/10] [Batch 229/1081] [D loss: 0.054160] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.564474] time: 1:16:56.868193\n",
      "(10, 128, 128, 3)\n",
      "0.98085785\n",
      "[Epoch 8/10] [Batch 230/1081] [D loss: 0.053295] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.260606] time: 1:16:57.457796\n",
      "(10, 128, 128, 3)\n",
      "0.9258711\n",
      "[Epoch 8/10] [Batch 231/1081] [D loss: 0.053910] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.104968] time: 1:16:58.055750\n",
      "(10, 128, 128, 3)\n",
      "0.9503315\n",
      "[Epoch 8/10] [Batch 232/1081] [D loss: 0.053937] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.283255] time: 1:16:58.728215\n",
      "(10, 128, 128, 3)\n",
      "0.8852337\n",
      "[Epoch 8/10] [Batch 233/1081] [D loss: 0.054444] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.933012] time: 1:16:59.358646\n",
      "(10, 128, 128, 3)\n",
      "0.91948956\n",
      "[Epoch 8/10] [Batch 234/1081] [D loss: 0.054207] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.000580] time: 1:17:00.033863\n",
      "(10, 128, 128, 3)\n",
      "0.8909491\n",
      "[Epoch 8/10] [Batch 235/1081] [D loss: 0.052563] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.865468] time: 1:17:00.668267\n",
      "(10, 128, 128, 3)\n",
      "0.9333636\n",
      "[Epoch 8/10] [Batch 236/1081] [D loss: 0.054459] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.215263] time: 1:17:01.314222\n",
      "(10, 128, 128, 3)\n",
      "0.9235737\n",
      "[Epoch 8/10] [Batch 237/1081] [D loss: 0.052221] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.695716] time: 1:17:01.926567\n",
      "(10, 128, 128, 3)\n",
      "0.8579378\n",
      "[Epoch 8/10] [Batch 238/1081] [D loss: 0.052573] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.883420] time: 1:17:02.596379\n",
      "(10, 128, 128, 3)\n",
      "0.8465164\n",
      "[Epoch 8/10] [Batch 239/1081] [D loss: 0.052813] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.040183] time: 1:17:03.230130\n",
      "(10, 128, 128, 3)\n",
      "0.9434831\n",
      "[Epoch 8/10] [Batch 240/1081] [D loss: 0.051980] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.559840] time: 1:17:03.881256\n",
      "(10, 128, 128, 3)\n",
      "0.89359266\n",
      "[Epoch 8/10] [Batch 241/1081] [D loss: 0.051824] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.175086] time: 1:17:04.523463\n",
      "(10, 128, 128, 3)\n",
      "0.9274891\n",
      "[Epoch 8/10] [Batch 242/1081] [D loss: 0.053242] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.947809] time: 1:17:05.199910\n",
      "(10, 128, 128, 3)\n",
      "0.9212772\n",
      "[Epoch 8/10] [Batch 243/1081] [D loss: 0.051414] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.279869] time: 1:17:05.882434\n",
      "(10, 128, 128, 3)\n",
      "0.93371946\n",
      "[Epoch 8/10] [Batch 244/1081] [D loss: 0.053281] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.170311] time: 1:17:06.499904\n",
      "(10, 128, 128, 3)\n",
      "0.89264554\n",
      "[Epoch 8/10] [Batch 245/1081] [D loss: 0.052667] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.313327] time: 1:17:07.120396\n",
      "(10, 128, 128, 3)\n",
      "0.87695163\n",
      "[Epoch 8/10] [Batch 246/1081] [D loss: 0.051675] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.934261] time: 1:17:07.762077\n",
      "(10, 128, 128, 3)\n",
      "0.8969555\n",
      "[Epoch 8/10] [Batch 247/1081] [D loss: 0.051587] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.774486] time: 1:17:08.424118\n",
      "(10, 128, 128, 3)\n",
      "0.90054303\n",
      "[Epoch 8/10] [Batch 248/1081] [D loss: 0.050923] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.518341] time: 1:17:09.093345\n",
      "(10, 128, 128, 3)\n",
      "0.9097147\n",
      "[Epoch 8/10] [Batch 249/1081] [D loss: 0.051061] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.042008] time: 1:17:09.756747\n",
      "(10, 128, 128, 3)\n",
      "0.929313\n",
      "[Epoch 8/10] [Batch 250/1081] [D loss: 0.050197] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.193266] time: 1:17:10.401842\n",
      "(10, 128, 128, 3)\n",
      "0.9622652\n",
      "[Epoch 8/10] [Batch 251/1081] [D loss: 0.051124] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.597267] time: 1:17:11.040295\n",
      "(10, 128, 128, 3)\n",
      "0.87530786\n",
      "[Epoch 8/10] [Batch 252/1081] [D loss: 0.050208] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.661967] time: 1:17:11.662425\n",
      "(10, 128, 128, 3)\n",
      "0.9098196\n",
      "[Epoch 8/10] [Batch 253/1081] [D loss: 0.052723] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.283278] time: 1:17:12.309537\n",
      "(10, 128, 128, 3)\n",
      "0.91369563\n",
      "[Epoch 8/10] [Batch 254/1081] [D loss: 0.051297] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.948801] time: 1:17:12.974781\n",
      "(10, 128, 128, 3)\n",
      "0.88290817\n",
      "[Epoch 8/10] [Batch 255/1081] [D loss: 0.058550] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.618251] time: 1:17:13.687217\n",
      "(10, 128, 128, 3)\n",
      "0.91952556\n",
      "[Epoch 8/10] [Batch 256/1081] [D loss: 0.051288] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.134748] time: 1:17:14.358049\n",
      "(10, 128, 128, 3)\n",
      "0.9206888\n",
      "[Epoch 8/10] [Batch 257/1081] [D loss: 0.051173] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.807153] time: 1:17:15.005298\n",
      "(10, 128, 128, 3)\n",
      "0.93222547\n",
      "[Epoch 8/10] [Batch 258/1081] [D loss: 0.050781] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.476281] time: 1:17:15.627995\n",
      "(10, 128, 128, 3)\n",
      "0.9224858\n",
      "[Epoch 8/10] [Batch 259/1081] [D loss: 0.051300] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.648563] time: 1:17:16.244411\n",
      "(10, 128, 128, 3)\n",
      "0.88866454\n",
      "[Epoch 8/10] [Batch 260/1081] [D loss: 0.050122] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.512424] time: 1:17:16.949619\n",
      "(10, 128, 128, 3)\n",
      "0.9328218\n",
      "[Epoch 8/10] [Batch 261/1081] [D loss: 0.053346] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.542230] time: 1:17:17.650319\n",
      "(10, 128, 128, 3)\n",
      "0.92495936\n",
      "[Epoch 8/10] [Batch 262/1081] [D loss: 0.049572] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.838336] time: 1:17:18.291668\n",
      "(10, 128, 128, 3)\n",
      "0.89441013\n",
      "[Epoch 8/10] [Batch 263/1081] [D loss: 0.049438] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.602105] time: 1:17:18.910412\n",
      "(10, 128, 128, 3)\n",
      "0.9429558\n",
      "[Epoch 8/10] [Batch 264/1081] [D loss: 0.049925] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.442474] time: 1:17:19.567119\n",
      "(10, 128, 128, 3)\n",
      "0.9133733\n",
      "[Epoch 8/10] [Batch 265/1081] [D loss: 0.049571] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.935558] time: 1:17:20.212756\n",
      "(10, 128, 128, 3)\n",
      "0.9481125\n",
      "[Epoch 8/10] [Batch 266/1081] [D loss: 0.049241] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.848213] time: 1:17:20.853573\n",
      "(10, 128, 128, 3)\n",
      "0.9678125\n",
      "[Epoch 8/10] [Batch 267/1081] [D loss: 0.048719] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.776889] time: 1:17:21.488993\n",
      "(10, 128, 128, 3)\n",
      "0.900774\n",
      "[Epoch 8/10] [Batch 268/1081] [D loss: 0.048631] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.925227] time: 1:17:22.113421\n",
      "(10, 128, 128, 3)\n",
      "0.95380944\n",
      "[Epoch 8/10] [Batch 269/1081] [D loss: 0.048914] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.553481] time: 1:17:22.790499\n",
      "(10, 128, 128, 3)\n",
      "0.90751123\n",
      "[Epoch 8/10] [Batch 270/1081] [D loss: 0.048771] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.647182] time: 1:17:23.488987\n",
      "(10, 128, 128, 3)\n",
      "0.9080534\n",
      "[Epoch 8/10] [Batch 271/1081] [D loss: 0.048553] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.853819] time: 1:17:24.118572\n",
      "(10, 128, 128, 3)\n",
      "0.92813295\n",
      "[Epoch 8/10] [Batch 272/1081] [D loss: 0.048715] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.257305] time: 1:17:24.789034\n",
      "(10, 128, 128, 3)\n",
      "0.93697757\n",
      "[Epoch 8/10] [Batch 273/1081] [D loss: 0.049782] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.840577] time: 1:17:25.414562\n",
      "(10, 128, 128, 3)\n",
      "0.87579226\n",
      "[Epoch 8/10] [Batch 274/1081] [D loss: 0.050897] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.446012] time: 1:17:26.102169\n",
      "(10, 128, 128, 3)\n",
      "0.9305255\n",
      "[Epoch 8/10] [Batch 275/1081] [D loss: 0.049521] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.718644] time: 1:17:26.748319\n",
      "(10, 128, 128, 3)\n",
      "0.9070447\n",
      "[Epoch 8/10] [Batch 276/1081] [D loss: 0.055201] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.758954] time: 1:17:27.396694\n",
      "(10, 128, 128, 3)\n",
      "0.90893453\n",
      "[Epoch 8/10] [Batch 277/1081] [D loss: 0.047769] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.228433] time: 1:17:28.078581\n",
      "(10, 128, 128, 3)\n",
      "0.8675639\n",
      "[Epoch 8/10] [Batch 278/1081] [D loss: 0.049508] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.226436] time: 1:17:28.752871\n",
      "(10, 128, 128, 3)\n",
      "0.9010579\n",
      "[Epoch 8/10] [Batch 279/1081] [D loss: 0.047627] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.711335] time: 1:17:29.395635\n",
      "(10, 128, 128, 3)\n",
      "0.9698133\n",
      "[Epoch 8/10] [Batch 280/1081] [D loss: 0.048053] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.235513] time: 1:17:30.073243\n",
      "(10, 128, 128, 3)\n",
      "0.91345435\n",
      "[Epoch 8/10] [Batch 281/1081] [D loss: 0.052648] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.246855] time: 1:17:30.785608\n",
      "(10, 128, 128, 3)\n",
      "0.85673994\n",
      "[Epoch 8/10] [Batch 282/1081] [D loss: 0.047841] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.861888] time: 1:17:31.413785\n",
      "(10, 128, 128, 3)\n",
      "0.949677\n",
      "[Epoch 8/10] [Batch 283/1081] [D loss: 0.048052] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.016041] time: 1:17:32.052651\n",
      "(10, 128, 128, 3)\n",
      "0.9200085\n",
      "[Epoch 8/10] [Batch 284/1081] [D loss: 0.048289] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.229856] time: 1:17:32.658188\n",
      "(10, 128, 128, 3)\n",
      "0.9686821\n",
      "[Epoch 8/10] [Batch 285/1081] [D loss: 0.048043] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.783224] time: 1:17:33.254466\n",
      "(10, 128, 128, 3)\n",
      "0.91246516\n",
      "[Epoch 8/10] [Batch 286/1081] [D loss: 0.048140] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.575141] time: 1:17:33.886933\n",
      "(10, 128, 128, 3)\n",
      "0.9743673\n",
      "[Epoch 8/10] [Batch 287/1081] [D loss: 0.048381] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.816539] time: 1:17:34.528299\n",
      "(10, 128, 128, 3)\n",
      "0.903776\n",
      "[Epoch 8/10] [Batch 288/1081] [D loss: 0.049385] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.932964] time: 1:17:35.166372\n",
      "(10, 128, 128, 3)\n",
      "0.8933029\n",
      "[Epoch 8/10] [Batch 289/1081] [D loss: 0.047796] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.231764] time: 1:17:35.828507\n",
      "(10, 128, 128, 3)\n",
      "0.917563\n",
      "[Epoch 8/10] [Batch 290/1081] [D loss: 0.046774] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.206276] time: 1:17:36.505048\n",
      "(10, 128, 128, 3)\n",
      "0.94171876\n",
      "[Epoch 8/10] [Batch 291/1081] [D loss: 0.047409] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.052767] time: 1:17:37.149441\n",
      "(10, 128, 128, 3)\n",
      "0.9219644\n",
      "[Epoch 8/10] [Batch 292/1081] [D loss: 0.047294] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.237884] time: 1:17:37.854284\n",
      "(10, 128, 128, 3)\n",
      "0.888376\n",
      "[Epoch 8/10] [Batch 293/1081] [D loss: 0.048193] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.341555] time: 1:17:38.525114\n",
      "(10, 128, 128, 3)\n",
      "0.9252295\n",
      "[Epoch 8/10] [Batch 294/1081] [D loss: 0.047194] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.828100] time: 1:17:39.157455\n",
      "(10, 128, 128, 3)\n",
      "0.8874299\n",
      "[Epoch 8/10] [Batch 295/1081] [D loss: 0.047044] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.095019] time: 1:17:39.787451\n",
      "(10, 128, 128, 3)\n",
      "0.9338868\n",
      "[Epoch 8/10] [Batch 296/1081] [D loss: 0.051630] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.850545] time: 1:17:40.401191\n",
      "(10, 128, 128, 3)\n",
      "0.9000685\n",
      "[Epoch 8/10] [Batch 297/1081] [D loss: 0.047779] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.560432] time: 1:17:41.092047\n",
      "(10, 128, 128, 3)\n",
      "0.88678426\n",
      "[Epoch 8/10] [Batch 298/1081] [D loss: 0.046846] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.342257] time: 1:17:41.762127\n",
      "(10, 128, 128, 3)\n",
      "0.9472541\n",
      "[Epoch 8/10] [Batch 299/1081] [D loss: 0.046739] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.301831] time: 1:17:42.396646\n",
      "(10, 128, 128, 3)\n",
      "0.907537\n",
      "[Epoch 8/10] [Batch 300/1081] [D loss: 0.046425] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.777614] time: 1:17:43.012121\n",
      "(10, 128, 128, 3)\n",
      "0.9353747\n",
      "[Epoch 8/10] [Batch 301/1081] [D loss: 0.046806] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.483314] time: 1:17:43.669417\n",
      "(10, 128, 128, 3)\n",
      "0.9377327\n",
      "[Epoch 8/10] [Batch 302/1081] [D loss: 0.049696] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.850555] time: 1:17:44.304654\n",
      "(10, 128, 128, 3)\n",
      "0.92795855\n",
      "[Epoch 8/10] [Batch 303/1081] [D loss: 0.047484] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.090772] time: 1:17:44.985901\n",
      "(10, 128, 128, 3)\n",
      "0.8603336\n",
      "[Epoch 8/10] [Batch 304/1081] [D loss: 0.046091] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.819855] time: 1:17:45.670242\n",
      "(10, 128, 128, 3)\n",
      "0.9269852\n",
      "[Epoch 8/10] [Batch 305/1081] [D loss: 0.047591] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.888239] time: 1:17:46.377124\n",
      "(10, 128, 128, 3)\n",
      "0.9778306\n",
      "[Epoch 8/10] [Batch 306/1081] [D loss: 0.048084] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.820558] time: 1:17:47.031634\n",
      "(10, 128, 128, 3)\n",
      "0.91768414\n",
      "[Epoch 8/10] [Batch 307/1081] [D loss: 0.048101] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.851685] time: 1:17:47.712170\n",
      "(10, 128, 128, 3)\n",
      "0.88876325\n",
      "[Epoch 8/10] [Batch 308/1081] [D loss: 0.047132] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.753238] time: 1:17:48.370381\n",
      "(10, 128, 128, 3)\n",
      "0.86121327\n",
      "[Epoch 8/10] [Batch 309/1081] [D loss: 0.046595] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.027513] time: 1:17:49.029419\n",
      "(10, 128, 128, 3)\n",
      "0.9249377\n",
      "[Epoch 8/10] [Batch 310/1081] [D loss: 0.045893] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.384760] time: 1:17:49.682366\n",
      "(10, 128, 128, 3)\n",
      "0.8854213\n",
      "[Epoch 8/10] [Batch 311/1081] [D loss: 0.046999] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.909844] time: 1:17:50.350422\n",
      "(10, 128, 128, 3)\n",
      "0.8953088\n",
      "[Epoch 8/10] [Batch 312/1081] [D loss: 0.045786] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.549159] time: 1:17:51.027988\n",
      "(10, 128, 128, 3)\n",
      "0.91562814\n",
      "[Epoch 8/10] [Batch 313/1081] [D loss: 0.046240] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.680547] time: 1:17:51.678079\n",
      "(10, 128, 128, 3)\n",
      "0.944563\n",
      "[Epoch 8/10] [Batch 314/1081] [D loss: 0.045543] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.748773] time: 1:17:52.346836\n",
      "(10, 128, 128, 3)\n",
      "0.93834966\n",
      "[Epoch 8/10] [Batch 315/1081] [D loss: 0.045622] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.424743] time: 1:17:52.960705\n",
      "(10, 128, 128, 3)\n",
      "0.89527875\n",
      "[Epoch 8/10] [Batch 316/1081] [D loss: 0.045281] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.868486] time: 1:17:53.582011\n",
      "(10, 128, 128, 3)\n",
      "0.91368264\n",
      "[Epoch 8/10] [Batch 317/1081] [D loss: 0.045939] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.513863] time: 1:17:54.249263\n",
      "(10, 128, 128, 3)\n",
      "0.90137666\n",
      "[Epoch 8/10] [Batch 318/1081] [D loss: 0.046205] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.872436] time: 1:17:54.905486\n",
      "(10, 128, 128, 3)\n",
      "0.88700604\n",
      "[Epoch 8/10] [Batch 319/1081] [D loss: 0.045206] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.564944] time: 1:17:55.530347\n",
      "(10, 128, 128, 3)\n",
      "0.91381305\n",
      "[Epoch 8/10] [Batch 320/1081] [D loss: 0.046196] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.221210] time: 1:17:56.139660\n",
      "(10, 128, 128, 3)\n",
      "0.888145\n",
      "[Epoch 8/10] [Batch 321/1081] [D loss: 0.045929] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.678375] time: 1:17:56.766754\n",
      "(10, 128, 128, 3)\n",
      "0.9322637\n",
      "[Epoch 8/10] [Batch 322/1081] [D loss: 0.044925] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.777378] time: 1:17:57.383610\n",
      "(10, 128, 128, 3)\n",
      "0.92683727\n",
      "[Epoch 8/10] [Batch 323/1081] [D loss: 0.045489] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.091678] time: 1:17:58.008195\n",
      "(10, 128, 128, 3)\n",
      "0.9079761\n",
      "[Epoch 8/10] [Batch 324/1081] [D loss: 0.045679] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.802787] time: 1:17:58.638415\n",
      "(10, 128, 128, 3)\n",
      "0.91355926\n",
      "[Epoch 8/10] [Batch 325/1081] [D loss: 0.044992] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.452934] time: 1:17:59.316424\n",
      "(10, 128, 128, 3)\n",
      "0.91931087\n",
      "[Epoch 8/10] [Batch 326/1081] [D loss: 0.044745] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.796210] time: 1:17:59.938511\n",
      "(10, 128, 128, 3)\n",
      "0.86889315\n",
      "[Epoch 8/10] [Batch 327/1081] [D loss: 0.045426] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.097675] time: 1:18:00.577458\n",
      "(10, 128, 128, 3)\n",
      "0.8883864\n",
      "[Epoch 8/10] [Batch 328/1081] [D loss: 0.046681] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.582206] time: 1:18:01.240383\n",
      "(10, 128, 128, 3)\n",
      "0.9278099\n",
      "[Epoch 8/10] [Batch 329/1081] [D loss: 0.044927] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.043413] time: 1:18:01.884488\n",
      "(10, 128, 128, 3)\n",
      "0.89362264\n",
      "[Epoch 8/10] [Batch 330/1081] [D loss: 0.045091] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.329977] time: 1:18:02.536763\n",
      "(10, 128, 128, 3)\n",
      "0.957463\n",
      "[Epoch 8/10] [Batch 331/1081] [D loss: 0.046058] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.665598] time: 1:18:03.159360\n",
      "(10, 128, 128, 3)\n",
      "0.92211574\n",
      "[Epoch 8/10] [Batch 332/1081] [D loss: 0.044344] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.405198] time: 1:18:03.813728\n",
      "(10, 128, 128, 3)\n",
      "0.92512965\n",
      "[Epoch 8/10] [Batch 333/1081] [D loss: 0.044203] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.907275] time: 1:18:04.428287\n",
      "(10, 128, 128, 3)\n",
      "0.87201256\n",
      "[Epoch 8/10] [Batch 334/1081] [D loss: 0.043966] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.865358] time: 1:18:05.109114\n",
      "(10, 128, 128, 3)\n",
      "0.92670625\n",
      "[Epoch 8/10] [Batch 335/1081] [D loss: 0.044741] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.605059] time: 1:18:05.762183\n",
      "(10, 128, 128, 3)\n",
      "0.8925083\n",
      "[Epoch 8/10] [Batch 336/1081] [D loss: 0.044509] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.796233] time: 1:18:06.434368\n",
      "(10, 128, 128, 3)\n",
      "0.89527553\n",
      "[Epoch 8/10] [Batch 337/1081] [D loss: 0.046483] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.969052] time: 1:18:07.051210\n",
      "(10, 128, 128, 3)\n",
      "0.9269435\n",
      "[Epoch 8/10] [Batch 338/1081] [D loss: 0.045157] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.702930] time: 1:18:07.715773\n",
      "(10, 128, 128, 3)\n",
      "0.92178345\n",
      "[Epoch 8/10] [Batch 339/1081] [D loss: 0.044186] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.820015] time: 1:18:08.376337\n",
      "(10, 128, 128, 3)\n",
      "0.919044\n",
      "[Epoch 8/10] [Batch 340/1081] [D loss: 0.051198] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.936819] time: 1:18:09.033257\n",
      "(10, 128, 128, 3)\n",
      "0.9573474\n",
      "[Epoch 8/10] [Batch 341/1081] [D loss: 0.046612] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.339845] time: 1:18:09.703366\n",
      "(10, 128, 128, 3)\n",
      "0.88876444\n",
      "[Epoch 8/10] [Batch 342/1081] [D loss: 0.045045] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.711003] time: 1:18:10.395501\n",
      "(10, 128, 128, 3)\n",
      "0.9217252\n",
      "[Epoch 8/10] [Batch 343/1081] [D loss: 0.045522] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.047338] time: 1:18:11.005289\n",
      "(10, 128, 128, 3)\n",
      "0.8731478\n",
      "[Epoch 8/10] [Batch 344/1081] [D loss: 0.045145] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.191437] time: 1:18:11.651306\n",
      "(10, 128, 128, 3)\n",
      "0.9089389\n",
      "[Epoch 8/10] [Batch 345/1081] [D loss: 0.043625] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.084911] time: 1:18:12.317214\n",
      "(10, 128, 128, 3)\n",
      "0.9327018\n",
      "[Epoch 8/10] [Batch 346/1081] [D loss: 0.043953] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.873247] time: 1:18:12.991995\n",
      "(10, 128, 128, 3)\n",
      "0.9075807\n",
      "[Epoch 8/10] [Batch 347/1081] [D loss: 0.046354] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.460740] time: 1:18:13.659826\n",
      "(10, 128, 128, 3)\n",
      "0.9321864\n",
      "[Epoch 8/10] [Batch 348/1081] [D loss: 0.044283] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.680897] time: 1:18:14.300659\n",
      "(10, 128, 128, 3)\n",
      "0.93343955\n",
      "[Epoch 8/10] [Batch 349/1081] [D loss: 0.043958] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.712053] time: 1:18:14.900674\n",
      "(10, 128, 128, 3)\n",
      "0.9211013\n",
      "[Epoch 8/10] [Batch 350/1081] [D loss: 0.043413] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.368603] time: 1:18:15.520993\n",
      "(10, 128, 128, 3)\n",
      "0.867084\n",
      "[Epoch 8/10] [Batch 351/1081] [D loss: 0.043694] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.446875] time: 1:18:16.135600\n",
      "(10, 128, 128, 3)\n",
      "0.90991193\n",
      "[Epoch 8/10] [Batch 352/1081] [D loss: 0.043760] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.831448] time: 1:18:16.801752\n",
      "(10, 128, 128, 3)\n",
      "0.871557\n",
      "[Epoch 8/10] [Batch 353/1081] [D loss: 0.043737] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.204582] time: 1:18:17.452466\n",
      "(10, 128, 128, 3)\n",
      "0.9051633\n",
      "[Epoch 8/10] [Batch 354/1081] [D loss: 0.043114] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.740866] time: 1:18:18.069229\n",
      "(10, 128, 128, 3)\n",
      "0.91138893\n",
      "[Epoch 8/10] [Batch 355/1081] [D loss: 0.043193] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.636756] time: 1:18:18.687001\n",
      "(10, 128, 128, 3)\n",
      "0.8860155\n",
      "[Epoch 8/10] [Batch 356/1081] [D loss: 0.043162] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.807271] time: 1:18:19.335215\n",
      "(10, 128, 128, 3)\n",
      "0.94633657\n",
      "[Epoch 8/10] [Batch 357/1081] [D loss: 0.042886] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.746214] time: 1:18:19.957524\n",
      "(10, 128, 128, 3)\n",
      "0.946547\n",
      "[Epoch 8/10] [Batch 358/1081] [D loss: 0.045744] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.167483] time: 1:18:20.597764\n",
      "(10, 128, 128, 3)\n",
      "0.93823504\n",
      "[Epoch 8/10] [Batch 359/1081] [D loss: 0.043036] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.843831] time: 1:18:21.336829\n",
      "(10, 128, 128, 3)\n",
      "0.89934224\n",
      "[Epoch 8/10] [Batch 360/1081] [D loss: 0.043125] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.643692] time: 1:18:21.956168\n",
      "(10, 128, 128, 3)\n",
      "0.9799183\n",
      "[Epoch 8/10] [Batch 361/1081] [D loss: 0.043609] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.827841] time: 1:18:22.582822\n",
      "(10, 128, 128, 3)\n",
      "0.9666767\n",
      "[Epoch 8/10] [Batch 362/1081] [D loss: 0.043069] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.025024] time: 1:18:23.241812\n",
      "(10, 128, 128, 3)\n",
      "0.95043343\n",
      "[Epoch 8/10] [Batch 363/1081] [D loss: 0.042731] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.201229] time: 1:18:23.868105\n",
      "(10, 128, 128, 3)\n",
      "0.908752\n",
      "[Epoch 8/10] [Batch 364/1081] [D loss: 0.042784] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.720975] time: 1:18:24.531659\n",
      "(10, 128, 128, 3)\n",
      "0.8858207\n",
      "[Epoch 8/10] [Batch 365/1081] [D loss: 0.045956] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.471514] time: 1:18:25.192829\n",
      "(10, 128, 128, 3)\n",
      "0.97989494\n",
      "[Epoch 8/10] [Batch 366/1081] [D loss: 0.043544] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.974434] time: 1:18:25.875656\n",
      "(10, 128, 128, 3)\n",
      "0.88967746\n",
      "[Epoch 8/10] [Batch 367/1081] [D loss: 0.042763] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.672321] time: 1:18:26.517182\n",
      "(10, 128, 128, 3)\n",
      "0.93267584\n",
      "[Epoch 8/10] [Batch 368/1081] [D loss: 0.042997] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.630315] time: 1:18:27.174369\n",
      "(10, 128, 128, 3)\n",
      "0.9043127\n",
      "[Epoch 8/10] [Batch 369/1081] [D loss: 0.043178] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.648254] time: 1:18:27.825610\n",
      "(10, 128, 128, 3)\n",
      "0.9024763\n",
      "[Epoch 8/10] [Batch 370/1081] [D loss: 0.042744] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.724730] time: 1:18:28.488874\n",
      "(10, 128, 128, 3)\n",
      "0.9037085\n",
      "[Epoch 8/10] [Batch 371/1081] [D loss: 0.042701] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.265695] time: 1:18:29.153795\n",
      "(10, 128, 128, 3)\n",
      "0.97623163\n",
      "[Epoch 8/10] [Batch 372/1081] [D loss: 0.042741] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.814085] time: 1:18:29.796957\n",
      "(10, 128, 128, 3)\n",
      "0.88890904\n",
      "[Epoch 8/10] [Batch 373/1081] [D loss: 0.042278] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.878291] time: 1:18:30.401617\n",
      "(10, 128, 128, 3)\n",
      "0.90280837\n",
      "[Epoch 8/10] [Batch 374/1081] [D loss: 0.043066] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.841104] time: 1:18:31.030170\n",
      "(10, 128, 128, 3)\n",
      "0.9057147\n",
      "[Epoch 8/10] [Batch 375/1081] [D loss: 0.042842] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.965466] time: 1:18:31.713455\n",
      "(10, 128, 128, 3)\n",
      "0.9385343\n",
      "[Epoch 8/10] [Batch 376/1081] [D loss: 0.043027] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.081721] time: 1:18:32.371367\n",
      "(10, 128, 128, 3)\n",
      "0.87270683\n",
      "[Epoch 8/10] [Batch 377/1081] [D loss: 0.042397] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.459591] time: 1:18:32.977810\n",
      "(10, 128, 128, 3)\n",
      "0.92569786\n",
      "[Epoch 8/10] [Batch 378/1081] [D loss: 0.042044] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.401833] time: 1:18:33.615324\n",
      "(10, 128, 128, 3)\n",
      "0.937599\n",
      "[Epoch 8/10] [Batch 379/1081] [D loss: 0.042119] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.080167] time: 1:18:34.236454\n",
      "(10, 128, 128, 3)\n",
      "0.8987439\n",
      "[Epoch 8/10] [Batch 380/1081] [D loss: 0.041916] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.170451] time: 1:18:34.859357\n",
      "(10, 128, 128, 3)\n",
      "0.9449568\n",
      "[Epoch 8/10] [Batch 381/1081] [D loss: 0.041866] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.012655] time: 1:18:35.539997\n",
      "(10, 128, 128, 3)\n",
      "0.9288717\n",
      "[Epoch 8/10] [Batch 382/1081] [D loss: 0.041927] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.541310] time: 1:18:36.197604\n",
      "(10, 128, 128, 3)\n",
      "0.8929288\n",
      "[Epoch 8/10] [Batch 383/1081] [D loss: 0.041977] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.536721] time: 1:18:36.897689\n",
      "(10, 128, 128, 3)\n",
      "0.92988044\n",
      "[Epoch 8/10] [Batch 384/1081] [D loss: 0.042039] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.084247] time: 1:18:37.525929\n",
      "(10, 128, 128, 3)\n",
      "0.9171656\n",
      "[Epoch 8/10] [Batch 385/1081] [D loss: 0.041897] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.988493] time: 1:18:38.135230\n",
      "(10, 128, 128, 3)\n",
      "0.89703894\n",
      "[Epoch 8/10] [Batch 386/1081] [D loss: 0.041783] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.625874] time: 1:18:38.854317\n",
      "(10, 128, 128, 3)\n",
      "0.90557384\n",
      "[Epoch 8/10] [Batch 387/1081] [D loss: 0.042033] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.217115] time: 1:18:39.530876\n",
      "(10, 128, 128, 3)\n",
      "0.8713835\n",
      "[Epoch 8/10] [Batch 388/1081] [D loss: 0.041968] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.849536] time: 1:18:40.193507\n",
      "(10, 128, 128, 3)\n",
      "0.9032522\n",
      "[Epoch 8/10] [Batch 389/1081] [D loss: 0.041929] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.756779] time: 1:18:40.843049\n",
      "(10, 128, 128, 3)\n",
      "0.92209935\n",
      "[Epoch 8/10] [Batch 390/1081] [D loss: 0.041656] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.115728] time: 1:18:41.500850\n",
      "(10, 128, 128, 3)\n",
      "0.9252507\n",
      "[Epoch 8/10] [Batch 391/1081] [D loss: 0.042125] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.721545] time: 1:18:42.203038\n",
      "(10, 128, 128, 3)\n",
      "0.88902444\n",
      "[Epoch 8/10] [Batch 392/1081] [D loss: 0.042037] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.922848] time: 1:18:42.844967\n",
      "(10, 128, 128, 3)\n",
      "0.94441676\n",
      "[Epoch 8/10] [Batch 393/1081] [D loss: 0.042067] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.968026] time: 1:18:43.501610\n",
      "(10, 128, 128, 3)\n",
      "0.90570253\n",
      "[Epoch 8/10] [Batch 394/1081] [D loss: 0.042069] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.696352] time: 1:18:44.160446\n",
      "(10, 128, 128, 3)\n",
      "0.9068947\n",
      "[Epoch 8/10] [Batch 395/1081] [D loss: 0.041363] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.234244] time: 1:18:44.842483\n",
      "(10, 128, 128, 3)\n",
      "0.8639218\n",
      "[Epoch 8/10] [Batch 396/1081] [D loss: 0.042352] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.548230] time: 1:18:45.474493\n",
      "(10, 128, 128, 3)\n",
      "0.9216661\n",
      "[Epoch 8/10] [Batch 397/1081] [D loss: 0.041295] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.928648] time: 1:18:46.088632\n",
      "(10, 128, 128, 3)\n",
      "0.94043714\n",
      "[Epoch 8/10] [Batch 398/1081] [D loss: 0.042416] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.881169] time: 1:18:46.733667\n",
      "(10, 128, 128, 3)\n",
      "0.971457\n",
      "[Epoch 8/10] [Batch 399/1081] [D loss: 0.045617] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.491007] time: 1:18:47.373839\n",
      "(10, 128, 128, 3)\n",
      "0.9107701\n",
      "[Epoch 8/10] [Batch 400/1081] [D loss: 0.041898] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.999635] time: 1:18:48.028458\n",
      "(10, 128, 128, 3)\n",
      "0.936687\n",
      "[Epoch 8/10] [Batch 401/1081] [D loss: 0.042220] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.434819] time: 1:18:48.669943\n",
      "(10, 128, 128, 3)\n",
      "0.8845818\n",
      "[Epoch 8/10] [Batch 402/1081] [D loss: 0.042952] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.838143] time: 1:18:49.365884\n",
      "(10, 128, 128, 3)\n",
      "0.9207395\n",
      "[Epoch 8/10] [Batch 403/1081] [D loss: 0.041215] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.525377] time: 1:18:50.003581\n",
      "(10, 128, 128, 3)\n",
      "0.9421613\n",
      "[Epoch 8/10] [Batch 404/1081] [D loss: 0.041540] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.567636] time: 1:18:50.633352\n",
      "(10, 128, 128, 3)\n",
      "0.9020067\n",
      "[Epoch 8/10] [Batch 405/1081] [D loss: 0.041478] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.159513] time: 1:18:51.298608\n",
      "(10, 128, 128, 3)\n",
      "0.9329517\n",
      "[Epoch 8/10] [Batch 406/1081] [D loss: 0.041490] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.874147] time: 1:18:51.921308\n",
      "(10, 128, 128, 3)\n",
      "0.90136504\n",
      "[Epoch 8/10] [Batch 407/1081] [D loss: 0.041401] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.260522] time: 1:18:52.602694\n",
      "(10, 128, 128, 3)\n",
      "0.95118076\n",
      "[Epoch 8/10] [Batch 408/1081] [D loss: 0.041081] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.588298] time: 1:18:53.202070\n",
      "(10, 128, 128, 3)\n",
      "0.88234633\n",
      "[Epoch 8/10] [Batch 409/1081] [D loss: 0.041084] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.573428] time: 1:18:53.908665\n",
      "(10, 128, 128, 3)\n",
      "0.9145104\n",
      "[Epoch 8/10] [Batch 410/1081] [D loss: 0.041024] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.564790] time: 1:18:54.541882\n",
      "(10, 128, 128, 3)\n",
      "0.9145178\n",
      "[Epoch 8/10] [Batch 411/1081] [D loss: 0.040837] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.145032] time: 1:18:55.205816\n",
      "(10, 128, 128, 3)\n",
      "0.874636\n",
      "[Epoch 8/10] [Batch 412/1081] [D loss: 0.041184] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.103831] time: 1:18:55.868603\n",
      "(10, 128, 128, 3)\n",
      "0.903197\n",
      "[Epoch 8/10] [Batch 413/1081] [D loss: 0.041300] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.065570] time: 1:18:56.478815\n",
      "(10, 128, 128, 3)\n",
      "0.9465864\n",
      "[Epoch 8/10] [Batch 414/1081] [D loss: 0.040918] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.352332] time: 1:18:57.113769\n",
      "(10, 128, 128, 3)\n",
      "0.90298325\n",
      "[Epoch 8/10] [Batch 415/1081] [D loss: 0.041336] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.288747] time: 1:18:57.710087\n",
      "(10, 128, 128, 3)\n",
      "0.90196353\n",
      "[Epoch 8/10] [Batch 416/1081] [D loss: 0.040743] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.098639] time: 1:18:58.324143\n",
      "(10, 128, 128, 3)\n",
      "0.863615\n",
      "[Epoch 8/10] [Batch 417/1081] [D loss: 0.040682] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.385068] time: 1:18:59.019817\n",
      "(10, 128, 128, 3)\n",
      "0.91059285\n",
      "[Epoch 8/10] [Batch 418/1081] [D loss: 0.040826] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.247546] time: 1:18:59.672009\n",
      "(10, 128, 128, 3)\n",
      "0.94730854\n",
      "[Epoch 8/10] [Batch 419/1081] [D loss: 0.040733] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.373693] time: 1:19:00.345775\n",
      "(10, 128, 128, 3)\n",
      "0.91596603\n",
      "[Epoch 8/10] [Batch 420/1081] [D loss: 0.041509] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.026186] time: 1:19:00.979427\n",
      "(10, 128, 128, 3)\n",
      "0.92374086\n",
      "[Epoch 8/10] [Batch 421/1081] [D loss: 0.041151] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.123555] time: 1:19:01.591153\n",
      "(10, 128, 128, 3)\n",
      "0.9313638\n",
      "[Epoch 8/10] [Batch 422/1081] [D loss: 0.040558] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.359644] time: 1:19:02.215270\n",
      "(10, 128, 128, 3)\n",
      "0.8713638\n",
      "[Epoch 8/10] [Batch 423/1081] [D loss: 0.040791] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.740276] time: 1:19:02.869461\n",
      "(10, 128, 128, 3)\n",
      "0.95959526\n",
      "[Epoch 8/10] [Batch 424/1081] [D loss: 0.041011] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.469579] time: 1:19:03.562543\n",
      "(10, 128, 128, 3)\n",
      "0.93456763\n",
      "[Epoch 8/10] [Batch 425/1081] [D loss: 0.040574] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.501015] time: 1:19:04.130794\n",
      "(10, 128, 128, 3)\n",
      "0.87845325\n",
      "[Epoch 8/10] [Batch 426/1081] [D loss: 0.040627] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.839638] time: 1:19:04.683412\n",
      "(10, 128, 128, 3)\n",
      "0.91692156\n",
      "[Epoch 8/10] [Batch 427/1081] [D loss: 0.041304] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.894709] time: 1:19:05.251901\n",
      "(10, 128, 128, 3)\n",
      "0.93034935\n",
      "[Epoch 8/10] [Batch 428/1081] [D loss: 0.040898] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.119775] time: 1:19:05.813654\n",
      "(10, 128, 128, 3)\n",
      "0.9163422\n",
      "[Epoch 8/10] [Batch 429/1081] [D loss: 0.041764] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.156435] time: 1:19:06.445694\n",
      "(10, 128, 128, 3)\n",
      "0.91223174\n",
      "[Epoch 8/10] [Batch 430/1081] [D loss: 0.041080] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.165709] time: 1:19:07.011033\n",
      "(10, 128, 128, 3)\n",
      "0.88875276\n",
      "[Epoch 8/10] [Batch 431/1081] [D loss: 0.040516] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.564195] time: 1:19:07.555996\n",
      "(10, 128, 128, 3)\n",
      "0.93483853\n",
      "[Epoch 8/10] [Batch 432/1081] [D loss: 0.041893] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.629212] time: 1:19:08.118932\n",
      "(10, 128, 128, 3)\n",
      "0.9190449\n",
      "[Epoch 8/10] [Batch 433/1081] [D loss: 0.040665] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.619658] time: 1:19:08.678475\n",
      "(10, 128, 128, 3)\n",
      "0.91728836\n",
      "[Epoch 8/10] [Batch 434/1081] [D loss: 0.041189] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.923022] time: 1:19:09.256347\n",
      "(10, 128, 128, 3)\n",
      "0.8787284\n",
      "[Epoch 8/10] [Batch 435/1081] [D loss: 0.040754] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.070883] time: 1:19:09.822465\n",
      "(10, 128, 128, 3)\n",
      "0.8949492\n",
      "[Epoch 8/10] [Batch 436/1081] [D loss: 0.040893] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.137109] time: 1:19:10.361427\n",
      "(10, 128, 128, 3)\n",
      "0.9361052\n",
      "[Epoch 8/10] [Batch 437/1081] [D loss: 0.040125] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.721350] time: 1:19:10.954641\n",
      "(10, 128, 128, 3)\n",
      "0.9531321\n",
      "[Epoch 8/10] [Batch 438/1081] [D loss: 0.040035] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.875306] time: 1:19:11.490800\n",
      "(10, 128, 128, 3)\n",
      "0.8691482\n",
      "[Epoch 8/10] [Batch 439/1081] [D loss: 0.041017] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.517821] time: 1:19:12.050171\n",
      "(10, 128, 128, 3)\n",
      "0.9066817\n",
      "[Epoch 8/10] [Batch 440/1081] [D loss: 0.041702] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.559960] time: 1:19:12.620413\n",
      "(10, 128, 128, 3)\n",
      "0.8759896\n",
      "[Epoch 8/10] [Batch 441/1081] [D loss: 0.040112] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.859177] time: 1:19:13.212443\n",
      "(10, 128, 128, 3)\n",
      "0.96313095\n",
      "[Epoch 8/10] [Batch 442/1081] [D loss: 0.040173] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.129234] time: 1:19:13.772465\n",
      "(10, 128, 128, 3)\n",
      "0.9295044\n",
      "[Epoch 8/10] [Batch 443/1081] [D loss: 0.039843] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.218770] time: 1:19:14.351370\n",
      "(10, 128, 128, 3)\n",
      "0.9263134\n",
      "[Epoch 8/10] [Batch 444/1081] [D loss: 0.040287] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.226210] time: 1:19:14.933345\n",
      "(10, 128, 128, 3)\n",
      "0.92001456\n",
      "[Epoch 8/10] [Batch 445/1081] [D loss: 0.040063] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.546110] time: 1:19:15.494339\n",
      "(10, 128, 128, 3)\n",
      "0.88702935\n",
      "[Epoch 8/10] [Batch 446/1081] [D loss: 0.039770] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.237636] time: 1:19:16.059762\n",
      "(10, 128, 128, 3)\n",
      "0.8964829\n",
      "[Epoch 8/10] [Batch 447/1081] [D loss: 0.363962] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 4.547344] time: 1:19:16.601284\n",
      "(10, 128, 128, 3)\n",
      "0.88991094\n",
      "[Epoch 8/10] [Batch 448/1081] [D loss: 0.100809] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.879941] time: 1:19:17.177048\n",
      "(10, 128, 128, 3)\n",
      "0.93331367\n",
      "[Epoch 8/10] [Batch 449/1081] [D loss: 0.161997] [D acc: 0.85 (1.00 real, 0.70 fake)] [G loss: 4.394764] time: 1:19:17.793747\n",
      "(10, 128, 128, 3)\n",
      "0.920352\n",
      "[Epoch 8/10] [Batch 450/1081] [D loss: 0.053142] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.115059] time: 1:19:18.379797\n",
      "(10, 128, 128, 3)\n",
      "0.90867376\n",
      "[Epoch 8/10] [Batch 451/1081] [D loss: 0.053536] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.267947] time: 1:19:18.938265\n",
      "(10, 128, 128, 3)\n",
      "0.95164305\n",
      "[Epoch 8/10] [Batch 452/1081] [D loss: 0.067193] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.716520] time: 1:19:19.490748\n",
      "(10, 128, 128, 3)\n",
      "0.8954728\n",
      "[Epoch 8/10] [Batch 453/1081] [D loss: 0.074031] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.350049] time: 1:19:20.003417\n",
      "(10, 128, 128, 3)\n",
      "0.90746194\n",
      "[Epoch 8/10] [Batch 454/1081] [D loss: 0.058304] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.962065] time: 1:19:20.588641\n",
      "(10, 128, 128, 3)\n",
      "0.897974\n",
      "[Epoch 8/10] [Batch 455/1081] [D loss: 0.053326] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.311946] time: 1:19:21.128277\n",
      "(10, 128, 128, 3)\n",
      "0.89366823\n",
      "[Epoch 8/10] [Batch 456/1081] [D loss: 0.059984] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.750141] time: 1:19:21.666491\n",
      "(10, 128, 128, 3)\n",
      "0.9141569\n",
      "[Epoch 8/10] [Batch 457/1081] [D loss: 0.057828] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.111163] time: 1:19:22.233848\n",
      "(10, 128, 128, 3)\n",
      "0.9758558\n",
      "[Epoch 8/10] [Batch 458/1081] [D loss: 0.053365] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.203918] time: 1:19:22.817963\n",
      "(10, 128, 128, 3)\n",
      "0.9215515\n",
      "[Epoch 8/10] [Batch 459/1081] [D loss: 0.056588] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.264982] time: 1:19:23.410932\n",
      "(10, 128, 128, 3)\n",
      "0.9235639\n",
      "[Epoch 8/10] [Batch 460/1081] [D loss: 0.060824] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.280847] time: 1:19:24.091237\n",
      "(10, 128, 128, 3)\n",
      "0.8885879\n",
      "[Epoch 8/10] [Batch 461/1081] [D loss: 0.057320] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.809008] time: 1:19:24.718515\n",
      "(10, 128, 128, 3)\n",
      "0.9188295\n",
      "[Epoch 8/10] [Batch 462/1081] [D loss: 0.050916] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.857994] time: 1:19:25.404912\n",
      "(10, 128, 128, 3)\n",
      "0.8911376\n",
      "[Epoch 8/10] [Batch 463/1081] [D loss: 0.051911] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.556868] time: 1:19:26.041020\n",
      "(10, 128, 128, 3)\n",
      "0.8560123\n",
      "[Epoch 8/10] [Batch 464/1081] [D loss: 0.054090] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.496827] time: 1:19:26.719840\n",
      "(10, 128, 128, 3)\n",
      "0.8400059\n",
      "[Epoch 8/10] [Batch 465/1081] [D loss: 0.051309] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.567220] time: 1:19:27.371609\n",
      "(10, 128, 128, 3)\n",
      "0.8824704\n",
      "[Epoch 8/10] [Batch 466/1081] [D loss: 0.053994] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.845533] time: 1:19:28.063126\n",
      "(10, 128, 128, 3)\n",
      "0.9381976\n",
      "[Epoch 8/10] [Batch 467/1081] [D loss: 0.051933] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.277610] time: 1:19:28.755304\n",
      "(10, 128, 128, 3)\n",
      "0.88621473\n",
      "[Epoch 8/10] [Batch 468/1081] [D loss: 0.051777] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.174615] time: 1:19:29.414384\n",
      "(10, 128, 128, 3)\n",
      "0.9089651\n",
      "[Epoch 8/10] [Batch 469/1081] [D loss: 0.055466] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.874412] time: 1:19:30.084296\n",
      "(10, 128, 128, 3)\n",
      "0.9495135\n",
      "[Epoch 8/10] [Batch 470/1081] [D loss: 0.055082] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.431797] time: 1:19:30.772007\n",
      "(10, 128, 128, 3)\n",
      "0.9393454\n",
      "[Epoch 8/10] [Batch 471/1081] [D loss: 0.057650] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.511265] time: 1:19:31.417544\n",
      "(10, 128, 128, 3)\n",
      "0.8992385\n",
      "[Epoch 8/10] [Batch 472/1081] [D loss: 0.050753] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.968496] time: 1:19:32.119919\n",
      "(10, 128, 128, 3)\n",
      "0.9032158\n",
      "[Epoch 8/10] [Batch 473/1081] [D loss: 0.050584] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.124883] time: 1:19:32.763675\n",
      "(10, 128, 128, 3)\n",
      "0.9201341\n",
      "[Epoch 8/10] [Batch 474/1081] [D loss: 0.049385] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.486124] time: 1:19:33.428420\n",
      "(10, 128, 128, 3)\n",
      "0.92676073\n",
      "[Epoch 8/10] [Batch 475/1081] [D loss: 0.051468] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.322851] time: 1:19:34.111899\n",
      "(10, 128, 128, 3)\n",
      "0.8962726\n",
      "[Epoch 8/10] [Batch 476/1081] [D loss: 0.051398] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.068280] time: 1:19:34.788990\n",
      "(10, 128, 128, 3)\n",
      "0.8917814\n",
      "[Epoch 8/10] [Batch 477/1081] [D loss: 0.051001] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.445066] time: 1:19:35.451993\n",
      "(10, 128, 128, 3)\n",
      "0.8615892\n",
      "[Epoch 8/10] [Batch 478/1081] [D loss: 0.053724] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.657541] time: 1:19:36.117888\n",
      "(10, 128, 128, 3)\n",
      "0.9566919\n",
      "[Epoch 8/10] [Batch 479/1081] [D loss: 0.049369] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.449219] time: 1:19:36.762076\n",
      "(10, 128, 128, 3)\n",
      "0.9069824\n",
      "[Epoch 8/10] [Batch 480/1081] [D loss: 0.048566] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.138730] time: 1:19:37.398295\n",
      "(10, 128, 128, 3)\n",
      "0.92448187\n",
      "[Epoch 8/10] [Batch 481/1081] [D loss: 0.051917] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.146550] time: 1:19:38.036081\n",
      "(10, 128, 128, 3)\n",
      "0.93975925\n",
      "[Epoch 8/10] [Batch 482/1081] [D loss: 0.050863] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.243420] time: 1:19:38.719718\n",
      "(10, 128, 128, 3)\n",
      "0.92674065\n",
      "[Epoch 8/10] [Batch 483/1081] [D loss: 0.049159] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.393871] time: 1:19:39.324459\n",
      "(10, 128, 128, 3)\n",
      "0.9049805\n",
      "[Epoch 8/10] [Batch 484/1081] [D loss: 0.050111] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.598104] time: 1:19:39.923325\n",
      "(10, 128, 128, 3)\n",
      "0.94156694\n",
      "[Epoch 8/10] [Batch 485/1081] [D loss: 0.047617] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.476107] time: 1:19:40.532517\n",
      "(10, 128, 128, 3)\n",
      "0.9506561\n",
      "[Epoch 8/10] [Batch 486/1081] [D loss: 0.049352] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.160412] time: 1:19:41.215848\n",
      "(10, 128, 128, 3)\n",
      "0.961482\n",
      "[Epoch 8/10] [Batch 487/1081] [D loss: 0.048441] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.118913] time: 1:19:41.911712\n",
      "(10, 128, 128, 3)\n",
      "0.96493554\n",
      "[Epoch 8/10] [Batch 488/1081] [D loss: 0.050004] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.813508] time: 1:19:42.613258\n",
      "(10, 128, 128, 3)\n",
      "0.9102323\n",
      "[Epoch 8/10] [Batch 489/1081] [D loss: 0.048062] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.800144] time: 1:19:43.209317\n",
      "(10, 128, 128, 3)\n",
      "0.9565716\n",
      "[Epoch 8/10] [Batch 490/1081] [D loss: 0.047249] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.068924] time: 1:19:43.818337\n",
      "(10, 128, 128, 3)\n",
      "0.9021182\n",
      "[Epoch 8/10] [Batch 491/1081] [D loss: 0.047001] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.249676] time: 1:19:44.485336\n",
      "(10, 128, 128, 3)\n",
      "0.865994\n",
      "[Epoch 8/10] [Batch 492/1081] [D loss: 0.047764] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.279551] time: 1:19:45.170917\n",
      "(10, 128, 128, 3)\n",
      "0.8777614\n",
      "[Epoch 8/10] [Batch 493/1081] [D loss: 0.050533] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.601687] time: 1:19:45.740211\n",
      "(10, 128, 128, 3)\n",
      "0.87618333\n",
      "[Epoch 8/10] [Batch 494/1081] [D loss: 0.050613] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.359633] time: 1:19:46.411939\n",
      "(10, 128, 128, 3)\n",
      "0.90431786\n",
      "[Epoch 8/10] [Batch 495/1081] [D loss: 0.047652] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.144726] time: 1:19:47.095134\n",
      "(10, 128, 128, 3)\n",
      "0.97237897\n",
      "[Epoch 8/10] [Batch 496/1081] [D loss: 0.047481] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.988610] time: 1:19:47.770521\n",
      "(10, 128, 128, 3)\n",
      "0.9476308\n",
      "[Epoch 8/10] [Batch 497/1081] [D loss: 0.046625] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.356308] time: 1:19:48.402765\n",
      "(10, 128, 128, 3)\n",
      "0.87560517\n",
      "[Epoch 8/10] [Batch 498/1081] [D loss: 0.047135] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.160347] time: 1:19:49.117083\n",
      "(10, 128, 128, 3)\n",
      "0.8954552\n",
      "[Epoch 8/10] [Batch 499/1081] [D loss: 0.054380] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.380998] time: 1:19:49.751140\n",
      "(10, 128, 128, 3)\n",
      "0.8986551\n",
      "[Epoch 8/10] [Batch 500/1081] [D loss: 0.049204] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.784166] time: 1:19:50.374449\n",
      "(10, 128, 128, 3)\n",
      "0.8908736\n",
      "[Epoch 8/10] [Batch 501/1081] [D loss: 0.047168] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.315573] time: 1:19:51.067758\n",
      "(10, 128, 128, 3)\n",
      "0.9163618\n",
      "[Epoch 8/10] [Batch 502/1081] [D loss: 0.059763] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.064487] time: 1:19:51.690801\n",
      "(10, 128, 128, 3)\n",
      "0.9332275\n",
      "[Epoch 8/10] [Batch 503/1081] [D loss: 0.046033] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.789724] time: 1:19:52.330574\n",
      "(10, 128, 128, 3)\n",
      "0.953891\n",
      "[Epoch 8/10] [Batch 504/1081] [D loss: 0.047405] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.719692] time: 1:19:52.927186\n",
      "(10, 128, 128, 3)\n",
      "0.93136215\n",
      "[Epoch 8/10] [Batch 505/1081] [D loss: 0.045649] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.006184] time: 1:19:53.538485\n",
      "(10, 128, 128, 3)\n",
      "0.91370827\n",
      "[Epoch 8/10] [Batch 506/1081] [D loss: 0.047350] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.314590] time: 1:19:54.183603\n",
      "(10, 128, 128, 3)\n",
      "0.9108111\n",
      "[Epoch 8/10] [Batch 507/1081] [D loss: 0.045849] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.365308] time: 1:19:54.856836\n",
      "(10, 128, 128, 3)\n",
      "0.8702235\n",
      "[Epoch 8/10] [Batch 508/1081] [D loss: 0.045441] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.053698] time: 1:19:55.470124\n",
      "(10, 128, 128, 3)\n",
      "0.9484997\n",
      "[Epoch 8/10] [Batch 509/1081] [D loss: 0.046050] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.742111] time: 1:19:56.100006\n",
      "(10, 128, 128, 3)\n",
      "0.9747657\n",
      "[Epoch 8/10] [Batch 510/1081] [D loss: 0.045559] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.909239] time: 1:19:56.775710\n",
      "(10, 128, 128, 3)\n",
      "0.940036\n",
      "[Epoch 8/10] [Batch 511/1081] [D loss: 0.044995] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.724620] time: 1:19:57.412326\n",
      "(10, 128, 128, 3)\n",
      "0.8908999\n",
      "[Epoch 8/10] [Batch 512/1081] [D loss: 0.045447] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.068887] time: 1:19:58.072016\n",
      "(10, 128, 128, 3)\n",
      "0.88173753\n",
      "[Epoch 8/10] [Batch 513/1081] [D loss: 0.044370] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.078310] time: 1:19:58.709485\n",
      "(10, 128, 128, 3)\n",
      "0.92383814\n",
      "[Epoch 8/10] [Batch 514/1081] [D loss: 0.046010] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.177319] time: 1:19:59.356644\n",
      "(10, 128, 128, 3)\n",
      "0.9368491\n",
      "[Epoch 8/10] [Batch 515/1081] [D loss: 0.044160] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.074261] time: 1:19:59.998496\n",
      "(10, 128, 128, 3)\n",
      "0.91533655\n",
      "[Epoch 8/10] [Batch 516/1081] [D loss: 0.045616] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.732901] time: 1:20:00.625799\n",
      "(10, 128, 128, 3)\n",
      "0.9334255\n",
      "[Epoch 8/10] [Batch 517/1081] [D loss: 0.044488] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.709515] time: 1:20:01.274489\n",
      "(10, 128, 128, 3)\n",
      "0.9033106\n",
      "[Epoch 8/10] [Batch 518/1081] [D loss: 0.046022] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.774432] time: 1:20:01.953034\n",
      "(10, 128, 128, 3)\n",
      "0.9684585\n",
      "[Epoch 8/10] [Batch 519/1081] [D loss: 0.047140] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.500049] time: 1:20:02.646774\n",
      "(10, 128, 128, 3)\n",
      "0.90681696\n",
      "[Epoch 8/10] [Batch 520/1081] [D loss: 0.045532] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.731995] time: 1:20:03.310858\n",
      "(10, 128, 128, 3)\n",
      "0.9154605\n",
      "[Epoch 8/10] [Batch 521/1081] [D loss: 0.044330] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.627388] time: 1:20:03.984169\n",
      "(10, 128, 128, 3)\n",
      "0.92540556\n",
      "[Epoch 8/10] [Batch 522/1081] [D loss: 0.045320] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.516518] time: 1:20:04.663042\n",
      "(10, 128, 128, 3)\n",
      "0.93190795\n",
      "[Epoch 8/10] [Batch 523/1081] [D loss: 0.044714] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.003405] time: 1:20:05.309838\n",
      "(10, 128, 128, 3)\n",
      "0.92967576\n",
      "[Epoch 8/10] [Batch 524/1081] [D loss: 0.044059] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.836428] time: 1:20:05.921067\n",
      "(10, 128, 128, 3)\n",
      "0.86515164\n",
      "[Epoch 8/10] [Batch 525/1081] [D loss: 0.043964] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.554871] time: 1:20:06.547006\n",
      "(10, 128, 128, 3)\n",
      "0.85577863\n",
      "[Epoch 8/10] [Batch 526/1081] [D loss: 0.044564] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.850808] time: 1:20:07.216792\n",
      "(10, 128, 128, 3)\n",
      "0.91608024\n",
      "[Epoch 8/10] [Batch 527/1081] [D loss: 0.043870] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.764706] time: 1:20:07.867549\n",
      "(10, 128, 128, 3)\n",
      "0.9465258\n",
      "[Epoch 8/10] [Batch 528/1081] [D loss: 0.043480] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.456447] time: 1:20:08.527418\n",
      "(10, 128, 128, 3)\n",
      "0.92094976\n",
      "[Epoch 8/10] [Batch 529/1081] [D loss: 0.043251] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.398949] time: 1:20:09.133647\n",
      "(10, 128, 128, 3)\n",
      "0.91105175\n",
      "[Epoch 8/10] [Batch 530/1081] [D loss: 0.043835] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.423395] time: 1:20:09.820772\n",
      "(10, 128, 128, 3)\n",
      "0.9200876\n",
      "[Epoch 8/10] [Batch 531/1081] [D loss: 0.044623] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.638892] time: 1:20:10.470053\n",
      "(10, 128, 128, 3)\n",
      "0.88701695\n",
      "[Epoch 8/10] [Batch 532/1081] [D loss: 0.044259] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.281994] time: 1:20:11.141825\n",
      "(10, 128, 128, 3)\n",
      "0.874718\n",
      "[Epoch 8/10] [Batch 533/1081] [D loss: 0.044342] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.573812] time: 1:20:11.771797\n",
      "(10, 128, 128, 3)\n",
      "0.91126186\n",
      "[Epoch 8/10] [Batch 534/1081] [D loss: 0.043577] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.405441] time: 1:20:12.439179\n",
      "(10, 128, 128, 3)\n",
      "0.8897951\n",
      "[Epoch 8/10] [Batch 535/1081] [D loss: 0.044681] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.890782] time: 1:20:13.085895\n",
      "(10, 128, 128, 3)\n",
      "0.9218862\n",
      "[Epoch 8/10] [Batch 536/1081] [D loss: 0.042989] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.775234] time: 1:20:13.716382\n",
      "(10, 128, 128, 3)\n",
      "0.86541533\n",
      "[Epoch 8/10] [Batch 537/1081] [D loss: 0.043376] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.953844] time: 1:20:14.350497\n",
      "(10, 128, 128, 3)\n",
      "0.8981805\n",
      "[Epoch 8/10] [Batch 538/1081] [D loss: 0.042680] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.887970] time: 1:20:14.967988\n",
      "(10, 128, 128, 3)\n",
      "0.9329469\n",
      "[Epoch 8/10] [Batch 539/1081] [D loss: 0.043401] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.676752] time: 1:20:15.637058\n",
      "(10, 128, 128, 3)\n",
      "0.8519907\n",
      "[Epoch 8/10] [Batch 540/1081] [D loss: 0.042600] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.565747] time: 1:20:16.271478\n",
      "(10, 128, 128, 3)\n",
      "0.8054245\n",
      "[Epoch 8/10] [Batch 541/1081] [D loss: 0.043138] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.604842] time: 1:20:16.930157\n",
      "(10, 128, 128, 3)\n",
      "0.8732159\n",
      "[Epoch 8/10] [Batch 542/1081] [D loss: 0.043169] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.728173] time: 1:20:17.589206\n",
      "(10, 128, 128, 3)\n",
      "0.89696735\n",
      "[Epoch 8/10] [Batch 543/1081] [D loss: 0.042452] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.253313] time: 1:20:18.242390\n",
      "(10, 128, 128, 3)\n",
      "0.9229657\n",
      "[Epoch 8/10] [Batch 544/1081] [D loss: 0.043262] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.837300] time: 1:20:18.930589\n",
      "(10, 128, 128, 3)\n",
      "0.9316847\n",
      "[Epoch 8/10] [Batch 545/1081] [D loss: 0.044279] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.490685] time: 1:20:19.631899\n",
      "(10, 128, 128, 3)\n",
      "0.88570267\n",
      "[Epoch 8/10] [Batch 546/1081] [D loss: 0.042258] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.370425] time: 1:20:20.243892\n",
      "(10, 128, 128, 3)\n",
      "0.9486988\n",
      "[Epoch 8/10] [Batch 547/1081] [D loss: 0.042794] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.616805] time: 1:20:20.930854\n",
      "(10, 128, 128, 3)\n",
      "0.93630713\n",
      "[Epoch 8/10] [Batch 548/1081] [D loss: 0.043070] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.682771] time: 1:20:21.558470\n",
      "(10, 128, 128, 3)\n",
      "0.9135404\n",
      "[Epoch 8/10] [Batch 549/1081] [D loss: 0.043394] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.287989] time: 1:20:22.199730\n",
      "(10, 128, 128, 3)\n",
      "0.8862455\n",
      "[Epoch 8/10] [Batch 550/1081] [D loss: 0.042188] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.939952] time: 1:20:22.836730\n",
      "(10, 128, 128, 3)\n",
      "0.90105945\n",
      "[Epoch 8/10] [Batch 551/1081] [D loss: 0.041945] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.199717] time: 1:20:23.491719\n",
      "(10, 128, 128, 3)\n",
      "0.9139617\n",
      "[Epoch 8/10] [Batch 552/1081] [D loss: 0.042615] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.691223] time: 1:20:24.126929\n",
      "(10, 128, 128, 3)\n",
      "0.9418566\n",
      "[Epoch 8/10] [Batch 553/1081] [D loss: 0.043372] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.673422] time: 1:20:24.744726\n",
      "(10, 128, 128, 3)\n",
      "0.911967\n",
      "[Epoch 8/10] [Batch 554/1081] [D loss: 0.041300] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.555859] time: 1:20:25.377761\n",
      "(10, 128, 128, 3)\n",
      "0.97384435\n",
      "[Epoch 8/10] [Batch 555/1081] [D loss: 0.041757] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.814750] time: 1:20:26.075630\n",
      "(10, 128, 128, 3)\n",
      "0.92981434\n",
      "[Epoch 8/10] [Batch 556/1081] [D loss: 0.041443] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.113563] time: 1:20:26.742468\n",
      "(10, 128, 128, 3)\n",
      "0.9057903\n",
      "[Epoch 8/10] [Batch 557/1081] [D loss: 0.041708] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.270679] time: 1:20:27.397800\n",
      "(10, 128, 128, 3)\n",
      "0.9240691\n",
      "[Epoch 8/10] [Batch 558/1081] [D loss: 0.041206] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.060195] time: 1:20:28.098833\n",
      "(10, 128, 128, 3)\n",
      "0.85503536\n",
      "[Epoch 8/10] [Batch 559/1081] [D loss: 0.042248] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.497132] time: 1:20:28.775676\n",
      "(10, 128, 128, 3)\n",
      "0.8836228\n",
      "[Epoch 8/10] [Batch 560/1081] [D loss: 0.043805] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.029146] time: 1:20:29.455373\n",
      "(10, 128, 128, 3)\n",
      "0.91124314\n",
      "[Epoch 8/10] [Batch 561/1081] [D loss: 0.041837] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.008970] time: 1:20:30.121778\n",
      "(10, 128, 128, 3)\n",
      "0.84047526\n",
      "[Epoch 8/10] [Batch 562/1081] [D loss: 0.041172] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.918103] time: 1:20:30.767690\n",
      "(10, 128, 128, 3)\n",
      "0.8746645\n",
      "[Epoch 8/10] [Batch 563/1081] [D loss: 0.040823] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.523121] time: 1:20:31.364834\n",
      "(10, 128, 128, 3)\n",
      "0.90050846\n",
      "[Epoch 8/10] [Batch 564/1081] [D loss: 0.040893] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.341876] time: 1:20:32.031896\n",
      "(10, 128, 128, 3)\n",
      "0.91597414\n",
      "[Epoch 8/10] [Batch 565/1081] [D loss: 0.042381] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.695564] time: 1:20:32.704156\n",
      "(10, 128, 128, 3)\n",
      "0.9159289\n",
      "[Epoch 8/10] [Batch 566/1081] [D loss: 0.042214] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.579041] time: 1:20:33.362890\n",
      "(10, 128, 128, 3)\n",
      "0.8644269\n",
      "[Epoch 8/10] [Batch 567/1081] [D loss: 0.040679] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.289678] time: 1:20:34.005119\n",
      "(10, 128, 128, 3)\n",
      "0.8923927\n",
      "[Epoch 8/10] [Batch 568/1081] [D loss: 0.042265] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.732844] time: 1:20:34.703496\n",
      "(10, 128, 128, 3)\n",
      "0.88868684\n",
      "[Epoch 8/10] [Batch 569/1081] [D loss: 0.042323] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.098905] time: 1:20:35.365596\n",
      "(10, 128, 128, 3)\n",
      "0.9113946\n",
      "[Epoch 8/10] [Batch 570/1081] [D loss: 0.040812] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.168254] time: 1:20:36.024213\n",
      "(10, 128, 128, 3)\n",
      "0.8411121\n",
      "[Epoch 8/10] [Batch 571/1081] [D loss: 0.041625] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.121731] time: 1:20:36.661513\n",
      "(10, 128, 128, 3)\n",
      "0.94850945\n",
      "[Epoch 8/10] [Batch 572/1081] [D loss: 0.041360] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.995477] time: 1:20:37.299233\n",
      "(10, 128, 128, 3)\n",
      "0.9675562\n",
      "[Epoch 8/10] [Batch 573/1081] [D loss: 0.040789] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.015901] time: 1:20:37.989976\n",
      "(10, 128, 128, 3)\n",
      "0.9373326\n",
      "[Epoch 8/10] [Batch 574/1081] [D loss: 0.041480] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.021978] time: 1:20:38.685074\n",
      "(10, 128, 128, 3)\n",
      "0.91223997\n",
      "[Epoch 8/10] [Batch 575/1081] [D loss: 0.040723] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.730816] time: 1:20:39.347323\n",
      "(10, 128, 128, 3)\n",
      "0.94417214\n",
      "[Epoch 8/10] [Batch 576/1081] [D loss: 0.040309] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.528456] time: 1:20:40.005970\n",
      "(10, 128, 128, 3)\n",
      "0.90550214\n",
      "[Epoch 8/10] [Batch 577/1081] [D loss: 0.042066] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.343178] time: 1:20:40.603337\n",
      "(10, 128, 128, 3)\n",
      "0.93226784\n",
      "[Epoch 8/10] [Batch 578/1081] [D loss: 0.186973] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 3.533499] time: 1:20:41.236499\n",
      "(10, 128, 128, 3)\n",
      "0.9315261\n",
      "[Epoch 8/10] [Batch 579/1081] [D loss: 0.797670] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 4.813672] time: 1:20:41.841160\n",
      "(10, 128, 128, 3)\n",
      "0.8987562\n",
      "[Epoch 8/10] [Batch 580/1081] [D loss: 0.473435] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 3.105018] time: 1:20:42.564728\n",
      "(10, 128, 128, 3)\n",
      "0.90776944\n",
      "[Epoch 8/10] [Batch 581/1081] [D loss: 0.407820] [D acc: 0.45 (0.90 real, 0.00 fake)] [G loss: 4.364490] time: 1:20:43.264494\n",
      "(10, 128, 128, 3)\n",
      "0.8871689\n",
      "[Epoch 8/10] [Batch 582/1081] [D loss: 0.403494] [D acc: 0.20 (0.40 real, 0.00 fake)] [G loss: 4.768916] time: 1:20:43.879989\n",
      "(10, 128, 128, 3)\n",
      "0.9485879\n",
      "[Epoch 8/10] [Batch 583/1081] [D loss: 0.385796] [D acc: 0.20 (0.00 real, 0.40 fake)] [G loss: 3.945448] time: 1:20:44.536232\n",
      "(10, 128, 128, 3)\n",
      "0.933664\n",
      "[Epoch 8/10] [Batch 584/1081] [D loss: 0.381942] [D acc: 0.05 (0.00 real, 0.10 fake)] [G loss: 3.736149] time: 1:20:45.224280\n",
      "(10, 128, 128, 3)\n",
      "0.9203179\n",
      "[Epoch 8/10] [Batch 585/1081] [D loss: 0.375198] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 4.749951] time: 1:20:45.926420\n",
      "(10, 128, 128, 3)\n",
      "0.9106493\n",
      "[Epoch 8/10] [Batch 586/1081] [D loss: 0.363115] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 3.279948] time: 1:20:46.620771\n",
      "(10, 128, 128, 3)\n",
      "0.89183855\n",
      "[Epoch 8/10] [Batch 587/1081] [D loss: 0.358066] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 4.550154] time: 1:20:47.208236\n",
      "(10, 128, 128, 3)\n",
      "0.92356896\n",
      "[Epoch 8/10] [Batch 588/1081] [D loss: 0.359049] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 4.253744] time: 1:20:47.839649\n",
      "(10, 128, 128, 3)\n",
      "0.9048577\n",
      "[Epoch 8/10] [Batch 589/1081] [D loss: 0.353355] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 4.173140] time: 1:20:48.489670\n",
      "(10, 128, 128, 3)\n",
      "0.9600722\n",
      "[Epoch 8/10] [Batch 590/1081] [D loss: 0.355800] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 3.461301] time: 1:20:49.172279\n",
      "(10, 128, 128, 3)\n",
      "0.93347126\n",
      "[Epoch 8/10] [Batch 591/1081] [D loss: 0.353299] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 3.188169] time: 1:20:49.825278\n",
      "(10, 128, 128, 3)\n",
      "0.9034175\n",
      "[Epoch 8/10] [Batch 592/1081] [D loss: 0.348658] [D acc: 0.10 (0.10 real, 0.10 fake)] [G loss: 4.418792] time: 1:20:50.445771\n",
      "(10, 128, 128, 3)\n",
      "0.91723305\n",
      "[Epoch 8/10] [Batch 593/1081] [D loss: 0.348973] [D acc: 0.05 (0.10 real, 0.00 fake)] [G loss: 4.275335] time: 1:20:51.111702\n",
      "(10, 128, 128, 3)\n",
      "0.903547\n",
      "[Epoch 8/10] [Batch 594/1081] [D loss: 0.349123] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 3.506070] time: 1:20:51.804303\n",
      "(10, 128, 128, 3)\n",
      "0.9575402\n",
      "[Epoch 8/10] [Batch 595/1081] [D loss: 0.343022] [D acc: 0.10 (0.00 real, 0.20 fake)] [G loss: 3.973947] time: 1:20:52.516298\n",
      "(10, 128, 128, 3)\n",
      "0.8982153\n",
      "[Epoch 8/10] [Batch 596/1081] [D loss: 0.340325] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 4.569147] time: 1:20:53.146533\n",
      "(10, 128, 128, 3)\n",
      "0.93575215\n",
      "[Epoch 8/10] [Batch 597/1081] [D loss: 0.374000] [D acc: 0.05 (0.10 real, 0.00 fake)] [G loss: 4.106306] time: 1:20:53.844478\n",
      "(10, 128, 128, 3)\n",
      "0.9092278\n",
      "[Epoch 8/10] [Batch 598/1081] [D loss: 0.346798] [D acc: 0.05 (0.10 real, 0.00 fake)] [G loss: 4.610527] time: 1:20:54.490343\n",
      "(10, 128, 128, 3)\n",
      "0.9840571\n",
      "[Epoch 8/10] [Batch 599/1081] [D loss: 0.342883] [D acc: 0.10 (0.20 real, 0.00 fake)] [G loss: 3.984440] time: 1:20:55.120435\n",
      "(10, 128, 128, 3)\n",
      "0.86168295\n",
      "[Epoch 8/10] [Batch 600/1081] [D loss: 0.338984] [D acc: 0.10 (0.20 real, 0.00 fake)] [G loss: 4.370294] time: 1:20:55.773806\n",
      "(10, 128, 128, 3)\n",
      "0.8841521\n",
      "[Epoch 8/10] [Batch 601/1081] [D loss: 0.332487] [D acc: 0.10 (0.00 real, 0.20 fake)] [G loss: 4.798278] time: 1:20:56.402048\n",
      "(10, 128, 128, 3)\n",
      "0.92403954\n",
      "[Epoch 8/10] [Batch 602/1081] [D loss: 0.339472] [D acc: 0.05 (0.10 real, 0.00 fake)] [G loss: 3.827998] time: 1:20:57.092113\n",
      "(10, 128, 128, 3)\n",
      "0.8795898\n",
      "[Epoch 8/10] [Batch 603/1081] [D loss: 0.337762] [D acc: 0.15 (0.20 real, 0.10 fake)] [G loss: 5.676590] time: 1:20:57.740792\n",
      "(10, 128, 128, 3)\n",
      "0.918835\n",
      "[Epoch 8/10] [Batch 604/1081] [D loss: 0.333461] [D acc: 0.05 (0.10 real, 0.00 fake)] [G loss: 3.653514] time: 1:20:58.364899\n",
      "(10, 128, 128, 3)\n",
      "0.9265189\n",
      "[Epoch 8/10] [Batch 605/1081] [D loss: 0.331163] [D acc: 0.10 (0.10 real, 0.10 fake)] [G loss: 4.232121] time: 1:20:59.010555\n",
      "(10, 128, 128, 3)\n",
      "0.87208676\n",
      "[Epoch 8/10] [Batch 606/1081] [D loss: 0.332081] [D acc: 0.10 (0.00 real, 0.20 fake)] [G loss: 5.166126] time: 1:20:59.713195\n",
      "(10, 128, 128, 3)\n",
      "0.9316669\n",
      "[Epoch 8/10] [Batch 607/1081] [D loss: 0.339511] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 3.409934] time: 1:21:00.380413\n",
      "(10, 128, 128, 3)\n",
      "0.92731017\n",
      "[Epoch 8/10] [Batch 608/1081] [D loss: 0.336769] [D acc: 0.10 (0.20 real, 0.00 fake)] [G loss: 4.194364] time: 1:21:01.014162\n",
      "(10, 128, 128, 3)\n",
      "0.8920582\n",
      "[Epoch 8/10] [Batch 609/1081] [D loss: 0.341685] [D acc: 0.05 (0.00 real, 0.10 fake)] [G loss: 3.752857] time: 1:21:01.676770\n",
      "(10, 128, 128, 3)\n",
      "0.94399565\n",
      "[Epoch 8/10] [Batch 610/1081] [D loss: 0.327397] [D acc: 0.15 (0.10 real, 0.20 fake)] [G loss: 4.676495] time: 1:21:02.311458\n",
      "(10, 128, 128, 3)\n",
      "0.9364961\n",
      "[Epoch 8/10] [Batch 611/1081] [D loss: 0.277378] [D acc: 0.70 (1.00 real, 0.40 fake)] [G loss: 3.439932] time: 1:21:02.963727\n",
      "(10, 128, 128, 3)\n",
      "0.924666\n",
      "[Epoch 8/10] [Batch 612/1081] [D loss: 0.356780] [D acc: 0.40 (0.80 real, 0.00 fake)] [G loss: 4.020318] time: 1:21:03.644789\n",
      "(10, 128, 128, 3)\n",
      "0.87675554\n",
      "[Epoch 8/10] [Batch 613/1081] [D loss: 0.311765] [D acc: 0.30 (0.30 real, 0.30 fake)] [G loss: 6.099824] time: 1:21:04.244106\n",
      "(10, 128, 128, 3)\n",
      "0.8824294\n",
      "[Epoch 8/10] [Batch 614/1081] [D loss: 0.398146] [D acc: 0.05 (0.10 real, 0.00 fake)] [G loss: 4.558059] time: 1:21:04.883214\n",
      "(10, 128, 128, 3)\n",
      "0.9379676\n",
      "[Epoch 8/10] [Batch 615/1081] [D loss: 0.261231] [D acc: 0.65 (1.00 real, 0.30 fake)] [G loss: 5.572207] time: 1:21:05.504207\n",
      "(10, 128, 128, 3)\n",
      "0.9163568\n",
      "[Epoch 8/10] [Batch 616/1081] [D loss: 0.427925] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 4.450243] time: 1:21:06.166525\n",
      "(10, 128, 128, 3)\n",
      "0.899791\n",
      "[Epoch 8/10] [Batch 617/1081] [D loss: 0.362729] [D acc: 0.15 (0.30 real, 0.00 fake)] [G loss: 4.898682] time: 1:21:06.805563\n",
      "(10, 128, 128, 3)\n",
      "0.9040732\n",
      "[Epoch 8/10] [Batch 618/1081] [D loss: 0.349258] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 4.041034] time: 1:21:07.490867\n",
      "(10, 128, 128, 3)\n",
      "0.8554122\n",
      "[Epoch 8/10] [Batch 619/1081] [D loss: 0.352813] [D acc: 0.30 (0.10 real, 0.50 fake)] [G loss: 4.014683] time: 1:21:08.087564\n",
      "(10, 128, 128, 3)\n",
      "0.94911593\n",
      "[Epoch 8/10] [Batch 620/1081] [D loss: 0.265697] [D acc: 0.80 (0.80 real, 0.80 fake)] [G loss: 4.499268] time: 1:21:08.725392\n",
      "(10, 128, 128, 3)\n",
      "0.91599864\n",
      "[Epoch 8/10] [Batch 621/1081] [D loss: 0.300427] [D acc: 0.55 (0.10 real, 1.00 fake)] [G loss: 3.920146] time: 1:21:09.380461\n",
      "(10, 128, 128, 3)\n",
      "0.90096134\n",
      "[Epoch 8/10] [Batch 622/1081] [D loss: 0.168924] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.549620] time: 1:21:10.082992\n",
      "(10, 128, 128, 3)\n",
      "0.94858664\n",
      "[Epoch 8/10] [Batch 623/1081] [D loss: 0.091539] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.587193] time: 1:21:10.736783\n",
      "(10, 128, 128, 3)\n",
      "0.92641497\n",
      "[Epoch 8/10] [Batch 624/1081] [D loss: 0.075477] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.605145] time: 1:21:11.339766\n",
      "(10, 128, 128, 3)\n",
      "0.8880174\n",
      "[Epoch 8/10] [Batch 625/1081] [D loss: 0.097261] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.028988] time: 1:21:11.969155\n",
      "(10, 128, 128, 3)\n",
      "0.95263004\n",
      "[Epoch 8/10] [Batch 626/1081] [D loss: 0.067537] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.662268] time: 1:21:12.673369\n",
      "(10, 128, 128, 3)\n",
      "0.9456999\n",
      "[Epoch 8/10] [Batch 627/1081] [D loss: 0.067994] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.052590] time: 1:21:13.371837\n",
      "(10, 128, 128, 3)\n",
      "0.95759386\n",
      "[Epoch 8/10] [Batch 628/1081] [D loss: 0.058263] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.353278] time: 1:21:13.983562\n",
      "(10, 128, 128, 3)\n",
      "0.90785694\n",
      "[Epoch 8/10] [Batch 629/1081] [D loss: 0.061132] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.462274] time: 1:21:14.618083\n",
      "(10, 128, 128, 3)\n",
      "0.94763845\n",
      "[Epoch 8/10] [Batch 630/1081] [D loss: 0.059519] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.347716] time: 1:21:15.256264\n",
      "(10, 128, 128, 3)\n",
      "0.90352345\n",
      "[Epoch 8/10] [Batch 631/1081] [D loss: 0.144416] [D acc: 0.85 (1.00 real, 0.70 fake)] [G loss: 4.717054] time: 1:21:15.904814\n",
      "(10, 128, 128, 3)\n",
      "0.9665606\n",
      "[Epoch 8/10] [Batch 632/1081] [D loss: 0.093171] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.844132] time: 1:21:16.499263\n",
      "(10, 128, 128, 3)\n",
      "0.9599634\n",
      "[Epoch 8/10] [Batch 633/1081] [D loss: 0.087616] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.094691] time: 1:21:17.167483\n",
      "(10, 128, 128, 3)\n",
      "0.94959\n",
      "[Epoch 8/10] [Batch 634/1081] [D loss: 0.061356] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.700093] time: 1:21:17.784545\n",
      "(10, 128, 128, 3)\n",
      "0.85130876\n",
      "[Epoch 8/10] [Batch 635/1081] [D loss: 0.058914] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.492751] time: 1:21:18.416685\n",
      "(10, 128, 128, 3)\n",
      "0.89285636\n",
      "[Epoch 8/10] [Batch 636/1081] [D loss: 0.058601] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.920710] time: 1:21:19.049939\n",
      "(10, 128, 128, 3)\n",
      "0.96215326\n",
      "[Epoch 8/10] [Batch 637/1081] [D loss: 0.580013] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 3.278325] time: 1:21:19.701202\n",
      "(10, 128, 128, 3)\n",
      "0.9502576\n",
      "[Epoch 8/10] [Batch 638/1081] [D loss: 0.271198] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 3.648412] time: 1:21:20.384610\n",
      "(10, 128, 128, 3)\n",
      "0.94241023\n",
      "[Epoch 8/10] [Batch 639/1081] [D loss: 0.289669] [D acc: 0.55 (1.00 real, 0.10 fake)] [G loss: 3.455482] time: 1:21:21.013520\n",
      "(10, 128, 128, 3)\n",
      "0.9106052\n",
      "[Epoch 8/10] [Batch 640/1081] [D loss: 0.205823] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 3.526884] time: 1:21:21.662230\n",
      "(10, 128, 128, 3)\n",
      "0.8758653\n",
      "[Epoch 8/10] [Batch 641/1081] [D loss: 0.183365] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 5.043949] time: 1:21:22.311950\n",
      "(10, 128, 128, 3)\n",
      "0.9093595\n",
      "[Epoch 8/10] [Batch 642/1081] [D loss: 0.172146] [D acc: 0.85 (1.00 real, 0.70 fake)] [G loss: 4.363706] time: 1:21:22.982271\n",
      "(10, 128, 128, 3)\n",
      "0.96049744\n",
      "[Epoch 8/10] [Batch 643/1081] [D loss: 0.287591] [D acc: 0.65 (0.90 real, 0.40 fake)] [G loss: 4.368239] time: 1:21:23.629984\n",
      "(10, 128, 128, 3)\n",
      "0.8723754\n",
      "[Epoch 8/10] [Batch 644/1081] [D loss: 0.210270] [D acc: 0.80 (0.60 real, 1.00 fake)] [G loss: 3.920005] time: 1:21:24.349393\n",
      "(10, 128, 128, 3)\n",
      "0.8982425\n",
      "[Epoch 8/10] [Batch 645/1081] [D loss: 0.181972] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.948010] time: 1:21:25.037610\n",
      "(10, 128, 128, 3)\n",
      "0.93281794\n",
      "[Epoch 8/10] [Batch 646/1081] [D loss: 0.073759] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.529436] time: 1:21:25.704754\n",
      "(10, 128, 128, 3)\n",
      "0.9630249\n",
      "[Epoch 8/10] [Batch 647/1081] [D loss: 0.124852] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.183497] time: 1:21:26.370698\n",
      "(10, 128, 128, 3)\n",
      "0.9463718\n",
      "[Epoch 8/10] [Batch 648/1081] [D loss: 0.086715] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.609769] time: 1:21:27.011006\n",
      "(10, 128, 128, 3)\n",
      "0.8972764\n",
      "[Epoch 8/10] [Batch 649/1081] [D loss: 0.073900] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.186764] time: 1:21:27.623767\n",
      "(10, 128, 128, 3)\n",
      "0.8760199\n",
      "[Epoch 8/10] [Batch 650/1081] [D loss: 0.078680] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.291043] time: 1:21:28.289098\n",
      "(10, 128, 128, 3)\n",
      "0.96758014\n",
      "[Epoch 8/10] [Batch 651/1081] [D loss: 0.070070] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.529372] time: 1:21:28.962607\n",
      "(10, 128, 128, 3)\n",
      "0.90690714\n",
      "[Epoch 8/10] [Batch 652/1081] [D loss: 0.100461] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.831949] time: 1:21:29.590351\n",
      "(10, 128, 128, 3)\n",
      "0.9712245\n",
      "[Epoch 8/10] [Batch 653/1081] [D loss: 0.106759] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.227453] time: 1:21:30.225414\n",
      "(10, 128, 128, 3)\n",
      "0.8912476\n",
      "[Epoch 8/10] [Batch 654/1081] [D loss: 0.074138] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.292533] time: 1:21:30.910244\n",
      "(10, 128, 128, 3)\n",
      "0.8828973\n",
      "[Epoch 8/10] [Batch 655/1081] [D loss: 0.076349] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.311714] time: 1:21:31.607614\n",
      "(10, 128, 128, 3)\n",
      "0.9362123\n",
      "[Epoch 8/10] [Batch 656/1081] [D loss: 0.077598] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.872626] time: 1:21:32.254943\n",
      "(10, 128, 128, 3)\n",
      "0.9278796\n",
      "[Epoch 8/10] [Batch 657/1081] [D loss: 0.070478] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.332044] time: 1:21:32.959453\n",
      "(10, 128, 128, 3)\n",
      "0.91365767\n",
      "[Epoch 8/10] [Batch 658/1081] [D loss: 0.068460] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.117235] time: 1:21:33.803993\n",
      "(10, 128, 128, 3)\n",
      "0.9713958\n",
      "[Epoch 8/10] [Batch 659/1081] [D loss: 0.067219] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.213952] time: 1:21:34.480724\n",
      "(10, 128, 128, 3)\n",
      "0.8719833\n",
      "[Epoch 8/10] [Batch 660/1081] [D loss: 0.069152] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.087852] time: 1:21:35.145861\n",
      "(10, 128, 128, 3)\n",
      "0.95389766\n",
      "[Epoch 8/10] [Batch 661/1081] [D loss: 0.069170] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.533829] time: 1:21:35.824420\n",
      "(10, 128, 128, 3)\n",
      "0.95009977\n",
      "[Epoch 8/10] [Batch 662/1081] [D loss: 0.066701] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.122509] time: 1:21:36.510633\n",
      "(10, 128, 128, 3)\n",
      "0.95187503\n",
      "[Epoch 8/10] [Batch 663/1081] [D loss: 0.065711] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.130957] time: 1:21:37.186682\n",
      "(10, 128, 128, 3)\n",
      "0.87500244\n",
      "[Epoch 8/10] [Batch 664/1081] [D loss: 0.066216] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.538013] time: 1:21:37.783278\n",
      "(10, 128, 128, 3)\n",
      "0.94330627\n",
      "[Epoch 8/10] [Batch 665/1081] [D loss: 0.065119] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.229691] time: 1:21:38.470002\n",
      "(10, 128, 128, 3)\n",
      "0.8748664\n",
      "[Epoch 8/10] [Batch 666/1081] [D loss: 0.067384] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.756541] time: 1:21:39.182501\n",
      "(10, 128, 128, 3)\n",
      "0.91727525\n",
      "[Epoch 8/10] [Batch 667/1081] [D loss: 0.174996] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 3.526450] time: 1:21:39.798670\n",
      "(10, 128, 128, 3)\n",
      "0.92364925\n",
      "[Epoch 8/10] [Batch 668/1081] [D loss: 0.068209] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.469160] time: 1:21:40.435291\n",
      "(10, 128, 128, 3)\n",
      "0.9229264\n",
      "[Epoch 8/10] [Batch 669/1081] [D loss: 0.194476] [D acc: 0.65 (1.00 real, 0.30 fake)] [G loss: 4.521143] time: 1:21:41.069228\n",
      "(10, 128, 128, 3)\n",
      "0.9368083\n",
      "[Epoch 8/10] [Batch 670/1081] [D loss: 0.072659] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.925608] time: 1:21:41.700784\n",
      "(10, 128, 128, 3)\n",
      "0.91597\n",
      "[Epoch 8/10] [Batch 671/1081] [D loss: 0.078232] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.551307] time: 1:21:42.314366\n",
      "(10, 128, 128, 3)\n",
      "0.9189925\n",
      "[Epoch 8/10] [Batch 672/1081] [D loss: 0.280826] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 4.605066] time: 1:21:42.902455\n",
      "(10, 128, 128, 3)\n",
      "0.9151556\n",
      "[Epoch 8/10] [Batch 673/1081] [D loss: 0.092269] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.769561] time: 1:21:43.601940\n",
      "(10, 128, 128, 3)\n",
      "0.8961251\n",
      "[Epoch 8/10] [Batch 674/1081] [D loss: 0.083668] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.167657] time: 1:21:44.253618\n",
      "(10, 128, 128, 3)\n",
      "0.93851405\n",
      "[Epoch 8/10] [Batch 675/1081] [D loss: 0.076745] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.854172] time: 1:21:44.878559\n",
      "(10, 128, 128, 3)\n",
      "0.9095073\n",
      "[Epoch 8/10] [Batch 676/1081] [D loss: 0.073508] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.527578] time: 1:21:45.539964\n",
      "(10, 128, 128, 3)\n",
      "0.9421435\n",
      "[Epoch 8/10] [Batch 677/1081] [D loss: 0.077495] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.976056] time: 1:21:46.154832\n",
      "(10, 128, 128, 3)\n",
      "0.980187\n",
      "[Epoch 8/10] [Batch 678/1081] [D loss: 0.083671] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.915606] time: 1:21:46.841280\n",
      "(10, 128, 128, 3)\n",
      "0.94927615\n",
      "[Epoch 8/10] [Batch 679/1081] [D loss: 0.076404] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.550675] time: 1:21:47.497635\n",
      "(10, 128, 128, 3)\n",
      "0.93261147\n",
      "[Epoch 8/10] [Batch 680/1081] [D loss: 0.067961] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.228551] time: 1:21:48.150891\n",
      "(10, 128, 128, 3)\n",
      "0.89942056\n",
      "[Epoch 8/10] [Batch 681/1081] [D loss: 0.068179] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.959443] time: 1:21:48.797460\n",
      "(10, 128, 128, 3)\n",
      "0.90555334\n",
      "[Epoch 8/10] [Batch 682/1081] [D loss: 0.067974] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.454723] time: 1:21:49.461127\n",
      "(10, 128, 128, 3)\n",
      "0.97396713\n",
      "[Epoch 8/10] [Batch 683/1081] [D loss: 0.075126] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.817514] time: 1:21:50.148485\n",
      "(10, 128, 128, 3)\n",
      "0.91783375\n",
      "[Epoch 8/10] [Batch 684/1081] [D loss: 0.069802] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.399273] time: 1:21:50.790544\n",
      "(10, 128, 128, 3)\n",
      "0.8502237\n",
      "[Epoch 8/10] [Batch 685/1081] [D loss: 0.082163] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.921690] time: 1:21:51.401953\n",
      "(10, 128, 128, 3)\n",
      "0.8671115\n",
      "[Epoch 8/10] [Batch 686/1081] [D loss: 0.070460] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.046077] time: 1:21:52.125096\n",
      "(10, 128, 128, 3)\n",
      "0.91018367\n",
      "[Epoch 8/10] [Batch 687/1081] [D loss: 0.064418] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.656653] time: 1:21:52.811140\n",
      "(10, 128, 128, 3)\n",
      "0.91039056\n",
      "[Epoch 8/10] [Batch 688/1081] [D loss: 0.084069] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.323685] time: 1:21:53.445724\n",
      "(10, 128, 128, 3)\n",
      "0.9200494\n",
      "[Epoch 8/10] [Batch 689/1081] [D loss: 0.067477] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.881460] time: 1:21:54.106517\n",
      "(10, 128, 128, 3)\n",
      "0.92708725\n",
      "[Epoch 8/10] [Batch 690/1081] [D loss: 0.065839] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.466205] time: 1:21:54.772956\n",
      "(10, 128, 128, 3)\n",
      "0.9261221\n",
      "[Epoch 8/10] [Batch 691/1081] [D loss: 0.073501] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.375860] time: 1:21:55.403049\n",
      "(10, 128, 128, 3)\n",
      "0.9121087\n",
      "[Epoch 8/10] [Batch 692/1081] [D loss: 0.069226] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.504585] time: 1:21:56.085763\n",
      "(10, 128, 128, 3)\n",
      "0.9574669\n",
      "[Epoch 8/10] [Batch 693/1081] [D loss: 0.067105] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.443534] time: 1:21:56.748475\n",
      "(10, 128, 128, 3)\n",
      "0.92964196\n",
      "[Epoch 8/10] [Batch 694/1081] [D loss: 0.067057] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.695026] time: 1:21:57.356182\n",
      "(10, 128, 128, 3)\n",
      "0.879889\n",
      "[Epoch 8/10] [Batch 695/1081] [D loss: 0.065567] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.690151] time: 1:21:57.987306\n",
      "(10, 128, 128, 3)\n",
      "0.93915987\n",
      "[Epoch 8/10] [Batch 696/1081] [D loss: 0.063156] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.217115] time: 1:21:58.642584\n",
      "(10, 128, 128, 3)\n",
      "0.93289703\n",
      "[Epoch 8/10] [Batch 697/1081] [D loss: 0.063177] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.328712] time: 1:21:59.234645\n",
      "(10, 128, 128, 3)\n",
      "0.87740475\n",
      "[Epoch 8/10] [Batch 698/1081] [D loss: 0.061819] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.498165] time: 1:21:59.896846\n",
      "(10, 128, 128, 3)\n",
      "0.9304142\n",
      "[Epoch 8/10] [Batch 699/1081] [D loss: 0.080713] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.533367] time: 1:22:00.582467\n",
      "(10, 128, 128, 3)\n",
      "0.8665123\n",
      "[Epoch 8/10] [Batch 700/1081] [D loss: 0.063815] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.209596] time: 1:22:01.267560\n",
      "(10, 128, 128, 3)\n",
      "0.8925207\n",
      "[Epoch 8/10] [Batch 701/1081] [D loss: 0.061541] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.491356] time: 1:22:01.925201\n",
      "(10, 128, 128, 3)\n",
      "0.9385007\n",
      "[Epoch 8/10] [Batch 702/1081] [D loss: 0.062049] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.339705] time: 1:22:02.573549\n",
      "(10, 128, 128, 3)\n",
      "0.8935366\n",
      "[Epoch 8/10] [Batch 703/1081] [D loss: 0.061399] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.642639] time: 1:22:03.189870\n",
      "(10, 128, 128, 3)\n",
      "0.9202416\n",
      "[Epoch 8/10] [Batch 704/1081] [D loss: 0.061780] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.892593] time: 1:22:03.890808\n",
      "(10, 128, 128, 3)\n",
      "0.8528154\n",
      "[Epoch 8/10] [Batch 705/1081] [D loss: 0.061283] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.452014] time: 1:22:04.536970\n",
      "(10, 128, 128, 3)\n",
      "0.90187496\n",
      "[Epoch 8/10] [Batch 706/1081] [D loss: 0.060836] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.193059] time: 1:22:05.225539\n",
      "(10, 128, 128, 3)\n",
      "0.97517824\n",
      "[Epoch 8/10] [Batch 707/1081] [D loss: 0.064783] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.602134] time: 1:22:05.829516\n",
      "(10, 128, 128, 3)\n",
      "0.9465561\n",
      "[Epoch 8/10] [Batch 708/1081] [D loss: 0.135970] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.016082] time: 1:22:06.450653\n",
      "(10, 128, 128, 3)\n",
      "0.9460301\n",
      "[Epoch 8/10] [Batch 709/1081] [D loss: 0.062550] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.383237] time: 1:22:07.034517\n",
      "(10, 128, 128, 3)\n",
      "0.9110244\n",
      "[Epoch 8/10] [Batch 710/1081] [D loss: 0.062686] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.292170] time: 1:22:07.701424\n",
      "(10, 128, 128, 3)\n",
      "0.9638291\n",
      "[Epoch 8/10] [Batch 711/1081] [D loss: 0.060123] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.812348] time: 1:22:08.398934\n",
      "(10, 128, 128, 3)\n",
      "0.8790405\n",
      "[Epoch 8/10] [Batch 712/1081] [D loss: 0.064847] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.547998] time: 1:22:09.013836\n",
      "(10, 128, 128, 3)\n",
      "0.90084726\n",
      "[Epoch 8/10] [Batch 713/1081] [D loss: 0.061104] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.239459] time: 1:22:09.667966\n",
      "(10, 128, 128, 3)\n",
      "0.8454965\n",
      "[Epoch 8/10] [Batch 714/1081] [D loss: 0.060228] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.094563] time: 1:22:10.330817\n",
      "(10, 128, 128, 3)\n",
      "0.9163046\n",
      "[Epoch 8/10] [Batch 715/1081] [D loss: 0.061460] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.219784] time: 1:22:11.001140\n",
      "(10, 128, 128, 3)\n",
      "0.90056485\n",
      "[Epoch 8/10] [Batch 716/1081] [D loss: 0.058994] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.462111] time: 1:22:11.716074\n",
      "(10, 128, 128, 3)\n",
      "0.8553357\n",
      "[Epoch 8/10] [Batch 717/1081] [D loss: 0.059687] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.101792] time: 1:22:12.350472\n",
      "(10, 128, 128, 3)\n",
      "0.92826843\n",
      "[Epoch 8/10] [Batch 718/1081] [D loss: 0.059188] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.158738] time: 1:22:12.967167\n",
      "(10, 128, 128, 3)\n",
      "0.9296748\n",
      "[Epoch 8/10] [Batch 719/1081] [D loss: 0.061032] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.997756] time: 1:22:13.663169\n",
      "(10, 128, 128, 3)\n",
      "0.8882448\n",
      "[Epoch 8/10] [Batch 720/1081] [D loss: 0.058710] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.790946] time: 1:22:14.353011\n",
      "(10, 128, 128, 3)\n",
      "0.917154\n",
      "[Epoch 8/10] [Batch 721/1081] [D loss: 0.058668] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.785895] time: 1:22:14.990014\n",
      "(10, 128, 128, 3)\n",
      "0.96365166\n",
      "[Epoch 8/10] [Batch 722/1081] [D loss: 0.058645] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.057508] time: 1:22:15.678584\n",
      "(10, 128, 128, 3)\n",
      "0.9259782\n",
      "[Epoch 8/10] [Batch 723/1081] [D loss: 0.057016] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.607793] time: 1:22:16.292623\n",
      "(10, 128, 128, 3)\n",
      "0.935129\n",
      "[Epoch 8/10] [Batch 724/1081] [D loss: 0.057710] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.463828] time: 1:22:16.961283\n",
      "(10, 128, 128, 3)\n",
      "0.9342656\n",
      "[Epoch 8/10] [Batch 725/1081] [D loss: 0.056832] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.976619] time: 1:22:17.587288\n",
      "(10, 128, 128, 3)\n",
      "0.9458716\n",
      "[Epoch 8/10] [Batch 726/1081] [D loss: 0.146555] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.956770] time: 1:22:18.276009\n",
      "(10, 128, 128, 3)\n",
      "0.9149513\n",
      "[Epoch 8/10] [Batch 727/1081] [D loss: 0.096399] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.179629] time: 1:22:19.545146\n",
      "(10, 128, 128, 3)\n",
      "0.93285507\n",
      "[Epoch 8/10] [Batch 728/1081] [D loss: 0.080874] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.142425] time: 1:22:20.180241\n",
      "(10, 128, 128, 3)\n",
      "0.9344411\n",
      "[Epoch 8/10] [Batch 729/1081] [D loss: 0.058240] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.742363] time: 1:22:20.880159\n",
      "(10, 128, 128, 3)\n",
      "0.91902757\n",
      "[Epoch 8/10] [Batch 730/1081] [D loss: 0.057806] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.931630] time: 1:22:21.603524\n",
      "(10, 128, 128, 3)\n",
      "0.8804552\n",
      "[Epoch 8/10] [Batch 731/1081] [D loss: 0.056604] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.962826] time: 1:22:22.290625\n",
      "(10, 128, 128, 3)\n",
      "0.8737455\n",
      "[Epoch 8/10] [Batch 732/1081] [D loss: 0.060027] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.655681] time: 1:22:22.965358\n",
      "(10, 128, 128, 3)\n",
      "0.89538103\n",
      "[Epoch 8/10] [Batch 733/1081] [D loss: 0.138628] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 7.063033] time: 1:22:23.578618\n",
      "(10, 128, 128, 3)\n",
      "0.902802\n",
      "[Epoch 8/10] [Batch 734/1081] [D loss: 0.477135] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 7.676407] time: 1:22:24.152696\n",
      "(10, 128, 128, 3)\n",
      "0.9199915\n",
      "[Epoch 8/10] [Batch 735/1081] [D loss: 0.306656] [D acc: 0.60 (1.00 real, 0.20 fake)] [G loss: 22.122150] time: 1:22:24.713945\n",
      "(10, 128, 128, 3)\n",
      "0.960946\n",
      "[Epoch 8/10] [Batch 736/1081] [D loss: 0.127619] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 8.432977] time: 1:22:25.282944\n",
      "(10, 128, 128, 3)\n",
      "0.871181\n",
      "[Epoch 8/10] [Batch 737/1081] [D loss: 0.102743] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.740306] time: 1:22:25.832179\n",
      "(10, 128, 128, 3)\n",
      "0.90674686\n",
      "[Epoch 8/10] [Batch 738/1081] [D loss: 0.079403] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.854804] time: 1:22:26.372800\n",
      "(10, 128, 128, 3)\n",
      "0.963605\n",
      "[Epoch 8/10] [Batch 739/1081] [D loss: 0.142372] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.263764] time: 1:22:26.968329\n",
      "(10, 128, 128, 3)\n",
      "0.8860824\n",
      "[Epoch 8/10] [Batch 740/1081] [D loss: 0.067894] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.376222] time: 1:22:27.570989\n",
      "(10, 128, 128, 3)\n",
      "0.86631364\n",
      "[Epoch 8/10] [Batch 741/1081] [D loss: 0.081159] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.630009] time: 1:22:28.112526\n",
      "(10, 128, 128, 3)\n",
      "0.92541605\n",
      "[Epoch 8/10] [Batch 742/1081] [D loss: 0.121091] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.858028] time: 1:22:28.674708\n",
      "(10, 128, 128, 3)\n",
      "0.90738374\n",
      "[Epoch 8/10] [Batch 743/1081] [D loss: 0.185449] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 4.444979] time: 1:22:29.252441\n",
      "(10, 128, 128, 3)\n",
      "0.9748526\n",
      "[Epoch 8/10] [Batch 744/1081] [D loss: 0.067622] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.570506] time: 1:22:29.788860\n",
      "(10, 128, 128, 3)\n",
      "0.93732977\n",
      "[Epoch 8/10] [Batch 745/1081] [D loss: 0.065214] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.214136] time: 1:22:30.357008\n",
      "(10, 128, 128, 3)\n",
      "0.93470484\n",
      "[Epoch 8/10] [Batch 746/1081] [D loss: 0.063545] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.850902] time: 1:22:30.910415\n",
      "(10, 128, 128, 3)\n",
      "0.90822643\n",
      "[Epoch 8/10] [Batch 747/1081] [D loss: 0.064196] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.435498] time: 1:22:31.466851\n",
      "(10, 128, 128, 3)\n",
      "0.9198473\n",
      "[Epoch 8/10] [Batch 748/1081] [D loss: 0.064085] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.769016] time: 1:22:32.024658\n",
      "(10, 128, 128, 3)\n",
      "0.89962935\n",
      "[Epoch 8/10] [Batch 749/1081] [D loss: 0.065618] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.866232] time: 1:22:32.568190\n",
      "(10, 128, 128, 3)\n",
      "0.8579967\n",
      "[Epoch 8/10] [Batch 750/1081] [D loss: 0.060494] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.523619] time: 1:22:33.146492\n",
      "(10, 128, 128, 3)\n",
      "0.8442088\n",
      "[Epoch 8/10] [Batch 751/1081] [D loss: 0.060270] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.867637] time: 1:22:33.747845\n",
      "(10, 128, 128, 3)\n",
      "0.92570287\n",
      "[Epoch 8/10] [Batch 752/1081] [D loss: 0.061791] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.305376] time: 1:22:34.327638\n",
      "(10, 128, 128, 3)\n",
      "0.89661527\n",
      "[Epoch 8/10] [Batch 753/1081] [D loss: 0.063439] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.085100] time: 1:22:34.897358\n",
      "(10, 128, 128, 3)\n",
      "0.89826965\n",
      "[Epoch 8/10] [Batch 754/1081] [D loss: 0.063285] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.653266] time: 1:22:35.462643\n",
      "(10, 128, 128, 3)\n",
      "0.8816209\n",
      "[Epoch 8/10] [Batch 755/1081] [D loss: 0.059968] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.490716] time: 1:22:36.058065\n",
      "(10, 128, 128, 3)\n",
      "0.8659099\n",
      "[Epoch 8/10] [Batch 756/1081] [D loss: 0.059546] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.689876] time: 1:22:36.669339\n",
      "(10, 128, 128, 3)\n",
      "0.9358666\n",
      "[Epoch 8/10] [Batch 757/1081] [D loss: 0.061530] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.609909] time: 1:22:37.250294\n",
      "(10, 128, 128, 3)\n",
      "0.903302\n",
      "[Epoch 8/10] [Batch 758/1081] [D loss: 0.062837] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.907845] time: 1:22:37.798232\n",
      "(10, 128, 128, 3)\n",
      "0.89054865\n",
      "[Epoch 8/10] [Batch 759/1081] [D loss: 0.081944] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.100719] time: 1:22:38.363237\n",
      "(10, 128, 128, 3)\n",
      "0.92380834\n",
      "[Epoch 8/10] [Batch 760/1081] [D loss: 0.063526] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.044315] time: 1:22:38.934704\n",
      "(10, 128, 128, 3)\n",
      "0.9173414\n",
      "[Epoch 8/10] [Batch 761/1081] [D loss: 0.058931] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.351365] time: 1:22:39.465544\n",
      "(10, 128, 128, 3)\n",
      "0.91265965\n",
      "[Epoch 8/10] [Batch 762/1081] [D loss: 0.067787] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.385457] time: 1:22:40.035703\n",
      "(10, 128, 128, 3)\n",
      "0.8847232\n",
      "[Epoch 8/10] [Batch 763/1081] [D loss: 0.058756] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.991599] time: 1:22:40.665826\n",
      "(10, 128, 128, 3)\n",
      "0.9673746\n",
      "[Epoch 8/10] [Batch 764/1081] [D loss: 0.058256] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.680231] time: 1:22:41.238044\n",
      "(10, 128, 128, 3)\n",
      "0.9366036\n",
      "[Epoch 8/10] [Batch 765/1081] [D loss: 0.059147] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.609018] time: 1:22:41.793449\n",
      "(10, 128, 128, 3)\n",
      "0.9414527\n",
      "[Epoch 8/10] [Batch 766/1081] [D loss: 0.057970] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.966725] time: 1:22:42.372649\n",
      "(10, 128, 128, 3)\n",
      "0.9175034\n",
      "[Epoch 8/10] [Batch 767/1081] [D loss: 0.058061] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.291839] time: 1:22:42.953297\n",
      "(10, 128, 128, 3)\n",
      "0.891918\n",
      "[Epoch 8/10] [Batch 768/1081] [D loss: 0.064645] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.777071] time: 1:22:43.534827\n",
      "(10, 128, 128, 3)\n",
      "0.9121218\n",
      "[Epoch 8/10] [Batch 769/1081] [D loss: 0.057616] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.125002] time: 1:22:44.196964\n",
      "(10, 128, 128, 3)\n",
      "0.8595961\n",
      "[Epoch 8/10] [Batch 770/1081] [D loss: 0.058104] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.122988] time: 1:22:44.872062\n",
      "(10, 128, 128, 3)\n",
      "0.8947428\n",
      "[Epoch 8/10] [Batch 771/1081] [D loss: 0.060426] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.656478] time: 1:22:45.543850\n",
      "(10, 128, 128, 3)\n",
      "0.9239499\n",
      "[Epoch 8/10] [Batch 772/1081] [D loss: 0.058008] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.091455] time: 1:22:46.181057\n",
      "(10, 128, 128, 3)\n",
      "0.91152495\n",
      "[Epoch 8/10] [Batch 773/1081] [D loss: 0.058952] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.996226] time: 1:22:46.884711\n",
      "(10, 128, 128, 3)\n",
      "0.92654705\n",
      "[Epoch 8/10] [Batch 774/1081] [D loss: 0.056705] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.975200] time: 1:22:47.498982\n",
      "(10, 128, 128, 3)\n",
      "0.9136593\n",
      "[Epoch 8/10] [Batch 775/1081] [D loss: 0.057310] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.977078] time: 1:22:48.141266\n",
      "(10, 128, 128, 3)\n",
      "0.93614197\n",
      "[Epoch 8/10] [Batch 776/1081] [D loss: 0.056546] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.538087] time: 1:22:48.752197\n",
      "(10, 128, 128, 3)\n",
      "0.88608533\n",
      "[Epoch 8/10] [Batch 777/1081] [D loss: 0.062185] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.380136] time: 1:22:49.391533\n",
      "(10, 128, 128, 3)\n",
      "0.90189075\n",
      "[Epoch 8/10] [Batch 778/1081] [D loss: 0.094730] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.783738] time: 1:22:49.998309\n",
      "(10, 128, 128, 3)\n",
      "0.9473343\n",
      "[Epoch 8/10] [Batch 779/1081] [D loss: 0.062269] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.696144] time: 1:22:50.662506\n",
      "(10, 128, 128, 3)\n",
      "0.9058195\n",
      "[Epoch 8/10] [Batch 780/1081] [D loss: 0.058922] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.147511] time: 1:22:51.319186\n",
      "(10, 128, 128, 3)\n",
      "0.83603233\n",
      "[Epoch 8/10] [Batch 781/1081] [D loss: 0.055475] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.482832] time: 1:22:51.965249\n",
      "(10, 128, 128, 3)\n",
      "0.92341655\n",
      "[Epoch 8/10] [Batch 782/1081] [D loss: 0.057095] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.470374] time: 1:22:52.570758\n",
      "(10, 128, 128, 3)\n",
      "0.886797\n",
      "[Epoch 8/10] [Batch 783/1081] [D loss: 0.055637] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.814276] time: 1:22:53.282404\n",
      "(10, 128, 128, 3)\n",
      "0.9382184\n",
      "[Epoch 8/10] [Batch 784/1081] [D loss: 0.055139] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.294195] time: 1:22:53.977527\n",
      "(10, 128, 128, 3)\n",
      "0.9351595\n",
      "[Epoch 8/10] [Batch 785/1081] [D loss: 0.060488] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.365982] time: 1:22:54.605003\n",
      "(10, 128, 128, 3)\n",
      "0.9454997\n",
      "[Epoch 8/10] [Batch 786/1081] [D loss: 0.056567] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.370368] time: 1:22:55.239935\n",
      "(10, 128, 128, 3)\n",
      "0.90675896\n",
      "[Epoch 8/10] [Batch 787/1081] [D loss: 0.055840] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.270938] time: 1:22:55.917505\n",
      "(10, 128, 128, 3)\n",
      "0.9013583\n",
      "[Epoch 8/10] [Batch 788/1081] [D loss: 0.055188] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.347745] time: 1:22:56.564132\n",
      "(10, 128, 128, 3)\n",
      "0.95283383\n",
      "[Epoch 8/10] [Batch 789/1081] [D loss: 0.055082] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.211445] time: 1:22:57.294469\n",
      "(10, 128, 128, 3)\n",
      "0.9355158\n",
      "[Epoch 8/10] [Batch 790/1081] [D loss: 0.054250] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.359951] time: 1:22:57.982406\n",
      "(10, 128, 128, 3)\n",
      "0.9296507\n",
      "[Epoch 8/10] [Batch 791/1081] [D loss: 0.055139] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.940182] time: 1:22:58.682988\n",
      "(10, 128, 128, 3)\n",
      "0.9419491\n",
      "[Epoch 8/10] [Batch 792/1081] [D loss: 0.054360] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.577683] time: 1:22:59.310765\n",
      "(10, 128, 128, 3)\n",
      "0.9146429\n",
      "[Epoch 8/10] [Batch 793/1081] [D loss: 0.062794] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.626472] time: 1:22:59.956388\n",
      "(10, 128, 128, 3)\n",
      "0.96550703\n",
      "[Epoch 8/10] [Batch 794/1081] [D loss: 0.054225] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.902919] time: 1:23:00.588687\n",
      "(10, 128, 128, 3)\n",
      "0.888639\n",
      "[Epoch 8/10] [Batch 795/1081] [D loss: 0.056085] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.887726] time: 1:23:01.221796\n",
      "(10, 128, 128, 3)\n",
      "0.90977836\n",
      "[Epoch 8/10] [Batch 796/1081] [D loss: 0.055266] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.534072] time: 1:23:01.900521\n",
      "(10, 128, 128, 3)\n",
      "0.89200515\n",
      "[Epoch 8/10] [Batch 797/1081] [D loss: 0.054172] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.443416] time: 1:23:02.532946\n",
      "(10, 128, 128, 3)\n",
      "0.8933546\n",
      "[Epoch 8/10] [Batch 798/1081] [D loss: 0.054613] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.209934] time: 1:23:03.244146\n",
      "(10, 128, 128, 3)\n",
      "0.9276846\n",
      "[Epoch 8/10] [Batch 799/1081] [D loss: 0.053983] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.397651] time: 1:23:03.939006\n",
      "(10, 128, 128, 3)\n",
      "0.9473893\n",
      "[Epoch 8/10] [Batch 800/1081] [D loss: 0.053455] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.649875] time: 1:23:04.636453\n",
      "(10, 128, 128, 3)\n",
      "0.92231375\n",
      "[Epoch 8/10] [Batch 801/1081] [D loss: 0.054185] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.970127] time: 1:23:05.234570\n",
      "(10, 128, 128, 3)\n",
      "0.91303617\n",
      "[Epoch 8/10] [Batch 802/1081] [D loss: 0.052975] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.536274] time: 1:23:05.883604\n",
      "(10, 128, 128, 3)\n",
      "0.9234262\n",
      "[Epoch 8/10] [Batch 803/1081] [D loss: 0.053174] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.857118] time: 1:23:06.543954\n",
      "(10, 128, 128, 3)\n",
      "0.92049867\n",
      "[Epoch 8/10] [Batch 804/1081] [D loss: 0.052601] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.903031] time: 1:23:07.184753\n",
      "(10, 128, 128, 3)\n",
      "0.9200649\n",
      "[Epoch 8/10] [Batch 805/1081] [D loss: 0.052452] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.869737] time: 1:23:07.814418\n",
      "(10, 128, 128, 3)\n",
      "0.9162969\n",
      "[Epoch 8/10] [Batch 806/1081] [D loss: 0.053208] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.906166] time: 1:23:08.429550\n",
      "(10, 128, 128, 3)\n",
      "0.8627898\n",
      "[Epoch 8/10] [Batch 807/1081] [D loss: 0.053041] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.180659] time: 1:23:09.084651\n",
      "(10, 128, 128, 3)\n",
      "0.94542766\n",
      "[Epoch 8/10] [Batch 808/1081] [D loss: 0.052766] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.144366] time: 1:23:09.752452\n",
      "(10, 128, 128, 3)\n",
      "0.9150854\n",
      "[Epoch 8/10] [Batch 809/1081] [D loss: 0.052818] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.995238] time: 1:23:10.402689\n",
      "(10, 128, 128, 3)\n",
      "0.95740074\n",
      "[Epoch 8/10] [Batch 810/1081] [D loss: 0.051860] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.504908] time: 1:23:11.049523\n",
      "(10, 128, 128, 3)\n",
      "0.9321954\n",
      "[Epoch 8/10] [Batch 811/1081] [D loss: 0.051807] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.642252] time: 1:23:11.696605\n",
      "(10, 128, 128, 3)\n",
      "0.9070923\n",
      "[Epoch 8/10] [Batch 812/1081] [D loss: 0.051540] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.858619] time: 1:23:12.346870\n",
      "(10, 128, 128, 3)\n",
      "0.90200204\n",
      "[Epoch 8/10] [Batch 813/1081] [D loss: 0.051977] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.133429] time: 1:23:13.022118\n",
      "(10, 128, 128, 3)\n",
      "0.88927907\n",
      "[Epoch 8/10] [Batch 814/1081] [D loss: 0.051455] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.491931] time: 1:23:13.662584\n",
      "(10, 128, 128, 3)\n",
      "0.9396627\n",
      "[Epoch 8/10] [Batch 815/1081] [D loss: 0.051952] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.535145] time: 1:23:14.364707\n",
      "(10, 128, 128, 3)\n",
      "0.9138859\n",
      "[Epoch 8/10] [Batch 816/1081] [D loss: 0.051285] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.976221] time: 1:23:15.002698\n",
      "(10, 128, 128, 3)\n",
      "0.889092\n",
      "[Epoch 8/10] [Batch 817/1081] [D loss: 0.051559] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.770835] time: 1:23:15.672018\n",
      "(10, 128, 128, 3)\n",
      "0.91333884\n",
      "[Epoch 8/10] [Batch 818/1081] [D loss: 0.089530] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.185059] time: 1:23:16.343385\n",
      "(10, 128, 128, 3)\n",
      "0.8922582\n",
      "[Epoch 8/10] [Batch 819/1081] [D loss: 0.051919] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.585606] time: 1:23:16.978159\n",
      "(10, 128, 128, 3)\n",
      "0.9176457\n",
      "[Epoch 8/10] [Batch 820/1081] [D loss: 0.051599] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.623401] time: 1:23:17.620841\n",
      "(10, 128, 128, 3)\n",
      "0.8515393\n",
      "[Epoch 8/10] [Batch 821/1081] [D loss: 0.052856] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.049720] time: 1:23:18.273905\n",
      "(10, 128, 128, 3)\n",
      "0.95709544\n",
      "[Epoch 8/10] [Batch 822/1081] [D loss: 0.051374] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.413024] time: 1:23:18.899006\n",
      "(10, 128, 128, 3)\n",
      "0.910351\n",
      "[Epoch 8/10] [Batch 823/1081] [D loss: 0.052150] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.245955] time: 1:23:19.528779\n",
      "(10, 128, 128, 3)\n",
      "0.88101894\n",
      "[Epoch 8/10] [Batch 824/1081] [D loss: 0.052314] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.599578] time: 1:23:20.183797\n",
      "(10, 128, 128, 3)\n",
      "0.9764063\n",
      "[Epoch 8/10] [Batch 825/1081] [D loss: 0.050706] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.256672] time: 1:23:20.905782\n",
      "(10, 128, 128, 3)\n",
      "0.9041286\n",
      "[Epoch 8/10] [Batch 826/1081] [D loss: 0.051373] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.844798] time: 1:23:21.544742\n",
      "(10, 128, 128, 3)\n",
      "0.8740795\n",
      "[Epoch 8/10] [Batch 827/1081] [D loss: 0.050991] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.031187] time: 1:23:22.186922\n",
      "(10, 128, 128, 3)\n",
      "0.81533116\n",
      "[Epoch 8/10] [Batch 828/1081] [D loss: 0.050195] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.327345] time: 1:23:22.815301\n",
      "(10, 128, 128, 3)\n",
      "0.92534846\n",
      "[Epoch 8/10] [Batch 829/1081] [D loss: 0.050168] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.786373] time: 1:23:23.497531\n",
      "(10, 128, 128, 3)\n",
      "0.88341933\n",
      "[Epoch 8/10] [Batch 830/1081] [D loss: 0.051061] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.237677] time: 1:23:24.206490\n",
      "(10, 128, 128, 3)\n",
      "0.9474184\n",
      "[Epoch 8/10] [Batch 831/1081] [D loss: 0.050002] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.978523] time: 1:23:24.910457\n",
      "(10, 128, 128, 3)\n",
      "0.8866892\n",
      "[Epoch 8/10] [Batch 832/1081] [D loss: 0.049829] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.007332] time: 1:23:25.566448\n",
      "(10, 128, 128, 3)\n",
      "0.92380434\n",
      "[Epoch 8/10] [Batch 833/1081] [D loss: 0.050108] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.788136] time: 1:23:26.278494\n",
      "(10, 128, 128, 3)\n",
      "0.9766128\n",
      "[Epoch 8/10] [Batch 834/1081] [D loss: 0.049935] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.182605] time: 1:23:26.973588\n",
      "(10, 128, 128, 3)\n",
      "0.87674826\n",
      "[Epoch 8/10] [Batch 835/1081] [D loss: 0.049754] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.031677] time: 1:23:27.632211\n",
      "(10, 128, 128, 3)\n",
      "0.90648204\n",
      "[Epoch 8/10] [Batch 836/1081] [D loss: 0.050021] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.384552] time: 1:23:28.233078\n",
      "(10, 128, 128, 3)\n",
      "0.9093519\n",
      "[Epoch 8/10] [Batch 837/1081] [D loss: 0.049460] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.247675] time: 1:23:28.840039\n",
      "(10, 128, 128, 3)\n",
      "0.89679605\n",
      "[Epoch 8/10] [Batch 838/1081] [D loss: 0.049770] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.777737] time: 1:23:29.442525\n",
      "(10, 128, 128, 3)\n",
      "0.87882966\n",
      "[Epoch 8/10] [Batch 839/1081] [D loss: 0.049835] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.786183] time: 1:23:30.066471\n",
      "(10, 128, 128, 3)\n",
      "0.8825879\n",
      "[Epoch 8/10] [Batch 840/1081] [D loss: 0.049701] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.251177] time: 1:23:30.781549\n",
      "(10, 128, 128, 3)\n",
      "0.8914161\n",
      "[Epoch 8/10] [Batch 841/1081] [D loss: 0.049669] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.137044] time: 1:23:31.485562\n",
      "(10, 128, 128, 3)\n",
      "0.95117635\n",
      "[Epoch 8/10] [Batch 842/1081] [D loss: 0.050114] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.682121] time: 1:23:32.135990\n",
      "(10, 128, 128, 3)\n",
      "0.9082956\n",
      "[Epoch 8/10] [Batch 843/1081] [D loss: 0.049041] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.053791] time: 1:23:32.832809\n",
      "(10, 128, 128, 3)\n",
      "0.94135207\n",
      "[Epoch 8/10] [Batch 844/1081] [D loss: 0.049034] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.056911] time: 1:23:33.489731\n",
      "(10, 128, 128, 3)\n",
      "0.9374855\n",
      "[Epoch 8/10] [Batch 845/1081] [D loss: 0.049283] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.353258] time: 1:23:34.184427\n",
      "(10, 128, 128, 3)\n",
      "0.9532588\n",
      "[Epoch 8/10] [Batch 846/1081] [D loss: 0.048913] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.018541] time: 1:23:34.852957\n",
      "(10, 128, 128, 3)\n",
      "0.91854334\n",
      "[Epoch 8/10] [Batch 847/1081] [D loss: 0.048700] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.062051] time: 1:23:35.494549\n",
      "(10, 128, 128, 3)\n",
      "0.94285107\n",
      "[Epoch 8/10] [Batch 848/1081] [D loss: 0.053635] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.383706] time: 1:23:36.121490\n",
      "(10, 128, 128, 3)\n",
      "0.8667571\n",
      "[Epoch 8/10] [Batch 849/1081] [D loss: 0.048568] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.953319] time: 1:23:36.726960\n",
      "(10, 128, 128, 3)\n",
      "0.94258434\n",
      "[Epoch 8/10] [Batch 850/1081] [D loss: 0.049065] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.559888] time: 1:23:37.434689\n",
      "(10, 128, 128, 3)\n",
      "0.93944687\n",
      "[Epoch 8/10] [Batch 851/1081] [D loss: 0.048727] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.366070] time: 1:23:38.121970\n",
      "(10, 128, 128, 3)\n",
      "0.90135694\n",
      "[Epoch 8/10] [Batch 852/1081] [D loss: 0.048185] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.120962] time: 1:23:38.712731\n",
      "(10, 128, 128, 3)\n",
      "0.90575975\n",
      "[Epoch 8/10] [Batch 853/1081] [D loss: 0.049546] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.642593] time: 1:23:39.344113\n",
      "(10, 128, 128, 3)\n",
      "0.9409957\n",
      "[Epoch 8/10] [Batch 854/1081] [D loss: 0.048304] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.368449] time: 1:23:39.980833\n",
      "(10, 128, 128, 3)\n",
      "0.9179287\n",
      "[Epoch 8/10] [Batch 855/1081] [D loss: 0.054430] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.959877] time: 1:23:40.743451\n",
      "(10, 128, 128, 3)\n",
      "0.9153018\n",
      "[Epoch 8/10] [Batch 856/1081] [D loss: 0.048027] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.947813] time: 1:23:41.390327\n",
      "(10, 128, 128, 3)\n",
      "0.9259829\n",
      "[Epoch 8/10] [Batch 857/1081] [D loss: 0.049455] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.313140] time: 1:23:41.991678\n",
      "(10, 128, 128, 3)\n",
      "0.89502317\n",
      "[Epoch 8/10] [Batch 858/1081] [D loss: 0.048622] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.298000] time: 1:23:42.653127\n",
      "(10, 128, 128, 3)\n",
      "0.85065645\n",
      "[Epoch 8/10] [Batch 859/1081] [D loss: 0.049784] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.820184] time: 1:23:43.298377\n",
      "(10, 128, 128, 3)\n",
      "0.92835623\n",
      "[Epoch 8/10] [Batch 860/1081] [D loss: 0.048095] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.308969] time: 1:23:43.935418\n",
      "(10, 128, 128, 3)\n",
      "0.90756994\n",
      "[Epoch 8/10] [Batch 861/1081] [D loss: 0.048479] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.057837] time: 1:23:44.595398\n",
      "(10, 128, 128, 3)\n",
      "0.8813879\n",
      "[Epoch 8/10] [Batch 862/1081] [D loss: 0.048138] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.375296] time: 1:23:45.265538\n",
      "(10, 128, 128, 3)\n",
      "0.9095645\n",
      "[Epoch 8/10] [Batch 863/1081] [D loss: 0.048775] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.426487] time: 1:23:45.921656\n",
      "(10, 128, 128, 3)\n",
      "0.94129366\n",
      "[Epoch 8/10] [Batch 864/1081] [D loss: 0.048360] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.697093] time: 1:23:46.584494\n",
      "(10, 128, 128, 3)\n",
      "0.8964215\n",
      "[Epoch 8/10] [Batch 865/1081] [D loss: 0.048122] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.134436] time: 1:23:47.259446\n",
      "(10, 128, 128, 3)\n",
      "0.8977595\n",
      "[Epoch 8/10] [Batch 866/1081] [D loss: 0.047582] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.426455] time: 1:23:47.872869\n",
      "(10, 128, 128, 3)\n",
      "0.9345372\n",
      "[Epoch 8/10] [Batch 867/1081] [D loss: 0.048501] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.879174] time: 1:23:48.527519\n",
      "(10, 128, 128, 3)\n",
      "0.87989146\n",
      "[Epoch 8/10] [Batch 868/1081] [D loss: 0.047237] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.467764] time: 1:23:49.130551\n",
      "(10, 128, 128, 3)\n",
      "0.91670924\n",
      "[Epoch 8/10] [Batch 869/1081] [D loss: 0.047737] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.214395] time: 1:23:49.771916\n",
      "(10, 128, 128, 3)\n",
      "0.89081305\n",
      "[Epoch 8/10] [Batch 870/1081] [D loss: 0.047211] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.677834] time: 1:23:50.437690\n",
      "(10, 128, 128, 3)\n",
      "0.9021233\n",
      "[Epoch 8/10] [Batch 871/1081] [D loss: 0.048215] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.662177] time: 1:23:51.128564\n",
      "(10, 128, 128, 3)\n",
      "0.94915867\n",
      "[Epoch 8/10] [Batch 872/1081] [D loss: 0.047983] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.645585] time: 1:23:51.793822\n",
      "(10, 128, 128, 3)\n",
      "0.9062266\n",
      "[Epoch 8/10] [Batch 873/1081] [D loss: 0.048162] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.373743] time: 1:23:52.467924\n",
      "(10, 128, 128, 3)\n",
      "0.9376712\n",
      "[Epoch 8/10] [Batch 874/1081] [D loss: 0.048390] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.221510] time: 1:23:53.091102\n",
      "(10, 128, 128, 3)\n",
      "0.9084845\n",
      "[Epoch 8/10] [Batch 875/1081] [D loss: 0.047856] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.267203] time: 1:23:53.698402\n",
      "(10, 128, 128, 3)\n",
      "0.854148\n",
      "[Epoch 8/10] [Batch 876/1081] [D loss: 0.046723] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.778706] time: 1:23:54.378928\n",
      "(10, 128, 128, 3)\n",
      "0.898951\n",
      "[Epoch 8/10] [Batch 877/1081] [D loss: 0.047531] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.347891] time: 1:23:54.998689\n",
      "(10, 128, 128, 3)\n",
      "0.88795227\n",
      "[Epoch 8/10] [Batch 878/1081] [D loss: 0.046930] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.718528] time: 1:23:55.666436\n",
      "(10, 128, 128, 3)\n",
      "0.86657137\n",
      "[Epoch 8/10] [Batch 879/1081] [D loss: 0.046517] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.709651] time: 1:23:56.353943\n",
      "(10, 128, 128, 3)\n",
      "0.9452498\n",
      "[Epoch 8/10] [Batch 880/1081] [D loss: 0.047137] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.179858] time: 1:23:57.026037\n",
      "(10, 128, 128, 3)\n",
      "0.92533493\n",
      "[Epoch 8/10] [Batch 881/1081] [D loss: 0.046581] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.854047] time: 1:23:57.709473\n",
      "(10, 128, 128, 3)\n",
      "0.8873632\n",
      "[Epoch 8/10] [Batch 882/1081] [D loss: 0.046157] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.895077] time: 1:23:58.330475\n",
      "(10, 128, 128, 3)\n",
      "0.84274155\n",
      "[Epoch 8/10] [Batch 883/1081] [D loss: 0.047011] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.120307] time: 1:23:58.994788\n",
      "(10, 128, 128, 3)\n",
      "0.9067109\n",
      "[Epoch 8/10] [Batch 884/1081] [D loss: 0.046067] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.422683] time: 1:23:59.681733\n",
      "(10, 128, 128, 3)\n",
      "0.92552406\n",
      "[Epoch 8/10] [Batch 885/1081] [D loss: 0.046084] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.567292] time: 1:24:00.348604\n",
      "(10, 128, 128, 3)\n",
      "0.929641\n",
      "[Epoch 8/10] [Batch 886/1081] [D loss: 0.046054] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.789062] time: 1:24:01.044327\n",
      "(10, 128, 128, 3)\n",
      "0.9083591\n",
      "[Epoch 8/10] [Batch 887/1081] [D loss: 0.047474] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.137565] time: 1:24:01.707784\n",
      "(10, 128, 128, 3)\n",
      "0.90536284\n",
      "[Epoch 8/10] [Batch 888/1081] [D loss: 0.046192] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.326347] time: 1:24:02.344867\n",
      "(10, 128, 128, 3)\n",
      "0.9369082\n",
      "[Epoch 8/10] [Batch 889/1081] [D loss: 0.047683] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.530801] time: 1:24:03.002284\n",
      "(10, 128, 128, 3)\n",
      "0.9568588\n",
      "[Epoch 8/10] [Batch 890/1081] [D loss: 0.046162] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.058577] time: 1:24:03.674611\n",
      "(10, 128, 128, 3)\n",
      "0.90540504\n",
      "[Epoch 8/10] [Batch 891/1081] [D loss: 0.045870] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.969983] time: 1:24:04.372845\n",
      "(10, 128, 128, 3)\n",
      "0.9520046\n",
      "[Epoch 8/10] [Batch 892/1081] [D loss: 0.046234] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.526657] time: 1:24:05.020139\n",
      "(10, 128, 128, 3)\n",
      "0.93484956\n",
      "[Epoch 8/10] [Batch 893/1081] [D loss: 0.045731] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.283281] time: 1:24:05.659469\n",
      "(10, 128, 128, 3)\n",
      "0.90840226\n",
      "[Epoch 8/10] [Batch 894/1081] [D loss: 0.045806] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.442899] time: 1:24:06.280974\n",
      "(10, 128, 128, 3)\n",
      "0.870502\n",
      "[Epoch 8/10] [Batch 895/1081] [D loss: 0.045954] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.874275] time: 1:24:06.991315\n",
      "(10, 128, 128, 3)\n",
      "0.910645\n",
      "[Epoch 8/10] [Batch 896/1081] [D loss: 0.045511] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.153129] time: 1:24:07.666484\n",
      "(10, 128, 128, 3)\n",
      "0.84106916\n",
      "[Epoch 8/10] [Batch 897/1081] [D loss: 0.045549] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.043825] time: 1:24:08.281574\n",
      "(10, 128, 128, 3)\n",
      "0.95751923\n",
      "[Epoch 8/10] [Batch 898/1081] [D loss: 0.046383] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.171868] time: 1:24:08.905919\n",
      "(10, 128, 128, 3)\n",
      "0.90921956\n",
      "[Epoch 8/10] [Batch 899/1081] [D loss: 0.045363] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.108604] time: 1:24:09.582039\n",
      "(10, 128, 128, 3)\n",
      "0.93713707\n",
      "[Epoch 8/10] [Batch 900/1081] [D loss: 0.045103] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.034736] time: 1:24:10.223315\n",
      "(10, 128, 128, 3)\n",
      "0.9467099\n",
      "[Epoch 8/10] [Batch 901/1081] [D loss: 0.045072] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.205377] time: 1:24:10.856780\n",
      "(10, 128, 128, 3)\n",
      "0.9127498\n",
      "[Epoch 8/10] [Batch 902/1081] [D loss: 0.049354] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.988624] time: 1:24:11.467763\n",
      "(10, 128, 128, 3)\n",
      "0.87958115\n",
      "[Epoch 8/10] [Batch 903/1081] [D loss: 0.047274] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.303276] time: 1:24:12.127271\n",
      "(10, 128, 128, 3)\n",
      "0.8935053\n",
      "[Epoch 8/10] [Batch 904/1081] [D loss: 0.045939] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.105694] time: 1:24:12.797981\n",
      "(10, 128, 128, 3)\n",
      "0.944108\n",
      "[Epoch 8/10] [Batch 905/1081] [D loss: 0.045765] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.813735] time: 1:24:13.462401\n",
      "(10, 128, 128, 3)\n",
      "0.9038207\n",
      "[Epoch 8/10] [Batch 906/1081] [D loss: 0.045437] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.518776] time: 1:24:14.103884\n",
      "(10, 128, 128, 3)\n",
      "0.87281156\n",
      "[Epoch 8/10] [Batch 907/1081] [D loss: 0.046163] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.533468] time: 1:24:14.807039\n",
      "(10, 128, 128, 3)\n",
      "0.9214475\n",
      "[Epoch 8/10] [Batch 908/1081] [D loss: 0.045032] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.188220] time: 1:24:15.457679\n",
      "(10, 128, 128, 3)\n",
      "0.9114749\n",
      "[Epoch 8/10] [Batch 909/1081] [D loss: 0.045451] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.185702] time: 1:24:16.114016\n",
      "(10, 128, 128, 3)\n",
      "0.880928\n",
      "[Epoch 8/10] [Batch 910/1081] [D loss: 0.044996] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.640708] time: 1:24:16.809166\n",
      "(10, 128, 128, 3)\n",
      "0.89508796\n",
      "[Epoch 8/10] [Batch 911/1081] [D loss: 0.045130] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.361722] time: 1:24:17.562768\n",
      "(10, 128, 128, 3)\n",
      "0.9228882\n",
      "[Epoch 8/10] [Batch 912/1081] [D loss: 0.044820] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.177923] time: 1:24:18.219733\n",
      "(10, 128, 128, 3)\n",
      "0.9372778\n",
      "[Epoch 8/10] [Batch 913/1081] [D loss: 0.045712] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.748836] time: 1:24:18.877625\n",
      "(10, 128, 128, 3)\n",
      "0.8877129\n",
      "[Epoch 8/10] [Batch 914/1081] [D loss: 0.044588] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.499996] time: 1:24:19.498148\n",
      "(10, 128, 128, 3)\n",
      "0.9389921\n",
      "[Epoch 8/10] [Batch 915/1081] [D loss: 0.045056] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.419647] time: 1:24:20.155833\n",
      "(10, 128, 128, 3)\n",
      "0.9414198\n",
      "[Epoch 8/10] [Batch 916/1081] [D loss: 0.044546] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.897246] time: 1:24:20.774783\n",
      "(10, 128, 128, 3)\n",
      "0.91618377\n",
      "[Epoch 8/10] [Batch 917/1081] [D loss: 0.044884] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.818702] time: 1:24:21.446670\n",
      "(10, 128, 128, 3)\n",
      "0.8502988\n",
      "[Epoch 8/10] [Batch 918/1081] [D loss: 0.044684] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.066774] time: 1:24:22.114888\n",
      "(10, 128, 128, 3)\n",
      "0.9353457\n",
      "[Epoch 8/10] [Batch 919/1081] [D loss: 0.044205] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.460997] time: 1:24:22.792780\n",
      "(10, 128, 128, 3)\n",
      "0.9245937\n",
      "[Epoch 8/10] [Batch 920/1081] [D loss: 0.727416] [D acc: 0.05 (0.00 real, 0.10 fake)] [G loss: 22.424215] time: 1:24:23.466442\n",
      "(10, 128, 128, 3)\n",
      "0.91649574\n",
      "[Epoch 8/10] [Batch 921/1081] [D loss: 0.468588] [D acc: 0.10 (0.20 real, 0.00 fake)] [G loss: 5.671901] time: 1:24:24.147823\n",
      "(10, 128, 128, 3)\n",
      "0.9088247\n",
      "[Epoch 8/10] [Batch 922/1081] [D loss: 0.441861] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 3.231219] time: 1:24:24.765423\n",
      "(10, 128, 128, 3)\n",
      "0.8845704\n",
      "[Epoch 8/10] [Batch 923/1081] [D loss: 0.360889] [D acc: 0.50 (0.10 real, 0.90 fake)] [G loss: 5.187940] time: 1:24:25.430473\n",
      "(10, 128, 128, 3)\n",
      "0.85219795\n",
      "[Epoch 8/10] [Batch 924/1081] [D loss: 0.557431] [D acc: 0.25 (0.00 real, 0.50 fake)] [G loss: 3.612564] time: 1:24:26.082864\n",
      "(10, 128, 128, 3)\n",
      "0.9359813\n",
      "[Epoch 8/10] [Batch 925/1081] [D loss: 0.426677] [D acc: 0.15 (0.30 real, 0.00 fake)] [G loss: 4.551230] time: 1:24:26.728150\n",
      "(10, 128, 128, 3)\n",
      "0.8659933\n",
      "[Epoch 8/10] [Batch 926/1081] [D loss: 0.412370] [D acc: 0.25 (0.50 real, 0.00 fake)] [G loss: 4.325161] time: 1:24:27.402410\n",
      "(10, 128, 128, 3)\n",
      "0.9370427\n",
      "[Epoch 8/10] [Batch 927/1081] [D loss: 0.419332] [D acc: 0.20 (0.30 real, 0.10 fake)] [G loss: 3.884649] time: 1:24:28.093609\n",
      "(10, 128, 128, 3)\n",
      "0.89843917\n",
      "[Epoch 8/10] [Batch 928/1081] [D loss: 0.382507] [D acc: 0.35 (0.00 real, 0.70 fake)] [G loss: 5.656862] time: 1:24:28.741807\n",
      "(10, 128, 128, 3)\n",
      "0.96378404\n",
      "[Epoch 8/10] [Batch 929/1081] [D loss: 0.396152] [D acc: 0.20 (0.40 real, 0.00 fake)] [G loss: 3.607730] time: 1:24:29.448758\n",
      "(10, 128, 128, 3)\n",
      "0.9337389\n",
      "[Epoch 8/10] [Batch 930/1081] [D loss: 0.375834] [D acc: 0.15 (0.10 real, 0.20 fake)] [G loss: 4.067484] time: 1:24:30.177575\n",
      "(10, 128, 128, 3)\n",
      "0.926826\n",
      "[Epoch 8/10] [Batch 931/1081] [D loss: 0.373884] [D acc: 0.20 (0.10 real, 0.30 fake)] [G loss: 3.562355] time: 1:24:30.826503\n",
      "(10, 128, 128, 3)\n",
      "0.8938883\n",
      "[Epoch 8/10] [Batch 932/1081] [D loss: 0.370756] [D acc: 0.40 (0.40 real, 0.40 fake)] [G loss: 3.654682] time: 1:24:31.437144\n",
      "(10, 128, 128, 3)\n",
      "0.9441313\n",
      "[Epoch 8/10] [Batch 933/1081] [D loss: 0.360128] [D acc: 0.30 (0.20 real, 0.40 fake)] [G loss: 5.749872] time: 1:24:32.118424\n",
      "(10, 128, 128, 3)\n",
      "0.87882596\n",
      "[Epoch 8/10] [Batch 934/1081] [D loss: 0.356304] [D acc: 0.20 (0.10 real, 0.30 fake)] [G loss: 4.059271] time: 1:24:32.730019\n",
      "(10, 128, 128, 3)\n",
      "0.879976\n",
      "[Epoch 8/10] [Batch 935/1081] [D loss: 0.375870] [D acc: 0.25 (0.20 real, 0.30 fake)] [G loss: 4.306526] time: 1:24:33.413193\n",
      "(10, 128, 128, 3)\n",
      "0.94081396\n",
      "[Epoch 8/10] [Batch 936/1081] [D loss: 0.332034] [D acc: 0.40 (0.60 real, 0.20 fake)] [G loss: 4.987860] time: 1:24:34.081309\n",
      "(10, 128, 128, 3)\n",
      "0.93068045\n",
      "[Epoch 8/10] [Batch 937/1081] [D loss: 0.294923] [D acc: 0.60 (0.20 real, 1.00 fake)] [G loss: 3.292746] time: 1:24:34.734361\n",
      "(10, 128, 128, 3)\n",
      "0.95208484\n",
      "[Epoch 8/10] [Batch 938/1081] [D loss: 0.279431] [D acc: 0.70 (0.40 real, 1.00 fake)] [G loss: 3.968342] time: 1:24:35.300452\n",
      "(10, 128, 128, 3)\n",
      "0.9090468\n",
      "[Epoch 8/10] [Batch 939/1081] [D loss: 0.284551] [D acc: 0.60 (0.20 real, 1.00 fake)] [G loss: 4.770411] time: 1:24:35.968177\n",
      "(10, 128, 128, 3)\n",
      "0.9019997\n",
      "[Epoch 8/10] [Batch 940/1081] [D loss: 0.263745] [D acc: 0.80 (0.60 real, 1.00 fake)] [G loss: 3.999414] time: 1:24:36.612341\n",
      "(10, 128, 128, 3)\n",
      "0.9581128\n",
      "[Epoch 8/10] [Batch 941/1081] [D loss: 0.138137] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.259940] time: 1:24:37.286513\n",
      "(10, 128, 128, 3)\n",
      "0.9302394\n",
      "[Epoch 8/10] [Batch 942/1081] [D loss: 0.132181] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.496099] time: 1:24:37.934593\n",
      "(10, 128, 128, 3)\n",
      "0.9053588\n",
      "[Epoch 8/10] [Batch 943/1081] [D loss: 0.154477] [D acc: 0.90 (1.00 real, 0.80 fake)] [G loss: 4.645200] time: 1:24:38.492756\n",
      "(10, 128, 128, 3)\n",
      "0.92283344\n",
      "[Epoch 8/10] [Batch 944/1081] [D loss: 0.124949] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.560626] time: 1:24:39.092391\n",
      "(10, 128, 128, 3)\n",
      "0.9318244\n",
      "[Epoch 8/10] [Batch 945/1081] [D loss: 0.136300] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.144839] time: 1:24:39.724797\n",
      "(10, 128, 128, 3)\n",
      "0.9105256\n",
      "[Epoch 8/10] [Batch 946/1081] [D loss: 0.232145] [D acc: 0.65 (1.00 real, 0.30 fake)] [G loss: 4.157848] time: 1:24:40.377792\n",
      "(10, 128, 128, 3)\n",
      "0.8785472\n",
      "[Epoch 8/10] [Batch 947/1081] [D loss: 0.123720] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 3.721270] time: 1:24:41.093784\n",
      "(10, 128, 128, 3)\n",
      "0.9078152\n",
      "[Epoch 8/10] [Batch 948/1081] [D loss: 0.204837] [D acc: 0.75 (0.50 real, 1.00 fake)] [G loss: 3.753879] time: 1:24:41.775003\n",
      "(10, 128, 128, 3)\n",
      "0.90712243\n",
      "[Epoch 8/10] [Batch 949/1081] [D loss: 0.085984] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.960939] time: 1:24:42.465432\n",
      "(10, 128, 128, 3)\n",
      "0.88684756\n",
      "[Epoch 8/10] [Batch 950/1081] [D loss: 0.081075] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.078689] time: 1:24:43.077491\n",
      "(10, 128, 128, 3)\n",
      "0.9115632\n",
      "[Epoch 8/10] [Batch 951/1081] [D loss: 0.086130] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.482164] time: 1:24:43.668689\n",
      "(10, 128, 128, 3)\n",
      "0.9156273\n",
      "[Epoch 8/10] [Batch 952/1081] [D loss: 0.086981] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.597156] time: 1:24:44.265543\n",
      "(10, 128, 128, 3)\n",
      "0.89735556\n",
      "[Epoch 8/10] [Batch 953/1081] [D loss: 0.100044] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.767785] time: 1:24:44.955510\n",
      "(10, 128, 128, 3)\n",
      "0.936285\n",
      "[Epoch 8/10] [Batch 954/1081] [D loss: 0.088767] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.467103] time: 1:24:45.589046\n",
      "(10, 128, 128, 3)\n",
      "0.90161705\n",
      "[Epoch 8/10] [Batch 955/1081] [D loss: 0.081770] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.047011] time: 1:24:46.238247\n",
      "(10, 128, 128, 3)\n",
      "0.9165549\n",
      "[Epoch 8/10] [Batch 956/1081] [D loss: 0.119472] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.176267] time: 1:24:46.831926\n",
      "(10, 128, 128, 3)\n",
      "0.96479875\n",
      "[Epoch 8/10] [Batch 957/1081] [D loss: 0.113524] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.179815] time: 1:24:47.471735\n",
      "(10, 128, 128, 3)\n",
      "0.93380183\n",
      "[Epoch 8/10] [Batch 958/1081] [D loss: 0.084236] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.996422] time: 1:24:48.145400\n",
      "(10, 128, 128, 3)\n",
      "0.87448853\n",
      "[Epoch 8/10] [Batch 959/1081] [D loss: 0.083138] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.348132] time: 1:24:48.771987\n",
      "(10, 128, 128, 3)\n",
      "0.919951\n",
      "[Epoch 8/10] [Batch 960/1081] [D loss: 0.077849] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.656823] time: 1:24:49.438998\n",
      "(10, 128, 128, 3)\n",
      "0.89988965\n",
      "[Epoch 8/10] [Batch 961/1081] [D loss: 0.084893] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.766898] time: 1:24:50.113814\n",
      "(10, 128, 128, 3)\n",
      "0.8678984\n",
      "[Epoch 8/10] [Batch 962/1081] [D loss: 0.084158] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.860881] time: 1:24:50.720557\n",
      "(10, 128, 128, 3)\n",
      "0.90875036\n",
      "[Epoch 8/10] [Batch 963/1081] [D loss: 0.076469] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.197550] time: 1:24:51.419267\n",
      "(10, 128, 128, 3)\n",
      "0.904156\n",
      "[Epoch 8/10] [Batch 964/1081] [D loss: 0.073833] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.784210] time: 1:24:52.119548\n",
      "(10, 128, 128, 3)\n",
      "0.9360381\n",
      "[Epoch 8/10] [Batch 965/1081] [D loss: 0.073798] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.649465] time: 1:24:52.810471\n",
      "(10, 128, 128, 3)\n",
      "0.9051563\n",
      "[Epoch 8/10] [Batch 966/1081] [D loss: 0.204123] [D acc: 0.85 (1.00 real, 0.70 fake)] [G loss: 2.874192] time: 1:24:53.404525\n",
      "(10, 128, 128, 3)\n",
      "0.89890546\n",
      "[Epoch 8/10] [Batch 967/1081] [D loss: 0.077301] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.482563] time: 1:24:54.027131\n",
      "(10, 128, 128, 3)\n",
      "0.9709386\n",
      "[Epoch 8/10] [Batch 968/1081] [D loss: 0.085290] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.728038] time: 1:24:54.680812\n",
      "(10, 128, 128, 3)\n",
      "0.8774469\n",
      "[Epoch 8/10] [Batch 969/1081] [D loss: 0.089996] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.533655] time: 1:24:55.354179\n",
      "(10, 128, 128, 3)\n",
      "0.9050267\n",
      "[Epoch 8/10] [Batch 970/1081] [D loss: 0.080293] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.215075] time: 1:24:56.007950\n",
      "(10, 128, 128, 3)\n",
      "0.9173038\n",
      "[Epoch 8/10] [Batch 971/1081] [D loss: 0.079577] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.298861] time: 1:24:56.702519\n",
      "(10, 128, 128, 3)\n",
      "0.89315015\n",
      "[Epoch 8/10] [Batch 972/1081] [D loss: 0.077423] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.931237] time: 1:24:57.285103\n",
      "(10, 128, 128, 3)\n",
      "0.9339519\n",
      "[Epoch 8/10] [Batch 973/1081] [D loss: 0.073852] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.127067] time: 1:24:57.919701\n",
      "(10, 128, 128, 3)\n",
      "0.98363876\n",
      "[Epoch 8/10] [Batch 974/1081] [D loss: 0.076278] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.146531] time: 1:24:58.592230\n",
      "(10, 128, 128, 3)\n",
      "0.8898561\n",
      "[Epoch 8/10] [Batch 975/1081] [D loss: 0.075139] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.856919] time: 1:24:59.258716\n",
      "(10, 128, 128, 3)\n",
      "0.90731233\n",
      "[Epoch 8/10] [Batch 976/1081] [D loss: 0.083776] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.431250] time: 1:24:59.937554\n",
      "(10, 128, 128, 3)\n",
      "0.9661796\n",
      "[Epoch 8/10] [Batch 977/1081] [D loss: 0.076809] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.591548] time: 1:25:00.583052\n",
      "(10, 128, 128, 3)\n",
      "0.90327615\n",
      "[Epoch 8/10] [Batch 978/1081] [D loss: 0.080920] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.700856] time: 1:25:01.220124\n",
      "(10, 128, 128, 3)\n",
      "0.8880291\n",
      "[Epoch 8/10] [Batch 979/1081] [D loss: 0.073834] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.752728] time: 1:25:01.837808\n",
      "(10, 128, 128, 3)\n",
      "0.9489393\n",
      "[Epoch 8/10] [Batch 980/1081] [D loss: 0.070382] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.378445] time: 1:25:02.490360\n",
      "(10, 128, 128, 3)\n",
      "0.9144392\n",
      "[Epoch 8/10] [Batch 981/1081] [D loss: 0.069768] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.738767] time: 1:25:03.208080\n",
      "(10, 128, 128, 3)\n",
      "0.89735556\n",
      "[Epoch 8/10] [Batch 982/1081] [D loss: 0.069558] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.136992] time: 1:25:03.900260\n",
      "(10, 128, 128, 3)\n",
      "0.9349006\n",
      "[Epoch 8/10] [Batch 983/1081] [D loss: 0.069291] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.392176] time: 1:25:04.635226\n",
      "(10, 128, 128, 3)\n",
      "0.9503684\n",
      "[Epoch 8/10] [Batch 984/1081] [D loss: 0.068763] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.570380] time: 1:25:05.284295\n",
      "(10, 128, 128, 3)\n",
      "0.91174895\n",
      "[Epoch 8/10] [Batch 985/1081] [D loss: 0.069056] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.800158] time: 1:25:05.923557\n",
      "(10, 128, 128, 3)\n",
      "0.9029381\n",
      "[Epoch 8/10] [Batch 986/1081] [D loss: 0.071498] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.037335] time: 1:25:06.615595\n",
      "(10, 128, 128, 3)\n",
      "0.889525\n",
      "[Epoch 8/10] [Batch 987/1081] [D loss: 0.069472] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.715240] time: 1:25:07.246388\n",
      "(10, 128, 128, 3)\n",
      "0.90069896\n",
      "[Epoch 8/10] [Batch 988/1081] [D loss: 0.073226] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.201649] time: 1:25:07.874883\n",
      "(10, 128, 128, 3)\n",
      "0.9533574\n",
      "[Epoch 8/10] [Batch 989/1081] [D loss: 0.067481] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.913478] time: 1:25:08.502383\n",
      "(10, 128, 128, 3)\n",
      "0.9261992\n",
      "[Epoch 8/10] [Batch 990/1081] [D loss: 0.070360] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.652711] time: 1:25:09.141525\n",
      "(10, 128, 128, 3)\n",
      "0.89096004\n",
      "[Epoch 8/10] [Batch 991/1081] [D loss: 0.066722] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.001704] time: 1:25:09.855806\n",
      "(10, 128, 128, 3)\n",
      "0.90408164\n",
      "[Epoch 8/10] [Batch 992/1081] [D loss: 0.067748] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.660781] time: 1:25:10.477915\n",
      "(10, 128, 128, 3)\n",
      "0.91701335\n",
      "[Epoch 8/10] [Batch 993/1081] [D loss: 0.065811] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.666217] time: 1:25:11.103350\n",
      "(10, 128, 128, 3)\n",
      "0.87862587\n",
      "[Epoch 8/10] [Batch 994/1081] [D loss: 0.068632] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.229764] time: 1:25:11.762741\n",
      "(10, 128, 128, 3)\n",
      "0.9526715\n",
      "[Epoch 8/10] [Batch 995/1081] [D loss: 0.706653] [D acc: 0.15 (0.00 real, 0.30 fake)] [G loss: 2.776188] time: 1:25:12.442561\n",
      "(10, 128, 128, 3)\n",
      "0.9550164\n",
      "[Epoch 8/10] [Batch 996/1081] [D loss: 0.147903] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 3.270659] time: 1:25:13.056017\n",
      "(10, 128, 128, 3)\n",
      "0.9118162\n",
      "[Epoch 8/10] [Batch 997/1081] [D loss: 0.079697] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.118578] time: 1:25:13.723339\n",
      "(10, 128, 128, 3)\n",
      "0.96706724\n",
      "[Epoch 8/10] [Batch 998/1081] [D loss: 0.071600] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.516957] time: 1:25:14.377983\n",
      "(10, 128, 128, 3)\n",
      "0.89427376\n",
      "[Epoch 8/10] [Batch 999/1081] [D loss: 0.081660] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.581155] time: 1:25:15.022419\n",
      "(10, 128, 128, 3)\n",
      "0.9302817\n",
      "[Epoch 8/10] [Batch 1000/1081] [D loss: 0.069814] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.451745] time: 1:25:15.717739\n",
      "(10, 128, 128, 3)\n",
      "0.89996773\n",
      "[Epoch 8/10] [Batch 1001/1081] [D loss: 0.068531] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.565793] time: 1:25:16.409859\n",
      "(10, 128, 128, 3)\n",
      "0.94539523\n",
      "[Epoch 8/10] [Batch 1002/1081] [D loss: 0.068486] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.110812] time: 1:25:17.069748\n",
      "(10, 128, 128, 3)\n",
      "0.9273483\n",
      "[Epoch 8/10] [Batch 1003/1081] [D loss: 0.074887] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.253208] time: 1:25:17.713727\n",
      "(10, 128, 128, 3)\n",
      "0.89198756\n",
      "[Epoch 8/10] [Batch 1004/1081] [D loss: 0.065148] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.140558] time: 1:25:18.375774\n",
      "(10, 128, 128, 3)\n",
      "0.9291857\n",
      "[Epoch 8/10] [Batch 1005/1081] [D loss: 0.065462] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.680841] time: 1:25:19.078932\n",
      "(10, 128, 128, 3)\n",
      "0.93682456\n",
      "[Epoch 8/10] [Batch 1006/1081] [D loss: 0.071759] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.804719] time: 1:25:19.748173\n",
      "(10, 128, 128, 3)\n",
      "0.88654923\n",
      "[Epoch 8/10] [Batch 1007/1081] [D loss: 0.067786] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.557065] time: 1:25:20.421384\n",
      "(10, 128, 128, 3)\n",
      "0.92722553\n",
      "[Epoch 8/10] [Batch 1008/1081] [D loss: 0.064582] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.602006] time: 1:25:21.055991\n",
      "(10, 128, 128, 3)\n",
      "0.86487573\n",
      "[Epoch 8/10] [Batch 1009/1081] [D loss: 0.069038] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.615255] time: 1:25:21.709028\n",
      "(10, 128, 128, 3)\n",
      "0.91771525\n",
      "[Epoch 8/10] [Batch 1010/1081] [D loss: 0.132399] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.870792] time: 1:25:22.382466\n",
      "(10, 128, 128, 3)\n",
      "0.9374135\n",
      "[Epoch 8/10] [Batch 1011/1081] [D loss: 0.077909] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.515572] time: 1:25:23.041782\n",
      "(10, 128, 128, 3)\n",
      "0.89888144\n",
      "[Epoch 8/10] [Batch 1012/1081] [D loss: 0.072788] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.296655] time: 1:25:23.660035\n",
      "(10, 128, 128, 3)\n",
      "0.9132679\n",
      "[Epoch 8/10] [Batch 1013/1081] [D loss: 0.070530] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.778731] time: 1:25:24.278777\n",
      "(10, 128, 128, 3)\n",
      "0.8947223\n",
      "[Epoch 8/10] [Batch 1014/1081] [D loss: 0.071909] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.749513] time: 1:25:24.933231\n",
      "(10, 128, 128, 3)\n",
      "0.90604275\n",
      "[Epoch 8/10] [Batch 1015/1081] [D loss: 0.070428] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.438730] time: 1:25:25.544917\n",
      "(10, 128, 128, 3)\n",
      "0.94103616\n",
      "[Epoch 8/10] [Batch 1016/1081] [D loss: 0.067732] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.226488] time: 1:25:26.213762\n",
      "(10, 128, 128, 3)\n",
      "0.8931408\n",
      "[Epoch 8/10] [Batch 1017/1081] [D loss: 0.069020] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.693567] time: 1:25:26.851860\n",
      "(10, 128, 128, 3)\n",
      "0.9263521\n",
      "[Epoch 8/10] [Batch 1018/1081] [D loss: 0.065391] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.740548] time: 1:25:27.506621\n",
      "(10, 128, 128, 3)\n",
      "0.9110498\n",
      "[Epoch 8/10] [Batch 1019/1081] [D loss: 0.065157] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.472370] time: 1:25:28.204490\n",
      "(10, 128, 128, 3)\n",
      "0.91136914\n",
      "[Epoch 8/10] [Batch 1020/1081] [D loss: 0.066445] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.115874] time: 1:25:28.853499\n",
      "(10, 128, 128, 3)\n",
      "0.92889637\n",
      "[Epoch 8/10] [Batch 1021/1081] [D loss: 0.065994] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.076464] time: 1:25:29.569458\n",
      "(10, 128, 128, 3)\n",
      "0.92930967\n",
      "[Epoch 8/10] [Batch 1022/1081] [D loss: 0.061730] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.986078] time: 1:25:30.219777\n",
      "(10, 128, 128, 3)\n",
      "0.9682627\n",
      "[Epoch 8/10] [Batch 1023/1081] [D loss: 0.063010] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.054734] time: 1:25:30.886443\n",
      "(10, 128, 128, 3)\n",
      "0.93138313\n",
      "[Epoch 8/10] [Batch 1024/1081] [D loss: 0.062065] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.205571] time: 1:25:31.521974\n",
      "(10, 128, 128, 3)\n",
      "0.9472239\n",
      "[Epoch 8/10] [Batch 1025/1081] [D loss: 0.064974] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.771074] time: 1:25:32.171816\n",
      "(10, 128, 128, 3)\n",
      "0.8813185\n",
      "[Epoch 8/10] [Batch 1026/1081] [D loss: 0.062557] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.915294] time: 1:25:32.859645\n",
      "(10, 128, 128, 3)\n",
      "0.9617569\n",
      "[Epoch 8/10] [Batch 1027/1081] [D loss: 0.061084] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.993574] time: 1:25:33.486343\n",
      "(10, 128, 128, 3)\n",
      "0.9123485\n",
      "[Epoch 8/10] [Batch 1028/1081] [D loss: 0.060824] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.848662] time: 1:25:34.162778\n",
      "(10, 128, 128, 3)\n",
      "0.8967288\n",
      "[Epoch 8/10] [Batch 1029/1081] [D loss: 0.062254] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.201812] time: 1:25:34.792044\n",
      "(10, 128, 128, 3)\n",
      "0.8895762\n",
      "[Epoch 8/10] [Batch 1030/1081] [D loss: 0.063451] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.569143] time: 1:25:35.405332\n",
      "(10, 128, 128, 3)\n",
      "0.90524316\n",
      "[Epoch 8/10] [Batch 1031/1081] [D loss: 0.060021] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.373062] time: 1:25:36.045601\n",
      "(10, 128, 128, 3)\n",
      "0.890104\n",
      "[Epoch 8/10] [Batch 1032/1081] [D loss: 0.059755] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.153974] time: 1:25:36.665878\n",
      "(10, 128, 128, 3)\n",
      "0.9545644\n",
      "[Epoch 8/10] [Batch 1033/1081] [D loss: 0.059906] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.589227] time: 1:25:37.327681\n",
      "(10, 128, 128, 3)\n",
      "0.93452114\n",
      "[Epoch 8/10] [Batch 1034/1081] [D loss: 0.060132] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.952036] time: 1:25:38.004438\n",
      "(10, 128, 128, 3)\n",
      "0.9191348\n",
      "[Epoch 8/10] [Batch 1035/1081] [D loss: 0.059492] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.917681] time: 1:25:38.680867\n",
      "(10, 128, 128, 3)\n",
      "0.8633556\n",
      "[Epoch 8/10] [Batch 1036/1081] [D loss: 0.058990] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.405571] time: 1:25:39.267165\n",
      "(10, 128, 128, 3)\n",
      "0.9251116\n",
      "[Epoch 8/10] [Batch 1037/1081] [D loss: 0.058690] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.324535] time: 1:25:39.929233\n",
      "(10, 128, 128, 3)\n",
      "0.93912464\n",
      "[Epoch 8/10] [Batch 1038/1081] [D loss: 0.059041] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.907897] time: 1:25:40.545899\n",
      "(10, 128, 128, 3)\n",
      "0.9445686\n",
      "[Epoch 8/10] [Batch 1039/1081] [D loss: 0.058381] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.077764] time: 1:25:41.178236\n",
      "(10, 128, 128, 3)\n",
      "0.9613934\n",
      "[Epoch 8/10] [Batch 1040/1081] [D loss: 0.058748] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.932307] time: 1:25:41.804482\n",
      "(10, 128, 128, 3)\n",
      "0.92439944\n",
      "[Epoch 8/10] [Batch 1041/1081] [D loss: 0.058528] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.369084] time: 1:25:42.479134\n",
      "(10, 128, 128, 3)\n",
      "0.927692\n",
      "[Epoch 8/10] [Batch 1042/1081] [D loss: 0.058942] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.224911] time: 1:25:43.140576\n",
      "(10, 128, 128, 3)\n",
      "0.9495351\n",
      "[Epoch 8/10] [Batch 1043/1081] [D loss: 0.058402] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.091053] time: 1:25:43.799119\n",
      "(10, 128, 128, 3)\n",
      "0.9101164\n",
      "[Epoch 8/10] [Batch 1044/1081] [D loss: 0.062951] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.492762] time: 1:25:44.470459\n",
      "(10, 128, 128, 3)\n",
      "0.8800256\n",
      "[Epoch 8/10] [Batch 1045/1081] [D loss: 0.058599] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.808450] time: 1:25:45.106805\n",
      "(10, 128, 128, 3)\n",
      "0.90983504\n",
      "[Epoch 8/10] [Batch 1046/1081] [D loss: 0.057821] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.525576] time: 1:25:45.728526\n",
      "(10, 128, 128, 3)\n",
      "0.9532836\n",
      "[Epoch 8/10] [Batch 1047/1081] [D loss: 0.059052] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.313673] time: 1:25:46.433653\n",
      "(10, 128, 128, 3)\n",
      "0.9018143\n",
      "[Epoch 8/10] [Batch 1048/1081] [D loss: 0.058700] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.007857] time: 1:25:47.061635\n",
      "(10, 128, 128, 3)\n",
      "0.9309798\n",
      "[Epoch 8/10] [Batch 1049/1081] [D loss: 0.057080] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.579270] time: 1:25:47.771052\n",
      "(10, 128, 128, 3)\n",
      "0.94673914\n",
      "[Epoch 8/10] [Batch 1050/1081] [D loss: 0.058950] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.694714] time: 1:25:48.434494\n",
      "(10, 128, 128, 3)\n",
      "0.8786855\n",
      "[Epoch 8/10] [Batch 1051/1081] [D loss: 0.057044] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.269286] time: 1:25:49.110686\n",
      "(10, 128, 128, 3)\n",
      "0.9490373\n",
      "[Epoch 8/10] [Batch 1052/1081] [D loss: 0.057087] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.551788] time: 1:25:49.609062\n",
      "(10, 128, 128, 3)\n",
      "0.9830964\n",
      "[Epoch 8/10] [Batch 1053/1081] [D loss: 0.056258] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.107605] time: 1:25:50.138526\n",
      "(10, 128, 128, 3)\n",
      "0.89392895\n",
      "[Epoch 8/10] [Batch 1054/1081] [D loss: 0.055848] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.740510] time: 1:25:50.691262\n",
      "(10, 128, 128, 3)\n",
      "0.9108036\n",
      "[Epoch 8/10] [Batch 1055/1081] [D loss: 0.055755] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.866551] time: 1:25:51.259743\n",
      "(10, 128, 128, 3)\n",
      "0.8963271\n",
      "[Epoch 8/10] [Batch 1056/1081] [D loss: 0.055610] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.896779] time: 1:25:51.796343\n",
      "(10, 128, 128, 3)\n",
      "0.9486088\n",
      "[Epoch 8/10] [Batch 1057/1081] [D loss: 0.056265] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.048452] time: 1:25:52.345043\n",
      "(10, 128, 128, 3)\n",
      "0.8845017\n",
      "[Epoch 8/10] [Batch 1058/1081] [D loss: 0.055411] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.253721] time: 1:25:52.889354\n",
      "(10, 128, 128, 3)\n",
      "0.9583266\n",
      "[Epoch 8/10] [Batch 1059/1081] [D loss: 0.056007] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.609985] time: 1:25:53.437602\n",
      "(10, 128, 128, 3)\n",
      "0.9770611\n",
      "[Epoch 8/10] [Batch 1060/1081] [D loss: 0.055975] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.745772] time: 1:25:54.000869\n",
      "(10, 128, 128, 3)\n",
      "0.8899928\n",
      "[Epoch 8/10] [Batch 1061/1081] [D loss: 0.055045] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.623013] time: 1:25:54.551054\n",
      "(10, 128, 128, 3)\n",
      "0.98174876\n",
      "[Epoch 8/10] [Batch 1062/1081] [D loss: 0.055143] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.083666] time: 1:25:55.111193\n",
      "(10, 128, 128, 3)\n",
      "0.9399995\n",
      "[Epoch 8/10] [Batch 1063/1081] [D loss: 0.055846] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.435541] time: 1:25:55.649473\n",
      "(10, 128, 128, 3)\n",
      "0.9606082\n",
      "[Epoch 8/10] [Batch 1064/1081] [D loss: 0.054663] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.373283] time: 1:25:56.198894\n",
      "(10, 128, 128, 3)\n",
      "0.90289325\n",
      "[Epoch 8/10] [Batch 1065/1081] [D loss: 0.054300] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.997623] time: 1:25:56.770736\n",
      "(10, 128, 128, 3)\n",
      "0.93240064\n",
      "[Epoch 8/10] [Batch 1066/1081] [D loss: 0.054731] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.787561] time: 1:25:57.334029\n",
      "(10, 128, 128, 3)\n",
      "0.92204994\n",
      "[Epoch 8/10] [Batch 1067/1081] [D loss: 0.054925] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.578286] time: 1:25:57.957753\n",
      "(10, 128, 128, 3)\n",
      "0.88587713\n",
      "[Epoch 8/10] [Batch 1068/1081] [D loss: 0.053964] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.039882] time: 1:25:58.569416\n",
      "(10, 128, 128, 3)\n",
      "0.93463653\n",
      "[Epoch 8/10] [Batch 1069/1081] [D loss: 0.053729] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.984032] time: 1:25:59.164632\n",
      "(10, 128, 128, 3)\n",
      "0.86697954\n",
      "[Epoch 8/10] [Batch 1070/1081] [D loss: 0.054105] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.545511] time: 1:25:59.731988\n",
      "(10, 128, 128, 3)\n",
      "0.93993574\n",
      "[Epoch 8/10] [Batch 1071/1081] [D loss: 0.053917] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.370528] time: 1:26:00.303014\n",
      "(10, 128, 128, 3)\n",
      "0.93373036\n",
      "[Epoch 8/10] [Batch 1072/1081] [D loss: 0.053299] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.149359] time: 1:26:00.844432\n",
      "(10, 128, 128, 3)\n",
      "0.8873925\n",
      "[Epoch 8/10] [Batch 1073/1081] [D loss: 0.053744] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.845884] time: 1:26:01.413282\n",
      "(10, 128, 128, 3)\n",
      "0.8962596\n",
      "[Epoch 8/10] [Batch 1074/1081] [D loss: 0.053856] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.674640] time: 1:26:01.981852\n",
      "(10, 128, 128, 3)\n",
      "0.9014876\n",
      "[Epoch 8/10] [Batch 1075/1081] [D loss: 0.053380] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.058122] time: 1:26:02.570530\n",
      "(10, 128, 128, 3)\n",
      "0.90876794\n",
      "[Epoch 8/10] [Batch 1076/1081] [D loss: 0.053600] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.476390] time: 1:26:03.162602\n",
      "(10, 128, 128, 3)\n",
      "0.8946875\n",
      "[Epoch 8/10] [Batch 1077/1081] [D loss: 0.054646] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.822875] time: 1:26:03.722482\n",
      "(10, 128, 128, 3)\n",
      "0.9300713\n",
      "[Epoch 8/10] [Batch 1078/1081] [D loss: 0.054285] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.661558] time: 1:26:04.285744\n",
      "(10, 128, 128, 3)\n",
      "0.92842793\n",
      "[Epoch 8/10] [Batch 1079/1081] [D loss: 0.052866] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.820904] time: 1:26:04.848174\n",
      "(10, 128, 128, 3)\n",
      "0.9589613\n",
      "[Epoch 8/10] [Batch 1080/1081] [D loss: 0.052848] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.060385] time: 1:26:05.390499\n",
      "############ VALIDATION OF EPOCH 8 ############\n",
      "############ TRAINING OF EPOCH 9 ############\n",
      "(10, 128, 128, 3)\n",
      "0.9157489\n",
      "[Epoch 9/10] [Batch 0/1081] [D loss: 0.054271] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.178104] time: 1:27:13.957124\n",
      "(10, 128, 128, 3)\n",
      "0.9462795\n",
      "[Epoch 9/10] [Batch 1/1081] [D loss: 0.052452] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.509559] time: 1:27:14.631015\n",
      "(10, 128, 128, 3)\n",
      "0.85660774\n",
      "[Epoch 9/10] [Batch 2/1081] [D loss: 0.052072] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.209396] time: 1:27:15.295964\n",
      "(10, 128, 128, 3)\n",
      "0.91362643\n",
      "[Epoch 9/10] [Batch 3/1081] [D loss: 0.051839] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.640014] time: 1:27:15.956007\n",
      "(10, 128, 128, 3)\n",
      "0.93289155\n",
      "[Epoch 9/10] [Batch 4/1081] [D loss: 0.052006] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.236215] time: 1:27:16.559005\n",
      "(10, 128, 128, 3)\n",
      "0.88973856\n",
      "[Epoch 9/10] [Batch 5/1081] [D loss: 0.052027] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.694489] time: 1:27:17.245932\n",
      "(10, 128, 128, 3)\n",
      "0.9029018\n",
      "[Epoch 9/10] [Batch 6/1081] [D loss: 0.051758] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.446524] time: 1:27:17.970944\n",
      "(10, 128, 128, 3)\n",
      "0.94002956\n",
      "[Epoch 9/10] [Batch 8/1081] [D loss: 0.051718] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.233122] time: 1:27:18.606661\n",
      "(10, 128, 128, 3)\n",
      "0.9446475\n",
      "[Epoch 9/10] [Batch 9/1081] [D loss: 0.051364] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.089863] time: 1:27:19.246951\n",
      "(10, 128, 128, 3)\n",
      "0.9272857\n",
      "[Epoch 9/10] [Batch 10/1081] [D loss: 0.051975] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.173154] time: 1:27:19.898591\n",
      "(10, 128, 128, 3)\n",
      "0.9227764\n",
      "[Epoch 9/10] [Batch 11/1081] [D loss: 0.051576] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.262078] time: 1:27:20.536739\n",
      "(10, 128, 128, 3)\n",
      "0.8666262\n",
      "[Epoch 9/10] [Batch 12/1081] [D loss: 0.052374] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.756568] time: 1:27:21.153463\n",
      "(10, 128, 128, 3)\n",
      "0.9281254\n",
      "[Epoch 9/10] [Batch 13/1081] [D loss: 0.051280] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.335401] time: 1:27:21.859104\n",
      "(10, 128, 128, 3)\n",
      "0.87597054\n",
      "[Epoch 9/10] [Batch 14/1081] [D loss: 0.050774] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.081908] time: 1:27:22.490575\n",
      "(10, 128, 128, 3)\n",
      "0.8554961\n",
      "[Epoch 9/10] [Batch 15/1081] [D loss: 0.050995] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.527764] time: 1:27:23.182431\n",
      "(10, 128, 128, 3)\n",
      "0.90909034\n",
      "[Epoch 9/10] [Batch 16/1081] [D loss: 0.050928] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.771998] time: 1:27:23.819566\n",
      "(10, 128, 128, 3)\n",
      "0.8761886\n",
      "[Epoch 9/10] [Batch 17/1081] [D loss: 0.050869] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.524986] time: 1:27:24.438502\n",
      "(10, 128, 128, 3)\n",
      "0.9059662\n",
      "[Epoch 9/10] [Batch 18/1081] [D loss: 0.050743] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.101919] time: 1:27:25.065363\n",
      "(10, 128, 128, 3)\n",
      "0.92410666\n",
      "[Epoch 9/10] [Batch 19/1081] [D loss: 0.050315] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.954205] time: 1:27:25.704641\n",
      "(10, 128, 128, 3)\n",
      "0.90757483\n",
      "[Epoch 9/10] [Batch 20/1081] [D loss: 0.050465] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.552684] time: 1:27:26.394489\n",
      "(10, 128, 128, 3)\n",
      "0.9780459\n",
      "[Epoch 9/10] [Batch 21/1081] [D loss: 0.050310] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.403325] time: 1:27:27.009122\n",
      "(10, 128, 128, 3)\n",
      "0.9493267\n",
      "[Epoch 9/10] [Batch 22/1081] [D loss: 0.050237] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.935119] time: 1:27:27.689499\n",
      "(10, 128, 128, 3)\n",
      "0.90678793\n",
      "[Epoch 9/10] [Batch 23/1081] [D loss: 0.049970] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.120110] time: 1:27:28.368778\n",
      "(10, 128, 128, 3)\n",
      "0.9473811\n",
      "[Epoch 9/10] [Batch 24/1081] [D loss: 0.049636] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.616387] time: 1:27:29.012376\n",
      "(10, 128, 128, 3)\n",
      "0.92760414\n",
      "[Epoch 9/10] [Batch 25/1081] [D loss: 0.049727] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.495479] time: 1:27:29.678201\n",
      "(10, 128, 128, 3)\n",
      "0.94251376\n",
      "[Epoch 9/10] [Batch 26/1081] [D loss: 0.049765] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.680850] time: 1:27:30.318171\n",
      "(10, 128, 128, 3)\n",
      "0.9054864\n",
      "[Epoch 9/10] [Batch 27/1081] [D loss: 0.053822] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.636575] time: 1:27:31.054530\n",
      "(10, 128, 128, 3)\n",
      "0.8753446\n",
      "[Epoch 9/10] [Batch 28/1081] [D loss: 0.050203] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.284407] time: 1:27:31.724837\n",
      "(10, 128, 128, 3)\n",
      "0.9164339\n",
      "[Epoch 9/10] [Batch 29/1081] [D loss: 0.067380] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.284122] time: 1:27:32.384588\n",
      "(10, 128, 128, 3)\n",
      "0.97198397\n",
      "[Epoch 9/10] [Batch 30/1081] [D loss: 0.050961] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.933722] time: 1:27:33.016150\n",
      "(10, 128, 128, 3)\n",
      "0.91886324\n",
      "[Epoch 9/10] [Batch 31/1081] [D loss: 0.051906] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.323445] time: 1:27:33.726977\n",
      "(10, 128, 128, 3)\n",
      "0.91823435\n",
      "[Epoch 9/10] [Batch 32/1081] [D loss: 0.053143] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.786463] time: 1:27:34.394608\n",
      "(10, 128, 128, 3)\n",
      "0.88538474\n",
      "[Epoch 9/10] [Batch 33/1081] [D loss: 0.050906] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.066282] time: 1:27:35.038972\n",
      "(10, 128, 128, 3)\n",
      "0.9161721\n",
      "[Epoch 9/10] [Batch 34/1081] [D loss: 0.050256] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.764941] time: 1:27:35.635333\n",
      "(10, 128, 128, 3)\n",
      "0.8773901\n",
      "[Epoch 9/10] [Batch 35/1081] [D loss: 0.049357] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.434825] time: 1:27:36.261847\n",
      "(10, 128, 128, 3)\n",
      "0.9236944\n",
      "[Epoch 9/10] [Batch 36/1081] [D loss: 0.049658] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.695003] time: 1:27:36.887875\n",
      "(10, 128, 128, 3)\n",
      "0.8900059\n",
      "[Epoch 9/10] [Batch 37/1081] [D loss: 0.050420] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.953751] time: 1:27:37.557834\n",
      "(10, 128, 128, 3)\n",
      "0.96602565\n",
      "[Epoch 9/10] [Batch 38/1081] [D loss: 0.051551] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.412942] time: 1:27:38.178010\n",
      "(10, 128, 128, 3)\n",
      "0.91885144\n",
      "[Epoch 9/10] [Batch 39/1081] [D loss: 0.049065] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.827113] time: 1:27:38.807202\n",
      "(10, 128, 128, 3)\n",
      "0.91063386\n",
      "[Epoch 9/10] [Batch 40/1081] [D loss: 0.048992] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.785664] time: 1:27:39.478965\n",
      "(10, 128, 128, 3)\n",
      "0.9230287\n",
      "[Epoch 9/10] [Batch 41/1081] [D loss: 0.049616] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.848146] time: 1:27:40.147500\n",
      "(10, 128, 128, 3)\n",
      "0.8836243\n",
      "[Epoch 9/10] [Batch 42/1081] [D loss: 0.048654] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.305459] time: 1:27:40.793601\n",
      "(10, 128, 128, 3)\n",
      "0.87389135\n",
      "[Epoch 9/10] [Batch 43/1081] [D loss: 0.048478] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.257156] time: 1:27:41.494334\n",
      "(10, 128, 128, 3)\n",
      "0.899218\n",
      "[Epoch 9/10] [Batch 44/1081] [D loss: 0.048200] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.232172] time: 1:27:42.194580\n",
      "(10, 128, 128, 3)\n",
      "0.91496104\n",
      "[Epoch 9/10] [Batch 45/1081] [D loss: 0.048072] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.458043] time: 1:27:42.828356\n",
      "(10, 128, 128, 3)\n",
      "0.9465296\n",
      "[Epoch 9/10] [Batch 46/1081] [D loss: 0.048124] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.173859] time: 1:27:43.486495\n",
      "(10, 128, 128, 3)\n",
      "0.9024647\n",
      "[Epoch 9/10] [Batch 47/1081] [D loss: 0.048042] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.820755] time: 1:27:44.147914\n",
      "(10, 128, 128, 3)\n",
      "0.918171\n",
      "[Epoch 9/10] [Batch 48/1081] [D loss: 0.048160] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.212774] time: 1:27:44.798201\n",
      "(10, 128, 128, 3)\n",
      "0.91249895\n",
      "[Epoch 9/10] [Batch 49/1081] [D loss: 0.047973] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.959739] time: 1:27:45.418871\n",
      "(10, 128, 128, 3)\n",
      "0.88764054\n",
      "[Epoch 9/10] [Batch 50/1081] [D loss: 0.049213] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.325282] time: 1:27:46.040495\n",
      "(10, 128, 128, 3)\n",
      "0.939054\n",
      "[Epoch 9/10] [Batch 51/1081] [D loss: 0.048017] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.164912] time: 1:27:46.714294\n",
      "(10, 128, 128, 3)\n",
      "0.8463729\n",
      "[Epoch 9/10] [Batch 52/1081] [D loss: 0.048226] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.164832] time: 1:27:47.346714\n",
      "(10, 128, 128, 3)\n",
      "0.94089\n",
      "[Epoch 9/10] [Batch 53/1081] [D loss: 0.047815] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.029142] time: 1:27:47.963090\n",
      "(10, 128, 128, 3)\n",
      "0.9345401\n",
      "[Epoch 9/10] [Batch 54/1081] [D loss: 0.047707] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.928528] time: 1:27:48.672044\n",
      "(10, 128, 128, 3)\n",
      "0.9408481\n",
      "[Epoch 9/10] [Batch 55/1081] [D loss: 0.050688] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.714020] time: 1:27:49.367833\n",
      "(10, 128, 128, 3)\n",
      "0.9273489\n",
      "[Epoch 9/10] [Batch 56/1081] [D loss: 0.048096] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.647930] time: 1:27:49.970516\n",
      "(10, 128, 128, 3)\n",
      "0.84400773\n",
      "[Epoch 9/10] [Batch 57/1081] [D loss: 0.047813] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.098841] time: 1:27:50.630491\n",
      "(10, 128, 128, 3)\n",
      "0.9192469\n",
      "[Epoch 9/10] [Batch 58/1081] [D loss: 0.046868] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.173127] time: 1:27:51.257058\n",
      "(10, 128, 128, 3)\n",
      "0.94252443\n",
      "[Epoch 9/10] [Batch 59/1081] [D loss: 0.047251] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.953902] time: 1:27:51.883201\n",
      "(10, 128, 128, 3)\n",
      "0.9145078\n",
      "[Epoch 9/10] [Batch 60/1081] [D loss: 0.047324] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.605892] time: 1:27:52.588406\n",
      "(10, 128, 128, 3)\n",
      "0.6788904\n",
      "[Epoch 9/10] [Batch 61/1081] [D loss: 0.507076] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 3.759644] time: 1:27:53.227544\n",
      "(10, 128, 128, 3)\n",
      "0.6568592\n",
      "[Epoch 9/10] [Batch 62/1081] [D loss: 0.388574] [D acc: 0.15 (0.20 real, 0.10 fake)] [G loss: 3.228164] time: 1:27:53.873575\n",
      "(10, 128, 128, 3)\n",
      "0.812577\n",
      "[Epoch 9/10] [Batch 63/1081] [D loss: 0.272559] [D acc: 0.70 (0.50 real, 0.90 fake)] [G loss: 3.777885] time: 1:27:54.518518\n",
      "(10, 128, 128, 3)\n",
      "0.7578316\n",
      "[Epoch 9/10] [Batch 64/1081] [D loss: 0.170270] [D acc: 0.90 (0.80 real, 1.00 fake)] [G loss: 4.007142] time: 1:27:55.164223\n",
      "(10, 128, 128, 3)\n",
      "0.8786108\n",
      "[Epoch 9/10] [Batch 65/1081] [D loss: 0.103565] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.266734] time: 1:27:55.832316\n",
      "(10, 128, 128, 3)\n",
      "0.9441531\n",
      "[Epoch 9/10] [Batch 66/1081] [D loss: 0.067286] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.118695] time: 1:27:56.478102\n",
      "(10, 128, 128, 3)\n",
      "0.91073793\n",
      "[Epoch 9/10] [Batch 67/1081] [D loss: 0.078745] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 4.520274] time: 1:27:57.136869\n",
      "(10, 128, 128, 3)\n",
      "0.9219856\n",
      "[Epoch 9/10] [Batch 68/1081] [D loss: 0.084282] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.246714] time: 1:27:57.732395\n",
      "(10, 128, 128, 3)\n",
      "0.90867734\n",
      "[Epoch 9/10] [Batch 69/1081] [D loss: 0.059961] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.639286] time: 1:27:58.404629\n",
      "(10, 128, 128, 3)\n",
      "0.8986793\n",
      "[Epoch 9/10] [Batch 70/1081] [D loss: 0.070937] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 3.978945] time: 1:27:59.063201\n",
      "(10, 128, 128, 3)\n",
      "0.93913037\n",
      "[Epoch 9/10] [Batch 71/1081] [D loss: 0.056873] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.980067] time: 1:27:59.709040\n",
      "(10, 128, 128, 3)\n",
      "0.8739794\n",
      "[Epoch 9/10] [Batch 72/1081] [D loss: 0.143940] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.277579] time: 1:28:00.342222\n",
      "(10, 128, 128, 3)\n",
      "0.9508872\n",
      "[Epoch 9/10] [Batch 73/1081] [D loss: 0.065935] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.353905] time: 1:28:00.993242\n",
      "(10, 128, 128, 3)\n",
      "0.90559226\n",
      "[Epoch 9/10] [Batch 74/1081] [D loss: 0.060356] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.011037] time: 1:28:01.582871\n",
      "(10, 128, 128, 3)\n",
      "0.8470127\n",
      "[Epoch 9/10] [Batch 75/1081] [D loss: 0.058663] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.743272] time: 1:28:02.212516\n",
      "(10, 128, 128, 3)\n",
      "0.9655664\n",
      "[Epoch 9/10] [Batch 76/1081] [D loss: 0.055433] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.512388] time: 1:28:02.877509\n",
      "(10, 128, 128, 3)\n",
      "0.9552534\n",
      "[Epoch 9/10] [Batch 77/1081] [D loss: 0.862425] [D acc: 0.00 (0.00 real, 0.00 fake)] [G loss: 2.704994] time: 1:28:03.497919\n",
      "(10, 128, 128, 3)\n",
      "0.8678314\n",
      "[Epoch 9/10] [Batch 78/1081] [D loss: 0.356479] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 4.366980] time: 1:28:04.154435\n",
      "(10, 128, 128, 3)\n",
      "0.930386\n",
      "[Epoch 9/10] [Batch 79/1081] [D loss: 0.379178] [D acc: 0.40 (0.50 real, 0.30 fake)] [G loss: 3.970127] time: 1:28:04.795665\n",
      "(10, 128, 128, 3)\n",
      "0.9287302\n",
      "[Epoch 9/10] [Batch 80/1081] [D loss: 0.456489] [D acc: 0.20 (0.30 real, 0.10 fake)] [G loss: 5.278719] time: 1:28:05.416032\n",
      "(10, 128, 128, 3)\n",
      "0.86978364\n",
      "[Epoch 9/10] [Batch 81/1081] [D loss: 0.317513] [D acc: 0.50 (0.50 real, 0.50 fake)] [G loss: 4.269544] time: 1:28:06.076058\n",
      "(10, 128, 128, 3)\n",
      "0.9234341\n",
      "[Epoch 9/10] [Batch 82/1081] [D loss: 0.387675] [D acc: 0.35 (0.00 real, 0.70 fake)] [G loss: 3.906612] time: 1:28:06.723280\n",
      "(10, 128, 128, 3)\n",
      "0.9252096\n",
      "[Epoch 9/10] [Batch 83/1081] [D loss: 0.343107] [D acc: 0.25 (0.20 real, 0.30 fake)] [G loss: 4.808243] time: 1:28:07.402418\n",
      "(10, 128, 128, 3)\n",
      "0.90223384\n",
      "[Epoch 9/10] [Batch 84/1081] [D loss: 0.319783] [D acc: 0.50 (0.20 real, 0.80 fake)] [G loss: 3.715125] time: 1:28:08.023966\n",
      "(10, 128, 128, 3)\n",
      "0.8868708\n",
      "[Epoch 9/10] [Batch 85/1081] [D loss: 0.292284] [D acc: 0.50 (0.60 real, 0.40 fake)] [G loss: 3.638613] time: 1:28:08.707278\n",
      "(10, 128, 128, 3)\n",
      "0.86333185\n",
      "[Epoch 9/10] [Batch 86/1081] [D loss: 0.249597] [D acc: 0.70 (0.80 real, 0.60 fake)] [G loss: 5.118838] time: 1:28:09.349253\n",
      "(10, 128, 128, 3)\n",
      "0.87926465\n",
      "[Epoch 9/10] [Batch 87/1081] [D loss: 0.186306] [D acc: 0.75 (0.50 real, 1.00 fake)] [G loss: 3.645017] time: 1:28:10.041308\n",
      "(10, 128, 128, 3)\n",
      "0.9185534\n",
      "[Epoch 9/10] [Batch 88/1081] [D loss: 0.183522] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.125082] time: 1:28:10.736955\n",
      "(10, 128, 128, 3)\n",
      "0.985008\n",
      "[Epoch 9/10] [Batch 89/1081] [D loss: 0.220513] [D acc: 0.90 (1.00 real, 0.80 fake)] [G loss: 3.382720] time: 1:28:11.368335\n",
      "(10, 128, 128, 3)\n",
      "0.91806984\n",
      "[Epoch 9/10] [Batch 90/1081] [D loss: 0.117081] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.386474] time: 1:28:12.038079\n",
      "(10, 128, 128, 3)\n",
      "0.95055264\n",
      "[Epoch 9/10] [Batch 91/1081] [D loss: 0.085511] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.152459] time: 1:28:12.719219\n",
      "(10, 128, 128, 3)\n",
      "0.92805845\n",
      "[Epoch 9/10] [Batch 92/1081] [D loss: 0.092864] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.496897] time: 1:28:13.409980\n",
      "(10, 128, 128, 3)\n",
      "0.94575095\n",
      "[Epoch 9/10] [Batch 93/1081] [D loss: 0.255000] [D acc: 0.65 (1.00 real, 0.30 fake)] [G loss: 3.592269] time: 1:28:14.086112\n",
      "(10, 128, 128, 3)\n",
      "0.8979991\n",
      "[Epoch 9/10] [Batch 94/1081] [D loss: 0.172874] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.983443] time: 1:28:14.686444\n",
      "(10, 128, 128, 3)\n",
      "0.8914735\n",
      "[Epoch 9/10] [Batch 95/1081] [D loss: 0.205197] [D acc: 0.80 (0.90 real, 0.70 fake)] [G loss: 3.253801] time: 1:28:15.361163\n",
      "(10, 128, 128, 3)\n",
      "0.9507351\n",
      "[Epoch 9/10] [Batch 96/1081] [D loss: 0.094330] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.016716] time: 1:28:15.986374\n",
      "(10, 128, 128, 3)\n",
      "0.90375954\n",
      "[Epoch 9/10] [Batch 97/1081] [D loss: 0.078971] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.951277] time: 1:28:16.546274\n",
      "(10, 128, 128, 3)\n",
      "0.91505164\n",
      "[Epoch 9/10] [Batch 98/1081] [D loss: 0.069484] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.093696] time: 1:28:17.219021\n",
      "(10, 128, 128, 3)\n",
      "0.91596717\n",
      "[Epoch 9/10] [Batch 99/1081] [D loss: 0.068993] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.575176] time: 1:28:17.879105\n",
      "(10, 128, 128, 3)\n",
      "0.9210715\n",
      "[Epoch 9/10] [Batch 100/1081] [D loss: 0.078169] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.169405] time: 1:28:18.556178\n",
      "(10, 128, 128, 3)\n",
      "0.8859318\n",
      "[Epoch 9/10] [Batch 101/1081] [D loss: 0.064336] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.033614] time: 1:28:19.175380\n",
      "(10, 128, 128, 3)\n",
      "0.93647534\n",
      "[Epoch 9/10] [Batch 102/1081] [D loss: 0.065172] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.301636] time: 1:28:19.806505\n",
      "(10, 128, 128, 3)\n",
      "0.9346902\n",
      "[Epoch 9/10] [Batch 103/1081] [D loss: 0.067406] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.735718] time: 1:28:20.453195\n",
      "(10, 128, 128, 3)\n",
      "0.92889524\n",
      "[Epoch 9/10] [Batch 104/1081] [D loss: 0.068038] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.561518] time: 1:28:21.130463\n",
      "(10, 128, 128, 3)\n",
      "0.96328455\n",
      "[Epoch 9/10] [Batch 105/1081] [D loss: 0.068234] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.053509] time: 1:28:21.761038\n",
      "(10, 128, 128, 3)\n",
      "0.87007713\n",
      "[Epoch 9/10] [Batch 106/1081] [D loss: 0.069243] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.723480] time: 1:28:22.482747\n",
      "(10, 128, 128, 3)\n",
      "0.91697913\n",
      "[Epoch 9/10] [Batch 107/1081] [D loss: 0.064007] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.409501] time: 1:28:23.161000\n",
      "(10, 128, 128, 3)\n",
      "0.8730871\n",
      "[Epoch 9/10] [Batch 108/1081] [D loss: 0.063058] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.373090] time: 1:28:23.817358\n",
      "(10, 128, 128, 3)\n",
      "0.921532\n",
      "[Epoch 9/10] [Batch 109/1081] [D loss: 0.065728] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.581121] time: 1:28:24.448115\n",
      "(10, 128, 128, 3)\n",
      "0.9113853\n",
      "[Epoch 9/10] [Batch 110/1081] [D loss: 0.066302] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.644555] time: 1:28:25.125445\n",
      "(10, 128, 128, 3)\n",
      "0.8983746\n",
      "[Epoch 9/10] [Batch 111/1081] [D loss: 0.060412] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.598989] time: 1:28:25.788376\n",
      "(10, 128, 128, 3)\n",
      "0.9265642\n",
      "[Epoch 9/10] [Batch 112/1081] [D loss: 0.062947] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.732462] time: 1:28:26.412867\n",
      "(10, 128, 128, 3)\n",
      "0.91818994\n",
      "[Epoch 9/10] [Batch 113/1081] [D loss: 0.076711] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.741624] time: 1:28:27.106337\n",
      "(10, 128, 128, 3)\n",
      "0.8766617\n",
      "[Epoch 9/10] [Batch 114/1081] [D loss: 0.061412] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.455523] time: 1:28:27.818967\n",
      "(10, 128, 128, 3)\n",
      "0.8750612\n",
      "[Epoch 9/10] [Batch 115/1081] [D loss: 0.061838] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.209816] time: 1:28:28.499075\n",
      "(10, 128, 128, 3)\n",
      "0.93221277\n",
      "[Epoch 9/10] [Batch 116/1081] [D loss: 0.061146] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.126698] time: 1:28:29.120041\n",
      "(10, 128, 128, 3)\n",
      "0.94022083\n",
      "[Epoch 9/10] [Batch 117/1081] [D loss: 0.060561] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.593589] time: 1:28:29.815942\n",
      "(10, 128, 128, 3)\n",
      "0.8890999\n",
      "[Epoch 9/10] [Batch 118/1081] [D loss: 0.059157] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.495475] time: 1:28:30.467352\n",
      "(10, 128, 128, 3)\n",
      "0.9104579\n",
      "[Epoch 9/10] [Batch 119/1081] [D loss: 0.059466] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.787807] time: 1:28:31.174618\n",
      "(10, 128, 128, 3)\n",
      "0.9328397\n",
      "[Epoch 9/10] [Batch 120/1081] [D loss: 0.058764] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.056321] time: 1:28:31.844713\n",
      "(10, 128, 128, 3)\n",
      "0.930661\n",
      "[Epoch 9/10] [Batch 121/1081] [D loss: 0.063708] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.140941] time: 1:28:32.479927\n",
      "(10, 128, 128, 3)\n",
      "0.91348726\n",
      "[Epoch 9/10] [Batch 122/1081] [D loss: 0.057522] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.983047] time: 1:28:33.168607\n",
      "(10, 128, 128, 3)\n",
      "0.9365528\n",
      "[Epoch 9/10] [Batch 123/1081] [D loss: 0.058169] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.357246] time: 1:28:33.871092\n",
      "(10, 128, 128, 3)\n",
      "0.9321265\n",
      "[Epoch 9/10] [Batch 124/1081] [D loss: 0.057738] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.306181] time: 1:28:34.542126\n",
      "(10, 128, 128, 3)\n",
      "0.93252015\n",
      "[Epoch 9/10] [Batch 125/1081] [D loss: 0.071398] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.819792] time: 1:28:35.165462\n",
      "(10, 128, 128, 3)\n",
      "0.89348626\n",
      "[Epoch 9/10] [Batch 126/1081] [D loss: 0.057993] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.839693] time: 1:28:35.856794\n",
      "(10, 128, 128, 3)\n",
      "0.84268975\n",
      "[Epoch 9/10] [Batch 127/1081] [D loss: 0.061247] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.721521] time: 1:28:36.560359\n",
      "(10, 128, 128, 3)\n",
      "0.9325579\n",
      "[Epoch 9/10] [Batch 128/1081] [D loss: 0.065180] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.301700] time: 1:28:37.217368\n",
      "(10, 128, 128, 3)\n",
      "0.9141178\n",
      "[Epoch 9/10] [Batch 129/1081] [D loss: 0.060554] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.913280] time: 1:28:37.846252\n",
      "(10, 128, 128, 3)\n",
      "0.9179209\n",
      "[Epoch 9/10] [Batch 130/1081] [D loss: 0.061792] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.707830] time: 1:28:38.524666\n",
      "(10, 128, 128, 3)\n",
      "0.9059537\n",
      "[Epoch 9/10] [Batch 131/1081] [D loss: 0.059980] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.446997] time: 1:28:39.198881\n",
      "(10, 128, 128, 3)\n",
      "0.92527133\n",
      "[Epoch 9/10] [Batch 132/1081] [D loss: 0.068003] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.634291] time: 1:28:39.893320\n",
      "(10, 128, 128, 3)\n",
      "0.9199598\n",
      "[Epoch 9/10] [Batch 133/1081] [D loss: 0.064352] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.931475] time: 1:28:40.606465\n",
      "(10, 128, 128, 3)\n",
      "0.93763083\n",
      "[Epoch 9/10] [Batch 134/1081] [D loss: 0.057879] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.971694] time: 1:28:41.192881\n",
      "(10, 128, 128, 3)\n",
      "0.94248724\n",
      "[Epoch 9/10] [Batch 135/1081] [D loss: 0.056895] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.823538] time: 1:28:41.851637\n",
      "(10, 128, 128, 3)\n",
      "0.88228005\n",
      "[Epoch 9/10] [Batch 136/1081] [D loss: 0.055783] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.750297] time: 1:28:42.508528\n",
      "(10, 128, 128, 3)\n",
      "0.96715474\n",
      "[Epoch 9/10] [Batch 137/1081] [D loss: 0.061687] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.841078] time: 1:28:43.204376\n",
      "(10, 128, 128, 3)\n",
      "0.90176743\n",
      "[Epoch 9/10] [Batch 138/1081] [D loss: 0.057630] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.503856] time: 1:28:43.872643\n",
      "(10, 128, 128, 3)\n",
      "0.92628497\n",
      "[Epoch 9/10] [Batch 139/1081] [D loss: 0.055226] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.683778] time: 1:28:44.542264\n",
      "(10, 128, 128, 3)\n",
      "0.9099772\n",
      "[Epoch 9/10] [Batch 140/1081] [D loss: 0.054797] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.510679] time: 1:28:45.200159\n",
      "(10, 128, 128, 3)\n",
      "0.9050892\n",
      "[Epoch 9/10] [Batch 141/1081] [D loss: 0.056340] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.877047] time: 1:28:45.830731\n",
      "(10, 128, 128, 3)\n",
      "0.92037636\n",
      "[Epoch 9/10] [Batch 142/1081] [D loss: 0.059892] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.158508] time: 1:28:46.479931\n",
      "(10, 128, 128, 3)\n",
      "0.90893817\n",
      "[Epoch 9/10] [Batch 143/1081] [D loss: 0.056450] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.752480] time: 1:28:47.137717\n",
      "(10, 128, 128, 3)\n",
      "0.85461885\n",
      "[Epoch 9/10] [Batch 144/1081] [D loss: 0.053193] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.354119] time: 1:28:47.800292\n",
      "(10, 128, 128, 3)\n",
      "0.87244695\n",
      "[Epoch 9/10] [Batch 145/1081] [D loss: 0.054452] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.824251] time: 1:28:48.424629\n",
      "(10, 128, 128, 3)\n",
      "0.90058523\n",
      "[Epoch 9/10] [Batch 146/1081] [D loss: 0.053357] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.670121] time: 1:28:49.107758\n",
      "(10, 128, 128, 3)\n",
      "0.9244449\n",
      "[Epoch 9/10] [Batch 147/1081] [D loss: 0.053750] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.846285] time: 1:28:49.788017\n",
      "(10, 128, 128, 3)\n",
      "0.9075425\n",
      "[Epoch 9/10] [Batch 148/1081] [D loss: 0.067162] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.856460] time: 1:28:50.395649\n",
      "(10, 128, 128, 3)\n",
      "0.90366\n",
      "[Epoch 9/10] [Batch 149/1081] [D loss: 0.055487] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.500025] time: 1:28:51.050476\n",
      "(10, 128, 128, 3)\n",
      "0.9062659\n",
      "[Epoch 9/10] [Batch 150/1081] [D loss: 0.054511] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.072886] time: 1:28:51.695071\n",
      "(10, 128, 128, 3)\n",
      "0.8831554\n",
      "[Epoch 9/10] [Batch 151/1081] [D loss: 0.053926] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.424182] time: 1:28:52.365974\n",
      "(10, 128, 128, 3)\n",
      "0.9402122\n",
      "[Epoch 9/10] [Batch 152/1081] [D loss: 0.053364] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.048047] time: 1:28:52.997750\n",
      "(10, 128, 128, 3)\n",
      "0.92433995\n",
      "[Epoch 9/10] [Batch 153/1081] [D loss: 0.053622] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.266590] time: 1:28:53.684342\n",
      "(10, 128, 128, 3)\n",
      "0.8594243\n",
      "[Epoch 9/10] [Batch 154/1081] [D loss: 0.054822] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.901552] time: 1:28:54.283272\n",
      "(10, 128, 128, 3)\n",
      "0.93136555\n",
      "[Epoch 9/10] [Batch 155/1081] [D loss: 0.053601] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.321658] time: 1:28:54.923823\n",
      "(10, 128, 128, 3)\n",
      "0.9461259\n",
      "[Epoch 9/10] [Batch 156/1081] [D loss: 0.082889] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 3.046548] time: 1:28:55.534777\n",
      "(10, 128, 128, 3)\n",
      "0.9131913\n",
      "[Epoch 9/10] [Batch 157/1081] [D loss: 0.068511] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.671293] time: 1:28:56.162071\n",
      "(10, 128, 128, 3)\n",
      "0.9189513\n",
      "[Epoch 9/10] [Batch 158/1081] [D loss: 0.055290] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.555943] time: 1:28:56.747472\n",
      "(10, 128, 128, 3)\n",
      "0.8813129\n",
      "[Epoch 9/10] [Batch 159/1081] [D loss: 0.074058] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.818124] time: 1:28:57.369811\n",
      "(10, 128, 128, 3)\n",
      "0.88636684\n",
      "[Epoch 9/10] [Batch 160/1081] [D loss: 0.059550] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.832693] time: 1:28:58.052839\n",
      "(10, 128, 128, 3)\n",
      "0.88088804\n",
      "[Epoch 9/10] [Batch 161/1081] [D loss: 0.055554] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.540625] time: 1:28:58.706466\n",
      "(10, 128, 128, 3)\n",
      "0.87785244\n",
      "[Epoch 9/10] [Batch 162/1081] [D loss: 0.055753] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.061173] time: 1:28:59.364868\n",
      "(10, 128, 128, 3)\n",
      "0.89533335\n",
      "[Epoch 9/10] [Batch 163/1081] [D loss: 0.054626] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.012159] time: 1:29:00.049606\n",
      "(10, 128, 128, 3)\n",
      "0.9129322\n",
      "[Epoch 9/10] [Batch 164/1081] [D loss: 0.051711] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.666227] time: 1:29:00.671631\n",
      "(10, 128, 128, 3)\n",
      "0.9480718\n",
      "[Epoch 9/10] [Batch 165/1081] [D loss: 0.051885] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.385216] time: 1:29:01.368545\n",
      "(10, 128, 128, 3)\n",
      "0.8993805\n",
      "[Epoch 9/10] [Batch 166/1081] [D loss: 0.051486] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.455551] time: 1:29:01.999923\n",
      "(10, 128, 128, 3)\n",
      "0.9686856\n",
      "[Epoch 9/10] [Batch 167/1081] [D loss: 0.055891] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.527889] time: 1:29:02.653683\n",
      "(10, 128, 128, 3)\n",
      "0.92342633\n",
      "[Epoch 9/10] [Batch 168/1081] [D loss: 0.052007] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.443951] time: 1:29:03.360906\n",
      "(10, 128, 128, 3)\n",
      "0.9147508\n",
      "[Epoch 9/10] [Batch 169/1081] [D loss: 0.053634] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.042142] time: 1:29:04.043499\n",
      "(10, 128, 128, 3)\n",
      "0.92933583\n",
      "[Epoch 9/10] [Batch 170/1081] [D loss: 0.050771] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.734507] time: 1:29:04.643229\n",
      "(10, 128, 128, 3)\n",
      "0.93024546\n",
      "[Epoch 9/10] [Batch 171/1081] [D loss: 0.052178] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.750351] time: 1:29:05.267507\n",
      "(10, 128, 128, 3)\n",
      "0.8822911\n",
      "[Epoch 9/10] [Batch 172/1081] [D loss: 0.051112] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.259475] time: 1:29:05.889815\n",
      "(10, 128, 128, 3)\n",
      "0.91035384\n",
      "[Epoch 9/10] [Batch 173/1081] [D loss: 0.051211] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.872776] time: 1:29:06.518234\n",
      "(10, 128, 128, 3)\n",
      "0.8544361\n",
      "[Epoch 9/10] [Batch 174/1081] [D loss: 0.058918] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.988357] time: 1:29:07.155275\n",
      "(10, 128, 128, 3)\n",
      "0.8797613\n",
      "[Epoch 9/10] [Batch 175/1081] [D loss: 0.051890] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.210686] time: 1:29:07.818739\n",
      "(10, 128, 128, 3)\n",
      "0.9357138\n",
      "[Epoch 9/10] [Batch 176/1081] [D loss: 0.050934] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.890107] time: 1:29:08.414154\n",
      "(10, 128, 128, 3)\n",
      "0.933892\n",
      "[Epoch 9/10] [Batch 177/1081] [D loss: 0.050631] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.278356] time: 1:29:09.101910\n",
      "(10, 128, 128, 3)\n",
      "0.93969536\n",
      "[Epoch 9/10] [Batch 178/1081] [D loss: 0.050056] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.196379] time: 1:29:09.744104\n",
      "(10, 128, 128, 3)\n",
      "0.9555778\n",
      "[Epoch 9/10] [Batch 179/1081] [D loss: 0.050817] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.104628] time: 1:29:10.410501\n",
      "(10, 128, 128, 3)\n",
      "0.9144559\n",
      "[Epoch 9/10] [Batch 180/1081] [D loss: 0.065069] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.460111] time: 1:29:11.018885\n",
      "(10, 128, 128, 3)\n",
      "0.8823271\n",
      "[Epoch 9/10] [Batch 181/1081] [D loss: 0.051564] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.655669] time: 1:29:11.560225\n",
      "(10, 128, 128, 3)\n",
      "0.8897789\n",
      "[Epoch 9/10] [Batch 182/1081] [D loss: 0.056671] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.612942] time: 1:29:12.089628\n",
      "(10, 128, 128, 3)\n",
      "0.94263506\n",
      "[Epoch 9/10] [Batch 183/1081] [D loss: 0.049884] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.074904] time: 1:29:12.640960\n",
      "(10, 128, 128, 3)\n",
      "0.88309723\n",
      "[Epoch 9/10] [Batch 184/1081] [D loss: 0.050223] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.749500] time: 1:29:13.187724\n",
      "(10, 128, 128, 3)\n",
      "0.879705\n",
      "[Epoch 9/10] [Batch 185/1081] [D loss: 0.050290] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.683440] time: 1:29:13.728060\n",
      "(10, 128, 128, 3)\n",
      "0.89782506\n",
      "[Epoch 9/10] [Batch 186/1081] [D loss: 0.049834] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.153586] time: 1:29:14.280472\n",
      "(10, 128, 128, 3)\n",
      "0.9339705\n",
      "[Epoch 9/10] [Batch 187/1081] [D loss: 0.057412] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.618230] time: 1:29:14.853101\n",
      "(10, 128, 128, 3)\n",
      "0.8986017\n",
      "[Epoch 9/10] [Batch 188/1081] [D loss: 0.053898] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.717752] time: 1:29:15.390032\n",
      "(10, 128, 128, 3)\n",
      "0.9079153\n",
      "[Epoch 9/10] [Batch 189/1081] [D loss: 0.051743] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.488757] time: 1:29:15.918390\n",
      "(10, 128, 128, 3)\n",
      "0.8961654\n",
      "[Epoch 9/10] [Batch 190/1081] [D loss: 0.052522] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.939507] time: 1:29:16.470133\n",
      "(10, 128, 128, 3)\n",
      "0.89959186\n",
      "[Epoch 9/10] [Batch 191/1081] [D loss: 0.049663] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.432252] time: 1:29:17.005025\n",
      "(10, 128, 128, 3)\n",
      "0.9239941\n",
      "[Epoch 9/10] [Batch 192/1081] [D loss: 0.051854] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.363183] time: 1:29:17.557177\n",
      "(10, 128, 128, 3)\n",
      "0.92067695\n",
      "[Epoch 9/10] [Batch 193/1081] [D loss: 0.048919] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.856099] time: 1:29:18.110426\n",
      "(10, 128, 128, 3)\n",
      "0.92613506\n",
      "[Epoch 9/10] [Batch 194/1081] [D loss: 0.048706] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.309922] time: 1:29:18.661599\n",
      "(10, 128, 128, 3)\n",
      "0.91271573\n",
      "[Epoch 9/10] [Batch 195/1081] [D loss: 0.049070] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.100344] time: 1:29:19.234631\n",
      "(10, 128, 128, 3)\n",
      "0.8906853\n",
      "[Epoch 9/10] [Batch 196/1081] [D loss: 0.052169] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.287188] time: 1:29:19.790200\n",
      "(10, 128, 128, 3)\n",
      "0.90261084\n",
      "[Epoch 9/10] [Batch 197/1081] [D loss: 0.051905] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.941097] time: 1:29:20.310479\n",
      "(10, 128, 128, 3)\n",
      "0.92211914\n",
      "[Epoch 9/10] [Batch 198/1081] [D loss: 0.049960] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.540711] time: 1:29:20.850110\n",
      "(10, 128, 128, 3)\n",
      "0.90778327\n",
      "[Epoch 9/10] [Batch 199/1081] [D loss: 0.048101] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.127597] time: 1:29:21.398501\n",
      "(10, 128, 128, 3)\n",
      "0.94608146\n",
      "[Epoch 9/10] [Batch 200/1081] [D loss: 0.048376] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.879714] time: 1:29:21.959026\n",
      "(10, 128, 128, 3)\n",
      "0.8985722\n",
      "[Epoch 9/10] [Batch 201/1081] [D loss: 0.047632] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.138534] time: 1:29:22.485123\n",
      "(10, 128, 128, 3)\n",
      "0.9102467\n",
      "[Epoch 9/10] [Batch 202/1081] [D loss: 0.047715] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.992432] time: 1:29:23.037132\n",
      "(10, 128, 128, 3)\n",
      "0.9275121\n",
      "[Epoch 9/10] [Batch 203/1081] [D loss: 0.047693] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.933712] time: 1:29:23.602714\n",
      "(10, 128, 128, 3)\n",
      "0.9100211\n",
      "[Epoch 9/10] [Batch 204/1081] [D loss: 0.047498] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.580492] time: 1:29:24.146480\n",
      "(10, 128, 128, 3)\n",
      "0.91383934\n",
      "[Epoch 9/10] [Batch 205/1081] [D loss: 0.047315] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.937622] time: 1:29:24.707127\n",
      "(10, 128, 128, 3)\n",
      "0.9122936\n",
      "[Epoch 9/10] [Batch 206/1081] [D loss: 0.048399] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.995408] time: 1:29:25.251792\n",
      "(10, 128, 128, 3)\n",
      "0.90072936\n",
      "[Epoch 9/10] [Batch 207/1081] [D loss: 0.047043] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.225163] time: 1:29:25.808086\n",
      "(10, 128, 128, 3)\n",
      "0.8953523\n",
      "[Epoch 9/10] [Batch 208/1081] [D loss: 0.047572] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.381354] time: 1:29:26.308192\n",
      "(10, 128, 128, 3)\n",
      "0.9314084\n",
      "[Epoch 9/10] [Batch 209/1081] [D loss: 0.046915] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.625523] time: 1:29:26.900367\n",
      "(10, 128, 128, 3)\n",
      "0.8617917\n",
      "[Epoch 9/10] [Batch 210/1081] [D loss: 0.046572] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.229084] time: 1:29:27.437921\n",
      "(10, 128, 128, 3)\n",
      "0.93077135\n",
      "[Epoch 9/10] [Batch 211/1081] [D loss: 0.046454] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.118998] time: 1:29:28.041507\n",
      "(10, 128, 128, 3)\n",
      "0.9143097\n",
      "[Epoch 9/10] [Batch 212/1081] [D loss: 0.046857] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.374703] time: 1:29:28.603489\n",
      "(10, 128, 128, 3)\n",
      "0.86836505\n",
      "[Epoch 9/10] [Batch 213/1081] [D loss: 0.046396] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.162140] time: 1:29:29.157153\n",
      "(10, 128, 128, 3)\n",
      "0.9322327\n",
      "[Epoch 9/10] [Batch 214/1081] [D loss: 0.049860] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.394301] time: 1:29:29.690054\n",
      "(10, 128, 128, 3)\n",
      "0.8969249\n",
      "[Epoch 9/10] [Batch 215/1081] [D loss: 0.048868] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.692448] time: 1:29:30.247239\n",
      "(10, 128, 128, 3)\n",
      "0.8655507\n",
      "[Epoch 9/10] [Batch 216/1081] [D loss: 0.046721] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.343481] time: 1:29:30.832007\n",
      "(10, 128, 128, 3)\n",
      "0.8602331\n",
      "[Epoch 9/10] [Batch 217/1081] [D loss: 0.055535] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.108654] time: 1:29:31.480245\n",
      "(10, 128, 128, 3)\n",
      "0.937681\n",
      "[Epoch 9/10] [Batch 218/1081] [D loss: 0.047113] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.319028] time: 1:29:32.101326\n",
      "(10, 128, 128, 3)\n",
      "0.89804745\n",
      "[Epoch 9/10] [Batch 219/1081] [D loss: 0.047192] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.526093] time: 1:29:32.793352\n",
      "(10, 128, 128, 3)\n",
      "0.8527858\n",
      "[Epoch 9/10] [Batch 220/1081] [D loss: 0.048868] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.964109] time: 1:29:33.430247\n",
      "(10, 128, 128, 3)\n",
      "0.89794827\n",
      "[Epoch 9/10] [Batch 221/1081] [D loss: 0.052053] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.718545] time: 1:29:34.103233\n",
      "(10, 128, 128, 3)\n",
      "0.8806572\n",
      "[Epoch 9/10] [Batch 222/1081] [D loss: 0.049102] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.610052] time: 1:29:34.711620\n",
      "(10, 128, 128, 3)\n",
      "0.92143613\n",
      "[Epoch 9/10] [Batch 223/1081] [D loss: 0.047544] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.809192] time: 1:29:35.345886\n",
      "(10, 128, 128, 3)\n",
      "0.8811245\n",
      "[Epoch 9/10] [Batch 224/1081] [D loss: 0.046306] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.685606] time: 1:29:35.989154\n",
      "(10, 128, 128, 3)\n",
      "0.94436306\n",
      "[Epoch 9/10] [Batch 225/1081] [D loss: 0.046735] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.304571] time: 1:29:36.614547\n",
      "(10, 128, 128, 3)\n",
      "0.89061207\n",
      "[Epoch 9/10] [Batch 226/1081] [D loss: 0.049319] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.646975] time: 1:29:37.266136\n",
      "(10, 128, 128, 3)\n",
      "0.9297216\n",
      "[Epoch 9/10] [Batch 227/1081] [D loss: 0.045593] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.671016] time: 1:29:37.981598\n",
      "(10, 128, 128, 3)\n",
      "0.9232386\n",
      "[Epoch 9/10] [Batch 228/1081] [D loss: 0.049466] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.996739] time: 1:29:38.724528\n",
      "(10, 128, 128, 3)\n",
      "0.90719223\n",
      "[Epoch 9/10] [Batch 229/1081] [D loss: 0.045878] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.727927] time: 1:29:39.434022\n",
      "(10, 128, 128, 3)\n",
      "0.89314514\n",
      "[Epoch 9/10] [Batch 230/1081] [D loss: 0.047854] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.780747] time: 1:29:40.037836\n",
      "(10, 128, 128, 3)\n",
      "0.8609392\n",
      "[Epoch 9/10] [Batch 231/1081] [D loss: 0.045797] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.621067] time: 1:29:40.713163\n",
      "(10, 128, 128, 3)\n",
      "0.9133795\n",
      "[Epoch 9/10] [Batch 232/1081] [D loss: 0.047140] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.981920] time: 1:29:41.431030\n",
      "(10, 128, 128, 3)\n",
      "0.93777704\n",
      "[Epoch 9/10] [Batch 233/1081] [D loss: 0.046237] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.081752] time: 1:29:42.073526\n",
      "(10, 128, 128, 3)\n",
      "0.9359855\n",
      "[Epoch 9/10] [Batch 234/1081] [D loss: 0.048152] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.960561] time: 1:29:42.731546\n",
      "(10, 128, 128, 3)\n",
      "0.85772365\n",
      "[Epoch 9/10] [Batch 235/1081] [D loss: 0.046744] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.131844] time: 1:29:43.392616\n",
      "(10, 128, 128, 3)\n",
      "0.96623605\n",
      "[Epoch 9/10] [Batch 236/1081] [D loss: 0.045569] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.031269] time: 1:29:44.018947\n",
      "(10, 128, 128, 3)\n",
      "0.92534226\n",
      "[Epoch 9/10] [Batch 237/1081] [D loss: 0.045510] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.234245] time: 1:29:44.681936\n",
      "(10, 128, 128, 3)\n",
      "0.8897064\n",
      "[Epoch 9/10] [Batch 238/1081] [D loss: 0.045795] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.332993] time: 1:29:45.351742\n",
      "(10, 128, 128, 3)\n",
      "0.9629454\n",
      "[Epoch 9/10] [Batch 239/1081] [D loss: 0.044916] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.739589] time: 1:29:46.055383\n",
      "(10, 128, 128, 3)\n",
      "0.9141442\n",
      "[Epoch 9/10] [Batch 240/1081] [D loss: 0.044876] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.187771] time: 1:29:46.668081\n",
      "(10, 128, 128, 3)\n",
      "0.9515121\n",
      "[Epoch 9/10] [Batch 241/1081] [D loss: 0.044749] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.132776] time: 1:29:47.326456\n",
      "(10, 128, 128, 3)\n",
      "0.80561584\n",
      "[Epoch 9/10] [Batch 242/1081] [D loss: 0.044938] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.549984] time: 1:29:47.945754\n",
      "(10, 128, 128, 3)\n",
      "0.88243383\n",
      "[Epoch 9/10] [Batch 243/1081] [D loss: 0.045887] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.463237] time: 1:29:48.641035\n",
      "(10, 128, 128, 3)\n",
      "0.9451175\n",
      "[Epoch 9/10] [Batch 244/1081] [D loss: 0.489097] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 3.671731] time: 1:29:49.274242\n",
      "(10, 128, 128, 3)\n",
      "0.9720804\n",
      "[Epoch 9/10] [Batch 245/1081] [D loss: 0.176234] [D acc: 0.85 (1.00 real, 0.70 fake)] [G loss: 3.998402] time: 1:29:49.888182\n",
      "(10, 128, 128, 3)\n",
      "0.9225958\n",
      "[Epoch 9/10] [Batch 246/1081] [D loss: 0.112765] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.948195] time: 1:29:50.534350\n",
      "(10, 128, 128, 3)\n",
      "0.9056802\n",
      "[Epoch 9/10] [Batch 247/1081] [D loss: 0.131039] [D acc: 0.85 (0.70 real, 1.00 fake)] [G loss: 3.603109] time: 1:29:51.214549\n",
      "(10, 128, 128, 3)\n",
      "0.88610286\n",
      "[Epoch 9/10] [Batch 248/1081] [D loss: 0.079829] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.865016] time: 1:29:51.904701\n",
      "(10, 128, 128, 3)\n",
      "0.9200303\n",
      "[Epoch 9/10] [Batch 249/1081] [D loss: 0.076699] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.382073] time: 1:29:52.549529\n",
      "(10, 128, 128, 3)\n",
      "0.9254194\n",
      "[Epoch 9/10] [Batch 250/1081] [D loss: 0.059767] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.993747] time: 1:29:53.164942\n",
      "(10, 128, 128, 3)\n",
      "0.86772823\n",
      "[Epoch 9/10] [Batch 251/1081] [D loss: 0.060014] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.955611] time: 1:29:53.785718\n",
      "(10, 128, 128, 3)\n",
      "0.931995\n",
      "[Epoch 9/10] [Batch 252/1081] [D loss: 0.058505] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.114345] time: 1:29:54.447144\n",
      "(10, 128, 128, 3)\n",
      "0.9352949\n",
      "[Epoch 9/10] [Batch 253/1081] [D loss: 0.054540] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.207487] time: 1:29:55.101801\n",
      "(10, 128, 128, 3)\n",
      "0.8862913\n",
      "[Epoch 9/10] [Batch 254/1081] [D loss: 0.054342] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.628051] time: 1:29:55.788051\n",
      "(10, 128, 128, 3)\n",
      "0.9083533\n",
      "[Epoch 9/10] [Batch 255/1081] [D loss: 0.056224] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.488090] time: 1:29:56.402238\n",
      "(10, 128, 128, 3)\n",
      "0.9000783\n",
      "[Epoch 9/10] [Batch 256/1081] [D loss: 0.054784] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.409740] time: 1:29:57.036449\n",
      "(10, 128, 128, 3)\n",
      "0.90036947\n",
      "[Epoch 9/10] [Batch 257/1081] [D loss: 0.056302] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.430956] time: 1:29:57.688821\n",
      "(10, 128, 128, 3)\n",
      "0.9194619\n",
      "[Epoch 9/10] [Batch 258/1081] [D loss: 0.059823] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.801883] time: 1:29:58.302351\n",
      "(10, 128, 128, 3)\n",
      "0.87699777\n",
      "[Epoch 9/10] [Batch 259/1081] [D loss: 0.055073] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.626330] time: 1:29:58.991204\n",
      "(10, 128, 128, 3)\n",
      "0.915363\n",
      "[Epoch 9/10] [Batch 260/1081] [D loss: 0.055044] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.483713] time: 1:29:59.582499\n",
      "(10, 128, 128, 3)\n",
      "0.94722337\n",
      "[Epoch 9/10] [Batch 261/1081] [D loss: 0.055048] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.577229] time: 1:30:00.250506\n",
      "(10, 128, 128, 3)\n",
      "0.93078834\n",
      "[Epoch 9/10] [Batch 262/1081] [D loss: 0.052852] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.898876] time: 1:30:00.889311\n",
      "(10, 128, 128, 3)\n",
      "0.9173886\n",
      "[Epoch 9/10] [Batch 263/1081] [D loss: 0.051658] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.282412] time: 1:30:01.495831\n",
      "(10, 128, 128, 3)\n",
      "0.89925975\n",
      "[Epoch 9/10] [Batch 264/1081] [D loss: 0.052225] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.386400] time: 1:30:02.116757\n",
      "(10, 128, 128, 3)\n",
      "0.87892723\n",
      "[Epoch 9/10] [Batch 265/1081] [D loss: 0.052761] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.003739] time: 1:30:02.771092\n",
      "(10, 128, 128, 3)\n",
      "0.8845244\n",
      "[Epoch 9/10] [Batch 266/1081] [D loss: 0.051320] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.598437] time: 1:30:03.409243\n",
      "(10, 128, 128, 3)\n",
      "0.8907952\n",
      "[Epoch 9/10] [Batch 267/1081] [D loss: 0.051605] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.865460] time: 1:30:04.095685\n",
      "(10, 128, 128, 3)\n",
      "0.9198273\n",
      "[Epoch 9/10] [Batch 268/1081] [D loss: 0.052352] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.961970] time: 1:30:04.690069\n",
      "(10, 128, 128, 3)\n",
      "0.8781155\n",
      "[Epoch 9/10] [Batch 269/1081] [D loss: 0.051833] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.981467] time: 1:30:05.332488\n",
      "(10, 128, 128, 3)\n",
      "0.9220318\n",
      "[Epoch 9/10] [Batch 270/1081] [D loss: 0.051045] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.133392] time: 1:30:05.975505\n",
      "(10, 128, 128, 3)\n",
      "0.86714506\n",
      "[Epoch 9/10] [Batch 271/1081] [D loss: 0.050577] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.156977] time: 1:30:06.654163\n",
      "(10, 128, 128, 3)\n",
      "0.8813588\n",
      "[Epoch 9/10] [Batch 272/1081] [D loss: 0.050409] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.670648] time: 1:30:07.337452\n",
      "(10, 128, 128, 3)\n",
      "0.93301624\n",
      "[Epoch 9/10] [Batch 273/1081] [D loss: 0.050820] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.342552] time: 1:30:08.033297\n",
      "(10, 128, 128, 3)\n",
      "0.90505356\n",
      "[Epoch 9/10] [Batch 274/1081] [D loss: 0.050078] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.966325] time: 1:30:08.629127\n",
      "(10, 128, 128, 3)\n",
      "0.9489673\n",
      "[Epoch 9/10] [Batch 275/1081] [D loss: 0.050311] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.773587] time: 1:30:09.235828\n",
      "(10, 128, 128, 3)\n",
      "0.9263835\n",
      "[Epoch 9/10] [Batch 276/1081] [D loss: 0.049839] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.037225] time: 1:30:09.892501\n",
      "(10, 128, 128, 3)\n",
      "0.90953606\n",
      "[Epoch 9/10] [Batch 277/1081] [D loss: 0.049394] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.256946] time: 1:30:10.570331\n",
      "(10, 128, 128, 3)\n",
      "0.9451134\n",
      "[Epoch 9/10] [Batch 278/1081] [D loss: 0.051224] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.583178] time: 1:30:11.222661\n",
      "(10, 128, 128, 3)\n",
      "0.9145875\n",
      "[Epoch 9/10] [Batch 279/1081] [D loss: 0.049418] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.290203] time: 1:30:11.820283\n",
      "(10, 128, 128, 3)\n",
      "0.8631442\n",
      "[Epoch 9/10] [Batch 280/1081] [D loss: 0.049122] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.588596] time: 1:30:12.500808\n",
      "(10, 128, 128, 3)\n",
      "0.8993748\n",
      "[Epoch 9/10] [Batch 281/1081] [D loss: 0.054219] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.197520] time: 1:30:13.166942\n",
      "(10, 128, 128, 3)\n",
      "0.8806737\n",
      "[Epoch 9/10] [Batch 282/1081] [D loss: 0.050521] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.151364] time: 1:30:13.785191\n",
      "(10, 128, 128, 3)\n",
      "0.8638218\n",
      "[Epoch 9/10] [Batch 283/1081] [D loss: 0.057333] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.930130] time: 1:30:14.427925\n",
      "(10, 128, 128, 3)\n",
      "0.9094737\n",
      "[Epoch 9/10] [Batch 284/1081] [D loss: 0.053635] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.909650] time: 1:30:15.061314\n",
      "(10, 128, 128, 3)\n",
      "0.92013437\n",
      "[Epoch 9/10] [Batch 285/1081] [D loss: 0.048820] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.251596] time: 1:30:15.726384\n",
      "(10, 128, 128, 3)\n",
      "0.88702774\n",
      "[Epoch 9/10] [Batch 286/1081] [D loss: 0.050300] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.649396] time: 1:30:16.386511\n",
      "(10, 128, 128, 3)\n",
      "0.8880384\n",
      "[Epoch 9/10] [Batch 287/1081] [D loss: 0.050179] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.553846] time: 1:30:17.024992\n",
      "(10, 128, 128, 3)\n",
      "0.8836878\n",
      "[Epoch 9/10] [Batch 288/1081] [D loss: 0.048970] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.825322] time: 1:30:17.634950\n",
      "(10, 128, 128, 3)\n",
      "0.83121324\n",
      "[Epoch 9/10] [Batch 289/1081] [D loss: 0.048142] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.510417] time: 1:30:18.281380\n",
      "(10, 128, 128, 3)\n",
      "0.9277137\n",
      "[Epoch 9/10] [Batch 290/1081] [D loss: 0.048606] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.183262] time: 1:30:18.927883\n",
      "(10, 128, 128, 3)\n",
      "0.9713724\n",
      "[Epoch 9/10] [Batch 291/1081] [D loss: 0.047792] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.474930] time: 1:30:19.575228\n",
      "(10, 128, 128, 3)\n",
      "0.94662666\n",
      "[Epoch 9/10] [Batch 292/1081] [D loss: 0.049723] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.272981] time: 1:30:20.244402\n",
      "(10, 128, 128, 3)\n",
      "0.87900156\n",
      "[Epoch 9/10] [Batch 293/1081] [D loss: 0.051369] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.280396] time: 1:30:20.926879\n",
      "(10, 128, 128, 3)\n",
      "0.9000328\n",
      "[Epoch 9/10] [Batch 294/1081] [D loss: 0.061550] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.578167] time: 1:30:21.529979\n",
      "(10, 128, 128, 3)\n",
      "0.9029975\n",
      "[Epoch 9/10] [Batch 295/1081] [D loss: 0.050317] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.722140] time: 1:30:22.182475\n",
      "(10, 128, 128, 3)\n",
      "0.91732496\n",
      "[Epoch 9/10] [Batch 296/1081] [D loss: 0.058106] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.328580] time: 1:30:22.834809\n",
      "(10, 128, 128, 3)\n",
      "0.9398572\n",
      "[Epoch 9/10] [Batch 297/1081] [D loss: 0.055085] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.438034] time: 1:30:23.463371\n",
      "(10, 128, 128, 3)\n",
      "0.91651416\n",
      "[Epoch 9/10] [Batch 298/1081] [D loss: 0.048603] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.436729] time: 1:30:24.113133\n",
      "(10, 128, 128, 3)\n",
      "0.8845229\n",
      "[Epoch 9/10] [Batch 299/1081] [D loss: 0.047629] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.365788] time: 1:30:24.812720\n",
      "(10, 128, 128, 3)\n",
      "0.90358996\n",
      "[Epoch 9/10] [Batch 300/1081] [D loss: 0.050052] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.803655] time: 1:30:25.452374\n",
      "(10, 128, 128, 3)\n",
      "0.88850313\n",
      "[Epoch 9/10] [Batch 301/1081] [D loss: 0.047811] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.910028] time: 1:30:26.091935\n",
      "(10, 128, 128, 3)\n",
      "0.8871333\n",
      "[Epoch 9/10] [Batch 302/1081] [D loss: 0.047577] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.413629] time: 1:30:26.727881\n",
      "(10, 128, 128, 3)\n",
      "0.9414387\n",
      "[Epoch 9/10] [Batch 303/1081] [D loss: 0.046991] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.148485] time: 1:30:27.330850\n",
      "(10, 128, 128, 3)\n",
      "0.89774984\n",
      "[Epoch 9/10] [Batch 304/1081] [D loss: 0.046388] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.417510] time: 1:30:27.987984\n",
      "(10, 128, 128, 3)\n",
      "0.9127199\n",
      "[Epoch 9/10] [Batch 305/1081] [D loss: 0.052238] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.951388] time: 1:30:28.583652\n",
      "(10, 128, 128, 3)\n",
      "0.9299092\n",
      "[Epoch 9/10] [Batch 306/1081] [D loss: 0.046767] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.567861] time: 1:30:29.213654\n",
      "(10, 128, 128, 3)\n",
      "0.9713495\n",
      "[Epoch 9/10] [Batch 307/1081] [D loss: 0.048351] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.942372] time: 1:30:29.865394\n",
      "(10, 128, 128, 3)\n",
      "0.92981166\n",
      "[Epoch 9/10] [Batch 308/1081] [D loss: 0.053615] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.216550] time: 1:30:30.527020\n",
      "(10, 128, 128, 3)\n",
      "0.919122\n",
      "[Epoch 9/10] [Batch 309/1081] [D loss: 0.048425] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.758785] time: 1:30:31.163369\n",
      "(10, 128, 128, 3)\n",
      "0.92619747\n",
      "[Epoch 9/10] [Batch 310/1081] [D loss: 0.045553] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.994648] time: 1:30:31.810496\n",
      "(10, 128, 128, 3)\n",
      "0.8859109\n",
      "[Epoch 9/10] [Batch 311/1081] [D loss: 0.045370] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.069914] time: 1:30:32.467703\n",
      "(10, 128, 128, 3)\n",
      "0.9249918\n",
      "[Epoch 9/10] [Batch 312/1081] [D loss: 0.045361] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.894497] time: 1:30:33.093913\n",
      "(10, 128, 128, 3)\n",
      "0.868159\n",
      "[Epoch 9/10] [Batch 313/1081] [D loss: 0.045880] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.484067] time: 1:30:33.747586\n",
      "(10, 128, 128, 3)\n",
      "0.8668258\n",
      "[Epoch 9/10] [Batch 314/1081] [D loss: 0.045722] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.571111] time: 1:30:34.410490\n",
      "(10, 128, 128, 3)\n",
      "0.93020934\n",
      "[Epoch 9/10] [Batch 315/1081] [D loss: 0.045612] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.314584] time: 1:30:35.060452\n",
      "(10, 128, 128, 3)\n",
      "0.92072815\n",
      "[Epoch 9/10] [Batch 316/1081] [D loss: 0.047983] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.029585] time: 1:30:35.732857\n",
      "(10, 128, 128, 3)\n",
      "0.9481125\n",
      "[Epoch 9/10] [Batch 317/1081] [D loss: 0.046702] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.797493] time: 1:30:36.371110\n",
      "(10, 128, 128, 3)\n",
      "0.8722232\n",
      "[Epoch 9/10] [Batch 318/1081] [D loss: 0.047667] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.444578] time: 1:30:37.027277\n",
      "(10, 128, 128, 3)\n",
      "0.93606853\n",
      "[Epoch 9/10] [Batch 319/1081] [D loss: 0.044905] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.800881] time: 1:30:37.648112\n",
      "(10, 128, 128, 3)\n",
      "0.8865083\n",
      "[Epoch 9/10] [Batch 320/1081] [D loss: 0.044983] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.179516] time: 1:30:38.299739\n",
      "(10, 128, 128, 3)\n",
      "0.92440224\n",
      "[Epoch 9/10] [Batch 321/1081] [D loss: 0.044621] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.201565] time: 1:30:38.932880\n",
      "(10, 128, 128, 3)\n",
      "0.96647674\n",
      "[Epoch 9/10] [Batch 322/1081] [D loss: 0.044395] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.464223] time: 1:30:39.564426\n",
      "(10, 128, 128, 3)\n",
      "0.9498809\n",
      "[Epoch 9/10] [Batch 323/1081] [D loss: 0.044319] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.835546] time: 1:30:40.194467\n",
      "(10, 128, 128, 3)\n",
      "0.9200099\n",
      "[Epoch 9/10] [Batch 324/1081] [D loss: 0.044235] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.553082] time: 1:30:40.867231\n",
      "(10, 128, 128, 3)\n",
      "0.8800294\n",
      "[Epoch 9/10] [Batch 325/1081] [D loss: 0.044588] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.065690] time: 1:30:41.518393\n",
      "(10, 128, 128, 3)\n",
      "0.87086296\n",
      "[Epoch 9/10] [Batch 326/1081] [D loss: 0.044593] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.963203] time: 1:30:42.172678\n",
      "(10, 128, 128, 3)\n",
      "0.8911135\n",
      "[Epoch 9/10] [Batch 327/1081] [D loss: 0.044262] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.871390] time: 1:30:42.823687\n",
      "(10, 128, 128, 3)\n",
      "0.94296116\n",
      "[Epoch 9/10] [Batch 328/1081] [D loss: 0.045131] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.548522] time: 1:30:43.485637\n",
      "(10, 128, 128, 3)\n",
      "0.9226446\n",
      "[Epoch 9/10] [Batch 329/1081] [D loss: 0.043784] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.000264] time: 1:30:44.151509\n",
      "(10, 128, 128, 3)\n",
      "0.91219956\n",
      "[Epoch 9/10] [Batch 330/1081] [D loss: 0.044018] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.246116] time: 1:30:44.815433\n",
      "(10, 128, 128, 3)\n",
      "0.8877354\n",
      "[Epoch 9/10] [Batch 331/1081] [D loss: 0.044545] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.319079] time: 1:30:45.464217\n",
      "(10, 128, 128, 3)\n",
      "0.85909706\n",
      "[Epoch 9/10] [Batch 332/1081] [D loss: 0.046003] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.882318] time: 1:30:46.144729\n",
      "(10, 128, 128, 3)\n",
      "0.914653\n",
      "[Epoch 9/10] [Batch 333/1081] [D loss: 0.044945] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.675820] time: 1:30:46.799463\n",
      "(10, 128, 128, 3)\n",
      "0.88943505\n",
      "[Epoch 9/10] [Batch 334/1081] [D loss: 0.049979] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.379795] time: 1:30:47.468297\n",
      "(10, 128, 128, 3)\n",
      "0.89054674\n",
      "[Epoch 9/10] [Batch 335/1081] [D loss: 0.045565] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.169515] time: 1:30:48.106463\n",
      "(10, 128, 128, 3)\n",
      "0.89056826\n",
      "[Epoch 9/10] [Batch 336/1081] [D loss: 0.045612] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.222834] time: 1:30:48.769219\n",
      "(10, 128, 128, 3)\n",
      "0.9273575\n",
      "[Epoch 9/10] [Batch 337/1081] [D loss: 0.045351] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.208396] time: 1:30:49.415424\n",
      "(10, 128, 128, 3)\n",
      "0.90413755\n",
      "[Epoch 9/10] [Batch 338/1081] [D loss: 0.044087] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.758492] time: 1:30:50.089981\n",
      "(10, 128, 128, 3)\n",
      "0.8658182\n",
      "[Epoch 9/10] [Batch 339/1081] [D loss: 0.044079] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.191801] time: 1:30:50.726060\n",
      "(10, 128, 128, 3)\n",
      "0.9410413\n",
      "[Epoch 9/10] [Batch 340/1081] [D loss: 0.043701] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.972050] time: 1:30:51.376305\n",
      "(10, 128, 128, 3)\n",
      "0.9247477\n",
      "[Epoch 9/10] [Batch 341/1081] [D loss: 0.042917] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.798236] time: 1:30:52.066719\n",
      "(10, 128, 128, 3)\n",
      "0.9485185\n",
      "[Epoch 9/10] [Batch 342/1081] [D loss: 0.043440] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.007360] time: 1:30:52.689535\n",
      "(10, 128, 128, 3)\n",
      "0.91527945\n",
      "[Epoch 9/10] [Batch 343/1081] [D loss: 0.043245] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.610439] time: 1:30:53.353502\n",
      "(10, 128, 128, 3)\n",
      "0.940155\n",
      "[Epoch 9/10] [Batch 344/1081] [D loss: 0.044960] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.140462] time: 1:30:53.986896\n",
      "(10, 128, 128, 3)\n",
      "0.9010052\n",
      "[Epoch 9/10] [Batch 345/1081] [D loss: 0.042741] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.385637] time: 1:30:54.600042\n",
      "(10, 128, 128, 3)\n",
      "0.9053969\n",
      "[Epoch 9/10] [Batch 346/1081] [D loss: 0.042691] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.415904] time: 1:30:55.259656\n",
      "(10, 128, 128, 3)\n",
      "0.8834443\n",
      "[Epoch 9/10] [Batch 347/1081] [D loss: 0.042280] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.389302] time: 1:30:55.901497\n",
      "(10, 128, 128, 3)\n",
      "0.9086728\n",
      "[Epoch 9/10] [Batch 348/1081] [D loss: 0.042357] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.168346] time: 1:30:56.538770\n",
      "(10, 128, 128, 3)\n",
      "0.9313231\n",
      "[Epoch 9/10] [Batch 349/1081] [D loss: 0.042215] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.871302] time: 1:30:57.224840\n",
      "(10, 128, 128, 3)\n",
      "0.93820715\n",
      "[Epoch 9/10] [Batch 350/1081] [D loss: 0.041898] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.058864] time: 1:30:57.924153\n",
      "(10, 128, 128, 3)\n",
      "0.9463222\n",
      "[Epoch 9/10] [Batch 351/1081] [D loss: 0.042006] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.649560] time: 1:30:58.617357\n",
      "(10, 128, 128, 3)\n",
      "0.8782079\n",
      "[Epoch 9/10] [Batch 352/1081] [D loss: 0.044119] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.277802] time: 1:30:59.257514\n",
      "(10, 128, 128, 3)\n",
      "0.8915821\n",
      "[Epoch 9/10] [Batch 353/1081] [D loss: 0.043133] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.363834] time: 1:30:59.901168\n",
      "(10, 128, 128, 3)\n",
      "0.8779099\n",
      "[Epoch 9/10] [Batch 354/1081] [D loss: 0.045190] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.692424] time: 1:31:00.536820\n",
      "(10, 128, 128, 3)\n",
      "0.9356497\n",
      "[Epoch 9/10] [Batch 355/1081] [D loss: 0.042915] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.407422] time: 1:31:01.225399\n",
      "(10, 128, 128, 3)\n",
      "0.91146046\n",
      "[Epoch 9/10] [Batch 356/1081] [D loss: 0.041615] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.852198] time: 1:31:01.907274\n",
      "(10, 128, 128, 3)\n",
      "0.9351271\n",
      "[Epoch 9/10] [Batch 357/1081] [D loss: 0.041904] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.025442] time: 1:31:02.543890\n",
      "(10, 128, 128, 3)\n",
      "0.9622998\n",
      "[Epoch 9/10] [Batch 358/1081] [D loss: 0.301245] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 4.758542] time: 1:31:03.195765\n",
      "(10, 128, 128, 3)\n",
      "0.85993594\n",
      "[Epoch 9/10] [Batch 359/1081] [D loss: 0.086112] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.824152] time: 1:31:03.822836\n",
      "(10, 128, 128, 3)\n",
      "0.90789485\n",
      "[Epoch 9/10] [Batch 360/1081] [D loss: 0.226263] [D acc: 0.70 (0.50 real, 0.90 fake)] [G loss: 4.350658] time: 1:31:04.490402\n",
      "(10, 128, 128, 3)\n",
      "0.9345251\n",
      "[Epoch 9/10] [Batch 361/1081] [D loss: 0.162739] [D acc: 0.90 (1.00 real, 0.80 fake)] [G loss: 2.905543] time: 1:31:05.132994\n",
      "(10, 128, 128, 3)\n",
      "0.93029165\n",
      "[Epoch 9/10] [Batch 362/1081] [D loss: 0.268719] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 4.191728] time: 1:31:05.823328\n",
      "(10, 128, 128, 3)\n",
      "0.967536\n",
      "[Epoch 9/10] [Batch 363/1081] [D loss: 0.085272] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 5.408751] time: 1:31:06.501914\n",
      "(10, 128, 128, 3)\n",
      "0.9102013\n",
      "[Epoch 9/10] [Batch 364/1081] [D loss: 0.835019] [D acc: 0.15 (0.30 real, 0.00 fake)] [G loss: 2.727942] time: 1:31:07.128968\n",
      "(10, 128, 128, 3)\n",
      "0.8674601\n",
      "[Epoch 9/10] [Batch 365/1081] [D loss: 0.348393] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 4.144242] time: 1:31:07.806345\n",
      "(10, 128, 128, 3)\n",
      "0.91660666\n",
      "[Epoch 9/10] [Batch 366/1081] [D loss: 0.453994] [D acc: 0.30 (0.20 real, 0.40 fake)] [G loss: 3.656353] time: 1:31:08.451083\n",
      "(10, 128, 128, 3)\n",
      "0.8855737\n",
      "[Epoch 9/10] [Batch 367/1081] [D loss: 0.409251] [D acc: 0.15 (0.30 real, 0.00 fake)] [G loss: 4.216944] time: 1:31:09.113864\n",
      "(10, 128, 128, 3)\n",
      "0.8963823\n",
      "[Epoch 9/10] [Batch 368/1081] [D loss: 0.350205] [D acc: 0.35 (0.60 real, 0.10 fake)] [G loss: 4.180936] time: 1:31:09.814376\n",
      "(10, 128, 128, 3)\n",
      "0.90931296\n",
      "[Epoch 9/10] [Batch 369/1081] [D loss: 0.331571] [D acc: 0.45 (0.60 real, 0.30 fake)] [G loss: 3.446809] time: 1:31:10.427346\n",
      "(10, 128, 128, 3)\n",
      "0.9738805\n",
      "[Epoch 9/10] [Batch 370/1081] [D loss: 0.347182] [D acc: 0.20 (0.30 real, 0.10 fake)] [G loss: 3.936668] time: 1:31:11.135010\n",
      "(10, 128, 128, 3)\n",
      "0.9054157\n",
      "[Epoch 9/10] [Batch 371/1081] [D loss: 0.336063] [D acc: 0.40 (0.10 real, 0.70 fake)] [G loss: 4.355782] time: 1:31:11.800416\n",
      "(10, 128, 128, 3)\n",
      "0.8991788\n",
      "[Epoch 9/10] [Batch 372/1081] [D loss: 0.262146] [D acc: 0.65 (0.40 real, 0.90 fake)] [G loss: 4.337803] time: 1:31:12.418850\n",
      "(10, 128, 128, 3)\n",
      "0.9038293\n",
      "[Epoch 9/10] [Batch 373/1081] [D loss: 0.156630] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.101562] time: 1:31:13.083060\n",
      "(10, 128, 128, 3)\n",
      "0.9081936\n",
      "[Epoch 9/10] [Batch 374/1081] [D loss: 0.126564] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.404673] time: 1:31:13.752184\n",
      "(10, 128, 128, 3)\n",
      "0.9079327\n",
      "[Epoch 9/10] [Batch 375/1081] [D loss: 0.103078] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.102324] time: 1:31:14.411954\n",
      "(10, 128, 128, 3)\n",
      "0.8912119\n",
      "[Epoch 9/10] [Batch 376/1081] [D loss: 0.106637] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.159997] time: 1:31:15.041933\n",
      "(10, 128, 128, 3)\n",
      "0.8895857\n",
      "[Epoch 9/10] [Batch 377/1081] [D loss: 0.076088] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.480805] time: 1:31:15.730532\n",
      "(10, 128, 128, 3)\n",
      "0.90348405\n",
      "[Epoch 9/10] [Batch 378/1081] [D loss: 0.090536] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.914870] time: 1:31:16.367277\n",
      "(10, 128, 128, 3)\n",
      "0.88168126\n",
      "[Epoch 9/10] [Batch 379/1081] [D loss: 0.094202] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.431707] time: 1:31:17.065979\n",
      "(10, 128, 128, 3)\n",
      "0.88750845\n",
      "[Epoch 9/10] [Batch 380/1081] [D loss: 0.070402] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.218411] time: 1:31:17.725354\n",
      "(10, 128, 128, 3)\n",
      "0.9170408\n",
      "[Epoch 9/10] [Batch 381/1081] [D loss: 0.068056] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.046870] time: 1:31:18.331942\n",
      "(10, 128, 128, 3)\n",
      "0.92289263\n",
      "[Epoch 9/10] [Batch 382/1081] [D loss: 0.066836] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.635251] time: 1:31:19.021259\n",
      "(10, 128, 128, 3)\n",
      "0.8733713\n",
      "[Epoch 9/10] [Batch 383/1081] [D loss: 0.071839] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.754641] time: 1:31:19.695612\n",
      "(10, 128, 128, 3)\n",
      "0.92670614\n",
      "[Epoch 9/10] [Batch 384/1081] [D loss: 0.066465] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.822657] time: 1:31:20.366958\n",
      "(10, 128, 128, 3)\n",
      "0.8950057\n",
      "[Epoch 9/10] [Batch 385/1081] [D loss: 0.075332] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.703793] time: 1:31:21.020895\n",
      "(10, 128, 128, 3)\n",
      "0.9347431\n",
      "[Epoch 9/10] [Batch 386/1081] [D loss: 0.067555] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.887178] time: 1:31:21.677501\n",
      "(10, 128, 128, 3)\n",
      "0.9006429\n",
      "[Epoch 9/10] [Batch 387/1081] [D loss: 0.064146] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.582965] time: 1:31:22.336864\n",
      "(10, 128, 128, 3)\n",
      "0.983015\n",
      "[Epoch 9/10] [Batch 388/1081] [D loss: 0.062905] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.095248] time: 1:31:22.959717\n",
      "(10, 128, 128, 3)\n",
      "0.8707638\n",
      "[Epoch 9/10] [Batch 389/1081] [D loss: 0.115412] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.105246] time: 1:31:23.595718\n",
      "(10, 128, 128, 3)\n",
      "0.86690336\n",
      "[Epoch 9/10] [Batch 390/1081] [D loss: 0.070884] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.623435] time: 1:31:24.302554\n",
      "(10, 128, 128, 3)\n",
      "0.9081745\n",
      "[Epoch 9/10] [Batch 391/1081] [D loss: 0.072534] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.353694] time: 1:31:24.910417\n",
      "(10, 128, 128, 3)\n",
      "0.892427\n",
      "[Epoch 9/10] [Batch 392/1081] [D loss: 0.075807] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.774411] time: 1:31:26.245572\n",
      "(10, 128, 128, 3)\n",
      "0.8947708\n",
      "[Epoch 9/10] [Batch 393/1081] [D loss: 0.084860] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.924747] time: 1:31:26.866522\n",
      "(10, 128, 128, 3)\n",
      "0.91571325\n",
      "[Epoch 9/10] [Batch 394/1081] [D loss: 0.078047] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.029718] time: 1:31:27.574471\n",
      "(10, 128, 128, 3)\n",
      "0.9432626\n",
      "[Epoch 9/10] [Batch 395/1081] [D loss: 0.065401] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.559542] time: 1:31:28.256724\n",
      "(10, 128, 128, 3)\n",
      "0.8864332\n",
      "[Epoch 9/10] [Batch 396/1081] [D loss: 0.064148] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.787052] time: 1:31:28.921330\n",
      "(10, 128, 128, 3)\n",
      "0.92417055\n",
      "[Epoch 9/10] [Batch 397/1081] [D loss: 0.065838] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.338216] time: 1:31:29.590949\n",
      "(10, 128, 128, 3)\n",
      "0.89359593\n",
      "[Epoch 9/10] [Batch 398/1081] [D loss: 0.061635] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.226945] time: 1:31:30.282723\n",
      "(10, 128, 128, 3)\n",
      "0.86211467\n",
      "[Epoch 9/10] [Batch 399/1081] [D loss: 0.062851] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.154317] time: 1:31:30.919887\n",
      "(10, 128, 128, 3)\n",
      "0.9671803\n",
      "[Epoch 9/10] [Batch 400/1081] [D loss: 0.064484] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.142565] time: 1:31:31.585209\n",
      "(10, 128, 128, 3)\n",
      "0.9240481\n",
      "[Epoch 9/10] [Batch 401/1081] [D loss: 0.061012] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.422552] time: 1:31:32.214476\n",
      "(10, 128, 128, 3)\n",
      "0.8864121\n",
      "[Epoch 9/10] [Batch 402/1081] [D loss: 0.060367] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.025564] time: 1:31:32.876535\n",
      "(10, 128, 128, 3)\n",
      "0.922189\n",
      "[Epoch 9/10] [Batch 403/1081] [D loss: 0.062914] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.907173] time: 1:31:33.570345\n",
      "(10, 128, 128, 3)\n",
      "0.90685654\n",
      "[Epoch 9/10] [Batch 404/1081] [D loss: 0.060249] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.251141] time: 1:31:34.273138\n",
      "(10, 128, 128, 3)\n",
      "0.9307053\n",
      "[Epoch 9/10] [Batch 405/1081] [D loss: 0.060726] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.024362] time: 1:31:34.945759\n",
      "(10, 128, 128, 3)\n",
      "0.897283\n",
      "[Epoch 9/10] [Batch 406/1081] [D loss: 0.060782] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.444262] time: 1:31:35.580689\n",
      "(10, 128, 128, 3)\n",
      "0.86344975\n",
      "[Epoch 9/10] [Batch 407/1081] [D loss: 0.084299] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.576593] time: 1:31:36.237828\n",
      "(10, 128, 128, 3)\n",
      "0.8416393\n",
      "[Epoch 9/10] [Batch 408/1081] [D loss: 0.071582] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.307892] time: 1:31:36.885965\n",
      "(10, 128, 128, 3)\n",
      "0.9305086\n",
      "[Epoch 9/10] [Batch 409/1081] [D loss: 0.061192] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.481943] time: 1:31:37.583965\n",
      "(10, 128, 128, 3)\n",
      "0.9399747\n",
      "[Epoch 9/10] [Batch 410/1081] [D loss: 0.060061] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.850671] time: 1:31:38.273626\n",
      "(10, 128, 128, 3)\n",
      "0.8986699\n",
      "[Epoch 9/10] [Batch 411/1081] [D loss: 0.058278] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.547234] time: 1:31:38.938956\n",
      "(10, 128, 128, 3)\n",
      "0.898566\n",
      "[Epoch 9/10] [Batch 412/1081] [D loss: 0.061448] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.797013] time: 1:31:39.687055\n",
      "(10, 128, 128, 3)\n",
      "0.9056316\n",
      "[Epoch 9/10] [Batch 413/1081] [D loss: 0.058257] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.758574] time: 1:31:40.377402\n",
      "(10, 128, 128, 3)\n",
      "0.98226213\n",
      "[Epoch 9/10] [Batch 414/1081] [D loss: 0.059922] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.395133] time: 1:31:41.005668\n",
      "(10, 128, 128, 3)\n",
      "0.9217345\n",
      "[Epoch 9/10] [Batch 415/1081] [D loss: 0.061606] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.379258] time: 1:31:41.637036\n",
      "(10, 128, 128, 3)\n",
      "0.8997572\n",
      "[Epoch 9/10] [Batch 416/1081] [D loss: 0.058376] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.711743] time: 1:31:42.319702\n",
      "(10, 128, 128, 3)\n",
      "0.9262247\n",
      "[Epoch 9/10] [Batch 417/1081] [D loss: 0.057137] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.809021] time: 1:31:43.047573\n",
      "(10, 128, 128, 3)\n",
      "0.9013495\n",
      "[Epoch 9/10] [Batch 418/1081] [D loss: 0.058209] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.719167] time: 1:31:43.747756\n",
      "(10, 128, 128, 3)\n",
      "0.94321877\n",
      "[Epoch 9/10] [Batch 419/1081] [D loss: 0.058467] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.887398] time: 1:31:44.378524\n",
      "(10, 128, 128, 3)\n",
      "0.9839985\n",
      "[Epoch 9/10] [Batch 420/1081] [D loss: 0.058229] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.732814] time: 1:31:45.076146\n",
      "(10, 128, 128, 3)\n",
      "0.9417154\n",
      "[Epoch 9/10] [Batch 421/1081] [D loss: 0.057693] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.950370] time: 1:31:45.747371\n",
      "(10, 128, 128, 3)\n",
      "0.9257067\n",
      "[Epoch 9/10] [Batch 422/1081] [D loss: 0.056333] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.489740] time: 1:31:46.445410\n",
      "(10, 128, 128, 3)\n",
      "0.94036156\n",
      "[Epoch 9/10] [Batch 423/1081] [D loss: 0.059609] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.509663] time: 1:31:47.054039\n",
      "(10, 128, 128, 3)\n",
      "0.8564976\n",
      "[Epoch 9/10] [Batch 424/1081] [D loss: 0.059529] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.298963] time: 1:31:47.714425\n",
      "(10, 128, 128, 3)\n",
      "0.877173\n",
      "[Epoch 9/10] [Batch 425/1081] [D loss: 0.056304] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.761503] time: 1:31:48.399051\n",
      "(10, 128, 128, 3)\n",
      "0.8834942\n",
      "[Epoch 9/10] [Batch 426/1081] [D loss: 0.059748] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.850868] time: 1:31:49.033997\n",
      "(10, 128, 128, 3)\n",
      "0.9140386\n",
      "[Epoch 9/10] [Batch 427/1081] [D loss: 0.055705] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.230499] time: 1:31:49.746083\n",
      "(10, 128, 128, 3)\n",
      "0.8633647\n",
      "[Epoch 9/10] [Batch 428/1081] [D loss: 0.055444] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.575886] time: 1:31:50.427505\n",
      "(10, 128, 128, 3)\n",
      "0.95513105\n",
      "[Epoch 9/10] [Batch 429/1081] [D loss: 0.186399] [D acc: 0.65 (0.30 real, 1.00 fake)] [G loss: 3.694562] time: 1:31:51.072680\n",
      "(10, 128, 128, 3)\n",
      "0.88487524\n",
      "[Epoch 9/10] [Batch 430/1081] [D loss: 0.160949] [D acc: 0.95 (1.00 real, 0.90 fake)] [G loss: 3.825037] time: 1:31:51.704393\n",
      "(10, 128, 128, 3)\n",
      "0.87260085\n",
      "[Epoch 9/10] [Batch 431/1081] [D loss: 0.061644] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.831010] time: 1:31:52.379391\n",
      "(10, 128, 128, 3)\n",
      "0.9427672\n",
      "[Epoch 9/10] [Batch 432/1081] [D loss: 0.069293] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.740981] time: 1:31:53.063314\n",
      "(10, 128, 128, 3)\n",
      "0.8487839\n",
      "[Epoch 9/10] [Batch 433/1081] [D loss: 0.068431] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.787250] time: 1:31:53.692540\n",
      "(10, 128, 128, 3)\n",
      "0.91219896\n",
      "[Epoch 9/10] [Batch 434/1081] [D loss: 0.064763] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.448576] time: 1:31:54.296030\n",
      "(10, 128, 128, 3)\n",
      "0.8851018\n",
      "[Epoch 9/10] [Batch 435/1081] [D loss: 0.072908] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.554702] time: 1:31:54.901446\n",
      "(10, 128, 128, 3)\n",
      "0.97209716\n",
      "[Epoch 9/10] [Batch 436/1081] [D loss: 0.063898] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.705634] time: 1:31:55.587168\n",
      "(10, 128, 128, 3)\n",
      "0.8651305\n",
      "[Epoch 9/10] [Batch 437/1081] [D loss: 0.061573] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.734096] time: 1:31:56.294493\n",
      "(10, 128, 128, 3)\n",
      "0.8609519\n",
      "[Epoch 9/10] [Batch 438/1081] [D loss: 0.062914] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.549574] time: 1:31:56.960062\n",
      "(10, 128, 128, 3)\n",
      "0.9310257\n",
      "[Epoch 9/10] [Batch 439/1081] [D loss: 0.063981] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.762405] time: 1:31:57.571518\n",
      "(10, 128, 128, 3)\n",
      "0.9632874\n",
      "[Epoch 9/10] [Batch 440/1081] [D loss: 0.062208] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.826656] time: 1:31:58.213926\n",
      "(10, 128, 128, 3)\n",
      "0.86370677\n",
      "[Epoch 9/10] [Batch 441/1081] [D loss: 0.062391] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.361564] time: 1:31:58.828911\n",
      "(10, 128, 128, 3)\n",
      "0.9491218\n",
      "[Epoch 9/10] [Batch 442/1081] [D loss: 0.062998] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.871374] time: 1:31:59.452338\n",
      "(10, 128, 128, 3)\n",
      "0.91039443\n",
      "[Epoch 9/10] [Batch 443/1081] [D loss: 0.059770] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.604476] time: 1:32:00.121082\n",
      "(10, 128, 128, 3)\n",
      "0.8794753\n",
      "[Epoch 9/10] [Batch 444/1081] [D loss: 0.060063] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.126996] time: 1:32:00.866615\n",
      "(10, 128, 128, 3)\n",
      "0.9268375\n",
      "[Epoch 9/10] [Batch 445/1081] [D loss: 0.681407] [D acc: 0.15 (0.00 real, 0.30 fake)] [G loss: 2.630022] time: 1:32:01.506065\n",
      "(10, 128, 128, 3)\n",
      "0.93493193\n",
      "[Epoch 9/10] [Batch 446/1081] [D loss: 0.154023] [D acc: 0.90 (1.00 real, 0.80 fake)] [G loss: 3.480832] time: 1:32:02.162122\n",
      "(10, 128, 128, 3)\n",
      "0.92223555\n",
      "[Epoch 9/10] [Batch 447/1081] [D loss: 0.067260] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.790287] time: 1:32:02.865610\n",
      "(10, 128, 128, 3)\n",
      "0.90738326\n",
      "[Epoch 9/10] [Batch 448/1081] [D loss: 0.075240] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.084292] time: 1:32:03.513235\n",
      "(10, 128, 128, 3)\n",
      "0.9183342\n",
      "[Epoch 9/10] [Batch 449/1081] [D loss: 0.063923] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.328364] time: 1:32:04.210623\n",
      "(10, 128, 128, 3)\n",
      "0.9456651\n",
      "[Epoch 9/10] [Batch 450/1081] [D loss: 0.068115] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.625442] time: 1:32:04.892306\n",
      "(10, 128, 128, 3)\n",
      "0.9333263\n",
      "[Epoch 9/10] [Batch 451/1081] [D loss: 0.060794] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.807111] time: 1:32:05.565066\n",
      "(10, 128, 128, 3)\n",
      "0.97663015\n",
      "[Epoch 9/10] [Batch 452/1081] [D loss: 0.060675] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.114755] time: 1:32:06.223088\n",
      "(10, 128, 128, 3)\n",
      "0.9349394\n",
      "[Epoch 9/10] [Batch 453/1081] [D loss: 0.059304] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.009547] time: 1:32:06.844964\n",
      "(10, 128, 128, 3)\n",
      "0.8413935\n",
      "[Epoch 9/10] [Batch 454/1081] [D loss: 0.061504] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.542345] time: 1:32:07.431580\n",
      "(10, 128, 128, 3)\n",
      "0.9141593\n",
      "[Epoch 9/10] [Batch 455/1081] [D loss: 0.060034] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.606969] time: 1:32:08.034155\n",
      "(10, 128, 128, 3)\n",
      "0.88884825\n",
      "[Epoch 9/10] [Batch 456/1081] [D loss: 0.059892] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.085217] time: 1:32:08.682385\n",
      "(10, 128, 128, 3)\n",
      "0.9044346\n",
      "[Epoch 9/10] [Batch 457/1081] [D loss: 0.058817] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.888596] time: 1:32:09.299473\n",
      "(10, 128, 128, 3)\n",
      "0.8754985\n",
      "[Epoch 9/10] [Batch 458/1081] [D loss: 0.058916] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.595868] time: 1:32:09.974480\n",
      "(10, 128, 128, 3)\n",
      "0.86326474\n",
      "[Epoch 9/10] [Batch 459/1081] [D loss: 0.058354] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.182366] time: 1:32:10.669306\n",
      "(10, 128, 128, 3)\n",
      "0.92960644\n",
      "[Epoch 9/10] [Batch 460/1081] [D loss: 0.061973] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.129056] time: 1:32:11.340682\n",
      "(10, 128, 128, 3)\n",
      "0.884109\n",
      "[Epoch 9/10] [Batch 461/1081] [D loss: 0.068000] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.009492] time: 1:32:11.972367\n",
      "(10, 128, 128, 3)\n",
      "0.92844653\n",
      "[Epoch 9/10] [Batch 462/1081] [D loss: 0.058744] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.169813] time: 1:32:12.640033\n",
      "(10, 128, 128, 3)\n",
      "0.8418751\n",
      "[Epoch 9/10] [Batch 463/1081] [D loss: 0.062969] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.443154] time: 1:32:13.365378\n",
      "(10, 128, 128, 3)\n",
      "0.8748951\n",
      "[Epoch 9/10] [Batch 464/1081] [D loss: 0.058089] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.302023] time: 1:32:14.015009\n",
      "(10, 128, 128, 3)\n",
      "0.9624479\n",
      "[Epoch 9/10] [Batch 465/1081] [D loss: 0.058906] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.614325] time: 1:32:14.634649\n",
      "(10, 128, 128, 3)\n",
      "0.8866768\n",
      "[Epoch 9/10] [Batch 466/1081] [D loss: 0.060306] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.887059] time: 1:32:15.267167\n",
      "(10, 128, 128, 3)\n",
      "0.89085484\n",
      "[Epoch 9/10] [Batch 467/1081] [D loss: 0.058051] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.737338] time: 1:32:15.954883\n",
      "(10, 128, 128, 3)\n",
      "0.90487695\n",
      "[Epoch 9/10] [Batch 468/1081] [D loss: 0.056800] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.605822] time: 1:32:16.622930\n",
      "(10, 128, 128, 3)\n",
      "0.8925276\n",
      "[Epoch 9/10] [Batch 469/1081] [D loss: 0.059078] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.518906] time: 1:32:17.236537\n",
      "(10, 128, 128, 3)\n",
      "0.9172866\n",
      "[Epoch 9/10] [Batch 470/1081] [D loss: 0.056637] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.456938] time: 1:32:17.881943\n",
      "(10, 128, 128, 3)\n",
      "0.9293315\n",
      "[Epoch 9/10] [Batch 471/1081] [D loss: 0.057403] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.262482] time: 1:32:18.490457\n",
      "(10, 128, 128, 3)\n",
      "0.9323335\n",
      "[Epoch 9/10] [Batch 472/1081] [D loss: 0.060414] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.130595] time: 1:32:19.183169\n",
      "(10, 128, 128, 3)\n",
      "0.8769531\n",
      "[Epoch 9/10] [Batch 473/1081] [D loss: 0.060934] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.342386] time: 1:32:19.821119\n",
      "(10, 128, 128, 3)\n",
      "0.9398896\n",
      "[Epoch 9/10] [Batch 474/1081] [D loss: 0.059885] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.073015] time: 1:32:20.466224\n",
      "(10, 128, 128, 3)\n",
      "0.90711\n",
      "[Epoch 9/10] [Batch 475/1081] [D loss: 0.056034] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.219417] time: 1:32:21.096668\n",
      "(10, 128, 128, 3)\n",
      "0.9056943\n",
      "[Epoch 9/10] [Batch 476/1081] [D loss: 0.056674] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.178617] time: 1:32:21.779421\n",
      "(10, 128, 128, 3)\n",
      "0.9361163\n",
      "[Epoch 9/10] [Batch 477/1081] [D loss: 0.056633] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.881747] time: 1:32:22.406229\n",
      "(10, 128, 128, 3)\n",
      "0.9324359\n",
      "[Epoch 9/10] [Batch 478/1081] [D loss: 0.055017] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.992363] time: 1:32:23.027448\n",
      "(10, 128, 128, 3)\n",
      "0.90985584\n",
      "[Epoch 9/10] [Batch 479/1081] [D loss: 0.055564] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.796416] time: 1:32:23.738534\n",
      "(10, 128, 128, 3)\n",
      "0.9344578\n",
      "[Epoch 9/10] [Batch 480/1081] [D loss: 0.054997] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.806056] time: 1:32:24.406394\n",
      "(10, 128, 128, 3)\n",
      "0.89902383\n",
      "[Epoch 9/10] [Batch 481/1081] [D loss: 0.057949] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.187433] time: 1:32:25.052368\n",
      "(10, 128, 128, 3)\n",
      "0.86624044\n",
      "[Epoch 9/10] [Batch 482/1081] [D loss: 0.054968] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.760969] time: 1:32:25.749850\n",
      "(10, 128, 128, 3)\n",
      "0.94372886\n",
      "[Epoch 9/10] [Batch 483/1081] [D loss: 0.055022] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.991092] time: 1:32:26.356689\n",
      "(10, 128, 128, 3)\n",
      "0.947645\n",
      "[Epoch 9/10] [Batch 484/1081] [D loss: 0.054650] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.313360] time: 1:32:27.040520\n",
      "(10, 128, 128, 3)\n",
      "0.91151476\n",
      "[Epoch 9/10] [Batch 485/1081] [D loss: 0.054314] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.951560] time: 1:32:27.654661\n",
      "(10, 128, 128, 3)\n",
      "0.97565454\n",
      "[Epoch 9/10] [Batch 486/1081] [D loss: 0.055949] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.373631] time: 1:32:28.260021\n",
      "(10, 128, 128, 3)\n",
      "0.9768203\n",
      "[Epoch 9/10] [Batch 487/1081] [D loss: 0.054100] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.453854] time: 1:32:28.895896\n",
      "(10, 128, 128, 3)\n",
      "0.9264261\n",
      "[Epoch 9/10] [Batch 488/1081] [D loss: 0.053855] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.758362] time: 1:32:29.569543\n",
      "(10, 128, 128, 3)\n",
      "0.88247377\n",
      "[Epoch 9/10] [Batch 489/1081] [D loss: 0.054419] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.864270] time: 1:32:30.233200\n",
      "(10, 128, 128, 3)\n",
      "0.94540244\n",
      "[Epoch 9/10] [Batch 490/1081] [D loss: 0.056807] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.215255] time: 1:32:30.914509\n",
      "(10, 128, 128, 3)\n",
      "0.9184447\n",
      "[Epoch 9/10] [Batch 491/1081] [D loss: 0.055780] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.366864] time: 1:32:31.532940\n",
      "(10, 128, 128, 3)\n",
      "0.9116113\n",
      "[Epoch 9/10] [Batch 492/1081] [D loss: 0.055070] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.459543] time: 1:32:32.194488\n",
      "(10, 128, 128, 3)\n",
      "0.90184754\n",
      "[Epoch 9/10] [Batch 493/1081] [D loss: 0.053506] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.742898] time: 1:32:32.733417\n",
      "(10, 128, 128, 3)\n",
      "0.89095026\n",
      "[Epoch 9/10] [Batch 494/1081] [D loss: 0.053021] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.042333] time: 1:32:33.289481\n",
      "(10, 128, 128, 3)\n",
      "0.84949046\n",
      "[Epoch 9/10] [Batch 495/1081] [D loss: 0.053405] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.740075] time: 1:32:33.867720\n",
      "(10, 128, 128, 3)\n",
      "0.92936945\n",
      "[Epoch 9/10] [Batch 496/1081] [D loss: 0.053287] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.891872] time: 1:32:34.486557\n",
      "(10, 128, 128, 3)\n",
      "0.9386284\n",
      "[Epoch 9/10] [Batch 497/1081] [D loss: 0.052465] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.021895] time: 1:32:35.031875\n",
      "(10, 128, 128, 3)\n",
      "0.9283798\n",
      "[Epoch 9/10] [Batch 498/1081] [D loss: 0.054890] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.822229] time: 1:32:35.572521\n",
      "(10, 128, 128, 3)\n",
      "0.86492306\n",
      "[Epoch 9/10] [Batch 499/1081] [D loss: 0.060438] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.349912] time: 1:32:36.150323\n",
      "(10, 128, 128, 3)\n",
      "0.9053435\n",
      "[Epoch 9/10] [Batch 500/1081] [D loss: 0.054359] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.680962] time: 1:32:36.717516\n",
      "(10, 128, 128, 3)\n",
      "0.9294321\n",
      "[Epoch 9/10] [Batch 501/1081] [D loss: 0.054261] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.558392] time: 1:32:37.266727\n",
      "(10, 128, 128, 3)\n",
      "0.8829233\n",
      "[Epoch 9/10] [Batch 502/1081] [D loss: 0.053252] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.312763] time: 1:32:37.801121\n",
      "(10, 128, 128, 3)\n",
      "0.98300314\n",
      "[Epoch 9/10] [Batch 503/1081] [D loss: 0.051901] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.190400] time: 1:32:38.375004\n",
      "(10, 128, 128, 3)\n",
      "0.92468315\n",
      "[Epoch 9/10] [Batch 504/1081] [D loss: 0.051795] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.735615] time: 1:32:38.913560\n",
      "(10, 128, 128, 3)\n",
      "0.89011663\n",
      "[Epoch 9/10] [Batch 505/1081] [D loss: 0.051702] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.608994] time: 1:32:39.477846\n",
      "(10, 128, 128, 3)\n",
      "0.9018429\n",
      "[Epoch 9/10] [Batch 506/1081] [D loss: 0.051443] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.723186] time: 1:32:40.026431\n",
      "(10, 128, 128, 3)\n",
      "0.9164036\n",
      "[Epoch 9/10] [Batch 507/1081] [D loss: 0.052477] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.978451] time: 1:32:40.550258\n",
      "(10, 128, 128, 3)\n",
      "0.92489725\n",
      "[Epoch 9/10] [Batch 508/1081] [D loss: 0.053088] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.336944] time: 1:32:41.129394\n",
      "(10, 128, 128, 3)\n",
      "0.90338355\n",
      "[Epoch 9/10] [Batch 509/1081] [D loss: 0.051584] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.074792] time: 1:32:41.674181\n",
      "(10, 128, 128, 3)\n",
      "0.92188495\n",
      "[Epoch 9/10] [Batch 510/1081] [D loss: 0.053588] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.146546] time: 1:32:42.289421\n",
      "(10, 128, 128, 3)\n",
      "0.9281442\n",
      "[Epoch 9/10] [Batch 511/1081] [D loss: 0.051063] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.314191] time: 1:32:42.890633\n",
      "(10, 128, 128, 3)\n",
      "0.90298766\n",
      "[Epoch 9/10] [Batch 512/1081] [D loss: 0.051124] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.023451] time: 1:32:43.452859\n",
      "(10, 128, 128, 3)\n",
      "0.86333346\n",
      "[Epoch 9/10] [Batch 513/1081] [D loss: 0.050557] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.499312] time: 1:32:44.021101\n",
      "(10, 128, 128, 3)\n",
      "0.86882037\n",
      "[Epoch 9/10] [Batch 514/1081] [D loss: 0.050919] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.214308] time: 1:32:44.573510\n",
      "(10, 128, 128, 3)\n",
      "0.91355246\n",
      "[Epoch 9/10] [Batch 515/1081] [D loss: 0.050575] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.058816] time: 1:32:45.130284\n",
      "(10, 128, 128, 3)\n",
      "0.9524148\n",
      "[Epoch 9/10] [Batch 516/1081] [D loss: 0.052965] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.134896] time: 1:32:45.702693\n",
      "(10, 128, 128, 3)\n",
      "0.8818219\n",
      "[Epoch 9/10] [Batch 517/1081] [D loss: 0.052508] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.899080] time: 1:32:46.276120\n",
      "(10, 128, 128, 3)\n",
      "0.9033732\n",
      "[Epoch 9/10] [Batch 518/1081] [D loss: 0.050569] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.334337] time: 1:32:46.857181\n",
      "(10, 128, 128, 3)\n",
      "0.92383474\n",
      "[Epoch 9/10] [Batch 519/1081] [D loss: 0.050276] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.576015] time: 1:32:47.404870\n",
      "(10, 128, 128, 3)\n",
      "0.91100556\n",
      "[Epoch 9/10] [Batch 520/1081] [D loss: 0.051538] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.876533] time: 1:32:47.993269\n",
      "(10, 128, 128, 3)\n",
      "0.9369297\n",
      "[Epoch 9/10] [Batch 521/1081] [D loss: 0.050431] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.506538] time: 1:32:48.539329\n",
      "(10, 128, 128, 3)\n",
      "0.91905403\n",
      "[Epoch 9/10] [Batch 522/1081] [D loss: 0.050143] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.042838] time: 1:32:49.080256\n",
      "(10, 128, 128, 3)\n",
      "0.9221675\n",
      "[Epoch 9/10] [Batch 523/1081] [D loss: 0.049812] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.834569] time: 1:32:49.633268\n",
      "(10, 128, 128, 3)\n",
      "0.9436751\n",
      "[Epoch 9/10] [Batch 524/1081] [D loss: 0.050233] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.982222] time: 1:32:50.180490\n",
      "(10, 128, 128, 3)\n",
      "0.89642256\n",
      "[Epoch 9/10] [Batch 525/1081] [D loss: 0.053526] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.391408] time: 1:32:50.744764\n",
      "(10, 128, 128, 3)\n",
      "0.8656066\n",
      "[Epoch 9/10] [Batch 526/1081] [D loss: 0.050056] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.119478] time: 1:32:51.286592\n",
      "(10, 128, 128, 3)\n",
      "0.867827\n",
      "[Epoch 9/10] [Batch 527/1081] [D loss: 0.049827] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.483662] time: 1:32:51.839478\n",
      "(10, 128, 128, 3)\n",
      "0.9389432\n",
      "[Epoch 9/10] [Batch 528/1081] [D loss: 0.049941] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.371626] time: 1:32:52.449481\n",
      "(10, 128, 128, 3)\n",
      "0.87422615\n",
      "[Epoch 9/10] [Batch 529/1081] [D loss: 0.051959] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.195264] time: 1:32:53.111145\n",
      "(10, 128, 128, 3)\n",
      "0.91197747\n",
      "[Epoch 9/10] [Batch 530/1081] [D loss: 0.049579] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.402442] time: 1:32:53.762585\n",
      "(10, 128, 128, 3)\n",
      "0.9474564\n",
      "[Epoch 9/10] [Batch 531/1081] [D loss: 0.049434] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.349443] time: 1:32:54.425194\n",
      "(10, 128, 128, 3)\n",
      "0.89851046\n",
      "[Epoch 9/10] [Batch 532/1081] [D loss: 0.049238] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.630095] time: 1:32:55.033661\n",
      "(10, 128, 128, 3)\n",
      "0.89931697\n",
      "[Epoch 9/10] [Batch 533/1081] [D loss: 0.049257] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.147591] time: 1:32:55.716844\n",
      "(10, 128, 128, 3)\n",
      "0.8849787\n",
      "[Epoch 9/10] [Batch 534/1081] [D loss: 0.049865] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.531341] time: 1:32:56.319630\n",
      "(10, 128, 128, 3)\n",
      "0.8769185\n",
      "[Epoch 9/10] [Batch 535/1081] [D loss: 0.049621] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.245305] time: 1:32:56.879976\n",
      "(10, 128, 128, 3)\n",
      "0.9611375\n",
      "[Epoch 9/10] [Batch 536/1081] [D loss: 0.053543] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.872369] time: 1:32:57.549166\n",
      "(10, 128, 128, 3)\n",
      "0.8862646\n",
      "[Epoch 9/10] [Batch 537/1081] [D loss: 0.048491] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.788196] time: 1:32:58.208881\n",
      "(10, 128, 128, 3)\n",
      "0.9079196\n",
      "[Epoch 9/10] [Batch 538/1081] [D loss: 0.048641] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.407913] time: 1:32:58.847752\n",
      "(10, 128, 128, 3)\n",
      "0.8869905\n",
      "[Epoch 9/10] [Batch 539/1081] [D loss: 0.050945] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.161281] time: 1:32:59.505944\n",
      "(10, 128, 128, 3)\n",
      "0.9216781\n",
      "[Epoch 9/10] [Batch 540/1081] [D loss: 0.048427] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.806749] time: 1:33:00.197935\n",
      "(10, 128, 128, 3)\n",
      "0.9229457\n",
      "[Epoch 9/10] [Batch 541/1081] [D loss: 0.048280] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.080023] time: 1:33:00.874693\n",
      "(10, 128, 128, 3)\n",
      "0.93936825\n",
      "[Epoch 9/10] [Batch 542/1081] [D loss: 0.051508] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.438503] time: 1:33:01.498724\n",
      "(10, 128, 128, 3)\n",
      "0.8529689\n",
      "[Epoch 9/10] [Batch 543/1081] [D loss: 0.049807] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.656243] time: 1:33:02.077654\n",
      "(10, 128, 128, 3)\n",
      "0.91220164\n",
      "[Epoch 9/10] [Batch 544/1081] [D loss: 0.053669] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.522260] time: 1:33:02.731405\n",
      "(10, 128, 128, 3)\n",
      "0.9323166\n",
      "[Epoch 9/10] [Batch 545/1081] [D loss: 0.056101] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.333036] time: 1:33:03.358598\n",
      "(10, 128, 128, 3)\n",
      "0.91196394\n",
      "[Epoch 9/10] [Batch 546/1081] [D loss: 0.048963] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.293573] time: 1:33:03.983030\n",
      "(10, 128, 128, 3)\n",
      "0.88884807\n",
      "[Epoch 9/10] [Batch 547/1081] [D loss: 0.048114] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.443942] time: 1:33:04.614481\n",
      "(10, 128, 128, 3)\n",
      "0.88684034\n",
      "[Epoch 9/10] [Batch 548/1081] [D loss: 0.049593] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.209930] time: 1:33:05.277696\n",
      "(10, 128, 128, 3)\n",
      "0.9149135\n",
      "[Epoch 9/10] [Batch 549/1081] [D loss: 0.047864] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.385118] time: 1:33:05.920339\n",
      "(10, 128, 128, 3)\n",
      "0.9661799\n",
      "[Epoch 9/10] [Batch 550/1081] [D loss: 0.048115] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.375381] time: 1:33:06.562683\n",
      "(10, 128, 128, 3)\n",
      "0.96283776\n",
      "[Epoch 9/10] [Batch 551/1081] [D loss: 0.047151] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.261788] time: 1:33:07.226518\n",
      "(10, 128, 128, 3)\n",
      "0.9203083\n",
      "[Epoch 9/10] [Batch 552/1081] [D loss: 0.047033] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.487252] time: 1:33:07.891627\n",
      "(10, 128, 128, 3)\n",
      "0.9059117\n",
      "[Epoch 9/10] [Batch 553/1081] [D loss: 0.047276] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.359487] time: 1:33:08.587743\n",
      "(10, 128, 128, 3)\n",
      "0.90908474\n",
      "[Epoch 9/10] [Batch 554/1081] [D loss: 0.046865] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.476937] time: 1:33:09.233831\n",
      "(10, 128, 128, 3)\n",
      "0.9171295\n",
      "[Epoch 9/10] [Batch 555/1081] [D loss: 0.047151] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.506378] time: 1:33:09.884259\n",
      "(10, 128, 128, 3)\n",
      "0.9248755\n",
      "[Epoch 9/10] [Batch 556/1081] [D loss: 0.046964] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.824286] time: 1:33:10.502910\n",
      "(10, 128, 128, 3)\n",
      "0.8752706\n",
      "[Epoch 9/10] [Batch 557/1081] [D loss: 0.048775] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.319765] time: 1:33:11.156780\n",
      "(10, 128, 128, 3)\n",
      "0.9327648\n",
      "[Epoch 9/10] [Batch 558/1081] [D loss: 0.046747] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.947820] time: 1:33:11.793286\n",
      "(10, 128, 128, 3)\n",
      "0.92782146\n",
      "[Epoch 9/10] [Batch 559/1081] [D loss: 0.046784] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.067257] time: 1:33:12.456770\n",
      "(10, 128, 128, 3)\n",
      "0.88174725\n",
      "[Epoch 9/10] [Batch 560/1081] [D loss: 0.047205] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.095743] time: 1:33:13.134333\n",
      "(10, 128, 128, 3)\n",
      "0.9184847\n",
      "[Epoch 9/10] [Batch 561/1081] [D loss: 0.046537] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.377423] time: 1:33:13.801381\n",
      "(10, 128, 128, 3)\n",
      "0.86381745\n",
      "[Epoch 9/10] [Batch 562/1081] [D loss: 0.046379] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.283698] time: 1:33:14.482788\n",
      "(10, 128, 128, 3)\n",
      "0.8706328\n",
      "[Epoch 9/10] [Batch 563/1081] [D loss: 0.046348] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.929985] time: 1:33:15.124679\n",
      "(10, 128, 128, 3)\n",
      "0.9204654\n",
      "[Epoch 9/10] [Batch 564/1081] [D loss: 0.046171] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.180567] time: 1:33:15.762442\n",
      "(10, 128, 128, 3)\n",
      "0.906065\n",
      "[Epoch 9/10] [Batch 565/1081] [D loss: 0.046052] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.921291] time: 1:33:16.401173\n",
      "(10, 128, 128, 3)\n",
      "0.92149645\n",
      "[Epoch 9/10] [Batch 566/1081] [D loss: 0.046713] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.523365] time: 1:33:17.012664\n",
      "(10, 128, 128, 3)\n",
      "0.92458224\n",
      "[Epoch 9/10] [Batch 567/1081] [D loss: 0.045943] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.962056] time: 1:33:17.663830\n",
      "(10, 128, 128, 3)\n",
      "0.95906013\n",
      "[Epoch 9/10] [Batch 568/1081] [D loss: 0.046352] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.594145] time: 1:33:18.319262\n",
      "(10, 128, 128, 3)\n",
      "0.9273977\n",
      "[Epoch 9/10] [Batch 569/1081] [D loss: 0.047503] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.032333] time: 1:33:18.938534\n",
      "(10, 128, 128, 3)\n",
      "0.90140676\n",
      "[Epoch 9/10] [Batch 570/1081] [D loss: 0.046022] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.553754] time: 1:33:19.596906\n",
      "(10, 128, 128, 3)\n",
      "0.8866124\n",
      "[Epoch 9/10] [Batch 571/1081] [D loss: 0.045725] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.945387] time: 1:33:20.277103\n",
      "(10, 128, 128, 3)\n",
      "0.9441119\n",
      "[Epoch 9/10] [Batch 572/1081] [D loss: 0.045556] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.143225] time: 1:33:20.958349\n",
      "(10, 128, 128, 3)\n",
      "0.92645574\n",
      "[Epoch 9/10] [Batch 573/1081] [D loss: 0.045522] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.716039] time: 1:33:21.590076\n",
      "(10, 128, 128, 3)\n",
      "0.93096143\n",
      "[Epoch 9/10] [Batch 574/1081] [D loss: 0.045529] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.260992] time: 1:33:22.209382\n",
      "(10, 128, 128, 3)\n",
      "0.90089417\n",
      "[Epoch 9/10] [Batch 575/1081] [D loss: 0.045426] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.732222] time: 1:33:22.839787\n",
      "(10, 128, 128, 3)\n",
      "0.9079333\n",
      "[Epoch 9/10] [Batch 576/1081] [D loss: 0.045392] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.196028] time: 1:33:23.498473\n",
      "(10, 128, 128, 3)\n",
      "0.87210083\n",
      "[Epoch 9/10] [Batch 577/1081] [D loss: 0.045219] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.324742] time: 1:33:24.209051\n",
      "(10, 128, 128, 3)\n",
      "0.9182563\n",
      "[Epoch 9/10] [Batch 578/1081] [D loss: 0.045825] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.993192] time: 1:33:24.781582\n",
      "(10, 128, 128, 3)\n",
      "0.9367389\n",
      "[Epoch 9/10] [Batch 579/1081] [D loss: 0.045097] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.067219] time: 1:33:25.468931\n",
      "(10, 128, 128, 3)\n",
      "0.89518595\n",
      "[Epoch 9/10] [Batch 580/1081] [D loss: 0.045198] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.713453] time: 1:33:26.094559\n",
      "(10, 128, 128, 3)\n",
      "0.9039952\n",
      "[Epoch 9/10] [Batch 581/1081] [D loss: 0.045008] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.801352] time: 1:33:26.775041\n",
      "(10, 128, 128, 3)\n",
      "0.8814387\n",
      "[Epoch 9/10] [Batch 582/1081] [D loss: 0.044932] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.754061] time: 1:33:27.473306\n",
      "(10, 128, 128, 3)\n",
      "0.9183211\n",
      "[Epoch 9/10] [Batch 583/1081] [D loss: 0.045170] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.325295] time: 1:33:28.144638\n",
      "(10, 128, 128, 3)\n",
      "0.90194494\n",
      "[Epoch 9/10] [Batch 584/1081] [D loss: 0.044832] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.436031] time: 1:33:28.799074\n",
      "(10, 128, 128, 3)\n",
      "0.94742507\n",
      "[Epoch 9/10] [Batch 585/1081] [D loss: 0.044594] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.040226] time: 1:33:29.471294\n",
      "(10, 128, 128, 3)\n",
      "0.92572975\n",
      "[Epoch 9/10] [Batch 586/1081] [D loss: 0.044590] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.921165] time: 1:33:30.103859\n",
      "(10, 128, 128, 3)\n",
      "0.9025586\n",
      "[Epoch 9/10] [Batch 587/1081] [D loss: 0.044695] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.070613] time: 1:33:30.767367\n",
      "(10, 128, 128, 3)\n",
      "0.87392664\n",
      "[Epoch 9/10] [Batch 588/1081] [D loss: 0.044580] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.056742] time: 1:33:31.456219\n",
      "(10, 128, 128, 3)\n",
      "0.8716689\n",
      "[Epoch 9/10] [Batch 589/1081] [D loss: 0.044421] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.384962] time: 1:33:32.136111\n",
      "(10, 128, 128, 3)\n",
      "0.89537024\n",
      "[Epoch 9/10] [Batch 590/1081] [D loss: 0.044563] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.659593] time: 1:33:32.846476\n",
      "(10, 128, 128, 3)\n",
      "0.9207012\n",
      "[Epoch 9/10] [Batch 591/1081] [D loss: 0.044447] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.060520] time: 1:33:33.528893\n",
      "(10, 128, 128, 3)\n",
      "0.90202355\n",
      "[Epoch 9/10] [Batch 592/1081] [D loss: 0.044792] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.485217] time: 1:33:34.208056\n",
      "(10, 128, 128, 3)\n",
      "0.9368021\n",
      "[Epoch 9/10] [Batch 593/1081] [D loss: 0.044086] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.838231] time: 1:33:34.894535\n",
      "(10, 128, 128, 3)\n",
      "0.93291515\n",
      "[Epoch 9/10] [Batch 594/1081] [D loss: 0.043970] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.373357] time: 1:33:35.571325\n",
      "(10, 128, 128, 3)\n",
      "0.86696976\n",
      "[Epoch 9/10] [Batch 595/1081] [D loss: 0.044150] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.030450] time: 1:33:36.233218\n",
      "(10, 128, 128, 3)\n",
      "0.92664176\n",
      "[Epoch 9/10] [Batch 596/1081] [D loss: 0.043915] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.961763] time: 1:33:36.904173\n",
      "(10, 128, 128, 3)\n",
      "0.93073225\n",
      "[Epoch 9/10] [Batch 597/1081] [D loss: 0.043799] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.149327] time: 1:33:37.607030\n",
      "(10, 128, 128, 3)\n",
      "0.9636011\n",
      "[Epoch 9/10] [Batch 598/1081] [D loss: 0.043857] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.775635] time: 1:33:38.300722\n",
      "(10, 128, 128, 3)\n",
      "0.86756843\n",
      "[Epoch 9/10] [Batch 599/1081] [D loss: 0.043740] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.022325] time: 1:33:38.934927\n",
      "(10, 128, 128, 3)\n",
      "0.9135857\n",
      "[Epoch 9/10] [Batch 600/1081] [D loss: 0.043786] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.639545] time: 1:33:39.614883\n",
      "(10, 128, 128, 3)\n",
      "0.9162226\n",
      "[Epoch 9/10] [Batch 601/1081] [D loss: 0.044134] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.940750] time: 1:33:40.289334\n",
      "(10, 128, 128, 3)\n",
      "0.95451146\n",
      "[Epoch 9/10] [Batch 602/1081] [D loss: 0.043596] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.735198] time: 1:33:40.932992\n",
      "(10, 128, 128, 3)\n",
      "0.92600983\n",
      "[Epoch 9/10] [Batch 603/1081] [D loss: 0.043726] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.170886] time: 1:33:41.600987\n",
      "(10, 128, 128, 3)\n",
      "0.9294791\n",
      "[Epoch 9/10] [Batch 604/1081] [D loss: 0.043408] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.097332] time: 1:33:42.240134\n",
      "(10, 128, 128, 3)\n",
      "0.96661156\n",
      "[Epoch 9/10] [Batch 605/1081] [D loss: 0.043466] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.459589] time: 1:33:42.904097\n",
      "(10, 128, 128, 3)\n",
      "0.9372966\n",
      "[Epoch 9/10] [Batch 606/1081] [D loss: 0.446658] [D acc: 0.50 (0.00 real, 1.00 fake)] [G loss: 2.741264] time: 1:33:43.512970\n",
      "(10, 128, 128, 3)\n",
      "0.91884327\n",
      "[Epoch 9/10] [Batch 607/1081] [D loss: 0.116843] [D acc: 0.90 (1.00 real, 0.80 fake)] [G loss: 4.817769] time: 1:33:44.128969\n",
      "(10, 128, 128, 3)\n",
      "0.9651942\n",
      "[Epoch 9/10] [Batch 608/1081] [D loss: 0.162837] [D acc: 0.90 (1.00 real, 0.80 fake)] [G loss: 8.296501] time: 1:33:44.830464\n",
      "(10, 128, 128, 3)\n",
      "0.8917237\n",
      "[Epoch 9/10] [Batch 609/1081] [D loss: 0.153291] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 7.073134] time: 1:33:45.472339\n",
      "(10, 128, 128, 3)\n",
      "0.9563799\n",
      "[Epoch 9/10] [Batch 610/1081] [D loss: 0.188607] [D acc: 0.80 (1.00 real, 0.60 fake)] [G loss: 3.383835] time: 1:33:46.111634\n",
      "(10, 128, 128, 3)\n",
      "0.959723\n",
      "[Epoch 9/10] [Batch 611/1081] [D loss: 0.087318] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.414361] time: 1:33:46.740124\n",
      "(10, 128, 128, 3)\n",
      "0.92932034\n",
      "[Epoch 9/10] [Batch 612/1081] [D loss: 0.070831] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.637703] time: 1:33:47.431572\n",
      "(10, 128, 128, 3)\n",
      "0.91633636\n",
      "[Epoch 9/10] [Batch 613/1081] [D loss: 0.087135] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.285632] time: 1:33:48.026035\n",
      "(10, 128, 128, 3)\n",
      "0.89309496\n",
      "[Epoch 9/10] [Batch 614/1081] [D loss: 0.071096] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.412694] time: 1:33:48.638094\n",
      "(10, 128, 128, 3)\n",
      "0.88388926\n",
      "[Epoch 9/10] [Batch 615/1081] [D loss: 0.066959] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.996755] time: 1:33:49.324280\n",
      "(10, 128, 128, 3)\n",
      "0.8675181\n",
      "[Epoch 9/10] [Batch 616/1081] [D loss: 0.069042] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.594885] time: 1:33:49.998939\n",
      "(10, 128, 128, 3)\n",
      "0.92298126\n",
      "[Epoch 9/10] [Batch 617/1081] [D loss: 0.064135] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.973090] time: 1:33:50.646647\n",
      "(10, 128, 128, 3)\n",
      "0.90879554\n",
      "[Epoch 9/10] [Batch 618/1081] [D loss: 0.072637] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.335950] time: 1:33:51.282470\n",
      "(10, 128, 128, 3)\n",
      "0.9383633\n",
      "[Epoch 9/10] [Batch 619/1081] [D loss: 0.071784] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.415820] time: 1:33:51.966419\n",
      "(10, 128, 128, 3)\n",
      "0.93469626\n",
      "[Epoch 9/10] [Batch 620/1081] [D loss: 0.100688] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.945160] time: 1:33:52.656333\n",
      "(10, 128, 128, 3)\n",
      "0.8612296\n",
      "[Epoch 9/10] [Batch 621/1081] [D loss: 0.076166] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.425726] time: 1:33:53.333365\n",
      "(10, 128, 128, 3)\n",
      "0.9409075\n",
      "[Epoch 9/10] [Batch 622/1081] [D loss: 0.065797] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.507481] time: 1:33:54.028769\n",
      "(10, 128, 128, 3)\n",
      "0.90662956\n",
      "[Epoch 9/10] [Batch 623/1081] [D loss: 0.064099] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.679305] time: 1:33:54.625651\n",
      "(10, 128, 128, 3)\n",
      "0.9258128\n",
      "[Epoch 9/10] [Batch 624/1081] [D loss: 0.062362] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.151226] time: 1:33:55.258736\n",
      "(10, 128, 128, 3)\n",
      "0.8797293\n",
      "[Epoch 9/10] [Batch 625/1081] [D loss: 0.064062] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.833406] time: 1:33:55.859109\n",
      "(10, 128, 128, 3)\n",
      "0.9356207\n",
      "[Epoch 9/10] [Batch 626/1081] [D loss: 0.063469] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.269264] time: 1:33:56.533201\n",
      "(10, 128, 128, 3)\n",
      "0.96558255\n",
      "[Epoch 9/10] [Batch 627/1081] [D loss: 0.062648] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.255579] time: 1:33:57.165472\n",
      "(10, 128, 128, 3)\n",
      "0.893291\n",
      "[Epoch 9/10] [Batch 628/1081] [D loss: 0.061761] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.037915] time: 1:33:57.832998\n",
      "(10, 128, 128, 3)\n",
      "0.92482585\n",
      "[Epoch 9/10] [Batch 629/1081] [D loss: 0.068305] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.586269] time: 1:33:58.510457\n",
      "(10, 128, 128, 3)\n",
      "0.9418788\n",
      "[Epoch 9/10] [Batch 630/1081] [D loss: 0.066269] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.117992] time: 1:33:59.100767\n",
      "(10, 128, 128, 3)\n",
      "0.8915112\n",
      "[Epoch 9/10] [Batch 631/1081] [D loss: 0.061788] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.156345] time: 1:33:59.751013\n",
      "(10, 128, 128, 3)\n",
      "0.8147147\n",
      "[Epoch 9/10] [Batch 632/1081] [D loss: 0.060420] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.539229] time: 1:34:00.382846\n",
      "(10, 128, 128, 3)\n",
      "0.88323516\n",
      "[Epoch 9/10] [Batch 633/1081] [D loss: 0.064278] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.602197] time: 1:34:01.045921\n",
      "(10, 128, 128, 3)\n",
      "0.89188987\n",
      "[Epoch 9/10] [Batch 634/1081] [D loss: 0.060679] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.899487] time: 1:34:01.679740\n",
      "(10, 128, 128, 3)\n",
      "0.92132473\n",
      "[Epoch 9/10] [Batch 635/1081] [D loss: 0.061412] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.461205] time: 1:34:02.356745\n",
      "(10, 128, 128, 3)\n",
      "0.92667437\n",
      "[Epoch 9/10] [Batch 636/1081] [D loss: 0.060548] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.162414] time: 1:34:02.982041\n",
      "(10, 128, 128, 3)\n",
      "0.8945963\n",
      "[Epoch 9/10] [Batch 637/1081] [D loss: 0.060514] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.389320] time: 1:34:03.619659\n",
      "(10, 128, 128, 3)\n",
      "0.8791123\n",
      "[Epoch 9/10] [Batch 638/1081] [D loss: 0.065388] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.283095] time: 1:34:04.223582\n",
      "(10, 128, 128, 3)\n",
      "0.92225075\n",
      "[Epoch 9/10] [Batch 639/1081] [D loss: 0.066723] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.017007] time: 1:34:04.849618\n",
      "(10, 128, 128, 3)\n",
      "0.9030388\n",
      "[Epoch 9/10] [Batch 640/1081] [D loss: 0.059268] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.138453] time: 1:34:05.530747\n",
      "(10, 128, 128, 3)\n",
      "0.9075701\n",
      "[Epoch 9/10] [Batch 641/1081] [D loss: 0.070854] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.386705] time: 1:34:06.191629\n",
      "(10, 128, 128, 3)\n",
      "0.8920979\n",
      "[Epoch 9/10] [Batch 642/1081] [D loss: 0.069546] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.886533] time: 1:34:06.799685\n",
      "(10, 128, 128, 3)\n",
      "0.94404703\n",
      "[Epoch 9/10] [Batch 643/1081] [D loss: 0.059120] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.111112] time: 1:34:07.410987\n",
      "(10, 128, 128, 3)\n",
      "0.9701612\n",
      "[Epoch 9/10] [Batch 644/1081] [D loss: 0.058111] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.387080] time: 1:34:08.045207\n",
      "(10, 128, 128, 3)\n",
      "0.8614239\n",
      "[Epoch 9/10] [Batch 645/1081] [D loss: 0.060289] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.365468] time: 1:34:08.739093\n",
      "(10, 128, 128, 3)\n",
      "0.9323897\n",
      "[Epoch 9/10] [Batch 646/1081] [D loss: 0.069006] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.197039] time: 1:34:09.334495\n",
      "(10, 128, 128, 3)\n",
      "0.94847965\n",
      "[Epoch 9/10] [Batch 647/1081] [D loss: 0.063468] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.135645] time: 1:34:09.935785\n",
      "(10, 128, 128, 3)\n",
      "0.94654435\n",
      "[Epoch 9/10] [Batch 648/1081] [D loss: 0.057217] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.173541] time: 1:34:10.611624\n",
      "(10, 128, 128, 3)\n",
      "0.94015616\n",
      "[Epoch 9/10] [Batch 649/1081] [D loss: 0.056559] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.079936] time: 1:34:11.205983\n",
      "(10, 128, 128, 3)\n",
      "0.9154727\n",
      "[Epoch 9/10] [Batch 650/1081] [D loss: 0.057712] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.582336] time: 1:34:11.883916\n",
      "(10, 128, 128, 3)\n",
      "0.92960805\n",
      "[Epoch 9/10] [Batch 651/1081] [D loss: 0.056878] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.196023] time: 1:34:12.587196\n",
      "(10, 128, 128, 3)\n",
      "0.91451424\n",
      "[Epoch 9/10] [Batch 652/1081] [D loss: 0.056173] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.147248] time: 1:34:13.301471\n",
      "(10, 128, 128, 3)\n",
      "0.9404864\n",
      "[Epoch 9/10] [Batch 653/1081] [D loss: 0.062373] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.991278] time: 1:34:13.906493\n",
      "(10, 128, 128, 3)\n",
      "0.8921861\n",
      "[Epoch 9/10] [Batch 654/1081] [D loss: 0.057212] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.462072] time: 1:34:14.494369\n",
      "(10, 128, 128, 3)\n",
      "0.93414813\n",
      "[Epoch 9/10] [Batch 655/1081] [D loss: 0.067259] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.835309] time: 1:34:15.110073\n",
      "(10, 128, 128, 3)\n",
      "0.93230313\n",
      "[Epoch 9/10] [Batch 656/1081] [D loss: 0.056005] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.244212] time: 1:34:15.747137\n",
      "(10, 128, 128, 3)\n",
      "0.9148595\n",
      "[Epoch 9/10] [Batch 657/1081] [D loss: 0.057221] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.498598] time: 1:34:16.398158\n",
      "(10, 128, 128, 3)\n",
      "0.9780485\n",
      "[Epoch 9/10] [Batch 658/1081] [D loss: 0.057959] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.547568] time: 1:34:17.059059\n",
      "(10, 128, 128, 3)\n",
      "0.91283274\n",
      "[Epoch 9/10] [Batch 659/1081] [D loss: 0.058794] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.869231] time: 1:34:17.663213\n",
      "(10, 128, 128, 3)\n",
      "0.91935176\n",
      "[Epoch 9/10] [Batch 660/1081] [D loss: 0.056309] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.017045] time: 1:34:18.294504\n",
      "(10, 128, 128, 3)\n",
      "0.8721158\n",
      "[Epoch 9/10] [Batch 661/1081] [D loss: 0.057437] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.352866] time: 1:34:18.930471\n",
      "(10, 128, 128, 3)\n",
      "0.93975836\n",
      "[Epoch 9/10] [Batch 662/1081] [D loss: 0.056957] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.618635] time: 1:34:19.561630\n",
      "(10, 128, 128, 3)\n",
      "0.939148\n",
      "[Epoch 9/10] [Batch 663/1081] [D loss: 0.054805] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.678209] time: 1:34:20.222832\n",
      "(10, 128, 128, 3)\n",
      "0.9523162\n",
      "[Epoch 9/10] [Batch 664/1081] [D loss: 0.057306] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.383199] time: 1:34:20.926961\n",
      "(10, 128, 128, 3)\n",
      "0.8887632\n",
      "[Epoch 9/10] [Batch 665/1081] [D loss: 0.054698] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.535623] time: 1:34:21.555863\n",
      "(10, 128, 128, 3)\n",
      "0.9188927\n",
      "[Epoch 9/10] [Batch 666/1081] [D loss: 0.054248] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.518712] time: 1:34:22.200332\n",
      "(10, 128, 128, 3)\n",
      "0.8785983\n",
      "[Epoch 9/10] [Batch 667/1081] [D loss: 0.054179] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.035657] time: 1:34:22.810300\n",
      "(10, 128, 128, 3)\n",
      "0.9505226\n",
      "[Epoch 9/10] [Batch 668/1081] [D loss: 0.054386] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.451416] time: 1:34:23.446913\n",
      "(10, 128, 128, 3)\n",
      "0.91300917\n",
      "[Epoch 9/10] [Batch 669/1081] [D loss: 0.058761] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.675391] time: 1:34:24.112495\n",
      "(10, 128, 128, 3)\n",
      "0.94097155\n",
      "[Epoch 9/10] [Batch 670/1081] [D loss: 0.053805] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.697961] time: 1:34:24.771387\n",
      "(10, 128, 128, 3)\n",
      "0.92635506\n",
      "[Epoch 9/10] [Batch 671/1081] [D loss: 0.056357] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.111273] time: 1:34:25.369191\n",
      "(10, 128, 128, 3)\n",
      "0.87343335\n",
      "[Epoch 9/10] [Batch 672/1081] [D loss: 0.054085] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.359561] time: 1:34:26.061766\n",
      "(10, 128, 128, 3)\n",
      "0.9307986\n",
      "[Epoch 9/10] [Batch 673/1081] [D loss: 0.053405] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.485490] time: 1:34:26.711793\n",
      "(10, 128, 128, 3)\n",
      "0.91863513\n",
      "[Epoch 9/10] [Batch 674/1081] [D loss: 0.053118] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.932224] time: 1:34:27.426469\n",
      "(10, 128, 128, 3)\n",
      "0.91844577\n",
      "[Epoch 9/10] [Batch 675/1081] [D loss: 0.082055] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 3.094544] time: 1:34:28.122649\n",
      "(10, 128, 128, 3)\n",
      "0.9159097\n",
      "[Epoch 9/10] [Batch 676/1081] [D loss: 0.059996] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.507783] time: 1:34:28.757047\n",
      "(10, 128, 128, 3)\n",
      "0.84914184\n",
      "[Epoch 9/10] [Batch 677/1081] [D loss: 0.054154] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.094546] time: 1:34:29.402119\n",
      "(10, 128, 128, 3)\n",
      "0.9052946\n",
      "[Epoch 9/10] [Batch 678/1081] [D loss: 0.063424] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.167641] time: 1:34:30.021844\n",
      "(10, 128, 128, 3)\n",
      "0.88488656\n",
      "[Epoch 9/10] [Batch 679/1081] [D loss: 0.057766] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.921969] time: 1:34:30.724940\n",
      "(10, 128, 128, 3)\n",
      "0.9329707\n",
      "[Epoch 9/10] [Batch 680/1081] [D loss: 0.052619] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.934333] time: 1:34:31.417542\n",
      "(10, 128, 128, 3)\n",
      "0.92986894\n",
      "[Epoch 9/10] [Batch 681/1081] [D loss: 0.052196] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.308677] time: 1:34:32.083447\n",
      "(10, 128, 128, 3)\n",
      "0.8814152\n",
      "[Epoch 9/10] [Batch 682/1081] [D loss: 0.051601] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.751610] time: 1:34:32.710700\n",
      "(10, 128, 128, 3)\n",
      "0.9204709\n",
      "[Epoch 9/10] [Batch 683/1081] [D loss: 0.051857] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.255415] time: 1:34:33.354952\n",
      "(10, 128, 128, 3)\n",
      "0.9185625\n",
      "[Epoch 9/10] [Batch 684/1081] [D loss: 0.052619] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.867423] time: 1:34:34.039885\n",
      "(10, 128, 128, 3)\n",
      "0.88982767\n",
      "[Epoch 9/10] [Batch 685/1081] [D loss: 0.051460] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.823177] time: 1:34:34.711201\n",
      "(10, 128, 128, 3)\n",
      "0.9502256\n",
      "[Epoch 9/10] [Batch 686/1081] [D loss: 0.052726] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.001639] time: 1:34:35.311553\n",
      "(10, 128, 128, 3)\n",
      "0.92990094\n",
      "[Epoch 9/10] [Batch 687/1081] [D loss: 0.052124] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.098409] time: 1:34:35.935634\n",
      "(10, 128, 128, 3)\n",
      "0.9413686\n",
      "[Epoch 9/10] [Batch 688/1081] [D loss: 0.051977] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.155831] time: 1:34:36.622805\n",
      "(10, 128, 128, 3)\n",
      "0.95658207\n",
      "[Epoch 9/10] [Batch 689/1081] [D loss: 0.050821] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.337455] time: 1:34:37.238201\n",
      "(10, 128, 128, 3)\n",
      "0.92254525\n",
      "[Epoch 9/10] [Batch 690/1081] [D loss: 0.050484] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.923984] time: 1:34:37.904121\n",
      "(10, 128, 128, 3)\n",
      "0.9321823\n",
      "[Epoch 9/10] [Batch 691/1081] [D loss: 0.052419] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.199214] time: 1:34:38.560955\n",
      "(10, 128, 128, 3)\n",
      "0.9605015\n",
      "[Epoch 9/10] [Batch 692/1081] [D loss: 0.050070] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.713997] time: 1:34:39.195623\n",
      "(10, 128, 128, 3)\n",
      "0.93566304\n",
      "[Epoch 9/10] [Batch 693/1081] [D loss: 0.050234] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.355861] time: 1:34:39.827225\n",
      "(10, 128, 128, 3)\n",
      "0.9145127\n",
      "[Epoch 9/10] [Batch 694/1081] [D loss: 0.049805] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.014631] time: 1:34:40.500641\n",
      "(10, 128, 128, 3)\n",
      "0.8940747\n",
      "[Epoch 9/10] [Batch 695/1081] [D loss: 0.050044] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.758064] time: 1:34:41.097373\n",
      "(10, 128, 128, 3)\n",
      "0.90395504\n",
      "[Epoch 9/10] [Batch 696/1081] [D loss: 0.049403] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.249379] time: 1:34:41.762500\n",
      "(10, 128, 128, 3)\n",
      "0.8828408\n",
      "[Epoch 9/10] [Batch 697/1081] [D loss: 0.049417] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.062646] time: 1:34:42.426525\n",
      "(10, 128, 128, 3)\n",
      "0.9832725\n",
      "[Epoch 9/10] [Batch 698/1081] [D loss: 0.049230] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.116735] time: 1:34:43.069131\n",
      "(10, 128, 128, 3)\n",
      "0.922005\n",
      "[Epoch 9/10] [Batch 699/1081] [D loss: 0.049177] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.986055] time: 1:34:43.682444\n",
      "(10, 128, 128, 3)\n",
      "0.9454856\n",
      "[Epoch 9/10] [Batch 700/1081] [D loss: 0.049223] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.487989] time: 1:34:44.309444\n",
      "(10, 128, 128, 3)\n",
      "0.9167978\n",
      "[Epoch 9/10] [Batch 701/1081] [D loss: 0.049103] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.042474] time: 1:34:44.955333\n",
      "(10, 128, 128, 3)\n",
      "0.9640055\n",
      "[Epoch 9/10] [Batch 702/1081] [D loss: 0.048871] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.697727] time: 1:34:45.605730\n",
      "(10, 128, 128, 3)\n",
      "0.9591539\n",
      "[Epoch 9/10] [Batch 703/1081] [D loss: 0.048592] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.110565] time: 1:34:46.220989\n",
      "(10, 128, 128, 3)\n",
      "0.9073469\n",
      "[Epoch 9/10] [Batch 704/1081] [D loss: 0.049340] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.524373] time: 1:34:46.886377\n",
      "(10, 128, 128, 3)\n",
      "0.8703699\n",
      "[Epoch 9/10] [Batch 705/1081] [D loss: 0.049741] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.636590] time: 1:34:47.593953\n",
      "(10, 128, 128, 3)\n",
      "0.9241429\n",
      "[Epoch 9/10] [Batch 706/1081] [D loss: 0.049144] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.048337] time: 1:34:48.269339\n",
      "(10, 128, 128, 3)\n",
      "0.8734429\n",
      "[Epoch 9/10] [Batch 707/1081] [D loss: 0.049283] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.922894] time: 1:34:48.934447\n",
      "(10, 128, 128, 3)\n",
      "0.88080055\n",
      "[Epoch 9/10] [Batch 708/1081] [D loss: 0.049096] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.784536] time: 1:34:49.664983\n",
      "(10, 128, 128, 3)\n",
      "0.87778217\n",
      "[Epoch 9/10] [Batch 709/1081] [D loss: 0.048294] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.672731] time: 1:34:50.299731\n",
      "(10, 128, 128, 3)\n",
      "0.9485369\n",
      "[Epoch 9/10] [Batch 710/1081] [D loss: 0.048931] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.662986] time: 1:34:51.006033\n",
      "(10, 128, 128, 3)\n",
      "0.919499\n",
      "[Epoch 9/10] [Batch 711/1081] [D loss: 0.048113] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.032395] time: 1:34:51.707224\n",
      "(10, 128, 128, 3)\n",
      "0.9271229\n",
      "[Epoch 9/10] [Batch 712/1081] [D loss: 0.193864] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 5.128500] time: 1:34:52.345474\n",
      "(10, 128, 128, 3)\n",
      "0.918605\n",
      "[Epoch 9/10] [Batch 713/1081] [D loss: 0.128816] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.407443] time: 1:34:52.966319\n",
      "(10, 128, 128, 3)\n",
      "0.9474426\n",
      "[Epoch 9/10] [Batch 714/1081] [D loss: 0.083429] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.796380] time: 1:34:53.588921\n",
      "(10, 128, 128, 3)\n",
      "0.93611026\n",
      "[Epoch 9/10] [Batch 715/1081] [D loss: 0.054311] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.684026] time: 1:34:54.169813\n",
      "(10, 128, 128, 3)\n",
      "0.8763385\n",
      "[Epoch 9/10] [Batch 716/1081] [D loss: 0.058450] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.230319] time: 1:34:54.840870\n",
      "(10, 128, 128, 3)\n",
      "0.957973\n",
      "[Epoch 9/10] [Batch 717/1081] [D loss: 0.055874] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.881825] time: 1:34:55.527623\n",
      "(10, 128, 128, 3)\n",
      "0.9319112\n",
      "[Epoch 9/10] [Batch 718/1081] [D loss: 0.057749] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.046198] time: 1:34:56.200585\n",
      "(10, 128, 128, 3)\n",
      "0.9311168\n",
      "[Epoch 9/10] [Batch 719/1081] [D loss: 0.052834] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.606307] time: 1:34:56.875757\n",
      "(10, 128, 128, 3)\n",
      "0.90752363\n",
      "[Epoch 9/10] [Batch 720/1081] [D loss: 0.052369] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.335712] time: 1:34:57.529949\n",
      "(10, 128, 128, 3)\n",
      "0.9178684\n",
      "[Epoch 9/10] [Batch 721/1081] [D loss: 0.053732] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.612535] time: 1:34:58.230594\n",
      "(10, 128, 128, 3)\n",
      "0.8616585\n",
      "[Epoch 9/10] [Batch 722/1081] [D loss: 0.061435] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.701309] time: 1:34:58.875128\n",
      "(10, 128, 128, 3)\n",
      "0.8881492\n",
      "[Epoch 9/10] [Batch 723/1081] [D loss: 0.056098] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.497913] time: 1:34:59.566758\n",
      "(10, 128, 128, 3)\n",
      "0.9490989\n",
      "[Epoch 9/10] [Batch 724/1081] [D loss: 0.053895] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.925821] time: 1:35:00.233243\n",
      "(10, 128, 128, 3)\n",
      "0.95478183\n",
      "[Epoch 9/10] [Batch 725/1081] [D loss: 0.051397] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.124412] time: 1:35:00.895649\n",
      "(10, 128, 128, 3)\n",
      "0.88889295\n",
      "[Epoch 9/10] [Batch 726/1081] [D loss: 0.052117] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.622098] time: 1:35:01.523093\n",
      "(10, 128, 128, 3)\n",
      "0.8184785\n",
      "[Epoch 9/10] [Batch 727/1081] [D loss: 0.051050] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.523685] time: 1:35:02.173673\n",
      "(10, 128, 128, 3)\n",
      "0.9300697\n",
      "[Epoch 9/10] [Batch 728/1081] [D loss: 0.050693] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.067710] time: 1:35:02.837666\n",
      "(10, 128, 128, 3)\n",
      "0.93571186\n",
      "[Epoch 9/10] [Batch 729/1081] [D loss: 0.053561] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.322881] time: 1:35:03.433684\n",
      "(10, 128, 128, 3)\n",
      "0.88891125\n",
      "[Epoch 9/10] [Batch 730/1081] [D loss: 0.052893] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.995847] time: 1:35:04.111480\n",
      "(10, 128, 128, 3)\n",
      "0.9002413\n",
      "[Epoch 9/10] [Batch 731/1081] [D loss: 0.051985] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.881149] time: 1:35:04.785864\n",
      "(10, 128, 128, 3)\n",
      "0.8954672\n",
      "[Epoch 9/10] [Batch 732/1081] [D loss: 0.053171] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.123904] time: 1:35:05.515459\n",
      "(10, 128, 128, 3)\n",
      "0.9050653\n",
      "[Epoch 9/10] [Batch 733/1081] [D loss: 0.054043] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.957819] time: 1:35:06.155580\n",
      "(10, 128, 128, 3)\n",
      "0.9370722\n",
      "[Epoch 9/10] [Batch 734/1081] [D loss: 0.050735] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.081451] time: 1:35:06.766023\n",
      "(10, 128, 128, 3)\n",
      "0.92595154\n",
      "[Epoch 9/10] [Batch 735/1081] [D loss: 0.051138] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.607754] time: 1:35:07.405782\n",
      "(10, 128, 128, 3)\n",
      "0.8944238\n",
      "[Epoch 9/10] [Batch 736/1081] [D loss: 0.052590] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.884055] time: 1:35:08.107660\n",
      "(10, 128, 128, 3)\n",
      "0.9803718\n",
      "[Epoch 9/10] [Batch 737/1081] [D loss: 0.049979] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.428675] time: 1:35:08.733410\n",
      "(10, 128, 128, 3)\n",
      "0.9150732\n",
      "[Epoch 9/10] [Batch 738/1081] [D loss: 0.051094] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.843503] time: 1:35:09.362564\n",
      "(10, 128, 128, 3)\n",
      "0.9515843\n",
      "[Epoch 9/10] [Batch 739/1081] [D loss: 0.049480] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.830048] time: 1:35:09.982443\n",
      "(10, 128, 128, 3)\n",
      "0.89592665\n",
      "[Epoch 9/10] [Batch 740/1081] [D loss: 0.049813] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.642436] time: 1:35:10.671094\n",
      "(10, 128, 128, 3)\n",
      "0.87904644\n",
      "[Epoch 9/10] [Batch 741/1081] [D loss: 0.050069] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.518864] time: 1:35:11.335939\n",
      "(10, 128, 128, 3)\n",
      "0.9216272\n",
      "[Epoch 9/10] [Batch 742/1081] [D loss: 0.049101] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.478750] time: 1:35:12.055821\n",
      "(10, 128, 128, 3)\n",
      "0.8982084\n",
      "[Epoch 9/10] [Batch 743/1081] [D loss: 0.049629] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.155475] time: 1:35:12.705602\n",
      "(10, 128, 128, 3)\n",
      "0.9282109\n",
      "[Epoch 9/10] [Batch 744/1081] [D loss: 0.050256] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.548095] time: 1:35:13.350100\n",
      "(10, 128, 128, 3)\n",
      "0.9466219\n",
      "[Epoch 9/10] [Batch 745/1081] [D loss: 0.048918] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.168899] time: 1:35:13.967346\n",
      "(10, 128, 128, 3)\n",
      "0.93053174\n",
      "[Epoch 9/10] [Batch 746/1081] [D loss: 0.053019] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.306810] time: 1:35:14.633710\n",
      "(10, 128, 128, 3)\n",
      "0.9153041\n",
      "[Epoch 9/10] [Batch 747/1081] [D loss: 0.049458] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.136506] time: 1:35:15.312958\n",
      "(10, 128, 128, 3)\n",
      "0.90308744\n",
      "[Epoch 9/10] [Batch 748/1081] [D loss: 0.049285] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.317492] time: 1:35:15.951530\n",
      "(10, 128, 128, 3)\n",
      "0.93357533\n",
      "[Epoch 9/10] [Batch 749/1081] [D loss: 0.049733] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.396599] time: 1:35:16.602603\n",
      "(10, 128, 128, 3)\n",
      "0.9457228\n",
      "[Epoch 9/10] [Batch 750/1081] [D loss: 0.049455] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.411795] time: 1:35:17.230095\n",
      "(10, 128, 128, 3)\n",
      "0.8501207\n",
      "[Epoch 9/10] [Batch 751/1081] [D loss: 0.055998] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.049735] time: 1:35:17.923359\n",
      "(10, 128, 128, 3)\n",
      "0.8793888\n",
      "[Epoch 9/10] [Batch 752/1081] [D loss: 0.055500] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.775925] time: 1:35:18.656611\n",
      "(10, 128, 128, 3)\n",
      "0.88218683\n",
      "[Epoch 9/10] [Batch 753/1081] [D loss: 0.049364] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.605777] time: 1:35:19.319831\n",
      "(10, 128, 128, 3)\n",
      "0.9313223\n",
      "[Epoch 9/10] [Batch 754/1081] [D loss: 0.048364] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.236041] time: 1:35:19.946358\n",
      "(10, 128, 128, 3)\n",
      "0.93138885\n",
      "[Epoch 9/10] [Batch 755/1081] [D loss: 0.048360] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.869710] time: 1:35:20.619325\n",
      "(10, 128, 128, 3)\n",
      "0.87965846\n",
      "[Epoch 9/10] [Batch 756/1081] [D loss: 0.049742] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.446098] time: 1:35:21.233558\n",
      "(10, 128, 128, 3)\n",
      "0.8912184\n",
      "[Epoch 9/10] [Batch 757/1081] [D loss: 0.048938] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.244481] time: 1:35:21.947068\n",
      "(10, 128, 128, 3)\n",
      "0.9304116\n",
      "[Epoch 9/10] [Batch 758/1081] [D loss: 0.047103] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.747245] time: 1:35:22.598411\n",
      "(10, 128, 128, 3)\n",
      "0.89989\n",
      "[Epoch 9/10] [Batch 759/1081] [D loss: 0.047134] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.022915] time: 1:35:23.198732\n",
      "(10, 128, 128, 3)\n",
      "0.95457727\n",
      "[Epoch 9/10] [Batch 760/1081] [D loss: 0.051173] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.013266] time: 1:35:23.842700\n",
      "(10, 128, 128, 3)\n",
      "0.9614718\n",
      "[Epoch 9/10] [Batch 761/1081] [D loss: 0.048656] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.864811] time: 1:35:24.491863\n",
      "(10, 128, 128, 3)\n",
      "0.9283125\n",
      "[Epoch 9/10] [Batch 762/1081] [D loss: 0.096957] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.071613] time: 1:35:25.136633\n",
      "(10, 128, 128, 3)\n",
      "0.94171476\n",
      "[Epoch 9/10] [Batch 763/1081] [D loss: 0.052471] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.271706] time: 1:35:25.732119\n",
      "(10, 128, 128, 3)\n",
      "0.86942226\n",
      "[Epoch 9/10] [Batch 764/1081] [D loss: 0.055104] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.326312] time: 1:35:26.366598\n",
      "(10, 128, 128, 3)\n",
      "0.95459944\n",
      "[Epoch 9/10] [Batch 765/1081] [D loss: 0.048756] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.457020] time: 1:35:27.017637\n",
      "(10, 128, 128, 3)\n",
      "0.9753046\n",
      "[Epoch 9/10] [Batch 766/1081] [D loss: 0.047499] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.322639] time: 1:35:27.599849\n",
      "(10, 128, 128, 3)\n",
      "0.89336246\n",
      "[Epoch 9/10] [Batch 767/1081] [D loss: 0.047671] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.726008] time: 1:35:28.253997\n",
      "(10, 128, 128, 3)\n",
      "0.96004415\n",
      "[Epoch 9/10] [Batch 768/1081] [D loss: 0.047109] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.557670] time: 1:35:28.899481\n",
      "(10, 128, 128, 3)\n",
      "0.9185514\n",
      "[Epoch 9/10] [Batch 769/1081] [D loss: 0.046852] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.508943] time: 1:35:29.522600\n",
      "(10, 128, 128, 3)\n",
      "0.9033858\n",
      "[Epoch 9/10] [Batch 770/1081] [D loss: 0.049867] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.388426] time: 1:35:30.165731\n",
      "(10, 128, 128, 3)\n",
      "0.9141361\n",
      "[Epoch 9/10] [Batch 771/1081] [D loss: 0.049779] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.052819] time: 1:35:30.833732\n",
      "(10, 128, 128, 3)\n",
      "0.9092607\n",
      "[Epoch 9/10] [Batch 772/1081] [D loss: 0.046428] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.190365] time: 1:35:31.539489\n",
      "(10, 128, 128, 3)\n",
      "0.93154883\n",
      "[Epoch 9/10] [Batch 773/1081] [D loss: 0.047706] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.215634] time: 1:35:32.205694\n",
      "(10, 128, 128, 3)\n",
      "0.9027876\n",
      "[Epoch 9/10] [Batch 774/1081] [D loss: 0.048405] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.334177] time: 1:35:32.821733\n",
      "(10, 128, 128, 3)\n",
      "0.90972453\n",
      "[Epoch 9/10] [Batch 775/1081] [D loss: 0.049215] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.886064] time: 1:35:33.505003\n",
      "(10, 128, 128, 3)\n",
      "0.96945065\n",
      "[Epoch 9/10] [Batch 776/1081] [D loss: 0.048440] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.759941] time: 1:35:34.188664\n",
      "(10, 128, 128, 3)\n",
      "0.88375074\n",
      "[Epoch 9/10] [Batch 777/1081] [D loss: 0.049454] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.638343] time: 1:35:34.850676\n",
      "(10, 128, 128, 3)\n",
      "0.90689355\n",
      "[Epoch 9/10] [Batch 778/1081] [D loss: 0.046937] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.327997] time: 1:35:35.491790\n",
      "(10, 128, 128, 3)\n",
      "0.8952355\n",
      "[Epoch 9/10] [Batch 779/1081] [D loss: 0.046828] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.664969] time: 1:35:36.199940\n",
      "(10, 128, 128, 3)\n",
      "0.97621226\n",
      "[Epoch 9/10] [Batch 780/1081] [D loss: 0.047235] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.041790] time: 1:35:36.894593\n",
      "(10, 128, 128, 3)\n",
      "0.9525259\n",
      "[Epoch 9/10] [Batch 781/1081] [D loss: 0.047955] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.366308] time: 1:35:37.566049\n",
      "(10, 128, 128, 3)\n",
      "0.9374818\n",
      "[Epoch 9/10] [Batch 782/1081] [D loss: 0.049037] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.906757] time: 1:35:38.224045\n",
      "(10, 128, 128, 3)\n",
      "0.9529889\n",
      "[Epoch 9/10] [Batch 783/1081] [D loss: 0.047405] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.919118] time: 1:35:38.871147\n",
      "(10, 128, 128, 3)\n",
      "0.94457525\n",
      "[Epoch 9/10] [Batch 784/1081] [D loss: 0.045689] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.568321] time: 1:35:39.489468\n",
      "(10, 128, 128, 3)\n",
      "0.8947463\n",
      "[Epoch 9/10] [Batch 785/1081] [D loss: 0.045712] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.008248] time: 1:35:40.134619\n",
      "(10, 128, 128, 3)\n",
      "0.8941784\n",
      "[Epoch 9/10] [Batch 786/1081] [D loss: 0.050607] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.446204] time: 1:35:40.784036\n",
      "(10, 128, 128, 3)\n",
      "0.87101626\n",
      "[Epoch 9/10] [Batch 787/1081] [D loss: 0.045901] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.620365] time: 1:35:41.409427\n",
      "(10, 128, 128, 3)\n",
      "0.9083652\n",
      "[Epoch 9/10] [Batch 788/1081] [D loss: 0.046260] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.322433] time: 1:35:42.025867\n",
      "(10, 128, 128, 3)\n",
      "0.9356756\n",
      "[Epoch 9/10] [Batch 789/1081] [D loss: 0.046952] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.150992] time: 1:35:42.654366\n",
      "(10, 128, 128, 3)\n",
      "0.93307143\n",
      "[Epoch 9/10] [Batch 790/1081] [D loss: 0.048918] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.884647] time: 1:35:43.325924\n",
      "(10, 128, 128, 3)\n",
      "0.91003746\n",
      "[Epoch 9/10] [Batch 791/1081] [D loss: 0.046064] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.189397] time: 1:35:43.980946\n",
      "(10, 128, 128, 3)\n",
      "0.93196136\n",
      "[Epoch 9/10] [Batch 792/1081] [D loss: 0.046475] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.375358] time: 1:35:44.635125\n",
      "(10, 128, 128, 3)\n",
      "0.90719795\n",
      "[Epoch 9/10] [Batch 793/1081] [D loss: 0.045230] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.995063] time: 1:35:45.268817\n",
      "(10, 128, 128, 3)\n",
      "0.8932579\n",
      "[Epoch 9/10] [Batch 794/1081] [D loss: 0.045434] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.891587] time: 1:35:45.938637\n",
      "(10, 128, 128, 3)\n",
      "0.91816473\n",
      "[Epoch 9/10] [Batch 795/1081] [D loss: 0.045194] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.637742] time: 1:35:46.586957\n",
      "(10, 128, 128, 3)\n",
      "0.9381833\n",
      "[Epoch 9/10] [Batch 796/1081] [D loss: 0.044847] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.770461] time: 1:35:47.301575\n",
      "(10, 128, 128, 3)\n",
      "0.9260051\n",
      "[Epoch 9/10] [Batch 797/1081] [D loss: 0.044692] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.289877] time: 1:35:47.990667\n",
      "(10, 128, 128, 3)\n",
      "0.8581951\n",
      "[Epoch 9/10] [Batch 798/1081] [D loss: 0.044333] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.442218] time: 1:35:48.638259\n",
      "(10, 128, 128, 3)\n",
      "0.9443404\n",
      "[Epoch 9/10] [Batch 799/1081] [D loss: 0.047309] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.911351] time: 1:35:49.305310\n",
      "(10, 128, 128, 3)\n",
      "0.90384316\n",
      "[Epoch 9/10] [Batch 800/1081] [D loss: 0.046627] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.583850] time: 1:35:49.947310\n",
      "(10, 128, 128, 3)\n",
      "0.97458583\n",
      "[Epoch 9/10] [Batch 801/1081] [D loss: 0.044341] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.368439] time: 1:35:50.615850\n",
      "(10, 128, 128, 3)\n",
      "0.9069002\n",
      "[Epoch 9/10] [Batch 802/1081] [D loss: 0.045151] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.859775] time: 1:35:51.271162\n",
      "(10, 128, 128, 3)\n",
      "0.9148724\n",
      "[Epoch 9/10] [Batch 803/1081] [D loss: 0.045296] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.609988] time: 1:35:51.870418\n",
      "(10, 128, 128, 3)\n",
      "0.8521547\n",
      "[Epoch 9/10] [Batch 804/1081] [D loss: 0.044063] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.320228] time: 1:35:52.504618\n",
      "(10, 128, 128, 3)\n",
      "0.9271987\n",
      "[Epoch 9/10] [Batch 805/1081] [D loss: 0.043880] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.564677] time: 1:35:53.117951\n",
      "(10, 128, 128, 3)\n",
      "0.90065604\n",
      "[Epoch 9/10] [Batch 806/1081] [D loss: 0.048763] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.629584] time: 1:35:53.729573\n",
      "(10, 128, 128, 3)\n",
      "0.90037876\n",
      "[Epoch 9/10] [Batch 807/1081] [D loss: 0.052413] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.915434] time: 1:35:54.415080\n",
      "(10, 128, 128, 3)\n",
      "0.9222401\n",
      "[Epoch 9/10] [Batch 808/1081] [D loss: 0.046096] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.273937] time: 1:35:55.129568\n",
      "(10, 128, 128, 3)\n",
      "0.8987712\n",
      "[Epoch 9/10] [Batch 809/1081] [D loss: 0.048507] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.457804] time: 1:35:55.782822\n",
      "(10, 128, 128, 3)\n",
      "0.8936174\n",
      "[Epoch 9/10] [Batch 810/1081] [D loss: 0.045517] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.936631] time: 1:35:56.340392\n",
      "(10, 128, 128, 3)\n",
      "0.90756273\n",
      "[Epoch 9/10] [Batch 811/1081] [D loss: 0.044877] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.689916] time: 1:35:56.891699\n",
      "(10, 128, 128, 3)\n",
      "0.9023157\n",
      "[Epoch 9/10] [Batch 812/1081] [D loss: 0.044965] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.139057] time: 1:35:57.437567\n",
      "(10, 128, 128, 3)\n",
      "0.90529925\n",
      "[Epoch 9/10] [Batch 813/1081] [D loss: 0.045382] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.951896] time: 1:35:57.978632\n",
      "(10, 128, 128, 3)\n",
      "0.9178161\n",
      "[Epoch 9/10] [Batch 814/1081] [D loss: 0.049096] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.382046] time: 1:35:58.497684\n",
      "(10, 128, 128, 3)\n",
      "0.94743246\n",
      "[Epoch 9/10] [Batch 815/1081] [D loss: 0.047017] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.301091] time: 1:35:59.024432\n",
      "(10, 128, 128, 3)\n",
      "0.8875198\n",
      "[Epoch 9/10] [Batch 816/1081] [D loss: 0.044088] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.670285] time: 1:35:59.569577\n",
      "(10, 128, 128, 3)\n",
      "0.90247375\n",
      "[Epoch 9/10] [Batch 817/1081] [D loss: 0.044363] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.308411] time: 1:36:00.174720\n",
      "(10, 128, 128, 3)\n",
      "0.89342517\n",
      "[Epoch 9/10] [Batch 818/1081] [D loss: 0.051208] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.067175] time: 1:36:00.710495\n",
      "(10, 128, 128, 3)\n",
      "0.9080203\n",
      "[Epoch 9/10] [Batch 819/1081] [D loss: 0.045687] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.874630] time: 1:36:01.302185\n",
      "(10, 128, 128, 3)\n",
      "0.9024171\n",
      "[Epoch 9/10] [Batch 820/1081] [D loss: 0.043634] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.235901] time: 1:36:01.864616\n",
      "(10, 128, 128, 3)\n",
      "0.89268756\n",
      "[Epoch 9/10] [Batch 821/1081] [D loss: 0.043427] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.249870] time: 1:36:02.400196\n",
      "(10, 128, 128, 3)\n",
      "0.88098955\n",
      "[Epoch 9/10] [Batch 822/1081] [D loss: 0.043781] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.344600] time: 1:36:02.989699\n",
      "(10, 128, 128, 3)\n",
      "0.90134937\n",
      "[Epoch 9/10] [Batch 823/1081] [D loss: 0.043832] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.235465] time: 1:36:03.540557\n",
      "(10, 128, 128, 3)\n",
      "0.9407223\n",
      "[Epoch 9/10] [Batch 824/1081] [D loss: 0.044536] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.626673] time: 1:36:04.167171\n",
      "(10, 128, 128, 3)\n",
      "0.90582126\n",
      "[Epoch 9/10] [Batch 825/1081] [D loss: 0.044186] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.007924] time: 1:36:04.739234\n",
      "(10, 128, 128, 3)\n",
      "0.90346885\n",
      "[Epoch 9/10] [Batch 826/1081] [D loss: 0.045557] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.944066] time: 1:36:05.323343\n",
      "(10, 128, 128, 3)\n",
      "0.90696687\n",
      "[Epoch 9/10] [Batch 827/1081] [D loss: 0.044095] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.775399] time: 1:36:05.886307\n",
      "(10, 128, 128, 3)\n",
      "0.9377759\n",
      "[Epoch 9/10] [Batch 828/1081] [D loss: 0.042883] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.440921] time: 1:36:06.424593\n",
      "(10, 128, 128, 3)\n",
      "0.8947734\n",
      "[Epoch 9/10] [Batch 829/1081] [D loss: 0.044125] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.098354] time: 1:36:06.999342\n",
      "(10, 128, 128, 3)\n",
      "0.86704856\n",
      "[Epoch 9/10] [Batch 830/1081] [D loss: 0.044033] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.944968] time: 1:36:07.552006\n",
      "(10, 128, 128, 3)\n",
      "0.85377437\n",
      "[Epoch 9/10] [Batch 831/1081] [D loss: 0.042711] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.997093] time: 1:36:08.129802\n",
      "(10, 128, 128, 3)\n",
      "0.9533467\n",
      "[Epoch 9/10] [Batch 832/1081] [D loss: 0.046828] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.364165] time: 1:36:08.690185\n",
      "(10, 128, 128, 3)\n",
      "0.91583043\n",
      "[Epoch 9/10] [Batch 833/1081] [D loss: 0.044508] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.100658] time: 1:36:09.233658\n",
      "(10, 128, 128, 3)\n",
      "0.92654324\n",
      "[Epoch 9/10] [Batch 834/1081] [D loss: 0.047120] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.872136] time: 1:36:09.791950\n",
      "(10, 128, 128, 3)\n",
      "0.8946107\n",
      "[Epoch 9/10] [Batch 835/1081] [D loss: 0.043967] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.050278] time: 1:36:10.328345\n",
      "(10, 128, 128, 3)\n",
      "0.915466\n",
      "[Epoch 9/10] [Batch 836/1081] [D loss: 0.042469] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.796252] time: 1:36:10.882882\n",
      "(10, 128, 128, 3)\n",
      "0.8655467\n",
      "[Epoch 9/10] [Batch 837/1081] [D loss: 0.044025] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.060849] time: 1:36:11.432615\n",
      "(10, 128, 128, 3)\n",
      "0.912138\n",
      "[Epoch 9/10] [Batch 838/1081] [D loss: 0.042764] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.998803] time: 1:36:12.006634\n",
      "(10, 128, 128, 3)\n",
      "0.89043707\n",
      "[Epoch 9/10] [Batch 839/1081] [D loss: 0.042597] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.968682] time: 1:36:12.570002\n",
      "(10, 128, 128, 3)\n",
      "0.92298025\n",
      "[Epoch 9/10] [Batch 840/1081] [D loss: 0.041988] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.299332] time: 1:36:13.154496\n",
      "(10, 128, 128, 3)\n",
      "0.9409592\n",
      "[Epoch 9/10] [Batch 841/1081] [D loss: 0.044351] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.860474] time: 1:36:13.705672\n",
      "(10, 128, 128, 3)\n",
      "0.93456286\n",
      "[Epoch 9/10] [Batch 842/1081] [D loss: 0.043226] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.886661] time: 1:36:14.266557\n",
      "(10, 128, 128, 3)\n",
      "0.89003927\n",
      "[Epoch 9/10] [Batch 843/1081] [D loss: 0.045359] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.253678] time: 1:36:14.818654\n",
      "(10, 128, 128, 3)\n",
      "0.92008424\n",
      "[Epoch 9/10] [Batch 844/1081] [D loss: 0.043280] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.959136] time: 1:36:15.392112\n",
      "(10, 128, 128, 3)\n",
      "0.91202754\n",
      "[Epoch 9/10] [Batch 845/1081] [D loss: 0.041464] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.227399] time: 1:36:16.017416\n",
      "(10, 128, 128, 3)\n",
      "0.90744853\n",
      "[Epoch 9/10] [Batch 846/1081] [D loss: 0.041614] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.348877] time: 1:36:16.684462\n",
      "(10, 128, 128, 3)\n",
      "0.87810546\n",
      "[Epoch 9/10] [Batch 847/1081] [D loss: 0.041617] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.127339] time: 1:36:17.305124\n",
      "(10, 128, 128, 3)\n",
      "0.892762\n",
      "[Epoch 9/10] [Batch 848/1081] [D loss: 0.041658] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.975177] time: 1:36:17.951189\n",
      "(10, 128, 128, 3)\n",
      "0.9124544\n",
      "[Epoch 9/10] [Batch 849/1081] [D loss: 0.041174] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.331782] time: 1:36:18.641153\n",
      "(10, 128, 128, 3)\n",
      "0.91846895\n",
      "[Epoch 9/10] [Batch 850/1081] [D loss: 0.041532] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.944144] time: 1:36:19.246466\n",
      "(10, 128, 128, 3)\n",
      "0.9079764\n",
      "[Epoch 9/10] [Batch 851/1081] [D loss: 0.041189] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.105196] time: 1:36:19.963892\n",
      "(10, 128, 128, 3)\n",
      "0.9071776\n",
      "[Epoch 9/10] [Batch 852/1081] [D loss: 0.041280] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.387391] time: 1:36:20.648964\n",
      "(10, 128, 128, 3)\n",
      "0.93318754\n",
      "[Epoch 9/10] [Batch 853/1081] [D loss: 0.040965] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.122493] time: 1:36:21.338446\n",
      "(10, 128, 128, 3)\n",
      "0.84707576\n",
      "[Epoch 9/10] [Batch 854/1081] [D loss: 0.041283] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.186424] time: 1:36:21.952515\n",
      "(10, 128, 128, 3)\n",
      "0.9056613\n",
      "[Epoch 9/10] [Batch 855/1081] [D loss: 0.041210] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.041285] time: 1:36:22.566618\n",
      "(10, 128, 128, 3)\n",
      "0.9831582\n",
      "[Epoch 9/10] [Batch 856/1081] [D loss: 0.040899] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.726475] time: 1:36:23.249783\n",
      "(10, 128, 128, 3)\n",
      "0.9264791\n",
      "[Epoch 9/10] [Batch 857/1081] [D loss: 0.040719] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.599332] time: 1:36:23.861702\n",
      "(10, 128, 128, 3)\n",
      "0.91955805\n",
      "[Epoch 9/10] [Batch 858/1081] [D loss: 0.041302] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.958219] time: 1:36:24.526203\n",
      "(10, 128, 128, 3)\n",
      "0.91899675\n",
      "[Epoch 9/10] [Batch 859/1081] [D loss: 0.040808] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.377419] time: 1:36:25.153832\n",
      "(10, 128, 128, 3)\n",
      "0.9158263\n",
      "[Epoch 9/10] [Batch 860/1081] [D loss: 0.040720] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.793717] time: 1:36:25.825034\n",
      "(10, 128, 128, 3)\n",
      "0.850611\n",
      "[Epoch 9/10] [Batch 861/1081] [D loss: 0.040439] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.586749] time: 1:36:26.497568\n",
      "(10, 128, 128, 3)\n",
      "0.9300421\n",
      "[Epoch 9/10] [Batch 862/1081] [D loss: 0.040528] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.088000] time: 1:36:27.170877\n",
      "(10, 128, 128, 3)\n",
      "0.9428203\n",
      "[Epoch 9/10] [Batch 863/1081] [D loss: 0.042312] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.503998] time: 1:36:27.832551\n",
      "(10, 128, 128, 3)\n",
      "0.91247505\n",
      "[Epoch 9/10] [Batch 864/1081] [D loss: 0.040631] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.298014] time: 1:36:28.500077\n",
      "(10, 128, 128, 3)\n",
      "0.9294706\n",
      "[Epoch 9/10] [Batch 865/1081] [D loss: 0.040757] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.272734] time: 1:36:29.173620\n",
      "(10, 128, 128, 3)\n",
      "0.8942046\n",
      "[Epoch 9/10] [Batch 866/1081] [D loss: 0.040628] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.307992] time: 1:36:29.789474\n",
      "(10, 128, 128, 3)\n",
      "0.9485483\n",
      "[Epoch 9/10] [Batch 867/1081] [D loss: 0.040327] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.298066] time: 1:36:30.388887\n",
      "(10, 128, 128, 3)\n",
      "0.9361658\n",
      "[Epoch 9/10] [Batch 868/1081] [D loss: 0.040165] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.060579] time: 1:36:30.999443\n",
      "(10, 128, 128, 3)\n",
      "0.9421454\n",
      "[Epoch 9/10] [Batch 869/1081] [D loss: 0.039975] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.664452] time: 1:36:31.654860\n",
      "(10, 128, 128, 3)\n",
      "0.91825056\n",
      "[Epoch 9/10] [Batch 870/1081] [D loss: 0.040645] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.628593] time: 1:36:32.267486\n",
      "(10, 128, 128, 3)\n",
      "0.94357914\n",
      "[Epoch 9/10] [Batch 871/1081] [D loss: 0.040100] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.785186] time: 1:36:32.962519\n",
      "(10, 128, 128, 3)\n",
      "0.9386185\n",
      "[Epoch 9/10] [Batch 872/1081] [D loss: 0.040046] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.455232] time: 1:36:33.679784\n",
      "(10, 128, 128, 3)\n",
      "0.90123624\n",
      "[Epoch 9/10] [Batch 873/1081] [D loss: 0.039781] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.590728] time: 1:36:34.245836\n",
      "(10, 128, 128, 3)\n",
      "0.91650456\n",
      "[Epoch 9/10] [Batch 874/1081] [D loss: 0.039637] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.772323] time: 1:36:34.853925\n",
      "(10, 128, 128, 3)\n",
      "0.9366353\n",
      "[Epoch 9/10] [Batch 875/1081] [D loss: 0.040006] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.548542] time: 1:36:35.541870\n",
      "(10, 128, 128, 3)\n",
      "0.9270322\n",
      "[Epoch 9/10] [Batch 876/1081] [D loss: 0.039502] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.152971] time: 1:36:36.167218\n",
      "(10, 128, 128, 3)\n",
      "0.9098508\n",
      "[Epoch 9/10] [Batch 877/1081] [D loss: 0.039522] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.401594] time: 1:36:36.804399\n",
      "(10, 128, 128, 3)\n",
      "0.90143985\n",
      "[Epoch 9/10] [Batch 878/1081] [D loss: 0.039977] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.786360] time: 1:36:37.467632\n",
      "(10, 128, 128, 3)\n",
      "0.91349965\n",
      "[Epoch 9/10] [Batch 879/1081] [D loss: 0.041396] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.139628] time: 1:36:38.090451\n",
      "(10, 128, 128, 3)\n",
      "0.8617716\n",
      "[Epoch 9/10] [Batch 880/1081] [D loss: 0.039754] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.713610] time: 1:36:38.727599\n",
      "(10, 128, 128, 3)\n",
      "0.926157\n",
      "[Epoch 9/10] [Batch 881/1081] [D loss: 0.039260] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.941132] time: 1:36:39.446372\n",
      "(10, 128, 128, 3)\n",
      "0.9415942\n",
      "[Epoch 9/10] [Batch 882/1081] [D loss: 0.039397] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.786454] time: 1:36:40.135082\n",
      "(10, 128, 128, 3)\n",
      "0.92674536\n",
      "[Epoch 9/10] [Batch 883/1081] [D loss: 0.039509] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.427311] time: 1:36:40.729255\n",
      "(10, 128, 128, 3)\n",
      "0.93862224\n",
      "[Epoch 9/10] [Batch 884/1081] [D loss: 0.039287] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.221130] time: 1:36:41.404345\n",
      "(10, 128, 128, 3)\n",
      "0.91368455\n",
      "[Epoch 9/10] [Batch 885/1081] [D loss: 0.039430] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.323812] time: 1:36:42.024703\n",
      "(10, 128, 128, 3)\n",
      "0.90656924\n",
      "[Epoch 9/10] [Batch 886/1081] [D loss: 0.038960] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.923384] time: 1:36:42.737697\n",
      "(10, 128, 128, 3)\n",
      "0.9469612\n",
      "[Epoch 9/10] [Batch 887/1081] [D loss: 0.039016] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.448528] time: 1:36:43.378718\n",
      "(10, 128, 128, 3)\n",
      "0.94813186\n",
      "[Epoch 9/10] [Batch 888/1081] [D loss: 0.041245] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.205293] time: 1:36:44.005266\n",
      "(10, 128, 128, 3)\n",
      "0.9267709\n",
      "[Epoch 9/10] [Batch 889/1081] [D loss: 0.039444] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.600546] time: 1:36:44.646401\n",
      "(10, 128, 128, 3)\n",
      "0.9004647\n",
      "[Epoch 9/10] [Batch 890/1081] [D loss: 0.049715] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.056875] time: 1:36:45.284941\n",
      "(10, 128, 128, 3)\n",
      "0.90876627\n",
      "[Epoch 9/10] [Batch 891/1081] [D loss: 0.045124] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.282829] time: 1:36:45.900967\n",
      "(10, 128, 128, 3)\n",
      "0.9043801\n",
      "[Epoch 9/10] [Batch 892/1081] [D loss: 0.040693] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 5.265772] time: 1:36:46.557241\n",
      "(10, 128, 128, 3)\n",
      "0.9295743\n",
      "[Epoch 9/10] [Batch 893/1081] [D loss: 0.040697] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.413561] time: 1:36:47.178689\n",
      "(10, 128, 128, 3)\n",
      "0.8888628\n",
      "[Epoch 9/10] [Batch 894/1081] [D loss: 0.039002] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.778624] time: 1:36:47.814873\n",
      "(10, 128, 128, 3)\n",
      "0.94237155\n",
      "[Epoch 9/10] [Batch 895/1081] [D loss: 0.038762] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.598964] time: 1:36:48.456230\n",
      "(10, 128, 128, 3)\n",
      "0.8790261\n",
      "[Epoch 9/10] [Batch 896/1081] [D loss: 0.038988] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.857726] time: 1:36:49.130126\n",
      "(10, 128, 128, 3)\n",
      "0.90824383\n",
      "[Epoch 9/10] [Batch 897/1081] [D loss: 0.038620] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.074810] time: 1:36:49.802278\n",
      "(10, 128, 128, 3)\n",
      "0.93362856\n",
      "[Epoch 9/10] [Batch 898/1081] [D loss: 0.039082] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.421619] time: 1:36:50.456672\n",
      "(10, 128, 128, 3)\n",
      "0.94518894\n",
      "[Epoch 9/10] [Batch 899/1081] [D loss: 0.038659] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.144591] time: 1:36:51.109779\n",
      "(10, 128, 128, 3)\n",
      "0.9125018\n",
      "[Epoch 9/10] [Batch 900/1081] [D loss: 0.038662] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.069348] time: 1:36:51.744009\n",
      "(10, 128, 128, 3)\n",
      "0.8744909\n",
      "[Epoch 9/10] [Batch 901/1081] [D loss: 0.038846] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.903254] time: 1:36:52.359247\n",
      "(10, 128, 128, 3)\n",
      "0.9104826\n",
      "[Epoch 9/10] [Batch 902/1081] [D loss: 0.038531] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.967946] time: 1:36:52.972192\n",
      "(10, 128, 128, 3)\n",
      "0.91417783\n",
      "[Epoch 9/10] [Batch 903/1081] [D loss: 0.038259] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.711345] time: 1:36:53.603270\n",
      "(10, 128, 128, 3)\n",
      "0.8689565\n",
      "[Epoch 9/10] [Batch 904/1081] [D loss: 0.038335] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.343913] time: 1:36:54.285298\n",
      "(10, 128, 128, 3)\n",
      "0.92671806\n",
      "[Epoch 9/10] [Batch 905/1081] [D loss: 0.051606] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.623547] time: 1:36:54.991412\n",
      "(10, 128, 128, 3)\n",
      "0.8385391\n",
      "[Epoch 9/10] [Batch 906/1081] [D loss: 0.288710] [D acc: 0.50 (1.00 real, 0.00 fake)] [G loss: 3.811061] time: 1:36:55.558358\n",
      "(10, 128, 128, 3)\n",
      "0.88265187\n",
      "[Epoch 9/10] [Batch 907/1081] [D loss: 0.537189] [D acc: 0.30 (0.60 real, 0.00 fake)] [G loss: 3.700328] time: 1:36:56.190638\n",
      "(10, 128, 128, 3)\n",
      "0.8705158\n",
      "[Epoch 9/10] [Batch 908/1081] [D loss: 0.274159] [D acc: 0.65 (0.80 real, 0.50 fake)] [G loss: 3.768667] time: 1:36:56.868058\n",
      "(10, 128, 128, 3)\n",
      "0.8283232\n",
      "[Epoch 9/10] [Batch 909/1081] [D loss: 0.228241] [D acc: 0.85 (0.80 real, 0.90 fake)] [G loss: 3.294903] time: 1:36:57.490573\n",
      "(10, 128, 128, 3)\n",
      "0.8786858\n",
      "[Epoch 9/10] [Batch 910/1081] [D loss: 0.105225] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 3.899632] time: 1:36:58.110885\n",
      "(10, 128, 128, 3)\n",
      "0.92848945\n",
      "[Epoch 9/10] [Batch 911/1081] [D loss: 0.143954] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 6.111443] time: 1:36:58.755159\n",
      "(10, 128, 128, 3)\n",
      "0.9171293\n",
      "[Epoch 9/10] [Batch 912/1081] [D loss: 0.100856] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 3.721139] time: 1:36:59.431743\n",
      "(10, 128, 128, 3)\n",
      "0.90083104\n",
      "[Epoch 9/10] [Batch 913/1081] [D loss: 0.105621] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 3.846486] time: 1:37:00.048289\n",
      "(10, 128, 128, 3)\n",
      "0.92086273\n",
      "[Epoch 9/10] [Batch 914/1081] [D loss: 0.098355] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.675217] time: 1:37:00.652123\n",
      "(10, 128, 128, 3)\n",
      "0.92250013\n",
      "[Epoch 9/10] [Batch 915/1081] [D loss: 0.057929] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.281502] time: 1:37:01.262732\n",
      "(10, 128, 128, 3)\n",
      "0.9307044\n",
      "[Epoch 9/10] [Batch 916/1081] [D loss: 0.068708] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.230606] time: 1:37:01.914494\n",
      "(10, 128, 128, 3)\n",
      "0.8805314\n",
      "[Epoch 9/10] [Batch 917/1081] [D loss: 0.104232] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 4.059614] time: 1:37:02.526484\n",
      "(10, 128, 128, 3)\n",
      "0.9048489\n",
      "[Epoch 9/10] [Batch 918/1081] [D loss: 0.149369] [D acc: 0.80 (0.60 real, 1.00 fake)] [G loss: 4.828630] time: 1:37:03.144874\n",
      "(10, 128, 128, 3)\n",
      "0.8955738\n",
      "[Epoch 9/10] [Batch 919/1081] [D loss: 0.098511] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.306358] time: 1:37:03.808413\n",
      "(10, 128, 128, 3)\n",
      "0.9163246\n",
      "[Epoch 9/10] [Batch 920/1081] [D loss: 0.060803] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.405460] time: 1:37:04.424907\n",
      "(10, 128, 128, 3)\n",
      "0.92885685\n",
      "[Epoch 9/10] [Batch 921/1081] [D loss: 0.068599] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.510871] time: 1:37:05.092162\n",
      "(10, 128, 128, 3)\n",
      "0.93594676\n",
      "[Epoch 9/10] [Batch 922/1081] [D loss: 0.078444] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 3.909267] time: 1:37:05.783297\n",
      "(10, 128, 128, 3)\n",
      "0.86083096\n",
      "[Epoch 9/10] [Batch 923/1081] [D loss: 0.053916] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.567558] time: 1:37:06.434437\n",
      "(10, 128, 128, 3)\n",
      "0.9165006\n",
      "[Epoch 9/10] [Batch 924/1081] [D loss: 0.049494] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.941870] time: 1:37:07.096782\n",
      "(10, 128, 128, 3)\n",
      "0.93378764\n",
      "[Epoch 9/10] [Batch 925/1081] [D loss: 0.050150] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.623183] time: 1:37:07.700381\n",
      "(10, 128, 128, 3)\n",
      "0.9377911\n",
      "[Epoch 9/10] [Batch 926/1081] [D loss: 0.067017] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.162661] time: 1:37:08.322319\n",
      "(10, 128, 128, 3)\n",
      "0.8743865\n",
      "[Epoch 9/10] [Batch 927/1081] [D loss: 0.059100] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.609131] time: 1:37:08.995951\n",
      "(10, 128, 128, 3)\n",
      "0.92614144\n",
      "[Epoch 9/10] [Batch 928/1081] [D loss: 0.048953] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.265182] time: 1:37:09.625723\n",
      "(10, 128, 128, 3)\n",
      "0.91500705\n",
      "[Epoch 9/10] [Batch 929/1081] [D loss: 0.049482] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.997006] time: 1:37:10.282063\n",
      "(10, 128, 128, 3)\n",
      "0.90281343\n",
      "[Epoch 9/10] [Batch 930/1081] [D loss: 0.070122] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.214690] time: 1:37:10.945324\n",
      "(10, 128, 128, 3)\n",
      "0.919146\n",
      "[Epoch 9/10] [Batch 931/1081] [D loss: 0.057625] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.752926] time: 1:37:11.623198\n",
      "(10, 128, 128, 3)\n",
      "0.88292885\n",
      "[Epoch 9/10] [Batch 932/1081] [D loss: 0.061448] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.482571] time: 1:37:12.233777\n",
      "(10, 128, 128, 3)\n",
      "0.90760994\n",
      "[Epoch 9/10] [Batch 933/1081] [D loss: 0.050687] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.907913] time: 1:37:12.918342\n",
      "(10, 128, 128, 3)\n",
      "0.9209426\n",
      "[Epoch 9/10] [Batch 934/1081] [D loss: 0.065597] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.724355] time: 1:37:13.551893\n",
      "(10, 128, 128, 3)\n",
      "0.9614832\n",
      "[Epoch 9/10] [Batch 935/1081] [D loss: 0.052978] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.377759] time: 1:37:14.232032\n",
      "(10, 128, 128, 3)\n",
      "0.9080758\n",
      "[Epoch 9/10] [Batch 936/1081] [D loss: 0.084245] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.669545] time: 1:37:14.921155\n",
      "(10, 128, 128, 3)\n",
      "0.9219291\n",
      "[Epoch 9/10] [Batch 937/1081] [D loss: 0.113572] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 3.932059] time: 1:37:15.524734\n",
      "(10, 128, 128, 3)\n",
      "0.94151574\n",
      "[Epoch 9/10] [Batch 938/1081] [D loss: 0.115019] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.172746] time: 1:37:16.177955\n",
      "(10, 128, 128, 3)\n",
      "0.91425157\n",
      "[Epoch 9/10] [Batch 939/1081] [D loss: 0.125968] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.337245] time: 1:37:16.815795\n",
      "(10, 128, 128, 3)\n",
      "0.89586586\n",
      "[Epoch 9/10] [Batch 940/1081] [D loss: 0.224379] [D acc: 0.80 (0.60 real, 1.00 fake)] [G loss: 4.564674] time: 1:37:17.508577\n",
      "(10, 128, 128, 3)\n",
      "0.89755136\n",
      "[Epoch 9/10] [Batch 941/1081] [D loss: 0.085845] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.058147] time: 1:37:18.155296\n",
      "(10, 128, 128, 3)\n",
      "0.8856404\n",
      "[Epoch 9/10] [Batch 942/1081] [D loss: 0.068275] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.517698] time: 1:37:18.769065\n",
      "(10, 128, 128, 3)\n",
      "0.9062104\n",
      "[Epoch 9/10] [Batch 943/1081] [D loss: 0.069619] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.030230] time: 1:37:19.470558\n",
      "(10, 128, 128, 3)\n",
      "0.8606739\n",
      "[Epoch 9/10] [Batch 944/1081] [D loss: 0.073364] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.412279] time: 1:37:20.189707\n",
      "(10, 128, 128, 3)\n",
      "0.9080391\n",
      "[Epoch 9/10] [Batch 945/1081] [D loss: 0.095990] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 4.423181] time: 1:37:20.814913\n",
      "(10, 128, 128, 3)\n",
      "0.86267394\n",
      "[Epoch 9/10] [Batch 946/1081] [D loss: 0.090773] [D acc: 0.95 (0.90 real, 1.00 fake)] [G loss: 4.748890] time: 1:37:21.442510\n",
      "(10, 128, 128, 3)\n",
      "0.94334245\n",
      "[Epoch 9/10] [Batch 947/1081] [D loss: 0.079922] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.487335] time: 1:37:22.116176\n",
      "(10, 128, 128, 3)\n",
      "0.89131135\n",
      "[Epoch 9/10] [Batch 948/1081] [D loss: 0.071083] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.043267] time: 1:37:22.853410\n",
      "(10, 128, 128, 3)\n",
      "0.88053393\n",
      "[Epoch 9/10] [Batch 949/1081] [D loss: 0.062750] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.737859] time: 1:37:23.510002\n",
      "(10, 128, 128, 3)\n",
      "0.9548133\n",
      "[Epoch 9/10] [Batch 950/1081] [D loss: 0.065773] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.272145] time: 1:37:24.114728\n",
      "(10, 128, 128, 3)\n",
      "0.9055519\n",
      "[Epoch 9/10] [Batch 951/1081] [D loss: 0.062506] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.957999] time: 1:37:24.720839\n",
      "(10, 128, 128, 3)\n",
      "0.95978284\n",
      "[Epoch 9/10] [Batch 952/1081] [D loss: 0.064735] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.348917] time: 1:37:25.371866\n",
      "(10, 128, 128, 3)\n",
      "0.88053757\n",
      "[Epoch 9/10] [Batch 953/1081] [D loss: 0.063901] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.297498] time: 1:37:26.026810\n",
      "(10, 128, 128, 3)\n",
      "0.89466566\n",
      "[Epoch 9/10] [Batch 954/1081] [D loss: 0.074256] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.690027] time: 1:37:26.680738\n",
      "(10, 128, 128, 3)\n",
      "0.91135293\n",
      "[Epoch 9/10] [Batch 955/1081] [D loss: 0.060064] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.816120] time: 1:37:27.291425\n",
      "(10, 128, 128, 3)\n",
      "0.93690294\n",
      "[Epoch 9/10] [Batch 956/1081] [D loss: 0.083915] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.635686] time: 1:37:27.970409\n",
      "(10, 128, 128, 3)\n",
      "0.951628\n",
      "[Epoch 9/10] [Batch 957/1081] [D loss: 0.060128] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.667265] time: 1:37:28.670757\n",
      "(10, 128, 128, 3)\n",
      "0.85259444\n",
      "[Epoch 9/10] [Batch 958/1081] [D loss: 0.065533] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.274294] time: 1:37:29.271296\n",
      "(10, 128, 128, 3)\n",
      "0.877378\n",
      "[Epoch 9/10] [Batch 959/1081] [D loss: 0.058772] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.291610] time: 1:37:29.920235\n",
      "(10, 128, 128, 3)\n",
      "0.88216853\n",
      "[Epoch 9/10] [Batch 960/1081] [D loss: 0.060984] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.677648] time: 1:37:30.613444\n",
      "(10, 128, 128, 3)\n",
      "0.87098354\n",
      "[Epoch 9/10] [Batch 961/1081] [D loss: 0.064730] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.891127] time: 1:37:31.263401\n",
      "(10, 128, 128, 3)\n",
      "0.88898355\n",
      "[Epoch 9/10] [Batch 962/1081] [D loss: 0.066007] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.375642] time: 1:37:31.863316\n",
      "(10, 128, 128, 3)\n",
      "0.8810513\n",
      "[Epoch 9/10] [Batch 963/1081] [D loss: 0.061132] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.247230] time: 1:37:32.501293\n",
      "(10, 128, 128, 3)\n",
      "0.9144792\n",
      "[Epoch 9/10] [Batch 964/1081] [D loss: 0.057963] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.760648] time: 1:37:33.124551\n",
      "(10, 128, 128, 3)\n",
      "0.9596102\n",
      "[Epoch 9/10] [Batch 965/1081] [D loss: 0.056046] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.837610] time: 1:37:33.763810\n",
      "(10, 128, 128, 3)\n",
      "0.9241002\n",
      "[Epoch 9/10] [Batch 966/1081] [D loss: 0.062118] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.104243] time: 1:37:34.413755\n",
      "(10, 128, 128, 3)\n",
      "0.9326455\n",
      "[Epoch 9/10] [Batch 967/1081] [D loss: 0.057148] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.974010] time: 1:37:35.074631\n",
      "(10, 128, 128, 3)\n",
      "0.9141548\n",
      "[Epoch 9/10] [Batch 968/1081] [D loss: 0.059806] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.590878] time: 1:37:35.733097\n",
      "(10, 128, 128, 3)\n",
      "0.92819303\n",
      "[Epoch 9/10] [Batch 969/1081] [D loss: 0.055967] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.171689] time: 1:37:36.357642\n",
      "(10, 128, 128, 3)\n",
      "0.89300674\n",
      "[Epoch 9/10] [Batch 970/1081] [D loss: 0.061211] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.183411] time: 1:37:36.943639\n",
      "(10, 128, 128, 3)\n",
      "0.864585\n",
      "[Epoch 9/10] [Batch 971/1081] [D loss: 0.064620] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.947491] time: 1:37:37.570345\n",
      "(10, 128, 128, 3)\n",
      "0.9200322\n",
      "[Epoch 9/10] [Batch 972/1081] [D loss: 0.055838] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.243907] time: 1:37:38.243040\n",
      "(10, 128, 128, 3)\n",
      "0.8810415\n",
      "[Epoch 9/10] [Batch 973/1081] [D loss: 0.055387] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.536980] time: 1:37:38.842893\n",
      "(10, 128, 128, 3)\n",
      "0.9409459\n",
      "[Epoch 9/10] [Batch 974/1081] [D loss: 0.062407] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.377371] time: 1:37:39.485832\n",
      "(10, 128, 128, 3)\n",
      "0.867373\n",
      "[Epoch 9/10] [Batch 975/1081] [D loss: 0.056813] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.792313] time: 1:37:40.094709\n",
      "(10, 128, 128, 3)\n",
      "0.95263296\n",
      "[Epoch 9/10] [Batch 976/1081] [D loss: 0.054753] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.792814] time: 1:37:40.756768\n",
      "(10, 128, 128, 3)\n",
      "0.90578693\n",
      "[Epoch 9/10] [Batch 977/1081] [D loss: 0.054263] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.115541] time: 1:37:41.378482\n",
      "(10, 128, 128, 3)\n",
      "0.8983379\n",
      "[Epoch 9/10] [Batch 978/1081] [D loss: 0.053684] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.910553] time: 1:37:42.082830\n",
      "(10, 128, 128, 3)\n",
      "0.89444536\n",
      "[Epoch 9/10] [Batch 979/1081] [D loss: 0.053782] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.607312] time: 1:37:42.709800\n",
      "(10, 128, 128, 3)\n",
      "0.9386349\n",
      "[Epoch 9/10] [Batch 980/1081] [D loss: 0.052562] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.272101] time: 1:37:43.330512\n",
      "(10, 128, 128, 3)\n",
      "0.88731676\n",
      "[Epoch 9/10] [Batch 981/1081] [D loss: 0.053730] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.533973] time: 1:37:44.000402\n",
      "(10, 128, 128, 3)\n",
      "0.9237986\n",
      "[Epoch 9/10] [Batch 982/1081] [D loss: 0.053692] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.688982] time: 1:37:44.639651\n",
      "(10, 128, 128, 3)\n",
      "0.90506166\n",
      "[Epoch 9/10] [Batch 983/1081] [D loss: 0.053047] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.186876] time: 1:37:45.241080\n",
      "(10, 128, 128, 3)\n",
      "0.920019\n",
      "[Epoch 9/10] [Batch 984/1081] [D loss: 0.051462] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.069031] time: 1:37:45.922852\n",
      "(10, 128, 128, 3)\n",
      "0.88428336\n",
      "[Epoch 9/10] [Batch 985/1081] [D loss: 0.052297] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.861661] time: 1:37:46.580276\n",
      "(10, 128, 128, 3)\n",
      "0.8997794\n",
      "[Epoch 9/10] [Batch 986/1081] [D loss: 0.053543] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.780251] time: 1:37:47.198527\n",
      "(10, 128, 128, 3)\n",
      "0.9477568\n",
      "[Epoch 9/10] [Batch 987/1081] [D loss: 0.059011] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.197930] time: 1:37:47.821256\n",
      "(10, 128, 128, 3)\n",
      "0.93419415\n",
      "[Epoch 9/10] [Batch 988/1081] [D loss: 0.052063] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.037637] time: 1:37:48.490549\n",
      "(10, 128, 128, 3)\n",
      "0.86464006\n",
      "[Epoch 9/10] [Batch 989/1081] [D loss: 0.051669] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.171125] time: 1:37:49.174476\n",
      "(10, 128, 128, 3)\n",
      "0.9381326\n",
      "[Epoch 9/10] [Batch 990/1081] [D loss: 0.052500] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.254346] time: 1:37:49.788011\n",
      "(10, 128, 128, 3)\n",
      "0.8702791\n",
      "[Epoch 9/10] [Batch 991/1081] [D loss: 0.051732] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.702502] time: 1:37:50.458494\n",
      "(10, 128, 128, 3)\n",
      "0.91544986\n",
      "[Epoch 9/10] [Batch 992/1081] [D loss: 0.054334] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.741292] time: 1:37:51.097282\n",
      "(10, 128, 128, 3)\n",
      "0.86820173\n",
      "[Epoch 9/10] [Batch 993/1081] [D loss: 0.052029] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.071049] time: 1:37:51.737513\n",
      "(10, 128, 128, 3)\n",
      "0.8894722\n",
      "[Epoch 9/10] [Batch 994/1081] [D loss: 0.053317] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.081874] time: 1:37:52.368828\n",
      "(10, 128, 128, 3)\n",
      "0.92184407\n",
      "[Epoch 9/10] [Batch 995/1081] [D loss: 0.052982] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.283776] time: 1:37:53.022637\n",
      "(10, 128, 128, 3)\n",
      "0.8926255\n",
      "[Epoch 9/10] [Batch 996/1081] [D loss: 0.050080] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.461484] time: 1:37:53.685055\n",
      "(10, 128, 128, 3)\n",
      "0.91752315\n",
      "[Epoch 9/10] [Batch 997/1081] [D loss: 0.051128] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.897737] time: 1:37:54.390047\n",
      "(10, 128, 128, 3)\n",
      "0.9335017\n",
      "[Epoch 9/10] [Batch 998/1081] [D loss: 0.050511] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.221924] time: 1:37:54.993069\n",
      "(10, 128, 128, 3)\n",
      "0.93393135\n",
      "[Epoch 9/10] [Batch 999/1081] [D loss: 0.049968] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.221554] time: 1:37:55.617755\n",
      "(10, 128, 128, 3)\n",
      "0.9134708\n",
      "[Epoch 9/10] [Batch 1000/1081] [D loss: 0.050575] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.179775] time: 1:37:56.238941\n",
      "(10, 128, 128, 3)\n",
      "0.9107682\n",
      "[Epoch 9/10] [Batch 1001/1081] [D loss: 0.050820] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.252937] time: 1:37:56.911450\n",
      "(10, 128, 128, 3)\n",
      "0.9040777\n",
      "[Epoch 9/10] [Batch 1002/1081] [D loss: 0.059584] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.253790] time: 1:37:57.566944\n",
      "(10, 128, 128, 3)\n",
      "0.9196343\n",
      "[Epoch 9/10] [Batch 1003/1081] [D loss: 0.067603] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.300083] time: 1:37:58.171344\n",
      "(10, 128, 128, 3)\n",
      "0.8663564\n",
      "[Epoch 9/10] [Batch 1004/1081] [D loss: 0.070676] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.365041] time: 1:37:58.830719\n",
      "(10, 128, 128, 3)\n",
      "0.91616505\n",
      "[Epoch 9/10] [Batch 1005/1081] [D loss: 0.052731] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.510654] time: 1:37:59.459522\n",
      "(10, 128, 128, 3)\n",
      "0.9276442\n",
      "[Epoch 9/10] [Batch 1006/1081] [D loss: 0.054983] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.864305] time: 1:38:00.096092\n",
      "(10, 128, 128, 3)\n",
      "0.9137599\n",
      "[Epoch 9/10] [Batch 1007/1081] [D loss: 0.050359] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.609885] time: 1:38:00.802079\n",
      "(10, 128, 128, 3)\n",
      "0.9045496\n",
      "[Epoch 9/10] [Batch 1008/1081] [D loss: 0.053351] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.074383] time: 1:38:01.467332\n",
      "(10, 128, 128, 3)\n",
      "0.9262185\n",
      "[Epoch 9/10] [Batch 1009/1081] [D loss: 0.052996] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.185370] time: 1:38:02.099336\n",
      "(10, 128, 128, 3)\n",
      "0.93129426\n",
      "[Epoch 9/10] [Batch 1010/1081] [D loss: 0.054380] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.917684] time: 1:38:02.752986\n",
      "(10, 128, 128, 3)\n",
      "0.9387161\n",
      "[Epoch 9/10] [Batch 1011/1081] [D loss: 0.054468] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.681566] time: 1:38:03.376082\n",
      "(10, 128, 128, 3)\n",
      "0.8872984\n",
      "[Epoch 9/10] [Batch 1012/1081] [D loss: 0.048094] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.795701] time: 1:38:03.987229\n",
      "(10, 128, 128, 3)\n",
      "0.89278084\n",
      "[Epoch 9/10] [Batch 1013/1081] [D loss: 0.051886] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.454137] time: 1:38:04.665237\n",
      "(10, 128, 128, 3)\n",
      "0.88526565\n",
      "[Epoch 9/10] [Batch 1014/1081] [D loss: 0.053017] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.249483] time: 1:38:05.251441\n",
      "(10, 128, 128, 3)\n",
      "0.86577433\n",
      "[Epoch 9/10] [Batch 1015/1081] [D loss: 0.049325] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.938863] time: 1:38:05.908504\n",
      "(10, 128, 128, 3)\n",
      "0.8693256\n",
      "[Epoch 9/10] [Batch 1016/1081] [D loss: 0.050420] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.045164] time: 1:38:06.524976\n",
      "(10, 128, 128, 3)\n",
      "0.9483765\n",
      "[Epoch 9/10] [Batch 1017/1081] [D loss: 0.058769] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.597642] time: 1:38:07.218043\n",
      "(10, 128, 128, 3)\n",
      "0.92735237\n",
      "[Epoch 9/10] [Batch 1018/1081] [D loss: 0.047547] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.033936] time: 1:38:07.806048\n",
      "(10, 128, 128, 3)\n",
      "0.9411115\n",
      "[Epoch 9/10] [Batch 1019/1081] [D loss: 0.050448] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.941078] time: 1:38:08.502656\n",
      "(10, 128, 128, 3)\n",
      "0.9076381\n",
      "[Epoch 9/10] [Batch 1020/1081] [D loss: 0.050290] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.292101] time: 1:38:09.121549\n",
      "(10, 128, 128, 3)\n",
      "0.9306144\n",
      "[Epoch 9/10] [Batch 1021/1081] [D loss: 0.048554] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.774392] time: 1:38:09.806654\n",
      "(10, 128, 128, 3)\n",
      "0.8967226\n",
      "[Epoch 9/10] [Batch 1022/1081] [D loss: 0.046696] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.629680] time: 1:38:10.496735\n",
      "(10, 128, 128, 3)\n",
      "0.9398816\n",
      "[Epoch 9/10] [Batch 1023/1081] [D loss: 0.048837] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.143517] time: 1:38:11.214126\n",
      "(10, 128, 128, 3)\n",
      "0.87000865\n",
      "[Epoch 9/10] [Batch 1024/1081] [D loss: 0.046289] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.787342] time: 1:38:11.856771\n",
      "(10, 128, 128, 3)\n",
      "0.8837994\n",
      "[Epoch 9/10] [Batch 1025/1081] [D loss: 0.051003] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.579086] time: 1:38:12.535748\n",
      "(10, 128, 128, 3)\n",
      "0.95755416\n",
      "[Epoch 9/10] [Batch 1026/1081] [D loss: 0.046683] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.889045] time: 1:38:13.210473\n",
      "(10, 128, 128, 3)\n",
      "0.8853045\n",
      "[Epoch 9/10] [Batch 1027/1081] [D loss: 0.046689] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.846632] time: 1:38:13.809995\n",
      "(10, 128, 128, 3)\n",
      "0.9432505\n",
      "[Epoch 9/10] [Batch 1028/1081] [D loss: 0.047732] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.316875] time: 1:38:14.426761\n",
      "(10, 128, 128, 3)\n",
      "0.8746298\n",
      "[Epoch 9/10] [Batch 1029/1081] [D loss: 0.045394] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.935968] time: 1:38:15.318566\n",
      "(10, 128, 128, 3)\n",
      "0.8505021\n",
      "[Epoch 9/10] [Batch 1030/1081] [D loss: 0.050764] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.790806] time: 1:38:16.192283\n",
      "(10, 128, 128, 3)\n",
      "0.92223215\n",
      "[Epoch 9/10] [Batch 1031/1081] [D loss: 0.048142] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.055480] time: 1:38:16.837415\n",
      "(10, 128, 128, 3)\n",
      "0.9426325\n",
      "[Epoch 9/10] [Batch 1032/1081] [D loss: 0.054529] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.065539] time: 1:38:17.486556\n",
      "(10, 128, 128, 3)\n",
      "0.9260709\n",
      "[Epoch 9/10] [Batch 1033/1081] [D loss: 0.047684] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.818317] time: 1:38:18.114408\n",
      "(10, 128, 128, 3)\n",
      "0.9154499\n",
      "[Epoch 9/10] [Batch 1034/1081] [D loss: 0.049049] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.106852] time: 1:38:18.779936\n",
      "(10, 128, 128, 3)\n",
      "0.9069254\n",
      "[Epoch 9/10] [Batch 1035/1081] [D loss: 0.045382] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.074801] time: 1:38:19.420220\n",
      "(10, 128, 128, 3)\n",
      "0.88858134\n",
      "[Epoch 9/10] [Batch 1036/1081] [D loss: 0.048581] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.556522] time: 1:38:20.092577\n",
      "(10, 128, 128, 3)\n",
      "0.93178445\n",
      "[Epoch 9/10] [Batch 1037/1081] [D loss: 0.046286] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.188403] time: 1:38:20.787172\n",
      "(10, 128, 128, 3)\n",
      "0.91086644\n",
      "[Epoch 9/10] [Batch 1038/1081] [D loss: 0.046984] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.754755] time: 1:38:21.429174\n",
      "(10, 128, 128, 3)\n",
      "0.9079495\n",
      "[Epoch 9/10] [Batch 1039/1081] [D loss: 0.047901] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.357396] time: 1:38:22.039443\n",
      "(10, 128, 128, 3)\n",
      "0.9248491\n",
      "[Epoch 9/10] [Batch 1040/1081] [D loss: 0.054322] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.287730] time: 1:38:22.720269\n",
      "(10, 128, 128, 3)\n",
      "0.9319303\n",
      "[Epoch 9/10] [Batch 1041/1081] [D loss: 0.046165] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.715188] time: 1:38:23.415478\n",
      "(10, 128, 128, 3)\n",
      "0.90597916\n",
      "[Epoch 9/10] [Batch 1042/1081] [D loss: 0.044871] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.552851] time: 1:38:24.029872\n",
      "(10, 128, 128, 3)\n",
      "0.8845419\n",
      "[Epoch 9/10] [Batch 1043/1081] [D loss: 0.045006] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.108545] time: 1:38:24.636270\n",
      "(10, 128, 128, 3)\n",
      "0.9036445\n",
      "[Epoch 9/10] [Batch 1044/1081] [D loss: 0.044576] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.440879] time: 1:38:25.312011\n",
      "(10, 128, 128, 3)\n",
      "0.879021\n",
      "[Epoch 9/10] [Batch 1045/1081] [D loss: 0.044673] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.560285] time: 1:38:25.910029\n",
      "(10, 128, 128, 3)\n",
      "0.91405493\n",
      "[Epoch 9/10] [Batch 1046/1081] [D loss: 0.043328] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.291178] time: 1:38:26.576237\n",
      "(10, 128, 128, 3)\n",
      "0.90928555\n",
      "[Epoch 9/10] [Batch 1047/1081] [D loss: 0.045123] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.425933] time: 1:38:27.199723\n",
      "(10, 128, 128, 3)\n",
      "0.8689053\n",
      "[Epoch 9/10] [Batch 1048/1081] [D loss: 0.043964] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.133340] time: 1:38:27.854439\n",
      "(10, 128, 128, 3)\n",
      "0.90356094\n",
      "[Epoch 9/10] [Batch 1049/1081] [D loss: 0.044816] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.590316] time: 1:38:28.533731\n",
      "(10, 128, 128, 3)\n",
      "0.91986626\n",
      "[Epoch 9/10] [Batch 1050/1081] [D loss: 0.045495] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.025383] time: 1:38:29.144705\n",
      "(10, 128, 128, 3)\n",
      "0.9109455\n",
      "[Epoch 9/10] [Batch 1051/1081] [D loss: 0.044392] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.725974] time: 1:38:29.807973\n",
      "(10, 128, 128, 3)\n",
      "0.88297135\n",
      "[Epoch 9/10] [Batch 1052/1081] [D loss: 0.043569] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.283138] time: 1:38:30.540682\n",
      "(10, 128, 128, 3)\n",
      "0.9059569\n",
      "[Epoch 9/10] [Batch 1053/1081] [D loss: 0.049516] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.485421] time: 1:38:31.226472\n",
      "(10, 128, 128, 3)\n",
      "0.93573445\n",
      "[Epoch 9/10] [Batch 1054/1081] [D loss: 0.051373] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.767459] time: 1:38:31.838492\n",
      "(10, 128, 128, 3)\n",
      "0.9714363\n",
      "[Epoch 9/10] [Batch 1055/1081] [D loss: 0.045188] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.536213] time: 1:38:32.472934\n",
      "(10, 128, 128, 3)\n",
      "0.9364428\n",
      "[Epoch 9/10] [Batch 1056/1081] [D loss: 0.043601] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.518684] time: 1:38:33.154441\n",
      "(10, 128, 128, 3)\n",
      "0.86847514\n",
      "[Epoch 9/10] [Batch 1057/1081] [D loss: 0.043124] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.125373] time: 1:38:33.789283\n",
      "(10, 128, 128, 3)\n",
      "0.9313826\n",
      "[Epoch 9/10] [Batch 1058/1081] [D loss: 0.043555] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.887980] time: 1:38:34.384209\n",
      "(10, 128, 128, 3)\n",
      "0.87446404\n",
      "[Epoch 9/10] [Batch 1059/1081] [D loss: 0.044612] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.851474] time: 1:38:35.001039\n",
      "(10, 128, 128, 3)\n",
      "0.90741736\n",
      "[Epoch 9/10] [Batch 1060/1081] [D loss: 0.043545] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.822731] time: 1:38:35.660854\n",
      "(10, 128, 128, 3)\n",
      "0.95314175\n",
      "[Epoch 9/10] [Batch 1061/1081] [D loss: 0.044880] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.925467] time: 1:38:36.310444\n",
      "(10, 128, 128, 3)\n",
      "0.8756092\n",
      "[Epoch 9/10] [Batch 1062/1081] [D loss: 0.043509] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.409803] time: 1:38:36.979521\n",
      "(10, 128, 128, 3)\n",
      "0.9006234\n",
      "[Epoch 9/10] [Batch 1063/1081] [D loss: 0.042820] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.726076] time: 1:38:37.666236\n",
      "(10, 128, 128, 3)\n",
      "0.9183381\n",
      "[Epoch 9/10] [Batch 1064/1081] [D loss: 0.108736] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.650007] time: 1:38:39.146373\n",
      "(10, 128, 128, 3)\n",
      "0.9236805\n",
      "[Epoch 9/10] [Batch 1065/1081] [D loss: 0.045755] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.561668] time: 1:38:39.865207\n",
      "(10, 128, 128, 3)\n",
      "0.8880689\n",
      "[Epoch 9/10] [Batch 1066/1081] [D loss: 0.056214] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.629673] time: 1:38:40.529726\n",
      "(10, 128, 128, 3)\n",
      "0.925595\n",
      "[Epoch 9/10] [Batch 1067/1081] [D loss: 0.045427] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.613863] time: 1:38:41.161840\n",
      "(10, 128, 128, 3)\n",
      "0.8801001\n",
      "[Epoch 9/10] [Batch 1068/1081] [D loss: 0.046287] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.207425] time: 1:38:41.803928\n",
      "(10, 128, 128, 3)\n",
      "0.91644007\n",
      "[Epoch 9/10] [Batch 1069/1081] [D loss: 0.054816] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.486386] time: 1:38:42.426407\n",
      "(10, 128, 128, 3)\n",
      "0.9622028\n",
      "[Epoch 9/10] [Batch 1070/1081] [D loss: 0.044003] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.303329] time: 1:38:43.091894\n",
      "(10, 128, 128, 3)\n",
      "0.9343383\n",
      "[Epoch 9/10] [Batch 1071/1081] [D loss: 0.047419] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.785829] time: 1:38:43.698456\n",
      "(10, 128, 128, 3)\n",
      "0.90803385\n",
      "[Epoch 9/10] [Batch 1072/1081] [D loss: 0.049974] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 4.449395] time: 1:38:44.417780\n",
      "(10, 128, 128, 3)\n",
      "0.9496333\n",
      "[Epoch 9/10] [Batch 1073/1081] [D loss: 0.044900] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.118189] time: 1:38:45.061943\n",
      "(10, 128, 128, 3)\n",
      "0.8878379\n",
      "[Epoch 9/10] [Batch 1074/1081] [D loss: 0.049578] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.520599] time: 1:38:45.746858\n",
      "(10, 128, 128, 3)\n",
      "0.9209654\n",
      "[Epoch 9/10] [Batch 1075/1081] [D loss: 0.045481] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.918131] time: 1:38:46.387964\n",
      "(10, 128, 128, 3)\n",
      "0.85642797\n",
      "[Epoch 9/10] [Batch 1076/1081] [D loss: 0.043425] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.836599] time: 1:38:47.029081\n",
      "(10, 128, 128, 3)\n",
      "0.93710995\n",
      "[Epoch 9/10] [Batch 1077/1081] [D loss: 0.047221] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.619852] time: 1:38:47.658024\n",
      "(10, 128, 128, 3)\n",
      "0.9047926\n",
      "[Epoch 9/10] [Batch 1078/1081] [D loss: 0.046077] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 2.879031] time: 1:38:48.319668\n",
      "(10, 128, 128, 3)\n",
      "0.9277797\n",
      "[Epoch 9/10] [Batch 1079/1081] [D loss: 0.046544] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.306532] time: 1:38:49.021722\n",
      "(10, 128, 128, 3)\n",
      "0.9468387\n",
      "[Epoch 9/10] [Batch 1080/1081] [D loss: 0.046289] [D acc: 1.00 (1.00 real, 1.00 fake)] [G loss: 3.735294] time: 1:38:49.754749\n",
      "############ VALIDATION OF EPOCH 9 ############\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import img_as_ubyte\n",
    "import numpy as np \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Training lists to be used for plotting.\n",
    "train_batch_loss_d = list()\n",
    "train_batch_loss_g = list()\n",
    "\n",
    "train_epoch_loss_d = list()\n",
    "train_epoch_loss_g = list()\n",
    "\n",
    "train_batch_acc_d = list()\n",
    "train_batch_acc_d_real = list()\n",
    "train_batch_acc_d_fake = list()\n",
    "\n",
    "train_epoch_acc_d = list()\n",
    "train_epoch_acc_d_real = list()\n",
    "train_epoch_acc_d_fake = list()\n",
    "\n",
    "# Validation lists to be used for plotting.\n",
    "val_batch_loss_d = list()\n",
    "val_batch_loss_g = list()\n",
    "\n",
    "val_epoch_loss_d = list()\n",
    "val_epoch_loss_g = list()\n",
    "\n",
    "val_batch_acc_d = list()\n",
    "val_batch_acc_d_real = list()\n",
    "val_batch_acc_d_fake = list()\n",
    "\n",
    "val_epoch_acc_d = list()\n",
    "val_epoch_acc_d_real = list()\n",
    "val_epoch_acc_d_fake = list()\n",
    "\n",
    "test_first_imgs, test_last_imgs = next(test_batch_generator)\n",
    "\n",
    "for epoch in range(cfg.NUM_EPOCHS):\n",
    "    print('############ TRAINING OF EPOCH %d ############' % (epoch))\n",
    "    steps_per_epoch = (nbr_train_data // cfg.BATCH_SIZE)\n",
    "    \n",
    "    train_batch_loss_d = []\n",
    "    train_batch_loss_g = []\n",
    "    train_batch_acc_d = []\n",
    "    train_batch_acc_d_real = []\n",
    "    train_batch_acc_d_fake = []\n",
    "    for batch_i in range(steps_per_epoch):\n",
    "        first_frames, last_frames= next(train_batch_generator)\n",
    "        if first_frames.shape[0] == cfg.BATCH_SIZE: \n",
    "             \n",
    "            # Condition on the first frame and generate the last frame\n",
    "            fake_last_frames = modelObj.generator.predict(first_frames)\n",
    "            #plt.imshow(fake_last_frames[1])\n",
    "            print(fake_last_frames.shape)\n",
    "            #print(tf.keras.backend.mean(fake_last_frames[0]))\n",
    "            print(np.mean(fake_last_frames[0]))\n",
    "\n",
    "            # Train the discriminator with combined loss  \n",
    "            d_loss_real = modelObj.discriminator.train_on_batch([last_frames, first_frames], valid)\n",
    "            d_loss_fake = modelObj.discriminator.train_on_batch([fake_last_frames, first_frames], fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    " \n",
    "            # Train the generator\n",
    "            g_loss = modelObj.combined.train_on_batch([last_frames, first_frames], [valid, last_frames])\n",
    "        \n",
    "            \n",
    "\n",
    "            elapsed_time = datetime.now() - start_time \n",
    "            print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [D acc: %.2f (%.2f real, %.2f fake)] [G loss: %f] time: %s\" % (epoch, cfg.NUM_EPOCHS,\n",
    "                                                                                               batch_i,\n",
    "                                                                                               steps_per_epoch,\n",
    "                                                                                               d_loss[0],\n",
    "                                                                                               d_loss[1],\n",
    "                                                                                               d_loss_real[1],\n",
    "                                                                                               d_loss_fake[1],\n",
    "                                                                                               g_loss[0],\n",
    "                                                                                               elapsed_time))\n",
    "            # Store loss values for plotting.\n",
    "            train_batch_loss_d.append(d_loss[0])\n",
    "            train_batch_loss_g.append(g_loss[0])\n",
    "            \n",
    "            # Store accuracy values for plotting.\n",
    "            train_batch_acc_d.append(d_loss[1])\n",
    "            train_batch_acc_d_real.append(d_loss_real[1])\n",
    "            train_batch_acc_d_fake.append(d_loss_fake[1])\n",
    "            \n",
    "            # run some tests to check how the generated images evolve during training\n",
    "            test_fake_last_imgs = modelObj.generator.predict(test_first_imgs)\n",
    "            test_img_name = output_log_dir + \"/gen_img_epoc_\" + str(epoch) + \".png\"\n",
    "            merged_img = np.vstack((first_frames[0],last_frames[0],fake_last_frames[0]))\n",
    "            imageio.imwrite(test_img_name, img_as_ubyte(merged_img)) #scipy.misc.imsave(test_img_name, merged_img)\n",
    "    \n",
    "    \n",
    "    # Calculate average loss for each epoch.\n",
    "    train_epoch_loss_d.append(sum(train_batch_loss_d)/len(train_batch_loss_d))\n",
    "    train_epoch_loss_g.append(sum(train_batch_loss_g)/len(train_batch_loss_g))\n",
    "    \n",
    "    # Calculate average accuracy for each epoch.\n",
    "    train_epoch_acc_d.append(sum(train_batch_acc_d)/len(train_batch_acc_d))\n",
    "    train_epoch_acc_d_real.append(sum(train_batch_acc_d_real)/len(train_batch_acc_d_real))\n",
    "    train_epoch_acc_d_fake.append(sum(train_batch_acc_d_fake)/len(train_batch_acc_d_fake))\n",
    "    \n",
    "    # Perform validation on the data.\n",
    "    print('############ VALIDATION OF EPOCH %d ############' % (epoch))\n",
    "    val_steps_per_epoch = (nbr_valid_data // cfg.BATCH_SIZE)\n",
    "    for batch_i in range(val_steps_per_epoch):\n",
    "        val_first_frames, val_last_frames = next(valid_batch_generator)\n",
    "        if val_first_frames.shape[0] == cfg.BATCH_SIZE:\n",
    "            # Generate last frame.\n",
    "            val_fake_last_imgs = modelObj.generator.predict(val_first_frames)\n",
    "            \n",
    "            # Test discriminator.\n",
    "            d_val_loss_real = modelObj.discriminator.test_on_batch([val_last_frames, val_first_frames], valid)\n",
    "            d_val_loss_fake = modelObj.discriminator.test_on_batch([val_fake_last_imgs, val_first_frames], fake)\n",
    "            d_val_loss = 0.5 * np.add(d_val_loss_real, d_val_loss_fake)\n",
    "            \n",
    "            # Test generator.\n",
    "            g_val_loss = modelObj.combined.test_on_batch([val_last_frames, val_first_frames], [valid, val_last_frames])\n",
    "            \n",
    "            # Store validation loss values for plotting.\n",
    "            val_batch_loss_d.append(d_val_loss[0])\n",
    "            val_batch_loss_g.append(g_val_loss[0])\n",
    "            \n",
    "            # Store validation accuracy values for plotting.\n",
    "            val_batch_acc_d.append(d_val_loss[1])\n",
    "            val_batch_acc_d_real.append(d_val_loss_real[1])\n",
    "            val_batch_acc_d_fake.append(d_val_loss_fake[1])\n",
    "            \n",
    "            \n",
    "    # Calculate average validation loss for each epoch.\n",
    "    val_epoch_loss_d.append(sum(val_batch_loss_d)/len(val_batch_loss_d))\n",
    "    val_epoch_loss_g.append(sum(val_batch_loss_g)/len(val_batch_loss_d))\n",
    "    \n",
    "    # Calculate average validation accuracy for each epoch.\n",
    "    val_epoch_acc_d.append(sum(val_batch_acc_d)/len(val_batch_acc_d))\n",
    "    val_epoch_acc_d_real.append(sum(val_batch_acc_d_real)/len(val_batch_acc_d_real))\n",
    "    val_epoch_acc_d_fake.append(sum(val_batch_acc_d_fake)/len(val_batch_acc_d_fake))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot scores from training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAG5CAYAAADGcOOUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAACn3ElEQVR4nOzdd3RcxdnH8e9sV++9WO5ylSUXbGODDYRqiumGJJQEEgghCW8SSKGEhBRIgySQkBAghIQSwPSOwRiDce/dli1ZVu9l+7x/3PVKsuWKVleyn885e7S7t+yzi7B+OzN3RmmtEUIIIYQQfctidgFCCCGEECciCWFCCCGEECaQECaEEEIIYQIJYUIIIYQQJpAQJoQQQghhAglhQgghhBAmkBAmhDgopZRWSg07xmNnKaXKuzxer5Sa1Vu1hc75V6XUncd47I+VUv/ozXqEEOJoKJknTIiBQSlVCmQAgS5PP6G1viWCr6mB4Vrrbcdw7Czg31rr3N6uq7/5Ip+TEOLEZTO7ACHEUTlfa/2e2UX0B0opq9Y6cPg9+zellE1r7Te7jq76Y01CHI+kO1KI44BS6lql1CdKqT8ppZqUUpuUUqd32Z6tlHpFKVWvlNqmlLqhyzZrqGtuu1KqRSm1XCmV1+X0ZyiltiqlGpRSf1FKqYPUEKWUeiK03wZg8n7bS5VSZ4TuT1FKLVNKNSulqpRSv++y3wyl1GKlVKNSqkwpdW3o+SeUUo8opd5QSrUBs0PP/SK0fZZSqlwp9UOlVLVSaq9S6iKl1LlKqS2h9/7jLq9zj1Lq36H7BaGu12uUUruVUrVKqZ902XeKUurTUE17lVJ/Vko5QtsWhnZbrZRqVUpdEXr+htBnXR/67LO7nE8rpb6llNoKbD3I5/m8Uqoy9N9zoVJqzH6f9e+UUrtC2xcppaIO8/l9qJT6epdzXKuUWnSompRSD4bO0Rz6vZjZZf8ef29CvyO/2++9vKqU+m5P71OIE5mEMCGOHycBO4BU4G7gRaVUcmjbf4FyIBu4FPhll5B2GzAPOBeIB64H2rucdw5GoCoCLgfOOsjr3w0MDd3OAq45RK0PAg9qreND+z8HoJTKB94E/gSkAROAVV2Ouwq4D4gDFnGgTMAF5AB3AX8HvgxMBGYCdymlhhyirhnASOD00L6jQs8HgO9hfLbTQttvBtBanxLap0hrHau1flYpdRrwK4zPKwvYBTyz32tdhPHfbPRBankTGA6kAyuAp7ts+23oPU0HkoEfAsEj+PwOZ/+alobOkQz8B3heKeUKbTvY782TwDyllAVAKZWK8Xn99yjqEOLEoLWWm9zkNgBuQCnQCjR2ud0Q2nYtUEFonGfouc+BrwB5GCEirsu2X2GMJwPYDFx4kNfUwIwuj58D7jjIvjuAs7s8vhEo36/+M0L3FwI/A1L3O8ePgJcOcv4ngH/18NwvQvdnAR2ANfQ4LlT/SV32Xw5cFLp/D8aYNYCC0L65+31+Vx6klu92rTN07LAujx8D7u/yOBbwAQVd9j/tKP7bJ4aOScD48tyBEfr23+9Qn9+HwNe7PL4WWLTfezhkTUDDvtc9zO/NRuBLofu3AG+Y9f+N3OTWn2/SEibEwHKR1jqxy+3vXbbt0Vp3vdJmF0bLVzZQr7Vu2W9bTuh+HrD9EK9Z2eV+O0ag6Ek2ULbfaxzM14ARwCal1FKl1JwjrKXsENsA6nTnOLGO0M+qLts7OHj9cJD3qpQaoZR6LdQ92Az8EqNV7GCy6fL+tdatQB2dnzkc4r2Euvp+Herqa8YIsIReMxWjta+nz+lwn9/hdKtJKfV/SqmNoS7PRowQuO99H+q1nsRogST086kvUJMQxy0JYUIcP3KU6jZeKx+jdawCSFZKxe23bU/ofhlGl+AXtRfjD3PX1+iR1nqr1noeRlfbb4D/KaVijqAWsy7nfgTYhHEFZDzwY6DHsXEhFcCgfQ9C7y2Fzs8cDv1ergIuBM7ACD4F+04F1AJuev6cDvX5tQHRXR5n9rBPuKbQ+K/bMbpUk7TWiUATne/7UK/1b+BCpVQRMAqYf5D9hDihSQgT4viRDtyqlLIrpS7D+OP3hta6DFgM/Eop5VJKjcdoido3xugfwM+VUsOVYbxSKuUYXv854EdKqSSlVC7w7YPtqJT6slIqTWsdxOhWBaPL9GmMCwEuV0rZlFIpSqkJx1BLb4sDmoFWpVQhcNN+26uArmPN/gNcp5SaoJRyYrScLdFalx7F63kwWs+iQ8cDEPrM/gn8XhkXXFiVUtNCr3Ooz28VcLFSKloZc7997Qhq8AM1gE0pdRfG2K99Dvp7o7UuxxhP9hTwgta6AyHEASSECTGwvBq6Am/f7aUu25ZgDOSuxRi8fqnWui60bR5Ga0oF8BJwt9b63dC232MEqHcwgsZjQNQx1PYzjC64naFzHaoL6mxgvVKqFWOQ/pVaa7fWejfGQO//A+oxgkPRMdTS276P0TrVgjHY/9n9tt8DPBm6IvFyrfX7wJ3ACxgthEOBK4/i9f6F8VnuATYAn/VQz1qMoFOP0ZpoOczn9wfAixEYn6T7QP+evI0xyH9LqBY33bsrD/d78yQwDumKFOKgZLJWIY4DoWkIvq61nmF2LUIAKKVOweiWLAi13gkh9iMtYUIIIXqVUsoOfAf4hwQwIQ5OQpgQQoheE5pbrRFjfrQ/mlqMEP2cdEcKIYQQQphAWsKEEEIIIUww4BbwTk1N1QUFBWaXIYQQQghxWMuXL6/VWqf1tG3AhbCCggKWLVtmdhlCCCGEEIellDro6iHSHSmEEEIIYQIJYUIIIYQQJpAQJoQQQghhAglhQgghhBAmkBAmhBBCCGECCWFCCCGEECaQECaEEEIIYQIJYUIIIYQQJohYCFNK/VMpVa2UWneQ7Uop9ZBSaptSao1SqiRStQghhBBC9DeRbAl7Ajj7ENvPAYaHbjcCj0SwFiGEEEKIfiViIUxrvRCoP8QuFwL/0obPgESlVFak6hFCCCGE6E/MHBOWA5R1eVweeu4ASqkblVLLlFLLampq+qQ4IYQQQohIMjOEqR6e0z3tqLV+VGs9SWs9KS2tx4XIhRBCCCEGFJuJr10O5HV5nAtUmFSLGKDcvgB7m9xUNHawp7GDvY3G/cYOLxaljJtFYVF0Pt5337Lfc5b9t+9/3JHs18P2A17rSF/v0OdSChTGNqUAjOcsSqEgvF2FtqvQ853HAt3O0eW4Lvuo0OvvOxf7nSO8fd9GIYQQR8TMEPYKcItS6hngJKBJa73XxHpEPxMIampaPEa4auqgorGDilDIqmgyAlddm7fbMUoHSfC0Ee9tI2Cx4lNWAhYrda54UAprMIBWiqCS2Vki5ZBBkM7wZgnd2T/I7TvOYbUQ47QR47QR57IR4+hy32k17oe2x4ZuMU4bsa7O+9F2KxaLhEMhRP8UsRCmlPovMAtIVUqVA3cDdgCt9V+BN4BzgW1AO3BdpGoR/Y/WmuYOPxXhcNVBRahFa2+jmz2NHVQ1u/EHu/dQO/0eMtvrSetoZEp7I2nuetLcNfyx6MsELDa+uekJLti84YDXO+fCBwD49qaHOWvLLoKA36rwWxRtLitfPf1XANy07U8UV1TgtygCFoXfCg1RTu4dfxcAV+35C4ObqoxjreC3QF10LP/O/IHxOk0Pk+yrIWDBOIcV6pxJLHR8G4BJ/IUoVWdstxq3ZnLY1vE1APKSHsLiaMRv0eHtHvcwWquuBiBmyG9RtpZu783fMhb33suM7cPuQ1m6B1Nf00Q8VRcAEDvi7gM+G2/DNLw1Z4PyEDv8lwdur5uFt242ytpCzNDfHrDdU3MmvoaTUfZaYgb/6YDt7qo5+JsmY3HuIXrQo+Hn9/2X7dh7Cf6W8VijSonKfbzzOBRNQTvuvZcRaBuBJWoXzvQ3QNshaEOHfnrrZhP0pmNxVmKLWwvajg7ajP20Dad3LDH2eKKi2nC6Gom2u4ixu4h1RBHnjCI5Kpl4l7MzxDmtxDrtxDitRrhzGc/HOGxYJdAJMeBprSmr72BlWQOryhppaPPyxyuLTaklYiFMaz3vMNs18K1Ivb4wl9sXoLLJ3T1cNXWwp3Ff0OqgzRs44LhYbzuDmyoo7GhkZkcDae4a0tx1PFg0jzpXKheWz+e6VUvD+wcU1MdBfKCWBksmnw2Lpjo3iiZnFBYN9gBYA4RHIC4ZlE59cjO2oMYWAGtQE1DW8PmqYqLZnezEFgRbQGMLaHSXVrO0Fh+Dq/1Ygxp7QGMLairjFP/ONLafsaGe0VXdQ9LmdFg43bh//cIaBte3dtu+OtvBHVOM+z/7Xw1ZLR3dtn+WV8XPJhr3//JoIzFeP36LIqgUQQt8kt/IX0ca23/7mBdbMBhq7VMEFSzMb+GZArAEA/z8SStBIGhRaIzjF+Z28EYWuPx+fvCMC60IHRs6PtfDomSIdfu4cX7cAdsXZQVYFQeJ7X4ueyuZYGi7Dm3/JE2xLQqSWoN86cMMghbVpQb4PMnKHjsktcCUz3LDz3vsihaXha02O80AWkPQirL4wN6OUn6U8kGDBwCLcy/OtPcP+J1q25FJa7MTu2UZruT5nRu8xq115ffRvlTsyQtxpr3TLcRpbaNj1zfQgRhsCctxJazHquzYLU7sFgcOi5OhtsuJd0bRYd2MR+0h2h5FtGNfyHMxKX0GsU4b7mAdyuohKSqGRFcUcc4YYuwx0o0rRIQ1dfhYU97Iqt2NrCozbnVtXpS1DR2IQSn4xdxxxDr7vnPQzO5IMUAFg5qaVs8B3YNG0DIe17Z6ezw2wdPKuNrtjOtoJL2jLhSyGnl4/EVsThjJlMaP+MHizj+kzVFQmwCxai91pPL5oDQashOpiU6g2pVCvSMNfyAZf3MSaFhpv4KV9oP/Ufs05go+jTn4e3sx62u8eIiJUh4s/C4UHnz796f+GFswiC3ox6YD2IIBdJdrUO4rvplovwdbMIAt6MeuA7Tao8LbHyu8jBhfR/hYezDA3piU8Pb3c2YQ7XNjDwaw6CAKzU7noPD2bbGF4W0WHURpTZMeEt7eHsw0ng9oLDqITWuUOwMAS9BCcpMrfF5r6PhVcfGQDE6/hfFl7tC5dXi/7Q4Hq+IgrgPOWV+JNbRdaY0FTUXxSWwbBGktAa75fMcBn1nN5GnsyYH8eg/fXrz5gO0/mTadFRkwdUcLtz+3gxZHNC32qNDPJP45xsmeOMguz2LM6gtocTppdThocdppdTpos6eCAn/rKNp3J8O+8GYxfupAHABBdy7e+pONkKd8KIsflA+tjX8mlcVL0NpIUPnwKz8dFh9K+dm18TTAijPjfRzJn3WrXQet/Om1+wBwZT2HPXFFt+0qEMOQjt+RGuuk0fEmXsseklxJpEQlkxmbwuDEHM4dejoxThttvjZcVhdWixUhRM/8gSCbKltYWbYvdDWwvaYNZW3BElWOsnjxtxUB4Mp6lo7y69Ea1pQ1Mn1Yap/Xq4wGqYFj0qRJetmyZWaXcVxrdvs6uwj3tVw1GV2EFaFuQl+gy+9N6A9y0GIl1tvOqXtWkdrRQLq7hrSOetI6mvnn2DP4OHMG45qXcP8HzwPgtkNtPNTGK/418nw2uk4hRa1lGO9QHZVMjTMNDykEfQkE2gdDMOqAWi0KMuJdZCW4yE6MMm4JLtLiXCgFQa0JBLXRiLLf/aCGgNZorQkGNQFtNFMb+xn76H37BbvcD+2jNaHjup8/GDpP1/tBbZx/3zl72m/fOY3HofuhYw/YN6jRGPtojGMJ3d9XZ3h76Fhjm/F8MPQ8dNYe3q47z7vvuGCX5+h2js7jerRvg1JYdBB7wBcKcDoc9NptTnxWO46Aj0RPixHetMYZ8BLnbWdnQjatjmgKmiqYXb6SOG+7cfMZP381+SuUx6UzZ8cnfGvNSweU8LUzbqciNo1zdn7KRds/NsKbI5oWu/Hz34Vn0mF3kd9cSaq7iWZHTDjktdtccKQtVcoPyrtfiAsQdBsz71hc5VjsdeHwh8WLQuOtPxUAZ8Yr2GI3o6xtKKsbgIAnnfYdtxHtsOLM+yt++w5sKgaXJZ4YWwKDYgu5fMjNpMU52dD0ETFOCxkxqSS6Ekl2JZPkSsJpdR5Z/UIMMFprKprc4bC1qqyRtXuacPuCANjiV2GLW4/VVYbF0UhCqwZvIuVVPyK/uZKb1/+HO6bdBsAPzhrJt2YPi0idSqnlWutJPW2TlrATQDCocfsDdHgDuP1BOrwBalo8B3YRNhmhq9Xj73a8PeDDHvTTbo/C6fdw2baPSHXXke6uJa2jidS2Vp4ZcxLPD55LDHu5ZfWL+C1GN2FtPGxNV7QkGfP2bk3I47Yrh1LlSqPVkkLQn4T2JRLwZEIQ6vQ46hhnjBJsh4QoO9mJUeTkuchKCIWsxM7AlR7nxG6VQfb9wf7hrWsQhO5Bbt92uuyzfxD0+IO0evy0efy0hm5tnrNo9QRodfup8RrPlbj9jPT4qc8/h3uLp6Gam1GtzVjbWnB1tBkXZQANrjhK4zOJ97aT1tHI4KYK4nwdPDXqLADO3PU5l2xf2O09+ZWFC8//FUGLlYu3fsj42u20OKJptUfT4oiiyRnL64ONvub01masBGmxR9Nmjzvg4o+gO5egO/egn5+n6gI8VeFXRtnaQfkAaPcG8NZMxuIowGtto8PWRqO1jbKqPbz/yXIAYob+AYuj+/zYSWo8sxJ+RFqskw8af43dCilRyWTEppIdm0JR+jhOyjoJgD2te0hwJEgXqei3Wj1+o1sx1Mq1sqyRmpZ2LM5KrFHlWKLKsOZUQunNoBWFLWsZVbad4WV2RlQ6yGht53/DRvPYWNgbk8qWuBHhc68qazTlPUkIM4k/EAwHIrcvgMcfoMMb7AxLvgAdvgAeX9fngnT4uu7f/Tm3P4jbG+h2DrcviDcQPGgdFh0k2d2MJRikOiYZtOYb614ivaOG9I4GUjtaSHR7eHVkIQ+P+joBm5+rN79DczTUxsHeDMXaeNiRboxjqnFmcf1XJ9BgSyMQTCLoS0T7Egj6jO5Ct85mo/smcIPDZiEvMYqstO6tWPuCVlZCFDEm9NGLY7NvWovQIzNLCfMHgrR5ArR6/bR5TqHFbYS6No+fao+fnR4/t3j8tHj8BEddxctVs9HNzaiWZqytzaiOdlITomnz+LEHAyS7mxnUUkmct4MYv5tGR0w4hN247hVO3msslRtE0WqPYld8Bj+caQx9vWTrAtI6mjq7Uh0x7I1JZlNyQQ+V29D++O7vpXnCId9r285bULY2LNY2lK0VZW1jjz+Of7XuAsCV24LF3oSyhlrbLH5oPol0bwcpsXY2um4CNBZsxNgSiHckckbu+Xx59NXERyue2vAESa4k4+ZMItmVTEZMBjH2Q/TvC3GMAkHNlqqWcOBaVdbI1upmtK3e+H9D27Enfk7syFdRFh/JzZphZQ6UJ4X3YzvQ/mh++vo2Erxt1EQlsDFpGC8XDGJl2nAALE4Hq8/7Cl/LS2RCXiIlg5JMeZ/SHRmitcYXMFqM3KFws38gcvuCXcJPgA5fMBR0OgPPvkB0QIAKhSyPz7jfrTvvKDkCPlx+L86AF2fAhzPgRaPYkWh0e0yu3Eiquwmn34srYOxX54rjtSEzAbh57TMMadpDenszyR3tWLXm0/ws7i35P0Dzj4U/JGDV1MYp6kLdhesTRrPcei2giUl5HW8wEe1PDIcsHYih69y/SkF6nPOAcJWVEEVOKGQlxzjkG7cYMAJBTbvX39k61+ahraGZFocR0li/FvaUEWxqgpYmVEsL7VYHb598Ca2eAPNe/TPDKjYT4+288GJTUh7fO/U7ANz/8cMkelqoc8VT70qgzhXP1qRcPs6ZAEByRxMtjhh81t74YqJBeUEFQ938AWwJq0JdoW1YQiHO3zIGX9NklLWF2BH3HXCWkxK/zNm5V2O1N/HXLbeT4komLTqZlCijK/SM/DMYlTKK2o5a3i59G7vFjlVZsVlsWC1WJqZPJCs2iwZ3A+tq12G1WLvtU5BQQLwjnjZfGzXtNQdsj3XEYrfYCeogWutjGi8XbrXdr+sdurfehp/v0mrrtFnki2IvqWp2szI8cL6BteVNtPnbsUbvxOoqwxpVhtVVjrK1077r6wTah3FG5VtMq1rFiKp2UtvbAdgRn8W3Tvs/AMbU7aQqOonaqESGpMYwIS+RCflG6CrMjMdh65teFOmOPAJBDSN++mavnCvK5ybO1x4KSD5cfg9xQT8r0o1L2IpqNzK4uRxXwI0r6MEZ8BBU8PdRxjQEV29/nuKqHTgDfpx+49bscvLtmT8F4J7lv6e4ovvyTbuTovjGqT8H4KrS/1JY2d753hSsz3GFQ1iaWgfRbjZkGiGrJtZOaXRiaG/FTRdcgtZ2tC8UsvwJoG3h7W11c4h32ToDVqjVKif0OCvBRWaCS7oJxXHFalHEuezEueyhZ+JgcJeBvBN77mr86r473zoZAB0IEGhqpqmqBntTO8+m51Hb6sURmIqlrJSs+joKmsqI2dvAat9YPssvxhfQPLzg9yR422hyRFPvSqDWFc+SrDHhlrjJlRtpdMZS54qn0XVgd2h3CrSzyxolVvxNEw+6tw7E0bLxFyhbO8rairK2o2xtfLA9jfc+XY2yNeLMiGO3tRFl24PV1g6WNl5c0kGsrw63dQeVMQ8ccN7ElutxeIrx2DfRlPCXA7ZH1X8Du2c0Xucq3MmPH7DdWnULyj2YQMwydOp/QSvAgtYW0FYCe24m6MlExS3HlvIOWltBW0Bb0NpKR/lX0f4EbPGrsCcu69yGcbx77yUQdGGLXY81dkt4O1jR2oK35kvEOBykJrWTGmslJy6T7IQEMuKdZMa7yEhwkRHvkmET++nwBli7pyk8jmvl7kb2Njdjde3BElVGsCOfgLcAi6uG6NzHSWtUDNsWz/DyaHJrXfx4urFyzriKRgbXBlmbPJJNQwexKTmfHQnZJEbbmZCXSHHeCCbkJ1KUm0BitMPkd90zCWEhVovCblX4ApoRzRuYWLcm3IpktCj5+POoa2mzJ3BuxSucu2MFDn8Alz+A0x/A6Q9yxTn34LHGcE3pP7lw/YFXgZ1z4f2gLJxW9ypnbqwGjCkWPA5ojlLhEGZ37kJH1dJkA68dPHZoiOrsUnxnXDzLC9vx2GzGzWqj2drZlHr/rJPA3oTH6sBjdeHDTtCfDE3G9l9MvQpQoZCVEPom3NkipVqmG+OuUrqPwcpKcJGTGEVWYpQpl/IKcTxQViu25CRSkpNIAcJDgR+4s9t+WmvGejx82emkucNPVWETrXv2oiurSaipJrGuFluyom1kGo2Nrdw7/7HwsQEUDa44Xhg2i/nDTsEe8HHp1g+pizJa2Pa1tjU7oo/8woNQF+n+3aQA2p+Ie8+X93s2iDFZSxOQiLLeCQSN1jcVMLYH4iDYBpY0LPU3o/ZtU0EgSKs7DR3oQNkysHZcCSqACh2LCuBviUf7fVgCadj0GeHz7zuP1+NC+4NYvbHQVhB6bWObIgjaGq7VuFiiyzYVZF9KtTirscWtD+3XWZ+35gzavAH86g3qHUvY4gFdEU1wdzxBXxLu8q8CCmvULhKiNalR6WTHZpIVn2iEtHgnGQmu0H0XSdH24653IBjUbK9pNa5WDHUtbq5qIRDUoHw4M17BmlxGbFYVSmmcXk0rpxHoKOD0zeVc95KDJE8HUI/bamdzUj7RHQ7aHPDQhMuw2G2Mzk6gOC+Rm0Ndi4NSogfM5yh/Sbtw2a34An7GtC3lq6vXhgOS2w5eG0TRRBsJeKObaUxox22z4LFZ8doceGzW0D8s8HH+EMoyvHisdjxWO26rA4/NgSKIxsLfx87h8eIa3BYnfosLtA0ddECbUceTBTfAYJ/R+hSes6jzP9WHUTfBgRcKhu11nwfu/d+bhbhoKy67FZd9MvFRdnISXWQnGKEqJ7GzuzAlxiGzjAthMqUUyuUCICHaTsK1Vx2wz3TgKkD7/bjPeB5fVRXN5Xtp2bOXuMoq5oyZwNgxo2gr3cWZr759wPF/G3sB84edQlp7A19f96rRDRoVHwpqCexMyKLFcaxjvrq2/FhDQxYOIugi6M4/6GbtTzzkmLigJxuvJ/ug2wNtwwm0DT/odn9zCf7mkoNu99bOIlBzCvag37gF/GilwGX8u+xrOIlA+yBjzJ29CYutKRQWjX9HHSkL8MVtYi+wF9CNLgJ78+goMyZptsWvQikflmAiya40MqMzyU5IIiPORWaCk4xQSNsX1qIc/XeaktpWT7f5uFaXNdAarAl3KVqiyrGlpxOovBgVtJDXsZ3h22yMKM9gRFU7gxoa+P4pI9mUDDVRySxLH8Om5Hw2JQ2iND6T3NQ4Tg+FrQn5iYzOisdl77+fx+HImLAuJt/3HjUtHuyWerA3EmBfQLIbYSgQTW+teW5RhAKRlSi7FafdQpR9X0iyhJ6zhp7ruq37Pvvudz2Xq8txLrsVp80yYL4VCCEiI+j14q+uwV9djb+6Gm9VFb4xRTTmDKZ+zXpifn031oZabO7OMWuPn3Ej72eMJWv3Jr6z8vlwODNa0uJZlDOe2qhE7AEfoHppvBqgNTYdwK+soBSxoSlJ7AHjAgl70I9VB1mfMhiAEQ27yWmt7RaSgsrCK0NnAPClXZ8zrHFP5/agn1Z7FH+ecCkA31wzn9F1O0PbjPNXxKTwoxk3AfD7j/7EqIZd3Upcn1zA90+5BYBffvI3Ejyt1LviqXfFUe+KZ1tCLp/kjAcg1bubthg3vqh2I6DZm9BBO96acwCIHvwgVlf3Vfv8bcPo2P11AByp7xofiz+BoC+BaEsy6dGZZMcnhQKaMxzQMuKN4SCpsc6Ir/Dg9gVYX9Ec6lI0uhb3NNei7PUE3cbS0FH5f8MWs9O432FlaGkyldaR7AzMYUztDn676GEA2mwuNiflszF5EO/lT6IyJoU4l80IW3mJFOcnUpSbSErswJtyRcaEHaE4p40ObwCXPROXPeeAMNMZdCyHDETdA1RP57DgsEowEkL0HYvDgSM3B0duTrfnswCypsFZ7wAQaG0LB7VfDh+GLSWF1jWZVD26jZzKSgI1e7FUrcXi8zFs1jS2pGSTteQDLnrrH7Q4Y6h17uvujOOxMefT7IxhesVazti9LByAHAHj549O/gatjmgu2/IBF2/7KByAHEFjmpwLzv8VPqudL296hwt3LOpWd0BZmHPh/QCct/NTzty9tNv2VpsrHMLG127npMoNeK12fBYrPouNmqjOIRwdNieNrnh8Vhs+qw2/xUZNdBIuuwWLUnw4dCqr3GPwW234rVb8VjsN0Qk4rBa8gSBbE3PJa6kmxd1EQXMlSZ4WPs0aEw5hf37vHyR422m1uUJBLZ7F2WN5NTSPcsmimTRHKxpjoSHOjzuqHR3sbDm0xa3D4qxGqc5Gkz1N49m+1WgddeX+CwIugv4E42p0fwJ4M0h1ZZEZ7yI93IrmDIe0fYEt3mU7or9FWmt21raFW7hWlTWycW8zAdterDFbsbrKjW7FzHp0wEXrlruwBYPMXprIyNo8RlY1kdfcgIW9PDNiFDtHw7bEXP5QfDmbkvLZm5DByOwEJuQl8v28JCbkGYPpj/deGWkJE0IIcVS01gSbmrBER6McDtybN9P6wQf4qqvxVlXjqawyWtt+9zAqOxfrO69jefFZsNvB7kA5HOBwYPnx3VjiE9CfLEQv+RTl6NyuHA4cV30Fi9NBYP062F2K2rfNaUfZnTimTMFqsRCsrgJ3B8rhxOJ0YHEYN2t01AELyO+/UPwX+TKstaah3Udlk5uqFjdVTW4qm91UNXZQX99CWYemusXNhPWfkOJuJtndTLKnmSR3C8syCnlm5Bk4Aj5efvVH3c7rttp5ZsQZPDvydJx+L9dueIN6VywN0XYaYi00xgapisqg1VcIBIge9DeUvQllazHGwwHeupl4qs8D5SVmyIMEfQnhljTtTyDQNoSgN4Mou4X0eAeZ8dHhgJYe5yQzwYXLZg0NoG9kVXkdLYE9RpeiqxxP1RzQDhxpb+NMXUB0UzxDdyUyotxGkzWNl/IvRGl49o270Sg2JeezMbmATUn5bEnKJyktKdzKNSE/kbHZCf26m/WLOFRLmIQwIYQQIoK8/iA1rR4jrDUbt8pmI7RVN3ZA2S4CtTVEtzYaQc3dwqq0YSzNHE16ez2PfPA7ov2ebufcN54vs62O25c9He4KbYhyUB9jZWXaCKocw7BYWnClv4p2hsaq2ZtRKoi7cg6+hhkoRw0xg//YLaAFfQn4m4sIerKxRu3Ekf42VtceYzUIQPudtO++iaAnk+s2vMTJFRvJaTUmCg6gWJQznl9P/gpgTK3iiU9ifF4SE/ITKQ4Fr/R4V9/+RzCRdEcKIYQQJnHYLOQkGtP49MyYZqTF7QuFNA+FTW5mNbupbnbz6OR/UF/XjLeqGl1XS0JHEzsSjG5lWzBAu81FVlstY+p2kOA1pie6b3IOVTkwvqqSX7y4kkZXHPXOOOpdQ2iIiuLFYXmUxUJCu4/cTeNojPfQFN9BMGo3trgmgu48gp5stLaS1OZl2MYhDN8DI6qbSWnv4OtnZIACh1+xKzaLt/Onsil5ENuTcsnPSWVeaD6uCXlJDEuPjfj4tIFKQpgQQgjRD+ybh25YetxB9wkENXVtHqqaPEZrWrObyubprG52U9nsoba+BW9NDXv8xnx2NVGJPDvidJI9RndoiruF4Y17eHOQMW/kpIo9/N+Kzt4lYx66JO6bksaeWJi3ciNf3rwbAJ+ysj0xm6UZhdiDfnxWO/NnXBEOWxfnJTI+N0EmsD0K8kkJIYQQA4TVokiPc5Ee52IcCQfdz+0LhFvVKpvPpLrZTVmTm6XNbqqbPbib3Tia3SxPH8ldU68n2d0SHrOW7G6hzRYNwMr0EbTbXWxKGsSetHwK81Mpzk/kodBYrqyEQ8yXJA5LQpgQQghxnHHZrQxKiWFQysHnZ9Na09ThC7WoecIXFuxodjOp2U2z28+giblMyE/k63mJjMyIwyYz//cqCWFCCCHECUgpRWK0g8RoB4WZZldzYpJIK4QQQghhAglhQgghhBAmkBAmhBBCCGECCWFCCCGEECaQECaEEEIIYQIJYUIIIYQQJpAQJoQQQghhAglhQgghhBAmkBAmhBBCCGECCWFCCCGEECaQECaEEEIIYQIJYUIIIYQQJpAQJoQQQghhAglhQgghhBAmkBAmhBBCCGECCWFCCCGEECaQECaEEEIIYQIJYUIIIYQQJpAQJoQQQghhAglhQgghhBAmkBAmhBBCCGECCWFCCCGEECaQECaEEEIIYQIJYUIIIYQQJpAQJoQQQghhAglhQgghhBAmkBAmhBBCCGECCWFCCCGEECaQECaEEEIIYQIJYUIIIYQQJpAQJoQQQghhAglhQgghhBAmkBAmhBBCCGECCWFCCCGEECaQECaEEEIIYQIJYUIIIYQQJpAQJoQQQghhAglhQgghhBAmkBAmhBBCCGECCWFCCCGEECaQECaEEEIIYQIJYUIIIYQQJpAQJoQQQghhAglhQgghhBAmiGgIU0qdrZTarJTappS6o4ftCUqpV5VSq5VS65VS10WyHiGEEEKI/iJiIUwpZQX+ApwDjAbmKaVG77fbt4ANWusiYBbwO6WUI1I1CSGEEEL0F5FsCZsCbNNa79Bae4FngAv320cDcUopBcQC9YA/gjUJIYQQQvQLkQxhOUBZl8floee6+jMwCqgA1gLf0VoH9z+RUupGpdQypdSympqaSNUrhBBCCNFnIhnCVA/P6f0enwWsArKBCcCflVLxBxyk9aNa60la60lpaWm9XWc3wUCQDYsq2L2+LqKvI4QQQogTWyRDWDmQ1+VxLkaLV1fXAS9qwzZgJ1AYwZoOSynFird3sfT1nWaWIYQQQojjXCRD2FJguFJqcGiw/ZXAK/vtsxs4HUAplQGMBHZEsKbDUhbFuNm5VO5opqq02cxShBBCCHEci1gI01r7gVuAt4GNwHNa6/VKqW8qpb4Z2u3nwHSl1FrgfeB2rXVtpGo6UqOmZWF3Wlm7oNzsUoQQQghxnLJF8uRa6zeAN/Z77q9d7lcAZ0ayhmPhiLJROD2L9Qv3MO3iocQkOM0uSQghhBDHGZkx/yDGz8olGNCs/3j/YWxCCCGEEF+chLCDSMyIJn9MCusW7iHgP2DWDCGEEEKIL0RC2CEUnZZLR7OXbcurzS5FCCGEEMcZCWGHkDcqmcSMaNbIAH0hhBBC9LKIDswf6JRFMe2ioQT8QbTWGKsrCSGEEEJ8cRLCDmNIcWRn6BdCCCHEiUm6I4+Au83HsjdLaWv0mF2KEEIIIY4TEsKOgKfdx+ev7GD3BllPUgghhBC9Q7ojj0BCWjRfuW86cckus0sRQgghxHFCWsKO0L4AFgzInGFCCCGE+OIkhB2FT1/azou/XYHW2uxShBBCCDHASQg7CnEpLqp2NlO5vcnsUoQQQggxwEkIOwojT8rEGW2TyVuFEEII8YVJCDsKdqeVUSdns31lDa0NbrPLEUIIIcQAJiHsKI07NQe0Zt1He8wuRQghhBADmISwoxSfGkXB+FTWf1yB3xswuxwhhBBCDFASwo5B0Wl5uNt8bFlaZXYpQgghhBigJIQdg+wRiaTkxLBmQblMVyGEEEKIYyIh7BgopRg/O4+GvW00VrWbXY4QQgghBiBZtugYjZiSwaBxKcQkOM0uRQghhBADkISwY2RzWLE5rAAEgxqLRZlckRBCCCEGEumO/AKCgSAv/3Eln83fbnYpQgghhBhgJIR9ARarhZTsWOJTo8wuRQghhBADjHRHfkEzLh9udglCCCGEGICkJawXBHxBtq+slukqhBBCCHHEJIT1gq3Lq3jrb+vYs7nB7FKEEEIIMUBICOsFwyam44q1s2ZBudmlCCGEEGKAkBDWC2x2K2NmZrNzTS3NtR1mlyOEEEKIAUBCWC8Ze0ouSinWfCitYUIIIYQ4PAlhvSQ2ycnQkjQ2frIXr9tvdjlCCCGE6OckhPWiotPy8Hb42bKk0uxShBBCCNHPSQjrRRmD40kfFMeaBeUyXYUQQgghDklCWC9SSjF+di4Nle2Ubaw3uxwhhBBC9GMSwnrZsIkZ5I9ORsmC3kIIIYQ4BFm2qJdZ7RbOv3WC2WUIIYQQop+TlrAIcbf5KN8kXZJCCCGE6JmEsAj55PmtvPHXtfi8AbNLEUIIIUQ/JN2RETLxnALGn56H3WE1uxQhhBBC9EMSwiIkMSPa7BKEEEII0Y9Jd2QEdbR6effx9exeX2d2KUIIIYToZ6QlLIIcLhvlmxpwt/jIH5NidjlCCCGE6EekJSyCrDYLY0/JYfeGehoq28wuRwghhBD9iISwCBszMweLTbF2QbnZpQghhBCiH5EQFmHR8Q5GTMpg42eVeDr8ZpcjhBBCiH5CQlgfGDc7F78nwKbFe80uRQghhBD9hISwPpA+KJ6soQmsWVBGMKjNLkcIIYQQ/YCEsD4y/rQ8mmvd7F4n01UIIYQQQkJYnxk8IZXYJCdrPpQB+kIIIYSQecL6jNVq4YxrRxOfFmV2KUIIIYToBySE9aGckUlmlyCEEEKIfkK6I/tYTVkLrz+8Bnebz+xShBBCCGEiCWF9TCmo2dVMY1W72aUIIYQQwkTSHdnHUnPj+Oovp2OxSv4VQgghTmSSBExgsVoIBIK0NnjMLkUIIYQQJpEQZpKXf7+S955Yb3YZQgghhDCJhDCTFBSlsmdzI3V7Ws0uRQghhBAmkBBmktEnZ2OzW1jzQZnZpQghhBDCBBLCTOKKsTNiaiabP6/C3SrTVQghhBAnGglhJho/K5eAL8iGTyrMLkUIIYQQfUxCmIlScmLJGZnE2g/LCQaCZpcjhBBCiD4kIcxk42fn0trgYceqWrNLEUIIIUQfimgIU0qdrZTarJTappS64yD7zFJKrVJKrVdKfRTJevqjgvGpxKW4WLNABugLIYQQJ5KIhTCllBX4C3AOMBqYp5Qavd8+icDDwAVa6zHAZZGqp7+yWBTjZuXi7fDj7fCbXY4QQggh+kgkly2aAmzTWu8AUEo9A1wIbOiyz1XAi1rr3QBa6+oI1tNvjT8tlwln5KGUMrsUIYQQQvSRSHZH5gBd+9jKQ891NQJIUkp9qJRarpT6ak8nUkrdqJRappRaVlNTE6FyzWO1WlBKSWuYEEIIcQKJZAjrqVlH7/fYBkwEzgPOAu5USo044CCtH9VaT9JaT0pLS+v9SvsBd6uPJ3/0CWsWlJtdihBCCCH6QCS7I8uBvC6Pc4H9J8QqB2q11m1Am1JqIVAEbIlgXf2SK9bOxHMKyBuVbHYpYgDYtrwavy9AfIqLuJQoYhKdWCzSnS2EEANJJEPYUmC4UmowsAe4EmMMWFcvA39WStkAB3AS8IcI1tSvlZw1yOwSRD+lg5qyTfXkjEjCarPQUNnG56/uDG+3WBSxyU7iU6OIS3ERn2L8HD4pHYtVZqIRQoj+KGIhTGvtV0rdArwNWIF/aq3XK6W+Gdr+V631RqXUW8AaIAj8Q2u9LlI1DQR1Fa3sXFXLpHMLzC5F9ANaa5RSlG2q59WHVnP2jWMZWpJOyZmDGD4pg+a6Dlrq3DTXummp66C5zk3p2jo6mr3Y7BZGTMkA4MP/bKa+opWLvz8RgO0rqgkGtBHYUqOIirPLhSFCCNHHItkShtb6DeCN/Z77636PHwAeiGQdA0n5xgaWvLKDvNHJZBTEm12OMEEwqNm9ro71iypIyYlh6oVDyS1M5uwbx1IwLhUAq91CYkY0iRnRPZ7D5w3Q3uQJB6u0vFiiYu3h7UtfL6VuT2v4sc1uIS7UtRmf4iIu1UVKTiyDxqRE8J0KIcSJLaIhTBy9wulZLHllB2sXlJNx3ejDHyCOGy31bjZ8UsGmxXtpbfAQFe8ga1gCYHQ3Di1JP+Jz2R1WEtI6A9qYmd0vTL74ByW01LtpqXXTXOfu0qLWQdXOJjztfnILk8Ih7PlfLSVraCIzLh8OwNoPy4lOcIS7PV0xdoQQQhwdCWH9jDPKRuH0LNYv3MO0i4cSk+A0uyQRQYFAkF1r61j/cQW7N9QBkD86mRmXD6dgfCrWCI3ncrhspGTHkpId2+N2T4cfn7tzupTcwiQSM2IA8HkCLHym+7UzjihbaCxa53i07OGJpOXHRaR+IYQ4HkgI64fGz8pl7YJyNiyqYPJ5g80uR0TIjpU1fPTfzbQ3e4lJcDDpnAJGTc8iPjXK7NJwRtlwRnX+8zBt7rDwfZvDwtd+N9NoOavrCI1HM+431XRQtrEevzfIpHMLSMuPw93m4993fcrMy0cw8qRM2pu9bFteTXyqK3wRgd1pNeNtCiFOUK0NHjztPlJyev4i2lckhPVDiRnR5I9JYd1Heyg5axBWm1zddjwIBILsXFVLclYMydkxRCc6SB8Ux+iZOQwakzxgrmJUSuGKseOKsffY0qW1xt3qC88UGAxohk/MCIfLuvJWPn62e0taVJyduGRX59WdqVHkj07uF4FUCDHweTv87NnaSNnGeso31tNQ2U7OiEQuuq3E1LqU1vvPn9q/TZo0SS9btszsMiJu1/o6XvvTas64bjQjT8o0uxzxBfi8AewOK54OP0/8cBFjT83h5EuHm12WabTWtDd7aanrbEFr3ne/toOWejdBv2bOt4sYNCaFPVsaWP7WLmZdNZL41Ci8bj9Wm0W+nAghDioQCFK1s5nyjfWUbWygqrQZHdTY7BayhyeSOyqZvFHJpOZGviVMKbVcaz2pp23SEtZP5Y9KJjEjmjULyiWEDUB+X4AdK2vYsKgCrzvA5T+ejDPKxqV3TCIpK8bs8kyllCImwUlMgpPMIQkHbNdBTVuTF1eM8c+TzxOgo8WLI9Q9uurd3Sx/cxdJWdGk5MQat9xYUnNiiU5wyFQbQpyAtNY0VrWTlGn8+/rBvzayZUkVSkHaoHhKzswnb1QymUMSsNr7zxc4CWH9lLIoxs/OZeEzW6jc2UTm4AP/WIn+p35vGxsWVbDps7142vzEp7oYPSObYCCIxWoxffzBQKAsitikzgtSCsalhqfmAMgdlUwgoKnb00rF1ka2fF4V3uaKsZOSG0NKTiwnXzIMi9USnmtNCHF8aWv0YHdZcbhsrP+4go/+s5mv/GIa8alRjJ2Zw5AJaeSMSOrXV29LCOvHRk7NpKXOLVdI9nN+b4BtK6rZsKiCvduasFgVg4vSGDMzm9yRSShZTqhXZQ9LJHtYYvixu81HfUUrteVt1O1ppba8lV3r6ph5ubEM7buPrcfT7uf8WycAULmzieh4B3HJLglnQgwgXrefPVsajS7GTQ007G0LD9nJH5PM7K8U4ow2Yk1Wl38j+jMJYf2Yw2Vj+iXDDr+jME3N7hZe/uNKPO1+EtKjmHbxUAqnZhEd7zC7tBOGK8ZO9vAksocnhZ/rOtY1a1giPk8g/PjtR9fR2uDBEWUjJSeG1FB3ZkpOLMnZMThc8s+iEP1B13Fd5ZsaqNrZTDCosYbGdRVOywwPaYhPiWL0yQPvQh7512YAKNtUT0eLlxGTZWyY2bTWbPp0LxaLYuTULJKzYhhanMaIKZlkj0iUlpV+out/h3GzcrttO+uGsdSWt1JX3krdnlY2LanE91FnSItPi2L0yVlMPLsAgObaDqPVTFo0hYgorTXeDj/OaDt+b4An7vgET7sfFKTnx1F8Zj65o5LJHBKPzX58TGsjIWwAWPNBOc21HQyflCF/5E3SXNtBfGoUSik2L6nCarMwcmoWVruF2V8ZZXZ54ihkDknodkGA1pqWOjd1e1rD3Zn75i3zdvh56qefMvWiIUw8uwB3m4+tS6tCFwTE4Izuv2NNhBgIPO2+8P9Hrz60imAQLvpeMTaHleIz80nMiO7347q+iMNOUaGUmgO8obUO9k1Jh3aiTFHRVVujB2eM7bhJ/gOFt8PPlqVVbFhUQW15K9f8ajoxCU7cbT6c0TYJxCcAr9vPtuXVZBTEk5ITS9mmel7546rw9thkJ6m5caTkGBcDpObGkpAWNWDmfBOir3ndfiq2NFK2yZg6orXBzdd+NxOr1cLmJZVorSmcmmV2mb3qUFNUHEkI+zcwDXgBeFxrvbH3SzxyJ2II2ycY1CiF/PGPIK01VaXNbFhUwdZl1fg9AVJyYhk9I5vCaZkyXugEp7WmrdHbrdWsbk8rjZXtBIPGv6VWu4U5txSROzKJlno3TdXtZA5NkC9R4oQUCASp3tlM2aYGyjfVU7Wj+7iu3MIkxp2ae1yvmvGF5gnTWn9ZKRUPzAMeV0pp4HHgv1rrlt4tVRxMbXkrbzyyhi9dN3rAXPUxkHjafWz5vIr1H1dQt6cVm9PK8EnpjJmRQ3pBnARfARhfgGKTnMQmORk0NiX8fMAXpL7SuDqzrryVxHRj8fQdK2tY9PxWrrt/Bja7la3LqqjZ1RK6ECCG+NQoCfbiuKK1RmuwWBQ7VtXw3hMb8LkD4XFdE87MJ68wSb6YhBzR//1a62al1AtAFPBdYC7wA6XUQ1rrP0WwPhGSkBaFt8PPmgXlEsJ6mc8b4F8/+RRvh5+0/DhOvWokIyZnhCcHFeJwrHYLaXlxpOV1X8Zp5NRMUnJiwlfL1uxuYfWCMoL+zh4IV4w9tI5mFPGpxpJNY2Zmo5SSOc7EgBAMaiwWRXNdBy/ev5zplw5jxORMkjKjGTE5g7xRyeSMPH7HdX0Rh/0ro5Q6H7geGAo8BUzRWlcrpaKBjYCEsD5gd1oZdXI2q98vo7XBTWySy+ySBrTNSyrZs7mB0746CrvDyvSLh5KWH0f6oHizSxPHEVeMndzC5PDj6RcP46QLh9BY1U59RZuxTFOdm+Y6N7XlLexcU4PDZWPsKTmAMcdZa6OHi78/EYBNn+5Fa018ShRxqS5ik1xY5KpN0cf2H9eVOyKRU+aNJDbJRd6oZGITjbktkzJjmHV1ocnV9m9H8lX/MuAPWuuFXZ/UWrcrpa6PTFmiJ+NOzWH1e7tZ+9Eepl001OxyBhStNRVbGskIXdrc1uihfm9beF3HMTNzzC5RnCCsVgsp2bGkZB+4eoIOajpafeHHuaOS8bT5w4+XvVlKU3VH+LHFoohNdhKfGkV8iou41CjS8uMYNCYFIXpLIBCkurTFWPy6h3FdaaEvrxaL4vRrR5tc7cByJAPzBwN7tdbu0OMoIENrXRr58g50Ig/MB3jzr2up2NrINb+ajs0h/emH097sZdNne9mwqIKm6g6+dP1oRkzJDDefCzGQBPxBWurdtNSGFj7v8rOlroOOFh8F41M57+bxADx992cMmZDGtLlD0Vqz+v0y4lJcxIe6PmWKDdETvy8QHq+16LmtbFhc0W1cV+6oZBnXdRS+6ALezwPTuzwOhJ6b3Au1iaM0fnYuO1bVsGVpFaNPzja7nH5Ja035pgbWf1zBztU1BAOarGEJTDq3gMET0gAkgIkByWqzkJgeHR74vz+v24/fa8wmpLWmYHwqqXlGi1tHi49P/ret2/7OaJsRykItafGpUWQPT5Q1Tk8gbU0eastbyR2RhNVuYdmbpSx/axc3/H4mFquF6AQHIyZnkFuYTG6hjOvqbUcSwmxaa+++B1prr1JK1mQxSfaIRFJyYlizoJxR07Nk0O5+GqvbWfDUJiq2NuKMsTFuVi6jT84mOTvG7NKEiDiHy4YjNFxUKcXJXZY9i4538LXfzTTGoNV2b0Vr2NvGrnV1BHxBps0dSkpOLC31bv7362WcOm8kQ4rTaGv0sGt9XTisxSY5ZT60AUQHNU01HdSUtVBb1kptufGzvdn48375jyeTlh9H1pAESs7MJ+DXWKxQctYgkys/vh1JCKtRSl2gtX4FQCl1IVAb2bLEwSilGD87jwX/3sTebY3d1ss70W34pIKPn9mCxWbh1KtGUjgtU5rKhejCFWPHFWMnLT/ugG06qGlv8WLtEqwGjUshNtkYZF1V2syCpzaFtymLIjbRaVzZ2aUlLW9UsqydajK/11iGy+awsnd7E4tf2Ertnjb8oTVULRZFUnYM+aOTSc2LIzU3lsRMo3U1Z2QSOSPl70pfOZIQ9k3gaaXUnwEFlAFfjWhV4pBGTMlg8Uvb2La8RkJYF9HxDnJHJTPrqpHEhK7OEUIcGWVRxCR0/n8Tl+zitC5LchWMS+Erv5hmtKLVubu1qO1eX0d7k9GiMvf/iomOd7B9ZTWfzd/B+d8uIj41iprdLTRWt4e7Pl2xdmnJ7wXuVh815S1ExTpIzY2lsaqd//xsCadfM4qRJ2Vid1qwWC2Mnp5Fal4sqblxJGfFYLVLK2Z/cCSTtW4HpiqlYjEG8ssErSazOaxcevskElIH3orxvUlrzfI3SwHFpHMLKBiXSsG4VLPLEuK4ZLFajAB1kH93/N4ALfVuYpON/lBntJ2UnBhcscYYoq3Lqlj5zu7w/jan1Wg9S+mcIy0uxUXBuFSsNgkI+9Na01zrDncj1pa3UlvWQmuDBzCunj9l3kjiU11MPHtQeFxfam4cc/+vxMzSxSEc0WyUSqnzgDGAa983F631vRGsSxzGvoG5OqhRJ+ggc6UUDVXtKGRSSyHMZnNYScrsHHuZOzKJ3C7dWpPOLWDElExawldzhsak1bmp2NqIN3T13TcfmgXAZy9vZ++2pnCA2L3BGLMWnxpFXIrruF5pIOAP4m7zEZPgRGvNKw+uorq02fiMAKUgKSuG7OGJpObGkZoXG54o2GK1cNIFQ8wsXxyFI5ms9a9ANDAb+AdwKfB5hOsSR2DzkkqWvraTK+6cgv0Ema7C7wuw7PVShk/OICUnltO+OqrbGBYhRP/kcNlIzTUWOd+f1hpPu5/WBne4mywu2YUnu8scaW+UsndbU/hxt5UGUlzEp7pIyowZcOOZPO0+astbaW/yMnxyBgDzf78Sq01x0W0lKKWISXQy4qRM4/PLiyMlO0amKDpOHMlXiela6/FKqTVa658ppX4HvBjpwsThxae4SM2Lw9vuPyFC2N7tTSx4aiMNle3YXVZScmIlgAlxHFBKhS8a2Gf/CZTP+eY4mmuM1rN949Fa6tzU7Wll55oagn5N+qA4LvuRMXvSa39eTWJ6NDMuHw7AlqWVRMU6iEtxEZfs6vMuT601rQ0eastaQl2JrdSUtdBS5wbA5rAwdGI6Foui+Mx8ujbsnyEToB63jiSEuUM/25VS2UAdMDhyJYkjlTUs8YRYR9LnCbDk5R2sXlBGbJKT828tIn+0zAguxIkkKtZBVKyDjMEHLi2mg5r2Zi9ed2fLWWJmNHGh5d2CQc37j28kGAxNTq4gNtEZniNt3wS26YPiemWOtEAgSGNlO8nZMSilWPHOLla8vatz9QNlDCnJGBzPmJnZ4SsU981fOCQ0n6E4/h1JCHtVKZUIPACsADTw90gWJY5O/d420ByXc2GVb6pnwb830VzrZtypOUydO/S4HgsihDh6ymJ02cXQeXXnjEuHd25XcPXPp4ZWGujemrZncwOtjR7QMP60XGZePoKAL8h/7l3C5HMLKJyWhbfDz841teGLCGISHOGxuF63n7pyY6D84KJUYpNcbFq8lw+f3sxXfjEtdDVoFENL0kkLdScmZ8fIv2MCOEwIU0pZgPe11o3AC0qp1wCX1rrpUMeJvhMIBJn/+xVkDkng3JvGm11Or/F0+Fn84jY2fFxBQloUc/+vWKbjEEIcE6WUsVRTShQ9rRIb8AdpbXCHJ5/1eQNkFMQTFWfMd1a/t433Ht8Q3t9iU8Qlu0BDU03nWp6uWDvDJ7nIG53MGdeNxhnqXh02MZ1hE9Mj9wbFgHUka0d+qrWe1kf1HNaJvnZkT5a8soNlb5bylZ9PO+jl4wNJMKh59hef07C3jQln5DPl/MEyCFUIYZqAPxieE60lvGanG7QOz72VmhdLTKJTrtIWB/iia0e+o5S6BHhRHy6xCVOMmZnDird2sfbDck7u0gQ/0HjafTiibFgsiilzBhOb5Opx/IcQQvQlq81CUmZMtyk4hOgNR3J5yG0YC3Z7lFLNSqkWpVRzhOsSRyE2ycnQkjQ2fLK328DUgaSppoOn7/6MjYv3AjC0JF0CmBBCiOPaYUOY1jpOa23RWju01vGhx/LXsZ8Zf1oe3g4/W5ZUml3KUQkGgoAx3cawknTSBx24pp0QQghxPDqSyVpP6el5rfXC3i9HHKuMwfGkD4pjzYJyxpyS0+/HJWit2bKkks9f28nF359ITKKTU+aNNLssIYQ4tGAQGnZC9UboaDAuvUR1+Wnp/twB20P79PYx4ec4xDGHOg89n/uoHOWIpaMa4RTJcwMxaeD84tOTHK0jGRP2gy73XcAUYDlwWkQqEsdEKcX42bm898RGyjc2kDc62eySDqql3s2HT29m9/o6Mock4PcFzS5JCCEO1FYLVeuNW/V6qNoANZvA1252ZaK3Xfo4jL24z1/2SBbwPr/rY6VUHnB/xCoSx2zYxAw+eWEbaxaU9csQpoOa9YsqWPziNnRQM+Py4YyblRueoFAIIUzhbTfCVfUGI2jtC1xt1WZXJo5zxzJbXDkwtrcLEV+c1W5hwhn5tDZ6+t3C3k017Sx4ahN7tjSSW5jErKsLSUgb+NNpCCEGkGAAGkpDLVsboGqdEbbqd3DU3V1C9IIjGRP2Jzp/Oy3ABGB1BGsSX0DJWYPMLqGbYFCz5oMylry8A4tVMfvLhYw6Oavfj1kTQgxwrTVGyOraulW9Cfwdhz9WiD5yJC1hXWdG9QP/1Vp/EqF6RC/QWrN3WyOpeXGmL43RWNnOpy9uJ39MMqdeNZLY0FpuQgjRK7ztULMxFLQ2dLZytdVE7jWdCZAxGpIKjEHsOhgaCK67/NzvOR3ssp0+OkYbTSgHPHcUxxzt4Pyj/oJ9FPsf9Xf3ozjAYc4ccEfyF/p/gFtrHQBQSlmVUtFaaxmZ2E/Vlrfy0u9WcsqVIxg3K7fPXz8QCLJ7fT2Dx6eSnB3D5T+ZHF7IVgghjkkwAPU7Q+O11neGrfqdRKwr0WKHtJGQPtoIXeljjJ/xOccQNoQ40JGEsPeBM4DW0OMo4B1geqSKEl9MWl4cZ984lvyxKaa8/rqP9rDoua1c/uPJpOXHkZLT95f9CiEGKK2htbpzcPy+1q2azZHtSkzIDwWt0ZAxxviZOhys9si9pjjhHUkIc2mt9wUwtNatSqnoCNYkesHQkr5dLDbgC9Jc10FSZgxjZmaTkBZFWr5MvCqEOARvmzFOKxy4Qi1c7XWRe01XQmeLVvpoyBgL6aPAJXOQi753JCGsTSlVorVeAaCUmgjIyMYBYNNne6nc0cysqyI7CWrljiY+eGoTfk+Aq382FZvdSsG41Ii+phBiAAn4jSsQ92/daiglYl2JVgekjjywdSs++wt3JWqt2blqGY17K0grGEJ6wVCc0dI2IY7ekYSw7wLPK6UqQo+zgCsiVpHoNS11btYv3EPRabkRWXjW5w2w5JUdrH6/jNhEJ7O+XIjVfiTLkQohjksBHzTsgrptULe1s3WrZjP43ZF73cT8/Vq3xkDKsF7vSgwGA2z57BM+f+k5anaXdtuWlJVD+uChZAwZRtGXzsHhkil4xOEdyWStS5VShcBIjEsNNmmtfRGvTHxhY2bmsOzNUtYuKO/1JYH2bG7gg39vormmg7Gn5DBt7lAcUeZeiSmE6APBILTsDQWtbVC3vfN+QykY13BFhivRCFj7WrUyxkBaYZ91JVZs2sjrD95PcnYuZ9/8PfLHFVG7q5SqHduo2rmNis0b2bpkMcVnG3Ocf/7y/6jfU87ZN38XgIDfh9UmY8xEpyOZJ+xbwNNa63Whx0lKqXla64cjXp34QqLjHQyflMHGzyo56aKhOHshJHk7/Cx+aTvrF+4hPi2Ki75XTM7IpF6oVgjRr7TXdw9Y+wJX/fbIL9tjdYSuShzT/arEuKw+vypx9btv4m5r5aSLLiNn1Bgu+fG95I8rwmKxAhCXnMrg4knh/d1trdjsRtDyeTz43J2jd5792Y9ob2wgY/CwcKtZxpBhRMXJeLQT1ZH8Vb5Ba/2XfQ+01g1KqRsACWEDwPjZuWz+rJJNi/dSdHreFzpX2aZ6PnhyI62NHorOyOOkC4Zgd1h7qVIhRJ/zthtjtXpq1eqo75saEgd1b9nKGAPJQ8FqXsu6z+vB7nACULFlI22NDUy58FKUUhQUlRzyWFdM59XgJ19+dbdtI6fOpGLLRqp2bmPLks7pNuPT0sPBLG/MeHJGjurFdyP6syP5LbcopZTWxmxxSikr4IhsWaK3pA+KJ2toAmsWlDFu9hdbpzEY0NhdNi75wVgyhyT0YpVCiIgJ+KBx934tWqHA1byn7+qISgpdidhlzq30QnD2n6uoO1qaWfHmq6x661Uu/ekvyBgyjC/dcAtWu71X5jmceN6FTDzvQgDcra1Ul243ujJ3bKO6dDtbP1/M2NlfImfkKLTWvP7QA4w+ZTZDiiejtZa5Fo9DRxLC3gaeU0r9FeMylm8Cb0a0KtGrxs3O5Z1/rGfXujoGj09l0+KF2OwOhk2eethjt6+spqXOzYQz8hk0JoW8wiQsVhl8L0S/ovWhx2kF/X1XS0y6MSg+ZSikjugMXHGZ/XaC09aGepa/Pp/V77yBz+Nm6KSp2EItYTZHZNocXLGx5I8tIn9sUfg5T3sbPo8HMAJhdekOBo2bAED9njL+94ufduvGzBg8jNhkc+aDFL3jSELY7cCNwE0YA/NXYlwhKQaIIcVpxCQ6WfNBGTnDo3n7kQfxez2c+uXrmXT+xYc8dueqWhqq2hk/OxeL1SIBTAgztdfv132477YDfG19V4cjDlKHGd2GKcM6Q1fKUGMergGiqbqKpa++yLoF7xD0Bxg5fSYnXXQZqfkFptTjjI7BGW1cyR4dn8D1f/hr50alyBtbRNWObexYuSy8lFFMYlJnMBs8jNzRY7t1iYr+TWl9+DlalFITgKswpqbYAbygtf5zZEvr2aRJk/SyZcsOv6PoZvnr2/js1d1MGrOARYtWkpXiYG+dl2knj2X6Becba6DFZaGVYsvnVaTkxJKaG4vX7cdqt2CV8CVE3zjYOK367ZGdxHR/VgckD+kSsIZ13mLS+m2r1pGoryjn8/nPs3HRh4BizKzTmXzBJSRlZptd2hHxujuoKd1J1c5tVO80ujTrysvQOsiV9z5AzshRlG9aT+mq5Uy+4JJwsBPmUEot11pP6mnbQVvClFIjgCuBeUAd8CyA1np2JIoUvUhraNgJ5cugfCmUL2P0nlKSE4eydIWbRLuTK9M+5sPgELJ3r4UnHgGglUw+bP02u1pHMzp/F7NPbcGRVGAEtKRBA+obrhD9WjBgdBP2dPVhc3kfFqIgMa97wNoXuBLywHJ8Xniz9oN32PzpIiaceR6Tzr+YuJSBNbm0wxVFTuFocgpHh5/zedzU7ColvWAIAFXbt7H89ZeZesk8AD594b/s2bSBjFCrWfrgYSSkZ8g4M5MdtCVMKRUEPga+prXeFnpuh9Z6SB/WdwBpCeuBuwn2LA+FrmWwZ1mP35hbfA4e3TaFaam7mZ62O/y81vBR/Wls8X0VjYuT4p5mfPTrWFSw+wmikoxAljgoFMwKOgNaQp6ssSbEoQT8UPoxrH8JNr7ad1cfgtFy1VOLVtJgsLv6rg6TtDU28M7fHmLCWXMYPGEiHa0t6ECA6IREs0uLqK7zki179UU2LPqQurJdBAPGXG6umNhwV2b64KFkDhlOYqaMNuptx9QSBlyC0RK2QCn1FvAMxpgwYaaAH2o2hlq4lhs/azcf0aEbmjIAhc0xHDBCWLM/nbfrr2V33WckxSzgkuy3SbBV9nyCjgbjVrHywG3KAgm5PQS00C06ZUB3XwhxTAJ+2PVJKHi9EtnuREfcgSFrAI7T6i1aa9oa6olNTsEVG0trQz3ulmYAomL7zxWZkdR1YthJ51/MpPMvxu/1Ulu2KzzBbNUOo8UsGPCTlJ0bHoe25v23iE1OYUjxZLPKPyEcNIRprV8CXlJKxQAXAd8DMpRSjwAvaa3f6ZsST3DNe42WrX2hq2LFMU+UuKstEac9gQ6VjdYfsKb9XD5r/TKKIBPTlzM98d84rMc427UOGpfBN+42vu3vzxHbcwtaUoGx5IhdlvgQx4lgAHYt7gxebTW9d26L/eDjtGLT5YsOoINBti//nCXzn6O1rpav/ekxbHY7X/7VH6XrDeNqz8yhw8kcOjz8XMDvo3b3LjztnRd3fPbis+SPLQpPj/HJs/8me2QhuaPGypJMveiIBuaHd1YqGbgMuEJrfVrEqjqE47o70tcBe1eHx3FRvqxXx4cEojNpSZlIwogpvP7RMHaVR5OfXM6szGeJa1sLnibcASvv7B3Bqek7SHB4eu21Dys2s+eAllRgbLPIhQGiHwsGYPdnRvDa8DK0VX+Bkymje7+nVq2EPFMnMe3PgsEAmz9dxOcvPUdt2S4S0jOYfMGljJ19hiwVdAwCfj8+jxtXTCzNtdX887vfIODzYbHayB5RSP64IgaNm0Dm0BFYrMfn2MHecqjuyKMKYf3BcRPCtDaugAoHrqVQta735vOxuSBrAuROgtzJxs/4nPA35c1LKkFrRpyU2fntsKOB6nWf8vyfH8Nq1VwyK4M0VWkMIG7c3bdzDXVldRqtZT0FtMRBfbZunBDdBINQtqQzeLUepBv/YGxRkD3hhB2n1VsCfh/rP/qApa/8j8bKvSTn5HHS3MspnH6KhINe5PN6qNi8kV1rV7F77Sqqdm4HrXFERZM3Zhz5YycwYurJxCYlm11qvyMhrD/oaDhw8HxHQ++dP2UY5EwKha5JxszUoYHywWCAZ+6+neKz5jBqxqzDnqq2bBcv/PIufB43F/3wLnILxxjf9Jv3QMMuI5Q1lEJjl/u92eVytKKSDwxoCblGF6jNaQTS8M8u94/TK79EBAWDxhem9S/BhvnGBKlHw+aC4WfCmLkw4ixwyNQBxyoYCLDqnddZ+uqLtNbVkj54KFPnXsGwyVNR0nIecR0tzZStXxMKZatprNrLFff8mtxRY6ku3UHt7lKGTz05vPzTiexYB+aLYxXwQ/X67oPn67b23vldCaHANdm45ZRA9MG/fXQ0N+OMij7imZ9T8wYx794H+N99d/LCL+7k/Nt+xJCSyUZrVGI+DJ554EGeVqO1rKeA1rAL/B0HHtNbOuqNW8WKozvOYtsvoPX0M+ow2w8S8Pb/ad9vu9UpXawDhdbGF6d9wetol/qxOmH4l0LB62xwykSaX0QwGMBisaIsFtYteJeEtAzOuvHbDCoqkTFffSgqLp4RU2cwYuoMAJqqK4lNNqb62Pzpxyx/fT7Dp54MwI6VS9HBILmjxuGMjjat5v5IWsJ6Q3NFKHDtGzy/svdCh7IaC9ruC1y5k4xZqvvgD3h7cxMv/upuqkt3cPZN32X0Kcc4DFBraK0+eEBr3oOxItYJxuo4wnDXU9hzGfM7ZRdD6kgZJ9TbtIY9K2D9i0ZXY1PZ0R1vdcCwUPAaeXa/Wh9xINv86SI++vdjfPU3f8IVG4u7tRVXrITa/kYHgzRW7SUpKweAZ++5g/KN61AWC1nDCxk0roj8cRPIGjYSq+34/7dLuiN7k7cd9q7qPni+paL3zh+fAzkTOwNX1gRwHPs3B5/HjbutlbjkY5uM0NvRzsu//QW7161h1le/zsTzLjrmWg7K74HGMmgs7RLOSju7Pj3Nvf+axxNbFGSOM8YXZRcbvzNpI6W79WhpbXyBWv8SrJ8PTbsPe0g3VgcMPb0zeJ2A00JEQmt9HcFgkPjUNKpLd/DZC88w65obiE9NM7s0cYT8Xi8VWzrHk1Xu2AZaY3dFkTd6LIPGTaBgwkSSs3PNLjUiTAthSqmzgQcBK/APrfWvD7LfZOAzjKsu/3eoc/ZpCAsGjaVCug2eXw/6GKdx2J8tyvij2W3wfO8um7Fh4Qe8+fAf+Or9fyLtGNdD8/t8vPGnB9i6ZDFzvns7I6f10B0ZKVobY+f2bz3bd7+pzLwLBvoze3QomIVCWXYxpA6XYLY/rY0rkte/ZNwadx3d8RY7DD0tFLzOgajEiJR5ImqqrmTpKy+wbsG7jJg2k3Nv+T+zSxK9pKO1hfL1a41Qtm4VDXsrGHPq6Zx98/fQWrPpk4/IH1tETGKS2aX2ClPGhCmlrMBfgC8B5cBSpdQrWusNPez3G+DtSNVyxNrrQ4Pnl3YOnnc39d75U0d0HzyfPjris8xv+HgBCWnppOYNOuZz2Ox25nz3dla/+ybDJk/txeqOgFLGeLfoZCNI7C/gN1oiuwW0ncaFAn4P+N09//R1cFx3gfrajSv3ypZ0PmePgazxnaEse4JxQceJFsy0hsq1ncGrYefRHW+xwZDZRvAqPNdYSUL0mrryMj6f/xwbP/kIi8XCmFlnMPmCS80uS/SiqNg4hp80neEnTQeguaaaQMD4Ml1fUc4bf/otX7rxFsaffjZtjQ3s3bqZvDHjjss1MCPZGTsF2Ka13gGglHoGuBDYsN9+3wZeAMydlnfL2/Cfy3vvfFFJXQbPTzIGz/fxP9at9XXsXruaky6+/AsPWLVYrBSfNQeA9qZGlsx/npnzrjniwf4RY7V1uWDglCM/TmujBa1rOPO59wtrBwlwh/y5/3MdB9+3r/naYPenxm0fRyxkju8MZdnFfTbmsE9pbbRi7wte9duP7nhlhSGzQsHrvENeCCOOTdWObSyZ/xxbP/8Um8NByTnnM3HO3GMeSiEGjvi09PD95KwcvvKbh8LreW5f/jnvPvonlMVC5rARDBo3gUFjJ5A1YuRxMf9bJENYDtB1NGs5cFLXHZRSOcBc4DQOEcKUUjcCNwLk5+f3eqGA0Sp1rCw2Y0qIboPnh5g+e/XGTz5C6yCjZvTumuu71q1mzftvMfqU08gYPLRXz91nlDJaIa12cwZNaw0B71EGui6teO5GozWnYuUXm+rE2wq7Fxu3fRxxkFXUfYxZ8pCBF8y0huqNncHraK9QVlYj2I+ZC4VzICYlMnWe4Oor9rDgyUcpXbUcZ3QMU+deTvE5FxAdL2PqTkTKYgkvQg4w+pTTSMrKZvfaVexau4olLz7HZy88g93pIjc0nix/3ARS8wYNyKtjIxnCevo09u//+SNwu9Y6cKgPT2v9KPAoGGPCeqvAbhJyjZnZj2TCxYS8/QbPF/XLZXc2LvyAzGEjSM7O6dXzjjr5VPLHjA/31/u8HpkL5mgpFbra8Qt+blobU4NUrDQuGKlYCRWrjJB2rLwtsGuRcdvHGW/8nmcVhVrNio1JRftjMKve1Bm8jnBd1TBlgYKZRvAadT7ESCtMJGit8bS34YqJxeZwULu7lBlXfpUJZ513XHY5iWNns9vJGz2OvNHjOPmKr+Bua6Vsw9pQKFvNzpX/wGqz8a3HnsHuclFdugNXbNyAuXAjkiGsHMjr8jgX2P8ywknAM6EAlgqcq5Tya63nR7CunillBKpNr3V/3h5z4OD5uMw+L+9o1ezaSc3uUk677hsROf++ALbm/bdZ9uoLXPLjn5OQnhGR1xKHoFRogtpBMOYi4zmtjfFxXUPZ3lVfbHyjp9lYE7TruqDOBGOMWdeuzKTB5rQA12zpDF41G4/uWGWBQSeHgtcFEDsw/vEeyObffy9+n4/LfvoL4lPTuOHP/5TZ7cURccXEMnzyNIZPngZAc201tbt3YXcZq0y8/9gjBIMBrr7v9wCUb1xHan4Brpj+OZVJJEPYUmC4UmowsAe4Eriq6w5a68H77iulngBeMyWA7ZM3BWq3doat3EmQNmpAzsG04eMFWKxWRk4/inFSxyAlJ4/25ib+e9cPuPTH95J6jFdgil6kFCQPNm5j5hrPaW0MQN8XyipWwt414PkiwazpwGDmSggN/J/Q2ZWZVBCZYFa7rTN4Va8/yoNVKHhdZASvOPkCEUnBQICtny9m+JTpWKxWhk+ZTjAYRGuNUkoCmDhm8anpxKd2jin70g3fwtPeDhi9NP+7706C/gCZQ4eTP24Cg8YVkTViFDZ7/xhPFukpKs7F6HK0Av/UWt+nlPomgNb6r/vt+wRGCDNvigqtTR/H1RuCwQB/v/k60ocMY+4P74r469XsLuWFX96F3+th7u33kDNyVMRfU/SCYLBLMFtpTNVQscrojuxNrsTuoSy72LiQ4lj+X6vb3jmPV9XaozxYQf40I5iOvmBAtGgPdH6fjw0fvc/nr/yPpqpKLrjtx+Er4oSItGAgEJqfbDW7165i77bN6GAQm8NJ7qgxDBo3gYlz5kZ8LJlM1nqCqdm1k6d//D3OueX7jJw2o09es6m6iv/d91Na6+u54LYfMbi4x9830d8Fg8bC8l3HmO1dbQzg701RSd1DWfYEY6xlT/8Y1u8wQtf6l6ByzdG/Vt7UzuDVy/PwiZ552ttY+8E7LH/tJVob6skcNoKT5l7B0JLJsq6jMI2nvb3LeLJVWG02vnr/nyL+uhLCTkDu1lZsTmefNrm2NzXywi/vpraslLNv+i6jZvbuVZnCJMEg1G3bb4zZamPKi94UndLZlZlVBPU7jeC1d9XRnyt3Sih4XQgJvXthiji4uvLdrHzrNTYs/ACfx03e6HGcNPcK8scVDcgr18Txzed2h8eSRZKEsBPIvjEWZvG0t/PyAz+nbMNaZl97IyXnXGBaLSKCggEjmHUdY1a5xpgk1iw5kzqDV2Le4fcXver9f/6VVW+/htVup3D6qRSfPYeMIcPMLksI00kIO4Fs/OQjVr7xChf+4KemLfng93p5/aEH2L1uFdf94W/EJsnElieEYABqt3QZ+L/KGPzfW4vZ9yS7pDN4JR37qhDi6LlbW1n7wduMO/0sXDGxbPlsEQ2Vexl32pkyx5cQXZiybJEwh81uxxUba+o/gjaHg/O/dwcNe/eEA5gOBmUsyPHOYoX0UcZtwjzjuYA/FMy6jDGrXPvFVgzImmAErzEXGVdeij4V8Puw2uw0VVey8OnHiUtNo3D6KYyY2jfjT4U4nkhLmIi4Za++yN6tmzn31u8fF8tMiC8o4IeaTd3HmFWuhYDn4Mdkju8MXslDDr6fiIiA38+2pZ+y8q3XSMzI4uybvwtAw949JGXJmDshDkVawk4QdXvKiE9J65OBhkdDWSxgsUhLmDBYbZA51rgVf9l4LuAzgtm+UFa9AWwuKJhhhK+UAbo81gDX3tTImvfeYvV7b9JaX0dCeka3K64lgAnxxUhL2HHkqdu/g93l4sqf/cbsUg6w74KBlvparDa7jBkRoh+r3LaFlW+9yuZPPybg9zNofDHFZ89hcPEkLBaZWFWIoyEtYSeA2rJdVJduZ/Y1N5hdSo+UUmitefmBX+B1u7n0J/d2m+VYCGG+qh3beP+xR9i7bTN2VxTjTj+bCWedR0qOXG0qRCRI/9BxYsPHC1AWC4Unn2p2KQellGLWNTfQ3tTAf+/8AXXlu80uSYgTXmt9HfUV5QC4YuPwdLQz+9pv8I1HnuT0678pAUyICJIQdhzQwSAbF31IQVEJ0QmJZpdzSLmFY7ji7l+jg0Geuft2KrZsMrskIU5YOhjkP3d+nw//9Q8AEtIzuPZ3D1Nyzvk4o6NNrk6I45+EsONA2YZ1tNbVMnqAzFCfNmgwV977AK6YWJ7/xU8oXbXc7JKEOCH4vB7WLniHl37zM4KBAMpi4cwbv81p134jvI/MbC9E35EQdhzY8PEHOKKiGDp5qtmlHLHEjEyuvPd+kjKzeen+n7Ppk4/MLkmI41ZzTTUL//MEj958He/89SGaa6ppra8DoKCohMTMLJMrFOLEJAPzBzifx83WJZ8w/KSTsTucZpdzVGISk7jinl8z//6f8/qffktHawvFZ80xuywhjgtaa8rWr2HlW6+xfdkSAIZNnkrx2XPIHT1OWryE6AckhA1w25ctwdvRweiZp5ldyjFxRsdw8Y9/xusP3k/Vjm2mr30pxEAXDARY+8HbrHzrNerKd+OKi2fyBRdTdOa5ckWyEP2MhLABrmrnduJS0sgbPdbsUo6Z3eHkgtt+DBjjUdoaG4iKj5f5iIQ4Cp72NpzRMSiLhRVvvorN7uCsb36HkSefMuBayYU4UchkrccBT3v7cXMlk7ejnX/98NsMGl/Ml264xexyhBgQlr76Ip+/9Bw3PPw4DlcU7c1NRMXFS6uyEP2ATNZ6nNq3KPbxEsAAHFHRFJ99PtkjR5ldihD9lqe9nfUfvc+gcRNIyc0jb9RYvB0d6GAQQFakEGKAkBA2gD1zzx3kFI7mlKuuNbuUXjXxvIvC99e8/zbDJk+VPypCYKwPu+rt11j/0Qf43B3MuPKrpOTmkTlsBJnDRphdnhDiKEkIG6CCgQBZw4aTlJVtdikR01RdxYLH/8by117ikp/8nPjUNLNLEqLPBYMBdq5cxsq3XmPXmpVYbTZGTptJ8dnnS/ASYoCTMWGiXyvfsI6X7r8XZ3QMl/zkXllCRZww3K2trF3wDqvfeZ2m6ipik1Mo+tK5jD/9rH6/MoYQotOhxoTJZK0DkA4GKduwNjz+43iWO3osV9zzawJ+H8/cfTt7t202uyQh+sRnL/6Xhf/+J7HJqcz57h18/U+PMfXiKySACXEckRA2AJVvWs9zP/sRW5Z8YnYpfSK9YAjz7n0AZ3Q0z9/7E0rXrDS7JCF6XXNNNc/+7A52r1sDQMm5F/GV3zzElT/7DSOnzcBqk9EjQhxvJIQNQBsWLsDuimJIyWSzS+kziZlZXPmz+0nMyOSlX/+MzZ9+bHZJQnxh7c1N4dbdqIQEfG4P3o52AOJT00gvGGJmeUKICJOvVgOMz+thy2eLGD5lGnany+xy+lRsUjKX3/Nr5t9/L689eD8+j4exs84wuywhjlprfR2LnnmKTYs/Ii45lesffBS7w8mXf/UHs0sTQvQhCWEDzI7ln+PtaB+wyxR9Ua6YWC75yc9599E/kzFkmNnlCHHUqnZuZ/5vfoa7rY2xs75E8dlzZFJVIU5QEsIGmA0LPyA2KZm8sePMLsU0doeTc2/5P8BYpHjb0k8ZNmkqyiK966J/2758Ca8/+ADO2Fjm/fwB6W4U4gQnf7UGkPbmJkpXr6BwxixZVzFk97rVvPK7X7Jx0YdmlyLEQWmtWf76fOY/8AuSc/K4+r7fSwATQkhL2ECyefFCgoEAo085Mbsie5I/togLf3AnQ0+gixTEwBIMBPjg8b+x+t03GD5lOufcctsJN55TCNEzaQkbQDZ8vIC0QYNJyy8wu5R+QynFsEknoSwWmqqreOV3v6SjpdnssoQIq9ldytoP3mHyBZdw/vfukAAmhAiTEDZAeNrb6GhpZvTM2WaX0m/V7yljx8qlPHP37bTU1ZpdjjjB7ZtqImPwUK79/cOccvV1Mm5RCNGNLFs0gGitCQb8WG12s0vpt8rWr2H+Az/H7opiygWXMPa0M3G4oswuS5xg6ivKee5nP2LWNTdQOP0Us8sRQphIli0a4LTWBPw+lFISwA4jb8x4rrjnNyRmZLLgyb/z95uvY9EzT9HW2GB2aeIEEp+WwaBxE0gbNNjsUoQQ/Zi0hA0A5ZvW8/Jv7+Pi2+8ma/hIs8sZMPZs3siyV19g27IlWG02xpx6OtMvu5qYxCSzSxPHIa01q995g5Enn0JUbJzZ5Qgh+olDtYTJ1ZEDgMMVxeAJE0nJyze7lAElZ+Qockb+lPqKcpa/Np8tSxYzY941AHja23FGR5tcoTheBPw+3n30L6z/6D08He2cdNFlZpckhBgApCVMnDB8Xg92hxOtNU//+Huk5hVw9s3fNbssMcB1tLbwyu/uo3zDOqZdOo9pl14lM+ALIcKkJWwAq91dirJaScnJM7uUAc/ucAKgg0FGz5xNTFIyAD63m82fLaLw5FOx2WXMnThyDXv38NJv7qW5popzb/k/RsnVy0KIoyAhrJ9b9Oy/qdy2mRsfeUJmye8lFquVknMvDD/e+vli3n7kjyx65l+UnHMBRV86B2d0jIkVioGgfOM6Xv7tfaAUl955H7mFY8wuSQgxwEgI68c6WprZuXIZxWfPkQAWQaNmziY6IZGlr7zAx/95giUvPcv4M86h5JwLiEtJNbs80Q9tWPgBb//1IRIyMrn49rtJzMwyuyQhxAAkIawf27z4Y4IBvyxTFGFKKQqKSigoKqFqxzaWvvoiy1+bz4o3XmHUjFOZNGcuqbJKgQjZvvxz3vzL78kbM54LbvsxrthYs0sSQgxQMjC/H/vPnd/H19HBVx/4swz07WNN1ZUsf/1l1i54B7/Hw5QLL2XmVdeaXZboB4KBAKvefo2iM8+VefuEEIclk7UOQA2VFezdsolRM2dLADNBQnomp133DW78y+NMv/xq8kaPA6CtsYEtny0iGAyYXKHoS+1Njbz6x9/Q1tgQHlMoAUwI8UVJCOunNn68AJRi1IxZZpdyQouKi2faJfMomDARgPUfvc+rf/wNTVWVJlcm+lJLfR1l61ZTu3uX2aUIIY4jMiasH9Jas/HjD8kfM14Ghvczk86fS07hGJKycgB459E/EZeSyoQzzyMqLt7k6kRva9i7h6SsHDIGD+Xrf35M1iEVQvQqaQnrhyq2bKKxaq8MyO+HLBYrOSNHAcbYoLbGBhY/9zSPfus6Pnj8bzRVV5lcoegta95/i8dvu4lNn3wEIAFMCNHrpCWsH2quriQmKZnhU6aZXYo4BIvVytwf3kVt2S6WvfoSq999k1XvvM6IqTOYfP7FZAwZZnaJ4hgEgwE+/s+TLHv1RQZPmMjg4slmlySEOE7J1ZH9VDAYkLnBBpiW+lpWvPEKa957E29HB/lji5h8wSUMGl8sF1cMED63mzf+/Fu2Lf2MCWfNYfY1N2Cxyv+HQohjd6irIyWE9TPejnbsrij5oz2AedrbWP3um6x48xU8ra3c8PDjRMcnmF2WOIzW+jrmP/BzqnfuYNY1N1ByzvlmlySEOA7I2pEDyFsP/5GO1mauuPvXZpcijpEzOoYpF15KybkXUrVjG9HxCWitee3B+xlaMlnG+vVD1aU7eOn+e/G0tXHRD+9kSIl0QQohIk9CWD8zdNJJ+Dwes8sQvcBmt4cH8Xs7OmhvbMDT0Q6A3+vF095GTGKSmSUKoHT1Cl753S9xxsZy5c9+Q3rBELNLEkKcICSE9TNjTj3d7BJEBDijo7ninl+jg0HAmG9swZOPMvqU05g0Zy7J2bkmV3jiiktJJWv4SM751m3EJqeYXY4Q4gQiY8L6kc2ffkzemPEyfugE0FBZwbJXX2T9R+8T8PsZNmkqky+4mOwRo8wu7YQQDATY/NkiCqefIuMvhRARJcsWDQCNVZW89sffsPb9t80uRfSBpMxsvnTDLdzw538yde7llG9Yy3/v/AHP3P1Dti9fEm4xE5Gx4eMFvPHQA5RvXGd2KUKIE5h0R/YTGz9eAMCombPMLUT0qZjEJE6+4itMvvBS1i14l+Wvz2f+/T8nOTuXU758PUMnTjG7xOOK1hqlFGNOOY3Y5JTwmqBCCGEGaQnrB7TWbPj4A/JGjyM+Nd3scoQJHK4oSs65gK89+HfOvfUH2BxOAj4vAJ72dtxtrSZXOPDt3baZp26/labqKpTFQsH4YrNLEkKc4KQlrB+o3LaFxsq9TLnoMrNLESazWK2MOvlUCqefAqHxmiveeJllr73E1x76u4wXPEZbPlvEm3/+PTFJSfhD4VZEhs/no7y8HLfbbXYpQvQpl8tFbm4udrv9iI+RENYPbPj4A2x2ByNOmmF2KaKfUEpBaMD40EknYXM6wwFs1duvkzNqDGn5BSZWODBorfn85f+x6L9PkjWikIu+/1OiExLNLuu4Vl5eTlxcHAUFBXLRgzhhaK2pq6ujvLycwYMHH/FxEsJMFvD72LT4Y4ZOOglndLTZ5Yh+KL1gSHjuKk97Gx//90m8He2k5hcwaHwxBUUl5BaOweZwmFxp/xLw+3jvHw+zbsG7jJx+Cmff9F35jPqA2+2WACZOOEopUlJSqKmpOarjJISZbOeqFbhbmmUWdXFEnNExfP1P/2D9h++xc9UyVr31Kstfewmb3UHu6LEUFJUwaHwxKbn5J/QfQXdrK6/8/peUrV/D1EvmMf2yq07oz6OvyWctTkTH8nsvIcxkGxd+QFR8AoNkkLA4QlFx8Uw6/2ImnX8xPrebso1rKV29gtLVK/nwX/8AYM53b2fktJm421rRwSBRcfEmV913GioreOnXP6O5popzvnWbfMERQvRbEsJMpLVGoxk9czZWm/ynEEfP7nIxpHgyQ4qNtQ6ba6opXbOCvDHjAdjw0fss+Nc/+MbDTxCbnEJ7cxPO6Jjj+vdtx/LP6Wht4dKf/oLcUWPNLkf0sbq6Ok4/3Vh5pLKyEqvVSlpaGgCff/45jkN0SS9btox//etfPPTQQ4d8jenTp7N48eLeK1qcsGTG/H5g39xFQvS2uvLdlK5eycTzLgTg1T/8mtLVK8gfO55B40soKCohMSPT5Cp7R3tzU3ix9PamRlmX0yQbN25k1KhRFNzxesRfq/TX5x1y+z333ENsbCzf//73w8/5/X5sx/GXkIMJBAJYrVazyzju7fv978q0GfOVUmcrpTYrpbYppe7oYfvVSqk1odtipVRRJOvpb9qbGgEZPyEiJyU3PxzAAMbMOp3C6adQXbqD9x97mMdu/TqP3XoD7z32CNuWLcEbWmB8oFn1zhs8/t1v0Fi5F6WUBDDRzbXXXsttt93G7Nmzuf322/n888+ZPn06xcXFTJ8+nc2bNwPw4YcfMmfOHMAIcNdffz2zZs1iyJAh3VrHYmNjw/vPmjWLSy+9lMLCQq6++mr2NWy88cYbFBYWMmPGDG699dbwebsqLS1l5syZlJSUUFJS0q117f7772fcuHEUFRVxxx3Gn89t27ZxxhlnUFRURElJCdu3b+9WM8Att9zCE088AUBBQQH33nsvM2bM4Pnnn+fvf/87kydPpqioiEsuuYT2duP/96qqKubOnUtRURFFRUUsXryYO++8kwcffDB83p/85CeHbSEURy9iXweUUlbgL8CXgHJgqVLqFa31hi677QRO1Vo3KKXOAR4FTopUTf1JU3UVj916A2fd9B1ZtFv0mX1dl1prGvZWULp6BbvWrGD9R++x+p3XsVitTDhrDrOvuQEYOK20gydMpLFyD3GpqWaXIvqpLVu28N5772G1WmlubmbhwoXYbDbee+89fvzjH/PCCy8ccMymTZtYsGABLS0tjBw5kptuuumAOaBWrlzJ+vXryc7O5uSTT+aTTz5h0qRJfOMb32DhwoUMHjyYefPm9VhTeno67777Li6Xi61btzJv3jyWLVvGm2++yfz581myZAnR0dHU19cDcPXVV3PHHXcwd+5c3G43wWCQsrKyQ75vl8vFokWLAKOr9oYbjP+3f/rTn/LYY4/x7W9/m1tvvZVTTz2Vl156iUAgQGtrK9nZ2Vx88cV85zvfIRgM8swzz/D5558f9ecuDi2SbbJTgG1a6x0ASqlngAuBcAjTWnftVP8MyI1gPf2K3elk2qXzZNkUYQqlFMnZOSRn51Byzvn4fT4qNm+kdM0KUnLyAGM6jMe/901mXXODMXlsP9Pe3MTqd95g6sVXkJCewayv3mB2SaIfu+yyy8LdcU1NTVxzzTVs3boVpRQ+n6/HY8477zycTidOp5P09HSqqqrIze3+Z2rKlCnh5yZMmEBpaSmxsbEMGTIkPF/UvHnzePTRRw84v8/n45ZbbmHVqlVYrVa2bNkCwHvvvcd1111HdGjaouTkZFpaWtizZw9z584FjHB1JK644orw/XXr1vHTn/6UxsZGWltbOeusswD44IMP+Ne//gWA1WolISGBhIQEUlJSWLlyJVVVVRQXF5OSknJErymOXCRDWA7QNaKXc+hWrq8Bb/a0QSl1I3AjQH5+fm/VZ6rohESmXdrztyMh+prNbid/7Hjyx44PP+ft6GDQuAkkpGUAULpmJR/96x/huclyRo3B7nCaUm9d+W5e+s3PaGtoYNiUaTJxrTismJiY8P0777yT2bNn89JLL1FaWsqsWbN6PMbp7Pz9tlqt+P3+I9rnSMda/+EPfyAjI4PVq1cTDAbDwaqnFuiDndNmsxEMBsOP91+poOv7vvbaa5k/fz5FRUU88cQTfPjhh4es7+tf/zpPPPEElZWVXH/99Uf0nsTRiWQI66kPo8ffIqXUbIwQ1uOU8VrrRzG6Kpk0adLAupKgB3V7yqgr383QiVOw2o58eQMh+lJcSirn3PJ/4cdWq5XohERWvf0ay1+fj83uIGfUGAqKSigYX0xK3qA+6brctWYVr/7hV1jtdi6/51cSwPqpww2aN1NTUxM5OTkA4fFTvamwsJAdO3ZQWlpKQUEBzz777EHryM3NxWKx8OSTTxIIBAA488wzuffee7nqqqvC3ZHJycnk5uYyf/58LrroIjweD4FAgEGDBrFhwwY8Hg9ut5v333+fGTN6Xn2lpaWFrKwsfD4fTz/9dPgzOP3003nkkUf47ne/SyAQoK2tjfj4eObOnctdd92Fz+fjP//5T69/TiKyIawcyOvyOBeo2H8npdR44B/AOVrrugjW02+sfucN1rz/Ft/821MSwsSAkTdmPHljxuNzuynfuM6Ym2zNSj566jE+AmKTUxg0vpgzvnZzxGamX/P+W7z3j4dJyclj7u13E58mC96Lo/fDH/6Qa665ht///vecdlrvzyMXFRXFww8/zNlnn01qaipTpkzpcb+bb76ZSy65hOeff57Zs2eHW63OPvtsVq1axaRJk3A4HJx77rn88pe/5KmnnuIb3/gGd911F3a7neeff54hQ4Zw+eWXM378eIYPH05x8cHnnPz5z3/OSSedxKBBgxg3bhwtLS0APPjgg9x444089thjWK1WHnnkEaZNm4bD4WD27NkkJibKlZURErEpKpRSNmALcDqwB1gKXKW1Xt9ln3zgA+Cr+40PO6iBPkVFwO/nbzddQ96osZx/24/MLkeIL6y5tprS1SvZtXoFTTXVfPlXfwDgk+eexhkdzaQ5c7/wa+hgkIX/eYJlr75IwYSJzPnO7bLMVz/V0yX6J6LW1lZiY2PRWvOtb32L4cOH873vfc/sso5KMBikpKSE559/nuHDh5tdzoBwtFNURKwlTGvtV0rdArwNWIF/aq3XK6W+Gdr+V+AuIAV4ONSN4T9YoceL0tUr6GhuYpTM4i2OE/Gp6Yw//SzGn35Wt3ErNbt24IqNA4zxLO/87SEyBg8z5ibLzDri8/vcbt7482/ZtvQzis48j9OuvRGLfCsX/dzf//53nnzySbxeL8XFxXzjG98wu6SjsmHDBubMmcPcuXMlgEWQTNbax17742/YtW413/zrk9IVKY57+wYYtzc38fSPb6O5pgqAxIys8AD/vDHjD9mq9fZfH2Tdh+8x+6tfp/icCwbElBknMmkJEyeyftMSJg7kaW9j+7IljD3tSxLAxAlhX2CKjk/g63/6B42VFeGxZBsWfsDqd9/AYrWSNbyQgvHFjD7ltAPGeZ18+ZcZftL08NJMQghxvJAQ1oe2LPkEv8/L6JnSFSlOPEopkrJySMrKofjs8wn4fVRs2RRafHwFnzz3b3IKRxOflk7Z+jWsevt1zvvOD4lNTiE2WeYnEkIcfySE9aGNCxeQlJVN5rARZpcihOmsNjt5o8eRN3ocM+ddE15cHKBswzpaGxvwtLcRFRdvcqVCCBEZEsL6SHNtNWUb1jL9sqtlTIsQPYiOTwjfn37ZVUy/7CoTqxFCiMiL6ALeolNbYwPpBUMZNXO22aUIIcRxa9asWbz99tvdnvvjH//IzTfffMhj9l3wde6559LY2HjAPvfccw+//e1vD/na8+fPZ8OGzuWR77rrLt57772jqF6caKQlrI9kDRvJV37z4OF3FEKI48E9CYff5wu/RtMBT82bN49nnnkmvC4iwDPPPMMDDzxwRKd84403jrmc+fPnM2fOHEaPHg3Avffee8znMksgEJCJWfuQtIT1gfbmJrwd7WaXIYQQx71LL72U1157DY/HA0BpaSkVFRXMmDGDm266iUmTJjFmzBjuvvvuHo8vKCigtrYWgPvuu4+RI0dyxhlnsHnz5vA+f//735k8eTJFRUVccskltLe3s3jxYl555RV+8IMfMGHCBLZv3861117L//73PwDef/99iouLGTduHNdff324voKCAu6++25KSkoYN24cmzZtOqCm0tJSZs6cSUlJCSUlJSxe3Dm3+f3338+4ceMoKirijjvuAGDbtm2cccYZFBUVUVJSwvbt2/nwww+ZM2dO+LhbbrklvGRTQUEB9957LzNmzOD555/v8f0BVFVVMXfuXIqKiigqKmLx4sXceeedPPhgZwPDT37yEx566KGj+492ApMQ1geWvPgsf//W9fi9XrNLEUKI41pKSgpTpkzhrbfeAoxWsCuuuAKlFPfddx/Lli1jzZo1fPTRR6xZs+ag51m+fDnPPPMMK1eu5MUXX2Tp0qXhbRdffDFLly5l9erVjBo1iscee4zp06dzwQUX8MADD7Bq1SqGDh0a3t/tdnPttdfy7LPPsnbtWvx+P4888kh4e2pqKitWrOCmm27qscszPT2dd999lxUrVvDss89y6623AvDmm28yf/58lixZwurVq/nhD38IwNVXX823vvUtVq9ezeLFi8nKOvzkyC6Xi0WLFnHllVf2+P4Abr31Vk499VRWr17NihUrGDNmDF/72td48sknAWOG/WeeeYarr776sK8nDBLC+sCoGbOYMe+aiK2nJ4QQotO+LkkwQti8efMAeO655ygpKaG4uJj169d3G7+1v48//pi5c+cSHR1NfHw8F1xwQXjbunXrmDlzJuPGjePpp59m/fr1Bz0PwObNmxk8eDAjRhhXxl9zzTUsXLgwvP3iiy8GYOLEiZSWlh5wvM/n44YbbmDcuHFcdtll4brfe+89rrvuOqJDkx0nJyfT0tLCnj17mDvXWC7M5XKFtx/KFVdccdj398EHH3DTTTcBYLVaSUhIoKCggJSUFFauXMk777xDcXExKSkypcyRkjFhfSBz2AiZlkIIIfrIRRddxG233caKFSvo6OigpKSEnTt38tvf/palS5eSlJTEtddei9vtPuR5DnYl+7XXXsv8+fMpKiriiSee4MMPPzzkeQ63Mo3T6QSMYOP3+w/Y/oc//IGMjAxWr15NMBjE5XKFz7t/jQd7LZvNRjAYDD/e/73vWzwcjv79ff3rX+eJJ56gsrKS66+//pD7iu4khEXYugXvkpo3SEKYEOLE0sOg+b4SGxvLrFmzuP7668OtYM3NzcTExJCQkEBVVRVvvvkms2bNOug5TjnlFK699lruuOMO/H4/r776anj9x5aWFrKysvD5fDz99NPk5OQAEBcXR0tLywHnKiwspLS0lG3btjFs2DCeeuopTj311CN+P01NTeTm5mKxWHjyyScJBAIAnHnmmdx7771cddVVREdHU19fT3JyMrm5ucyfP5+LLroIj8dDIBBg0KBBbNiwAY/Hg9vt5v3332fGjBk9vt7B3t/pp5/OI488wne/+10CgQBtbW3Ex8czd+5c7rrrLnw+H//5z3+O+H0J6Y6MKG9HO+//86+s+/Bds0sRQogTyrx581i9ejVXXnklAEVFRRQXFzNmzBiuv/56Tj755EMeX1JSwhVXXMGECRO45JJLmDlzZnjbz3/+c0466SS+9KUvUVhYGH7+yiuv5IEHHqC4uJjt27eHn3e5XDz++ONcdtlljBs3DovFwje/+c0jfi8333wzTz75JFOnTmXLli3hVquzzz6bCy64gEmTJjFhwoTweLKnnnqKhx56iPHjxzN9+nQqKyvJy8vj8ssvZ/z48Vx99dUUFxcf9PUO9v4efPBBFixYwLhx45g4cWK4m9LhcDB79mwuv/xyubLyKMkC3hG07sP3ePuRP3LlvQ+QM1IWtBVCHP9kAe8TTzAYpKSkhOeff57hw4ebXY6pjnYBb2kJi6CNHy8gMSOL7BGFh99ZCCGEGGA2bNjAsGHDOP3000/4AHYsZExYhLTU1bJ7/RqmXXKlLFMkhBDiuDR69Gh27NhhdhkDlrSERcjGRR+C1rJMkRBCCCF6JCEsArTWbPx4AVkjCknKzDa7HCGEEEL0QxLCIqBm105qy3YxeuZpZpcihBBCiH5KQlgEbFj4ARarjZHTep6DRQghhBBCQlgERCckMnb2GUTFxZtdihBCnFDq6uqYMGECEyZMIDMzk5ycnPBj72HW7122bFl4XcZDmT59em+V+4WUlpYyduzYA56vqKjg0ksvNaEicbTk6sgImHKh/PILIYQZUlJSWLVqFQD33HMPsbGxfP/73w9v9/v92Gw9/+mbNGkSkyb1OJ1TN4sXL+6VWrs6VF1HKzs7m//973+9cq6Bojc/v74kLWG9rLZsF8FgwOwyhBCiX7juresOuD2zyVhcu8Pf0eP2+dvmA9Dgbjhg27G49tprue2225g9eza33347n3/+OdOnT6e4uJjp06ezefNmAD788EPmzJkDGAHu+uuvZ9asWQwZMoSHHnoofL7Y2Njw/rNmzeLSSy+lsLCQq6++Orx24xtvvEFhYSEzZszg1ltvDZ+3qyeeeILLLruM888/nzPPPJO2tjauv/56Jk+eTHFxMS+//DJgtHjNnDmTkpISSkpKDhsCu7aQPfHEE1x00UWcf/75DB48mD//+c/8/ve/p7i4mKlTp1L//+3de1hVVf748fcCUzCMvOV4qZHMEcNzDndBRUHkMjlh3sJLJfHTSjNRv+VoSVoN80zpmNqUPfoNL33HwFLJ6VFjTt7TBLmqeEGUbpqiDgghyWX//gD2QHJQEDqin9fz+MTZe+21P2tt049rrbPX5csArFq1Ci8vL0wmE6NHj6a4uBiAnJwcfHx88PLy4vXXX9fbDrBo0SK8vLwwGo0sWLCgzlimTp2Kp6cnLi4utcokJyczYMAATCYT3t7eFBYWUl5ezssvv4zBYMBoNPLee+8B0LNnTy5evAhUjlZWbze1cOFCnnvuOYKDg3nmmWfq7ad33nkHg8GAyWRi7ty55OTk4O7urp/Pzs7Gw8Oj3n5tDi0vbbyNXSu5yj9fm41p2B/xf2aytcMRQghR5eTJk5jNZmxtbbly5Qp79uyhVatWmM1mXn31VTZu3HjdNcePH2fnzp0UFhbSp08fpk6dyj333FOrTFpaGkePHqVbt24MHDiQr7/+Gk9PT55//nn27NmDk5OTvn9lXQ4cOEBmZiYdOnTg1VdfZejQocTGxpKfn4+3tzfDhg3jgQce4N///jd2dnZkZ2czfvx4GrJzzJEjR0hLS6OkpIRHHnmEt99+m7S0NGbNmsW6deuYOXMmo0aNYsqUKQDMnz+fjz76iJdeeomoqCiioqIYP348H374oV5nYmIi2dnZJCUloWkaYWFh7Nmzh8GDB9e6d0xMDB06dKC8vJzAwEAyMzNxdnYmPDyc+Ph4vLy8uHLlCvb29qxcuZIzZ86QlpZGq1at9ASxPikpKezbtw97e3uKi4vr7Kdt27aRkJDAwYMHa+2x6ejoSHp6Oq6urqxevZqIiIib7tOmIklYE7Jt1YrQqbPo0L2HtUMRQojbwurQ1RbP2beyr/d8e7v29Z5viLFjx+r7GhYUFDBp0iSys7NRSlFaWlrnNcOHD6dNmza0adOGBx54gPPnz9OjR+0/3729vfVjrq6u5Obm4uDgwMMPP4yTkxNQuY/lypUr67xHUFAQHTp0ACoTmy1btuh7QJaUlPDdd9/RrVs3pk+fTnp6Ora2tpw8ebJBbQ8ICKBdu3a0a9cOR0dHHn/8cQAMBgOZmZlAZaI2f/588vPzKSoqIiQkBKhMEhMSEgCYMGGCPrWbmJhIYmKivgdlUVER2dnZ1yVhGzZsYOXKlZSVlXHu3DmysrJQStG1a1e8vLwAuO++yvXTZrOZF154QZ9WrO6X+oSFhWFvbw9AaWlpnf1kNpt59tlnadu2ba16J0+ezOrVq1myZAnx8fEkJSU1qF+bgiRhTci21T3yjUghhLgNVW96DRAdHU1AQACbN28mNzdXn976tTZt2ug/29raUlZWdlNlGrInc824NE1j48aN9OnTp1aZhQsX0qVLFzIyMqioqMDOzu6m6/91jDY2NvpnGxsbvU0REREkJCRgMplYs2YNu3btqrdOTdOYN28ezz//vMUyZ86cYfHixSQnJ9O+fXsiIiIoKSlB07Q6d5KxdLxVq1ZUVFQAlYlpTTX77913362znyzVO3r0aN544w2GDh2Kh4cHHTt2rLfNzUHWhDWRosuX+GZjHMUF+dYORQghRD0KCgro3r07ULlmqqk5Oztz+vRpcnNzAYiPj7+p60JCQnjvvff0JC4tLU2Pt2vXrtjY2PDxxx9TXt70644LCwvp2rUrpaWl/POf/9SP+/j46FO1cXFxtWKNjY2lqKgIgB9//JELFy7UqvPKlSvce++9ODo6cv78ebZt2wZU9s/Zs2dJTk7W711WVkZwcDAffvihnhhWT0f27NmTlJQUgDqnjatZ6qfg4GBiY2P1dW7V9drZ2RESEsLUqVN59tnGrTe8VZKENZFjX+/m6w3/R8nPP1s7FCGEEPWYM2cO8+bNY+DAgc2S0Njb2/PBBx8QGhrKoEGD6NKlC46Ojje8Ljo6mtLSUoxGI/369SM6OhqAadOmsXbtWnx8fDh58mSt0Z+m8tZbb9G/f3+CgoJwdnbWjy9dupQlS5bg7e3NuXPn9HYEBwczYcIEfH19MRgMjBkzhsLCwlp1mkwm3NzccHFxITIykoEDBwLQunVr4uPjeemllzCZTAQFBVFSUsLkyZN56KGHMBqNmEwm1q9fD8CCBQuIiorCz89Pn1Kui6V+Cg0NJSwsDE9PT1xdXfXpXoCJEyeilCI4OLhpOrKBVEOGTW8Hnp6eWkMWJP5W1r0yHdvWrZkYs8TaoQghhNUcO3aMvn37WjsMqysqKsLBwQFN03jxxRfp3bs3s2bNsnZYDVZcXIy9vT1KKeLi4vjkk0/0b23eCRYvXkxBQQFvvfVWk9RX1+9/pVSKpml1vvtE1oQ1gbxvz5D3XS5Dn7U8Ny6EEOLusWrVKtauXcu1a9dwc3Ord+3U7SwlJYXp06ejaRr3338/sbGx1g6pyYwcOZKcnBx27NhhtRgkCWsCWXt3YmNrS58Bg29cWAghxB1v1qxZLXLk69f8/PzIyMiwdhjNYvPmzdYOQdaE3aqKinKO79tFT1cP2t534zl/IYQQQgiQJOyWfX/kMEX/ucyjfkOtHYoQQgghWhBJwm5R1t4dtLZvy8MeXtYORQghhBAtiCRht6C0pITsg/v5g88g7mnd5sYXCCGEEEJUkSTsFvxS/DO9PPvj4h9o7VCEEEIAly5dwtXVFVdXV373u9/RvXt3/fO1a9fqvfbQoUPMmDHjhvcYMGBAU4XL+PHjMRqNvPvuuxbLRERE8NlnnzWq/scee4z8/PxGRieam3w78hY4dOjI8BmvWDsMIYQQVTp27Eh6ejpQud2Pg4ODvt8hQFlZmb434a95enri6Vnn65xq2b9/f5PE+tNPP7F//36+/fbbJqmvLlu3bm22um9H5eXl9b7Q9XYjI2GNdLXwChe/y7V2GEIIcVv79ulnrvt1uepN6BVXr9Z5Pn9T5asDyv7zn+vONUZERASzZ88mICCAP//5zyQlJTFgwADc3NwYMGAAJ06cAGDXrl386U9/AioTuMjISPz9/Xn44YdZvny5Xp+Dg4Ne3t/fnzFjxuDs7MzEiRP1LYe2bt2Ks7MzgwYNYsaMGXq9NQUHB3PhwgVcXV3Zu3cvq1atwsvLC5PJxOjRo/VtdmqKjo4mIiKCiooKFi1ahJeXF0ajkQULFtTZ9p49e3Lx4kVyc3NxdnZm8uTJ9OvXj4kTJ2I2mxk4cCC9e/fWN6+21DfFxcU8+eSTGI1GwsPD6d+/P9UvTk9MTMTX1xd3d3fGjh2rb2VUk6W2nT9/npEjR2IymTCZTHqCu27dOv3N+U8//bT+HGuOCNZ8DgEBAUyYMAGDwQDAE088gYeHBy4uLrU2T9++fTvu7u6YTCYCAwOpqKigd+/e5OXlAVBRUcEjjzzCxYsX6+zPpiZJWCMd3f0Va1+ZTv5P56wdihBCiBs4efIkZrOZv//97zg7O7Nnzx7S0tJ48803efXVV+u85vjx43z55ZckJSXxxhtvUFpael2ZtLQ0li5dSlZWFqdPn+brr7+mpKSE559/nm3btrFv3z79L/hf27JlC7169SI9PR0/Pz9GjRpFcnIyGRkZ9O3bl48++qhW+Tlz5nDhwgVWr16N2WwmOzubpKQk0tPTSUlJYc+ePfX2walTp4iKiiIzM5Pjx4+zfv169u3bx+LFi/nrX/8KYLFvPvjgA9q3b09mZibR0dH6Xo4XL17kL3/5C2azmdTUVDw9PVmy5PqdYyy1bcaMGQwZMoSMjAxSU1NxcXHh6NGjxMTEsGPHDjIyMli2bFm97YLK5DEmJoasrCwAYmNjSUlJ4dChQyxfvpxLly6Rl5fHlClT2LhxIxkZGXz66afY2Njw1FNP6ftlms1mTCYTnTp1uuE9m4JMRzbSo34B3Ot4P/f/rqu1QxFCiNvW7z9eZ/Gcjb19vedbtW9f7/mGGDt2rD5NVVBQwKRJk8jOzkYpVWdyBTB8+HDatGlDmzZteOCBBzh//jw9evSoVcbb21s/5urqSm5uLg4ODjz88MM4OTkBleu+ao7GWHLkyBHmz59Pfn4+RUVFhISE6Oeq93asricxMZHExETc3NyAym2SsrOzGTzY8kvDnZyc9JEiFxcXAgMDUUphMBj0zcYt9c2+ffuIiooCoF+/fhiNRgC++eYbsrKy9H0hr127hq+v7023bceOHaxbV/mMbW1tcXR0ZN26dYwZM0ZPhDp06HDDvvP29tb7G2D58uX6y1i///57srOzycvLY/DgwXq56nojIyMZMWIEM2fOJDY29jfdzFuSsEZq63g/ff0CrB2GEEKIm1Bz0+vo6GgCAgLYvHkzubm5+Pv713lNmzb//da7ra0tZWVlN1WmsXsyR0REkJCQgMlkYs2aNezatUs/5+XlRUpKCpcvX6ZDhw5omsa8efMatB1SzVhtbGz0zzY2NnrbLPWNpTZpmkZQUBCffPJJo9tWV51KqeuOt2rVioqKCr1MzS9a1Hy+u3btwmw2c+DAAdq2bYu/vz8lJSUW633wwQfp0qULO3bs4ODBg/qo2G9BpiMb4fDORI7u/sraYQghhGiEgoICunfvDsCaNWuavH5nZ2dOnz6tjy7Fx8ff1HWFhYV07dqV0tLS6xKB0NBQ5s6dy/DhwyksLCQkJITY2Fh9/dWPP/7IhQsXbjl2S30zaNAgNmzYAEBWVhaHDx8GwMfHh6+//ppTp04BlWvHTp48edNtCwwMZMWKFUDlovorV64QGBjIhg0buHTpEgCXL18GKte3VU+Dfv755xZHMAsKCmjfvj1t27bl+PHjfPPNNwD4+vqye/duzpw5U6tegMmTJ/PUU0/x5JNP/qYL+yUJayCtooL9n67nxIG91g5FCCFEI8yZM4d58+YxcOBAysvLm7x+e3t7PvjgA0JDQxk0aBBdunTB0fHG29pVTzkGBQXh7Ox83fmxY8cyZcoUwsLC8PPzY8KECfj6+mIwGBgzZgyFhYW3HLulvpk2bRp5eXkYjUbefvttjEYjjo6OdO7cmTVr1uiv2vDx8eH48eM33bZly5axc+dODAYDHh4eHD16FBcXF1577TWGDBmCyWRi9uzZAEyZMoXdu3fj7e3NwYMHa41+1RQaGkpZWRlGo5Ho6Gh8fHwA6Ny5MytXrmTUqFGYTCbCw8P1a8LCwigqKvpNpyIBVGOHTa3F09NTq/5GhjV8dySTT996leEzXsF54BCrxSGEELejY8eO0bdvX2uHYXVFRUU4ODigaRovvvgivXv3btEbepeXl1NaWoqdnR05OTkEBgZy8uRJWrdube3QmsShQ4eYNWsWe/fe2gBLXb//lVIpmqbV+e4TWRPWQJXbFNnTy8vH2qEIIYS4Ta1atYq1a9dy7do13NzcGrR263ZUXFxMQEAApaWlaJrGihUr7pgE7G9/+xsrVqz4TdeCVZORsAYo/aWED59/mt79BxI6daZVYhBCiNuZjISJu1lDR8JkTVgD5Bw6yLWrV3nUb6i1QxFCCCFECydJWANk7d2JQ8dOPPhoP2uHIoQQQogWTpKwm/Rz/n/IzUil7yB/lI10mxBCCCFujWQTN+nE/j1oFRU8Ki9oFUIIIUQTkCTsJjl26YpxWCidHvy9tUMRQghhgb+/P19++WWtY0uXLmXatGn1XlP9ha/HHnuM/Pz868osXLiQxYsX13vvhIQEfe9CgNdffx2z2dyA6JtHbm4u/fpdv4zm7NmzjBkzxgoRiWqShN2kXh7eBE2Zbu0whBBC1GP8+PHExcXVOhYXF8f48eNv6vqtW7dy//33N+rev07C3nzzTYYNG9aouiypa+ukxurWrRufffZZk9XXEjRl/zUFScJuwtmTxyguyLd2GEII0eJs/nvqDX+lJX5Xq/yx/ecAuFp07bqyNzJmzBi++OILfvnlF6ByFOjs2bMMGjSIqVOn4unpiYuLCwsWLKjz+p49e3Lx4kUAYmJi6NOnD8OGDePEiRN6mVWrVuHl5YXJZGL06NEUFxezf/9+tmzZwiuvvIKrqys5OTlEREToSc5XX32Fm5sbBoOByMhIPb6ePXuyYMEC3N3dMRgMdb5tfs2aNYwdO5bHH3+c4OBgfv75ZyIjI/Hy8sLNzY3PP/9cb6ufnx/u7u64u7uzf//+evuq5gjZmjVreOKJJ3j88cdxcnLiH//4B0uWLMHNzQ0fHx99i5+62g6Qk5ODj48PXl5evP766zg4OOj3WbRoEV5eXhiNRov9bunZJCcnM2DAAEwmE97e3hQWFlJeXs7LL7+MwWDAaDTy3nvvXffsDh06pO97uXDhQp577jmCg4N55pln6u2nd955B4PBgMlkYu7cueTk5ODu7q6fz87OxsPDo95+bQhJwm5Aq6jgi2XvsH3FUmuHIoQQ4gY6duyIt7c327dvBypHwcLDw1FKERMTw6FDh8jMzGT37t1kZmZarCclJYW4uDjS0tLYtGkTycnJ+rlRo0aRnJxMRkYGffv25aOPPmLAgAGEhYWxaNEi0tPT6dWrl16+pKSEiIgI4uPjOXz4MGVlZfp+iQCdOnUiNTWVqVOnWpzyPHDgAGvXrmXHjh3ExMQwdOhQkpOT2blzJ6+88go///wzDzzwAP/+979JTU0lPj6eGTNmNKjvjhw5wvr160lKSuK1116jbdu2pKWl4evry7p16yy2HSAqKoqoqCiSk5Pp1q2bXmdiYiLZ2dkkJSWRnp5OSkoKe/bsue7edT2ba9euER4ezrJly8jIyMBsNmNvb8/KlSs5c+YMaWlpZGZmMnHixBu2LSUlhc8//5z169db7Kdt27aRkJDAwYMHycjIYM6cOfTq1QtHR0fS09MBWL16NREREQ3q1/rIG/NvQNnYMGruQspvsyFMIYRoCUb+j/uNC1kob+/QusHXw3+nJEeMGEFcXByxsbEAbNiwgZUrV1JWVsa5c+fIysrCaDTWWcfevXsZOXIkbdu2BSr3Fqx25MgR5s+fT35+PkVFRYSEhNQbz4kTJ3BycuIPf/gDAJMmTeL9999n5syZQGViA+Dh4cGmTZvqrCMoKIgOHToAlYnNli1b9IStpKSE7777jm7dujF9+nTS09OxtbWtcyPt+gQEBNCuXTvatWuHo6Mjjz/+OAAGg0FPWC21/cCBAyQkJAAwYcIEXn75ZT3WxMRE3NzcgMrtnLKzsxk8eHCte9f1bJRSdO3aFS8vLwDuu+8+AMxmMy+88AKtWlWmMNX9Up+wsDDs7e0BKC0trbOfzGYzzz77rP7Mq+udPHkyq1evZsmSJcTHx5OUlNSgfq2PJGE3QRbjCyFEy/HEE08we/ZsUlNTuXr1Ku7u7pw5c4bFixeTnJxM+/btiYiIoKSkpN56lFJ1Ho+IiCAhIQGTycSaNWvYtWtXvfXcaGeaNm3aAGBra2txzVLNzao1TWPjxo306dOnVpmFCxfSpUsXMjIyqKiowM7Ort77WooDwMbGRv9sY2Ojx9WYts+bN6/ebZssPRtN0+p8BpaOt2rVioqKCoDrnm3N/nv33Xfr7CdL9Y4ePZo33niDoUOH4uHhQceOHettc0PIdGQ9Sq/9wvYPlnIh97S1QxFCCHGTHBwc8Pf3JzIyUl+Qf+XKFe69914cHR05f/4827Ztq7eOwYMHs3nzZq5evUphYSH/+te/9HOFhYV07dqV0tLSWvsNtmvXjsLCwuvqcnZ2Jjc3l1OnTgHw8ccfM2TIkEa3LyQkhPfee09P7tLS0gAoKCiga9eu2NjY8PHHH1NeXt7oe1hiqe0+Pj5s3LgRoNYXI0JCQoiNjaWoqAiAH3/8kQsXLtSq09KzcXZ25uzZs/pUcGFhIWVlZQQHB/Phhx/qiWH1erWePXuSkpICoMdSF0v9FBwcTGxsrL7OrbpeOzs7QkJCmDp1Ks8++2xjus0iScLqcToliaO7zVy9csXaoQghhGiA8ePHk5GRwbhx4wAwmUy4ubnh4uJCZGQkAwcOrPd6d3d3wsPDcXV1ZfTo0fj5+enn3nrrLfr3709QUBDOzs768XHjxrFo0SLc3NzIycnRj9vZ2bF69WrGjh2LwWDAxsaGF154odFti46OprS0FKPRSL9+/YiOjgZg2rRprF27Fh8fH06ePFlr9KepWGr70qVLWbJkCd7e3pw7dw5HR0egMrGZMGECvr6+GAwGxowZc12iaunZtG7dmvj4eF566SVMJhNBQUGUlJQwefJkHnroIYxGIyaTifXr1wOwYMECoqKi8PPzw9bW1mIbLPVTaGgoYWFheHp64urqWmt93sSJE1FKERwc3DQdWUU28K7H5nfe5MLpU0z5YDU2NpYfqBBCiEqygffdqbi4GHt7e5RSxMXF8cknn+jf2rwTLF68mIKCAt566616yzV0A29ZE2ZB8ZUCctNTcH9shCRgQgghRD1SUlKYPn06mqZx//3361+GuBOMHDmSnJwcduzY0eR1SxJmwYn9e6goL+fRwUOtHYoQQghxW/Pz8yMjI8PaYTSLzZs3N1vdsibMgqy9O+n8eyc6P9TT2qEIIYQQ4g7UrEmYUipUKXVCKXVKKTW3jvNKKbW86nymUqrhL4RpBpfP/sBPp07KZt1CCCGEaDbNloQppWyB94E/Ao8C45VSj/6q2B+B3lW/ngNWcBs4tncnStngPLDxXyEWQgghhKhPc46EeQOnNE07rWnaNSAOGPGrMiOAdVqlb4D7lVJdmzGmG9IqKsjau4uHDCYcOjTdC9mEEEIIIWpqziSsO/B9jc8/VB1raJnfVHlZGcbAENxCH7dmGEIIIRrB39+fL7/8staxpUuXMm3atHqvqX710WOPPUZ+fv51ZRYuXGhxX8dqCQkJZGVl6Z9ff/11zGZzA6K3bPz48RiNRt59912LZWpuGN5Qltotmldzfjuyrv0efv1Sspspg1LqOSqnK3nooYduPbJ6tGrdmv4jn2zWewghhGge1ftG1tzPMS4ujkWLFt3U9Vu3bm30vRMSEvjTn/7Eo49Wrrx58803G11XTT/99BP79+/n22+/bZL66nIr7W6JysvL632h62+lOUfCfgAerPG5B3C2EWXQNG2lpmmemqZ5du7cuckDFUII0Tzi35h7w1/J/9pUq/yRXZWjR8VXCq4reyNjxozhiy++4JdffgEgNzeXs2fPMmjQIKZOnYqnpycuLi4sWLCgzut79uzJxYsXAYiJiaFPnz4MGzaMEydO6GVWrVqFl5cXJpOJ0aNHU1xczP79+9myZQuvvPIKrq6u5OTk1BqZ+uqrr3Bzc8NgMBAZGanH17NnTxYsWIC7uzsGg4Hjx49fF1NwcDAXLlzA1dWVvXv31nn/X4uOjiYiIoKKigoWLVqEl5cXRqPxhu3Ozc3F2dmZyZMn069fPyZOnIjZbGbgwIH07t1b37w6KSmJAQMG4ObmxoABA/T+KS4u5sknn8RoNBIeHk7//v31UcbExER8fX1xd3dn7Nix+lZGNVlq2/nz5xk5ciQmkwmTycT+/fsBWLdunf7m/Keffhq4fkTQwcEBgF27dhEQEMCECRMwGAxA5T6jHh4euLi4sHLlSv2a7du34+7ujslkIjAwkIqKCnr37k1eXh4AFRUVPPLII/rvlcZqziQsGeitlHJSSrUGxgFbflVmC/BM1bckfYACTdPONWNMQggh7mAdO3bE29ub7du3A5WjYOHh4SiliImJ4dChQ2RmZrJ7924yMzMt1pOSkkJcXBxpaWls2rRJ378QYNSoUSQnJ5ORkUHfvn356KOPGDBgAGFhYSxatIj09HR69eqlly8pKSEiIoL4+HgOHz5MWVkZK1b893tonTp1IjU1lalTp9Y55bllyxZ69epFeno6fn5+dd6/pjlz5nDhwgVWr16N2WwmOzubpKQk0tPTSUlJYc+ePfX24alTp4iKiiIzM5Pjx4+zfv169u3bx+LFi/nrX/8KVO7ruGfPHtLS0njzzTd59dVXAfjggw9o3749mZmZREdH63s5Xrx4kb/85S+YzWZSU1Px9PRkyZIl193bUttmzJjBkCFDyMjIIDU1FRcXF44ePUpMTAw7duwgIyODZcuW1dsuqEweY2Ji9Gnj2NhYUlJSOHToEMuXL+fSpUvk5eUxZcoUNm7cSEZGBp9++ik2NjY89dRT+n6ZZrMZk8lEp06dbnjP+jTbdKSmaWVKqenAl4AtEKtp2lGl1AtV5z8EtgKPAaeAYqBpd8YUQghhVeEL/tbo8m3vc2zw9fDfKckRI0YQFxenv719w4YNrFy5krKyMs6dO0dWVhZGo7HOOvbu3cvIkSNp27YtAGFhYfq5I0eOMH/+fPLz8ykqKqo19VmXEydO4OTkxB/+8AcAJk2axPvvv8/MmTOBysQDwMPDg02bNlmq5qbuX723Y/WoTmJiIomJibi5uQFQVFREdnY2gwcPtli/k5OTPlLk4uJCYGAgSikMBgO5ublA5SbYkyZNIjs7G6UUpaWlAOzbt4+oqCgA+vXrp/fvN998Q1ZWlr4v5LVr1/D19b3ptu3YsYN169YBYGtri6OjI+vWrWPMmDF6ItShQ4cb9p23tzdOTk765+XLl+svY/3+++/Jzs4mLy+PwYMH6+Wq642MjGTEiBHMnDmT2NjYJtnMu1nfmK9p2lYqE62axz6s8bMGvNicMQghhLi7PPHEE8yePZvU1FSuXr2Ku7s7Z86cYfHixSQnJ9O+fXsiIiIoKSmptx6l6lq2XDndlZCQgMlkYs2aNezataveem60R3ObNm2AyuSirKys3rI3ur+XlxcpKSlcvnyZDh06oGka8+bN4/nnn79hvb+OB8DGxkb/bGNjo8cXHR1NQEAAmzdvJjc3F39//3rbqmkaQUFBfPLJJ41uW1111vWMWrVqRUVFhV7m2rVr+rmam5rv2rULs9nMgQMHaNu2Lf7+/pSUlFis98EHH6RLly7s2LGDgwcP6qNit0LemC+EEOKO4uDggL+/P5GRkYwfPx6AK1eucO+99+Lo6Mj58+fZtm1bvXUMHjyYzZs3c/XqVQoLC/nXv/6lnyssLKRr166UlpbW+ou4Xbt2FBYWXleXs7Mzubm5nDp1CoCPP/6YIUMa/x5KS/cHCA0NZe7cuQwfPpzCwkJCQkKIjY3V11/9+OOPXLhwodH3rlZQUED37pUvM1izZo1+fNCgQWzYsAGArKwsDh8+DICPjw9ff/213gfFxcWcPHnyptsWGBioT+GWl5dz5coVAgMD2bBhA5cuXQLg8uXLQOX6tupp0M8//1wfpaurDe3bt6dt27YcP36cb775BgBfX192797NmTNnatULMHnyZJ566imefPLJJlnYL0mYEEKIO8748ePJyMhg3LhxAJhMJtzc3HBxcSEyMlKfFrPE3d2d8PBwXF1dGT16NH5+fvq56im/oKAgnJ2d9ePjxo1j0aJFuLm5kZOTox+3s7Nj9erVjB07FoPBgI2NDS+88EKj22bp/tXGjh3LlClTCAsLw8/PjwkTJuDr64vBYGDMmDF1JooNNWfOHObNm8fAgQMpLy/Xj0+bNo28vDyMRiNvv/02RqMRR0dHOnfuzJo1a/RXbfj4+NT5JQRLbVu2bBk7d+7EYDDg4eHB0aNHcXFx4bXXXmPIkCGYTCZmz54NwJQpU9i9ezfe3t4cPHiw1uhXTaGhoZSVlWE0GomOjsbHxweAzp07s3LlSkaNGoXJZCI8PFy/JiwsjKKioiaZigRQNxomvd14enpq1d+0EEIIcXs5duwYffv2tXYYwkrKy8spLS3Fzs6OnJwcAgMDOXnyJK1bt7Z2aE3i0KFDzJo1i71799Z5vq7f/0qpFE3TPOsq36xrwoQQQghx9yguLiYgIIDS0lI0TWPFihV3TAL2t7/9jRUrVjTJWrBqkoQJIYQQokm0a9eOO3W2au7cucyde+N31TWErAkTQgjRpFraMhchmkJjft9LEiaEEKLJ2NnZcenSJUnExF1F0zQuXbqEnZ1dg66T6UghhBBNpkePHvzwww/69i5C3C3s7Ozo0aNHg66RJEwIIUSTueeee2q9kVwIYZlMRwohhBBCWIEkYUIIIYQQViBJmBBCCCGEFbS4N+YrpfKAb3+DW3UCLv4G9xHNQ55fyyfPsOWTZ9iyyfNrGr/XNK1zXSdaXBL2W1FKHbK0zYC4/cnza/nkGbZ88gxbNnl+zU+mI4UQQgghrECSMCGEEEIIK5AkzLKV1g5A3BJ5fi2fPMOWT55hyybPr5nJmjAhhBBCCCuQkTAhhBBCCCuQJEwIIYQQwgokCfsVpVSoUuqEUuqUUmquteMRDaOUelAptVMpdUwpdVQpFWXtmETDKaVslVJpSqkvrB2LaDil1P1Kqc+UUser/l/0tXZMomGUUrOq/gw9opT6RCllZ+2Y7kSShNWglLIF3gf+CDwKjFdKPWrdqEQDlQH/o2laX8AHeFGeYYsUBRyzdhCi0ZYB2zVNcwZMyLNsUZRS3YEZgKemaf0AW2CcdaO6M0kSVps3cErTtNOapl0D4oARVo5JNICmaec0TUut+rmQyj/8u1s3KtEQSqkewHDgf60di2g4pdR9wGDgIwBN065pmpZv1aBEY7QC7JVSrYC2wFkrx3NHkiSstu7A9zU+/4D8Bd5iKaV6Am7AQSuHIhpmKTAHqLByHKJxHgbygNVVU8r/q5S619pBiZunadqPwGLgO+AcUKBpWqJ1o7ozSRJWm6rjmLzDowVSSjkAG4GZmqZdsXY84uYopf4EXNA0LcXasYhGawW4Ays0TXMDfgZkfW0LopRqT+UskBPQDbhXKfWUdaO6M0kSVtsPwIM1PvdAhmBbHKXUPVQmYP/UNG2TteMRDTIQCFNK5VK5HGCoUur/rBuSaKAfgB80Tasegf6MyqRMtBzDgDOapuVpmlYKbAIGWDmmO5IkYbUlA72VUk5KqdZULkTcYuWYRAMopRSVa1GOaZq2xNrxiIbRNG2epmk9NE3rSeX/fzs0TZN/gbcgmqb9BHyvlOpTdSgQyLJiSKLhvgN8lFJtq/5MDUS+XNEsWlk7gNuJpmllSqnpwJdUfhskVtO0o1YOSzTMQOBp4LBSKr3q2Kuapm21XkhC3HVeAv5Z9Y/Z08CzVo5HNICmaQeVUp8BqVR+4zwN2cKoWci2RUIIIYQQViDTkUIIIYQQViBJmBBCCCGEFUgSJoQQQghhBZKECSGEEEJYgSRhQgghhBBWIEmYEOKOopQqV0ql1/jVZG9rV0r1VEodaar6hBB3N3lPmBDiTnNV0zRXawchhBA3IiNhQoi7glIqVyn1tlIqqerXI1XHf6+U+koplVn134eqjndRSm1WSmVU/aretsVWKbVKKXVUKZWolLK3WqOEEC2aJGFCiDuN/a+mI8NrnLuiaZo38A9gadWxfwDrNE0zAv8EllcdXw7s1jTNROXeh9W7Z/QG3tc0zQXIB0Y3a2uEEHcseWO+EOKOopQq0jTNoY7jucBQTdNOV23y/pOmaR2VUheBrpqmlVYdP6dpWielVB7QQ9O0X2rU0RP4t6Zpvas+/xm4R9O0v/wGTRNC3GFkJEwIcTfRLPxsqUxdfqnxczmytlYI0UiShAkh7ibhNf57oOrn/cC4qp8nAvuqfv4KmAqglLJVSt33WwUphLg7yL/ghBB3GnulVHqNz9s1Tat+TUUbpdRBKv8BOr7q2AwgVin1CpAHPFt1PApYqZT6f1SOeE0FzjV38EKIu4esCRNC3BWq1oR5app20dqxCCEEyHSkEEIIIYRVyEiYEEIIIYQVyEiYEEIIIYQVSBImhBBCCGEFkoQJIYQQQliBJGFCCCGEEFYgSZgQQgghhBX8fx4pulbRwTZVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 7]\n",
    "plt.plot(train_epoch_loss_g, label='Training loss')\n",
    "plt.plot(val_epoch_loss_g, label='Validation loss')\n",
    "plt.title('Epoch loss generator')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_epoch_loss_d, label='Training loss')\n",
    "plt.plot(val_epoch_loss_d, label='Validation loss')\n",
    "plt.title('Epoch loss discriminator')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_epoch_acc_d, label='Training accuracy', linewidth=5)\n",
    "plt.plot(val_epoch_acc_d, label='Validation accuracy', linewidth=5)\n",
    "plt.plot(train_epoch_acc_d_real, '--', label='Training real image accuracy')\n",
    "plt.plot(train_epoch_acc_d_fake, '--', label='Training fake image accuracy')\n",
    "plt.plot(val_epoch_acc_d_real, '-.', label='Validation real image accuracy')\n",
    "plt.plot(val_epoch_acc_d_fake, '-.', label='Validation fake image accuracy')\n",
    "plt.title('Epoch discriminator accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) We can test the model with 100 test data which will be saved as images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_i in range(100):\n",
    "    test_first_imgs, test_last_imgs = next(test_batch_generator)\n",
    "    test_fake_last_imgs = modelObj.generator.predict(test_first_imgs) \n",
    "\n",
    "    test_img_name = output_log_dir + \"/gen_img_test_\" + str(batch_i) + \".png\"\n",
    "    merged_img = np.vstack((test_first_imgs[0],test_last_imgs[0],test_fake_last_imgs[0]))\n",
    "    imageio.imwrite(test_img_name, img_as_ubyte(merged_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1)\n",
    "Update the network architecture given in  **build_generator**  and  **build_discriminator**  of the class GANModel. Please note that the current image resolution is set to 32x32 (i.e. IMAGE_WIDTH and IMAGE_HEIGHT values) in the file configGAN.py. \n",
    "This way initial experiements can run faster. Once you implement the inital version of the network, please set the resolution values back to 128x128. Experimental results should be provided for this high resolution images.  \n",
    "\n",
    "**Hint:** As a generator model, you can use the segmentation model implemented in lab03. Do not forget to adapt the input and output shapes of the generator model in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2) \n",
    "Use different **optimization** (e.g. ADAM, SGD, etc) and **regularization** (e.g. data augmentation, dropout) methods to increase the network accuracy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
